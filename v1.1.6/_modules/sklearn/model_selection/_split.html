
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sklearn.model_selection._split &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=8fec244e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/sklearn/model_selection/_split';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = '/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'v1.1.6';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="canonical" href="https://www.bayesflow.org/_modules/sklearn/model_selection/_split.html" />
    <link rel="icon" href="../../../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/bayesflow_hor.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <img src="../../../_static/bayesflow_hor_dark.png" class="logo__image only-dark pst-js-only" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../index.html">
    BayesFlow
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../api/bayesflow.html">
    Public API: bayesflow package
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../installation.html">
    Full Installation Instructions
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../about.html">
    About us
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../index.html">
    BayesFlow
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../api/bayesflow.html">
    Public API: bayesflow package
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../installation.html">
    Full Installation Instructions
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../about.html">
    About us
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">sklearn.model_selection._split</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for sklearn.model_selection._split</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The :mod:`sklearn.model_selection._split` module includes classes and</span>
<span class="sd">functions to split the data based on a preset strategy.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Authors: The scikit-learn developers</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numbers</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections.abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">Iterable</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">inspect</span><span class="w"> </span><span class="kn">import</span> <span class="n">signature</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">itertools</span><span class="w"> </span><span class="kn">import</span> <span class="n">chain</span><span class="p">,</span> <span class="n">combinations</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">ceil</span><span class="p">,</span> <span class="n">floor</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.special</span><span class="w"> </span><span class="kn">import</span> <span class="n">comb</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">..utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_safe_indexing</span><span class="p">,</span>
    <span class="n">check_random_state</span><span class="p">,</span>
    <span class="n">indexable</span><span class="p">,</span>
    <span class="n">metadata_routing</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils._array_api</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_convert_to_numpy</span><span class="p">,</span>
    <span class="n">ensure_common_namespace_device</span><span class="p">,</span>
    <span class="n">get_namespace</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils._param_validation</span><span class="w"> </span><span class="kn">import</span> <span class="n">Interval</span><span class="p">,</span> <span class="n">RealNotInt</span><span class="p">,</span> <span class="n">validate_params</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.extmath</span><span class="w"> </span><span class="kn">import</span> <span class="n">_approximate_mode</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.metadata_routing</span><span class="w"> </span><span class="kn">import</span> <span class="n">_MetadataRequester</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.multiclass</span><span class="w"> </span><span class="kn">import</span> <span class="n">type_of_target</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.validation</span><span class="w"> </span><span class="kn">import</span> <span class="n">_num_samples</span><span class="p">,</span> <span class="n">check_array</span><span class="p">,</span> <span class="n">column_or_1d</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;BaseCrossValidator&quot;</span><span class="p">,</span>
    <span class="s2">&quot;KFold&quot;</span><span class="p">,</span>
    <span class="s2">&quot;GroupKFold&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LeaveOneGroupOut&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LeaveOneOut&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LeavePGroupsOut&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LeavePOut&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RepeatedStratifiedKFold&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RepeatedKFold&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ShuffleSplit&quot;</span><span class="p">,</span>
    <span class="s2">&quot;GroupShuffleSplit&quot;</span><span class="p">,</span>
    <span class="s2">&quot;StratifiedKFold&quot;</span><span class="p">,</span>
    <span class="s2">&quot;StratifiedGroupKFold&quot;</span><span class="p">,</span>
    <span class="s2">&quot;StratifiedShuffleSplit&quot;</span><span class="p">,</span>
    <span class="s2">&quot;PredefinedSplit&quot;</span><span class="p">,</span>
    <span class="s2">&quot;train_test_split&quot;</span><span class="p">,</span>
    <span class="s2">&quot;check_cv&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_UnsupportedGroupCVMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin for splitters that do not support Groups.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The groups parameter is ignored by </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="ne">UserWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">GroupsConsumerMixin</span><span class="p">(</span><span class="n">_MetadataRequester</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Mixin to ``groups`` by default.</span>

<span class="sd">    This Mixin makes the object to request ``groups`` by default as ``True``.</span>

<span class="sd">    .. versionadded:: 1.3</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">__metadata_request__split</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>


<span class="k">class</span><span class="w"> </span><span class="nc">BaseCrossValidator</span><span class="p">(</span><span class="n">_MetadataRequester</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for all cross-validators.</span>

<span class="sd">    Implementations must define `_iter_test_masks` or `_iter_test_indices`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># This indicates that by default CV splitters don&#39;t have a &quot;groups&quot; kwarg,</span>
    <span class="c1"># unless indicated by inheriting from ``GroupsConsumerMixin``.</span>
    <span class="c1"># This also prevents ``set_split_request`` to be generated for splitters</span>
    <span class="c1"># which don&#39;t support ``groups``.</span>
    <span class="n">__metadata_request__split</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="n">metadata_routing</span><span class="o">.</span><span class="n">UNUSED</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_test_masks</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
            <span class="n">train_index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">test_index</span><span class="p">)]</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
            <span class="k">yield</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span>

    <span class="c1"># Since subclasses must implement either _iter_test_masks or</span>
    <span class="c1"># _iter_test_indices, neither can be abstract.</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generates boolean masks corresponding to test sets.</span>

<span class="sd">        By default, delegates to _iter_test_indices(X, y, groups)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_test_indices</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
            <span class="n">test_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="n">test_mask</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">yield</span> <span class="n">test_mask</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generates integer indices corresponding to test sets.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_build_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">LeaveOneOut</span><span class="p">(</span><span class="n">_UnsupportedGroupCVMixin</span><span class="p">,</span> <span class="n">BaseCrossValidator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Leave-One-Out cross-validator.</span>

<span class="sd">    Provides train/test indices to split data in train/test sets. Each</span>
<span class="sd">    sample is used once as a test set (singleton) while the remaining</span>
<span class="sd">    samples form the training set.</span>

<span class="sd">    Note: ``LeaveOneOut()`` is equivalent to ``KFold(n_splits=n)`` and</span>
<span class="sd">    ``LeavePOut(p=1)`` where ``n`` is the number of samples.</span>

<span class="sd">    Due to the high number of test sets (which is the same as the</span>
<span class="sd">    number of samples) this cross-validation method can be very costly.</span>
<span class="sd">    For large datasets one should favor :class:`KFold`, :class:`ShuffleSplit`</span>
<span class="sd">    or :class:`StratifiedKFold`.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;leave_one_out&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import LeaveOneOut</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2])</span>
<span class="sd">    &gt;&gt;&gt; loo = LeaveOneOut()</span>
<span class="sd">    &gt;&gt;&gt; loo.get_n_splits(X)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(loo)</span>
<span class="sd">    LeaveOneOut()</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(loo.split(X)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[1]</span>
<span class="sd">      Test:  index=[0]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0]</span>
<span class="sd">      Test:  index=[1]</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    LeaveOneGroupOut : For splitting the data according to explicit,</span>
<span class="sd">        domain-specific stratification of the dataset.</span>
<span class="sd">    GroupKFold : K-fold iterator variant with non-overlapping groups.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot perform LeaveOneOut with n_samples=</span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;X&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">LeavePOut</span><span class="p">(</span><span class="n">_UnsupportedGroupCVMixin</span><span class="p">,</span> <span class="n">BaseCrossValidator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Leave-P-Out cross-validator.</span>

<span class="sd">    Provides train/test indices to split data in train/test sets. This results</span>
<span class="sd">    in testing on all distinct samples of size p, while the remaining n - p</span>
<span class="sd">    samples form the training set in each iteration.</span>

<span class="sd">    Note: ``LeavePOut(p)`` is NOT equivalent to</span>
<span class="sd">    ``KFold(n_splits=n_samples // p)`` which creates non-overlapping test sets.</span>

<span class="sd">    Due to the high number of iterations which grows combinatorically with the</span>
<span class="sd">    number of samples this cross-validation method can be very costly. For</span>
<span class="sd">    large datasets one should favor :class:`KFold`, :class:`StratifiedKFold`</span>
<span class="sd">    or :class:`ShuffleSplit`.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;leave_p_out&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : int</span>
<span class="sd">        Size of the test sets. Must be strictly less than the number of</span>
<span class="sd">        samples.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import LeavePOut</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; lpo = LeavePOut(2)</span>
<span class="sd">    &gt;&gt;&gt; lpo.get_n_splits(X)</span>
<span class="sd">    6</span>
<span class="sd">    &gt;&gt;&gt; print(lpo)</span>
<span class="sd">    LeavePOut(p=2)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(lpo.split(X)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[2 3]</span>
<span class="sd">      Test:  index=[0 1]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[1 3]</span>
<span class="sd">      Test:  index=[0 2]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[1 2]</span>
<span class="sd">      Test:  index=[0 3]</span>
<span class="sd">    Fold 3:</span>
<span class="sd">      Train: index=[0 3]</span>
<span class="sd">      Test:  index=[1 2]</span>
<span class="sd">    Fold 4:</span>
<span class="sd">      Train: index=[0 2]</span>
<span class="sd">      Test:  index=[1 3]</span>
<span class="sd">    Fold 5:</span>
<span class="sd">      Train: index=[0 1]</span>
<span class="sd">      Test:  index=[2 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;p=</span><span class="si">{}</span><span class="s2"> must be strictly less than the number of samples=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">n_samples</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">combination</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">combination</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;X&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">comb</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">exact</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_BaseKFold</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for K-Fold cross-validators and TimeSeriesSplit.&quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The number of folds must be of Integral type. &quot;</span>
                <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> of type </span><span class="si">%s</span><span class="s2"> was passed.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">n_splits</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_splits</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_splits</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;k-fold cross-validation requires at least one&quot;</span>
                <span class="s2">&quot; train/test split by setting n_splits=2 or more,&quot;</span>
                <span class="s2">&quot; got n_splits=</span><span class="si">{0}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_splits</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shuffle</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;shuffle must be True or False; got </span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">shuffle</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">shuffle</span> <span class="ow">and</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># None is the default</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="s2">&quot;Setting a random_state has no effect since shuffle is &quot;</span>
                    <span class="s2">&quot;False. You should leave &quot;</span>
                    <span class="s2">&quot;random_state to its default (None), or set shuffle=True.&quot;</span>
                <span class="p">),</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">=</span> <span class="n">n_splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">&gt;</span> <span class="n">n_samples</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="s2">&quot;Cannot have number of splits n_splits=</span><span class="si">{0}</span><span class="s2"> greater&quot;</span>
                    <span class="s2">&quot; than the number of samples: n_samples=</span><span class="si">{1}</span><span class="s2">.&quot;</span>
                <span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span>


<div class="viewcode-block" id="KFold">
<a class="viewcode-back" href="../../../api/bayesflow.computational_utilities.html#bayesflow.computational_utilities.KFold">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">KFold</span><span class="p">(</span><span class="n">_UnsupportedGroupCVMixin</span><span class="p">,</span> <span class="n">_BaseKFold</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;K-Fold cross-validator.</span>

<span class="sd">    Provides train/test indices to split data in train/test sets. Split</span>
<span class="sd">    dataset into k consecutive folds (without shuffling by default).</span>

<span class="sd">    Each fold is then used once as a validation while the k - 1 remaining</span>
<span class="sd">    folds form the training set.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;k_fold&gt;`.</span>

<span class="sd">    For visualisation of cross-validation behaviour and</span>
<span class="sd">    comparison between common scikit-learn split methods</span>
<span class="sd">    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``n_splits`` default value changed from 3 to 5.</span>

<span class="sd">    shuffle : bool, default=False</span>
<span class="sd">        Whether to shuffle the data before splitting into batches.</span>
<span class="sd">        Note that the samples within each split will not be shuffled.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        When `shuffle` is True, `random_state` affects the ordering of the</span>
<span class="sd">        indices, which controls the randomness of each fold. Otherwise, this</span>
<span class="sd">        parameter has no effect.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import KFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; kf = KFold(n_splits=2)</span>
<span class="sd">    &gt;&gt;&gt; kf.get_n_splits(X)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(kf)</span>
<span class="sd">    KFold(n_splits=2, random_state=None, shuffle=False)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(kf.split(X)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[2 3]</span>
<span class="sd">      Test:  index=[0 1]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0 1]</span>
<span class="sd">      Test:  index=[2 3]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The first ``n_samples % n_splits`` folds have size</span>
<span class="sd">    ``n_samples // n_splits + 1``, other folds have size</span>
<span class="sd">    ``n_samples // n_splits``, where ``n_samples`` is the number of samples.</span>

<span class="sd">    Randomized CV splitters may return different results for each call of</span>
<span class="sd">    split. You can make the results identical by setting `random_state`</span>
<span class="sd">    to an integer.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    StratifiedKFold : Takes class information into account to avoid building</span>
<span class="sd">        folds with imbalanced class distributions (for binary or multiclass</span>
<span class="sd">        classification tasks).</span>

<span class="sd">    GroupKFold : K-fold iterator variant with non-overlapping groups.</span>

<span class="sd">    RepeatedKFold : Repeats K-Fold n times.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
            <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

        <span class="n">n_splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span>
        <span class="n">fold_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="n">n_splits</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">fold_sizes</span><span class="p">[:</span> <span class="n">n_samples</span> <span class="o">%</span> <span class="n">n_splits</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">current</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">fold_size</span> <span class="ow">in</span> <span class="n">fold_sizes</span><span class="p">:</span>
            <span class="n">start</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">current</span><span class="p">,</span> <span class="n">current</span> <span class="o">+</span> <span class="n">fold_size</span>
            <span class="k">yield</span> <span class="n">indices</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">]</span>
            <span class="n">current</span> <span class="o">=</span> <span class="n">stop</span></div>



<span class="k">class</span><span class="w"> </span><span class="nc">GroupKFold</span><span class="p">(</span><span class="n">GroupsConsumerMixin</span><span class="p">,</span> <span class="n">_BaseKFold</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;K-fold iterator variant with non-overlapping groups.</span>

<span class="sd">    Each group will appear exactly once in the test set across all folds (the</span>
<span class="sd">    number of distinct groups has to be at least equal to the number of folds).</span>

<span class="sd">    The folds are approximately balanced in the sense that the number of</span>
<span class="sd">    samples is approximately the same in each test fold when `shuffle` is True.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;group_k_fold&gt;`.</span>

<span class="sd">    For visualisation of cross-validation behaviour and</span>
<span class="sd">    comparison between common scikit-learn split methods</span>
<span class="sd">    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``n_splits`` default value changed from 3 to 5.</span>

<span class="sd">    shuffle : bool, default=False</span>
<span class="sd">        Whether to shuffle the groups before splitting into batches.</span>
<span class="sd">        Note that the samples within each split will not be shuffled.</span>

<span class="sd">        .. versionadded:: 1.6</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        When `shuffle` is True, `random_state` affects the ordering of the</span>
<span class="sd">        indices, which controls the randomness of each fold. Otherwise, this</span>
<span class="sd">        parameter has no effect.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">        .. versionadded:: 1.6</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Groups appear in an arbitrary order throughout the folds.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import GroupKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5, 6])</span>
<span class="sd">    &gt;&gt;&gt; groups = np.array([0, 0, 2, 2, 3, 3])</span>
<span class="sd">    &gt;&gt;&gt; group_kfold = GroupKFold(n_splits=2)</span>
<span class="sd">    &gt;&gt;&gt; group_kfold.get_n_splits(X, y, groups)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(group_kfold)</span>
<span class="sd">    GroupKFold(n_splits=2, random_state=None, shuffle=False)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(group_kfold.split(X, y, groups)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}, group={groups[train_index]}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}, group={groups[test_index]}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[2 3], group=[2 2]</span>
<span class="sd">      Test:  index=[0 1 4 5], group=[0 0 3 3]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0 1 4 5], group=[0 0 3 3]</span>
<span class="sd">      Test:  index=[2 3], group=[2 2]</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    LeaveOneGroupOut : For splitting the data according to explicit</span>
<span class="sd">        domain-specific stratification of the dataset.</span>

<span class="sd">    StratifiedKFold : Takes class information into account to avoid building</span>
<span class="sd">        folds with imbalanced class proportions (for binary or multiclass</span>
<span class="sd">        classification tasks).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;groups&quot;</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">unique_groups</span><span class="p">,</span> <span class="n">group_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">n_groups</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">&gt;</span> <span class="n">n_groups</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot have number of splits n_splits=</span><span class="si">%d</span><span class="s2"> greater&quot;</span>
                <span class="s2">&quot; than the number of groups: </span><span class="si">%d</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">n_groups</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
            <span class="c1"># Split and shuffle unique groups across n_splits</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">unique_groups</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">)</span>
            <span class="n">split_groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">test_group_ids</span> <span class="ow">in</span> <span class="n">split_groups</span><span class="p">:</span>
                <span class="n">test_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">test_group_ids</span><span class="p">)</span>
                <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">test_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Weight groups by their number of occurrences</span>
            <span class="n">n_samples_per_group</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">group_idx</span><span class="p">)</span>

            <span class="c1"># Distribute the most frequent groups first</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">n_samples_per_group</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">n_samples_per_group</span> <span class="o">=</span> <span class="n">n_samples_per_group</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

            <span class="c1"># Total weight of each fold</span>
            <span class="n">n_samples_per_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span>

            <span class="c1"># Mapping from group index to fold index</span>
            <span class="n">group_to_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">))</span>

            <span class="c1"># Distribute samples by adding the largest weight to the lightest fold</span>
            <span class="k">for</span> <span class="n">group_index</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_samples_per_group</span><span class="p">):</span>
                <span class="n">lightest_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">n_samples_per_fold</span><span class="p">)</span>
                <span class="n">n_samples_per_fold</span><span class="p">[</span><span class="n">lightest_fold</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weight</span>
                <span class="n">group_to_fold</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">group_index</span><span class="p">]]</span> <span class="o">=</span> <span class="n">lightest_fold</span>

            <span class="n">indices</span> <span class="o">=</span> <span class="n">group_to_fold</span><span class="p">[</span><span class="n">group_idx</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">indices</span> <span class="o">==</span> <span class="n">f</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">StratifiedKFold</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Stratified K-Fold cross-validator.</span>

<span class="sd">    Provides train/test indices to split data in train/test sets.</span>

<span class="sd">    This cross-validation object is a variation of KFold that returns</span>
<span class="sd">    stratified folds. The folds are made by preserving the percentage of</span>
<span class="sd">    samples for each class.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;stratified_k_fold&gt;`.</span>

<span class="sd">    For visualisation of cross-validation behaviour and</span>
<span class="sd">    comparison between common scikit-learn split methods</span>
<span class="sd">    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``n_splits`` default value changed from 3 to 5.</span>

<span class="sd">    shuffle : bool, default=False</span>
<span class="sd">        Whether to shuffle each class&#39;s samples before splitting into batches.</span>
<span class="sd">        Note that the samples within each split will not be shuffled.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        When `shuffle` is True, `random_state` affects the ordering of the</span>
<span class="sd">        indices, which controls the randomness of each fold for each class.</span>
<span class="sd">        Otherwise, leave `random_state` as `None`.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import StratifiedKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; skf = StratifiedKFold(n_splits=2)</span>
<span class="sd">    &gt;&gt;&gt; skf.get_n_splits(X, y)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(skf)</span>
<span class="sd">    StratifiedKFold(n_splits=2, random_state=None, shuffle=False)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(skf.split(X, y)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[1 3]</span>
<span class="sd">      Test:  index=[0 2]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0 2]</span>
<span class="sd">      Test:  index=[1 3]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The implementation is designed to:</span>

<span class="sd">    * Generate test sets such that all contain the same distribution of</span>
<span class="sd">      classes, or as close as possible.</span>
<span class="sd">    * Be invariant to class label: relabelling ``y = [&quot;Happy&quot;, &quot;Sad&quot;]`` to</span>
<span class="sd">      ``y = [1, 0]`` should not change the indices generated.</span>
<span class="sd">    * Preserve order dependencies in the dataset ordering, when</span>
<span class="sd">      ``shuffle=False``: all samples from class k in some test set were</span>
<span class="sd">      contiguous in y, or separated in y by samples from classes other than k.</span>
<span class="sd">    * Generate test sets where the smallest and largest differ by at most one</span>
<span class="sd">      sample.</span>

<span class="sd">    .. versionchanged:: 0.22</span>
<span class="sd">        The previous implementation did not follow the last constraint.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    RepeatedStratifiedKFold : Repeats Stratified K-Fold n times.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_make_test_folds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="c1"># XXX: as of now, cross-validation splitters only operate in NumPy-land</span>
        <span class="c1"># without attempting to leverage array API namespace features. However</span>
        <span class="c1"># they might be fed by array API inputs, e.g. in CV-enabled estimators so</span>
        <span class="c1"># we need the following explicit conversion:</span>
        <span class="n">xp</span><span class="p">,</span> <span class="n">is_array_api</span> <span class="o">=</span> <span class="n">get_namespace</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_array_api</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">_convert_to_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">xp</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">type_of_target_y</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">allowed_target_types</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">type_of_target_y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed_target_types</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Supported target types are: </span><span class="si">{}</span><span class="s2">. Got </span><span class="si">{!r}</span><span class="s2"> instead.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">allowed_target_types</span><span class="p">,</span> <span class="n">type_of_target_y</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">y_idx</span><span class="p">,</span> <span class="n">y_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># y_inv encodes y according to lexicographic order. We invert y_idx to</span>
        <span class="c1"># map the classes so that they are encoded by order of appearance:</span>
        <span class="c1"># 0 represents the first label appearing in y, 1 the second, etc.</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">class_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_idx</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">y_encoded</span> <span class="o">=</span> <span class="n">class_perm</span><span class="p">[</span><span class="n">y_inv</span><span class="p">]</span>

        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_idx</span><span class="p">)</span>
        <span class="n">y_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_encoded</span><span class="p">)</span>
        <span class="n">min_groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_counts</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">&gt;</span> <span class="n">y_counts</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;n_splits=</span><span class="si">%d</span><span class="s2"> cannot be greater than the&quot;</span>
                <span class="s2">&quot; number of members in each class.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">&gt;</span> <span class="n">min_groups</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The least populated class in y has only </span><span class="si">%d</span><span class="s2">&quot;</span>
                <span class="s2">&quot; members, which is less than n_splits=</span><span class="si">%d</span><span class="s2">.&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="n">min_groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">),</span>
                <span class="ne">UserWarning</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Determine the optimal number of samples from each class in each fold,</span>
        <span class="c1"># using round robin over the sorted y. (This can be done direct from</span>
        <span class="c1"># counts, but that code is unreadable.)</span>
        <span class="n">y_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">y_encoded</span><span class="p">)</span>
        <span class="n">allocation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_order</span><span class="p">[</span><span class="n">i</span> <span class="p">::</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">],</span> <span class="n">minlength</span><span class="o">=</span><span class="n">n_classes</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># To maintain the data order dependencies as best as possible within</span>
        <span class="c1"># the stratification constraint, we assign samples from each class in</span>
        <span class="c1"># blocks (and then mess that up when shuffle=True).</span>
        <span class="n">test_folds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;i&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
            <span class="c1"># since the kth column of allocation stores the number of samples</span>
            <span class="c1"># of class k in each test set, this generates blocks of fold</span>
            <span class="c1"># indices corresponding to the allocation for class k.</span>
            <span class="n">folds_for_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">allocation</span><span class="p">[:,</span> <span class="n">k</span><span class="p">])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
                <span class="n">rng</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">folds_for_class</span><span class="p">)</span>
            <span class="n">test_folds</span><span class="p">[</span><span class="n">y_encoded</span> <span class="o">==</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">folds_for_class</span>
        <span class="k">return</span> <span class="n">test_folds</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">test_folds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_test_folds</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">test_folds</span> <span class="o">==</span> <span class="n">i</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">            Note that providing ``y`` is sufficient to generate the splits and</span>
<span class="sd">            hence ``np.zeros(n_samples)`` may be used as a placeholder for</span>
<span class="sd">            ``X`` instead of actual training data.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            The target variable for supervised learning problems.</span>
<span class="sd">            Stratification is done based on the y labels.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Randomized CV splitters may return different results for each call of</span>
<span class="sd">        split. You can make the results identical by setting `random_state`</span>
<span class="sd">        to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The groups parameter is ignored by </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="ne">UserWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">StratifiedGroupKFold</span><span class="p">(</span><span class="n">GroupsConsumerMixin</span><span class="p">,</span> <span class="n">_BaseKFold</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Stratified K-Fold iterator variant with non-overlapping groups.</span>

<span class="sd">    This cross-validation object is a variation of StratifiedKFold attempts to</span>
<span class="sd">    return stratified folds with non-overlapping groups. The folds are made by</span>
<span class="sd">    preserving the percentage of samples for each class.</span>

<span class="sd">    Each group will appear exactly once in the test set across all folds (the</span>
<span class="sd">    number of distinct groups has to be at least equal to the number of folds).</span>

<span class="sd">    The difference between :class:`GroupKFold`</span>
<span class="sd">    and `StratifiedGroupKFold` is that</span>
<span class="sd">    the former attempts to create balanced folds such that the number of</span>
<span class="sd">    distinct groups is approximately the same in each fold, whereas</span>
<span class="sd">    `StratifiedGroupKFold` attempts to create folds which preserve the</span>
<span class="sd">    percentage of samples for each class as much as possible given the</span>
<span class="sd">    constraint of non-overlapping groups between splits.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;stratified_group_k_fold&gt;`.</span>

<span class="sd">    For visualisation of cross-validation behaviour and</span>
<span class="sd">    comparison between common scikit-learn split methods</span>
<span class="sd">    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">    shuffle : bool, default=False</span>
<span class="sd">        Whether to shuffle each class&#39;s samples before splitting into batches.</span>
<span class="sd">        Note that the samples within each split will not be shuffled.</span>
<span class="sd">        This implementation can only shuffle groups that have approximately the</span>
<span class="sd">        same y distribution, no global shuffle will be performed.</span>

<span class="sd">    random_state : int or RandomState instance, default=None</span>
<span class="sd">        When `shuffle` is True, `random_state` affects the ordering of the</span>
<span class="sd">        indices, which controls the randomness of each fold for each class.</span>
<span class="sd">        Otherwise, leave `random_state` as `None`.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import StratifiedGroupKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.ones((17, 2))</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])</span>
<span class="sd">    &gt;&gt;&gt; groups = np.array([1, 1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 7, 8, 8])</span>
<span class="sd">    &gt;&gt;&gt; sgkf = StratifiedGroupKFold(n_splits=3)</span>
<span class="sd">    &gt;&gt;&gt; sgkf.get_n_splits(X, y)</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; print(sgkf)</span>
<span class="sd">    StratifiedGroupKFold(n_splits=3, random_state=None, shuffle=False)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(sgkf.split(X, y, groups)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;         group={groups[train_index]}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;         group={groups[test_index]}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[ 0  1  2  3  7  8  9 10 11 15 16]</span>
<span class="sd">             group=[1 1 2 2 4 5 5 5 5 8 8]</span>
<span class="sd">      Test:  index=[ 4  5  6 12 13 14]</span>
<span class="sd">             group=[3 3 3 6 6 7]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[ 4  5  6  7  8  9 10 11 12 13 14]</span>
<span class="sd">             group=[3 3 3 4 5 5 5 5 6 6 7]</span>
<span class="sd">      Test:  index=[ 0  1  2  3 15 16]</span>
<span class="sd">             group=[1 1 2 2 8 8]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[ 0  1  2  3  4  5  6 12 13 14 15 16]</span>
<span class="sd">             group=[1 1 2 2 3 3 3 6 6 7 8 8]</span>
<span class="sd">      Test:  index=[ 7  8  9 10 11]</span>
<span class="sd">             group=[4 5 5 5 5]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The implementation is designed to:</span>

<span class="sd">    * Mimic the behavior of StratifiedKFold as much as possible for trivial</span>
<span class="sd">      groups (e.g. when each group contains only one sample).</span>
<span class="sd">    * Be invariant to class label: relabelling ``y = [&quot;Happy&quot;, &quot;Sad&quot;]`` to</span>
<span class="sd">      ``y = [1, 0]`` should not change the indices generated.</span>
<span class="sd">    * Stratify based on samples as much as possible while keeping</span>
<span class="sd">      non-overlapping groups constraint. That means that in some cases when</span>
<span class="sd">      there is a small number of groups containing a large number of samples</span>
<span class="sd">      the stratification will not be possible and the behavior will be close</span>
<span class="sd">      to GroupKFold.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    StratifiedKFold: Takes class information into account to build folds which</span>
<span class="sd">        retain class distributions (for binary or multiclass classification</span>
<span class="sd">        tasks).</span>

<span class="sd">    GroupKFold: K-fold iterator variant with non-overlapping groups.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
        <span class="c1"># Implementation is based on this kaggle kernel:</span>
        <span class="c1"># https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation</span>
        <span class="c1"># and is a subject to Apache 2.0 License. You may obtain a copy of the</span>
        <span class="c1"># License at http://www.apache.org/licenses/LICENSE-2.0</span>
        <span class="c1"># Changelist:</span>
        <span class="c1"># - Refactored function to a class following scikit-learn KFold</span>
        <span class="c1">#   interface.</span>
        <span class="c1"># - Added heuristic for assigning group to the least populated fold in</span>
        <span class="c1">#   cases when all other criteria are equal</span>
        <span class="c1"># - Swtch from using python ``Counter`` to ``np.unique`` to get class</span>
        <span class="c1">#   distribution</span>
        <span class="c1"># - Added scikit-learn checks for input: checking that target is binary</span>
        <span class="c1">#   or multiclass, checking passed random state, checking that number</span>
        <span class="c1">#   of splits is less than number of members in each class, checking</span>
        <span class="c1">#   that least populated class has more members than there are splits.</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">type_of_target_y</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">allowed_target_types</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">type_of_target_y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed_target_types</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Supported target types are: </span><span class="si">{}</span><span class="s2">. Got </span><span class="si">{!r}</span><span class="s2"> instead.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">allowed_target_types</span><span class="p">,</span> <span class="n">type_of_target_y</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">y_inv</span><span class="p">,</span> <span class="n">y_cnt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">&gt;</span> <span class="n">y_cnt</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;n_splits=</span><span class="si">%d</span><span class="s2"> cannot be greater than the&quot;</span>
                <span class="s2">&quot; number of members in each class.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">n_smallest_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_cnt</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">&gt;</span> <span class="n">n_smallest_class</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The least populated class in y has only </span><span class="si">%d</span><span class="s2">&quot;</span>
                <span class="s2">&quot; members, which is less than n_splits=</span><span class="si">%d</span><span class="s2">.&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="n">n_smallest_class</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">),</span>
                <span class="ne">UserWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_cnt</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">groups_inv</span><span class="p">,</span> <span class="n">groups_cnt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
            <span class="n">groups</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="n">y_counts_per_group</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">groups_cnt</span><span class="p">),</span> <span class="n">n_classes</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">class_idx</span><span class="p">,</span> <span class="n">group_idx</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">y_inv</span><span class="p">,</span> <span class="n">groups_inv</span><span class="p">):</span>
            <span class="n">y_counts_per_group</span><span class="p">[</span><span class="n">group_idx</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">y_counts_per_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>
        <span class="n">groups_per_fold</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">set</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
            <span class="n">rng</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">y_counts_per_group</span><span class="p">)</span>

        <span class="c1"># Stable sort to keep shuffled order for groups with the same</span>
        <span class="c1"># class distribution variance</span>
        <span class="n">sorted_groups_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span>
            <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y_counts_per_group</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;mergesort&quot;</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">group_idx</span> <span class="ow">in</span> <span class="n">sorted_groups_idx</span><span class="p">:</span>
            <span class="n">group_y_counts</span> <span class="o">=</span> <span class="n">y_counts_per_group</span><span class="p">[</span><span class="n">group_idx</span><span class="p">]</span>
            <span class="n">best_fold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_best_fold</span><span class="p">(</span>
                <span class="n">y_counts_per_fold</span><span class="o">=</span><span class="n">y_counts_per_fold</span><span class="p">,</span>
                <span class="n">y_cnt</span><span class="o">=</span><span class="n">y_cnt</span><span class="p">,</span>
                <span class="n">group_y_counts</span><span class="o">=</span><span class="n">group_y_counts</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">y_counts_per_fold</span><span class="p">[</span><span class="n">best_fold</span><span class="p">]</span> <span class="o">+=</span> <span class="n">group_y_counts</span>
            <span class="n">groups_per_fold</span><span class="p">[</span><span class="n">best_fold</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">group_idx</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">):</span>
            <span class="n">test_indices</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">idx</span>
                <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">group_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">groups_inv</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">group_idx</span> <span class="ow">in</span> <span class="n">groups_per_fold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="p">]</span>
            <span class="k">yield</span> <span class="n">test_indices</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_find_best_fold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_counts_per_fold</span><span class="p">,</span> <span class="n">y_cnt</span><span class="p">,</span> <span class="n">group_y_counts</span><span class="p">):</span>
        <span class="n">best_fold</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">min_eval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">min_samples_in_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">):</span>
            <span class="n">y_counts_per_fold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">group_y_counts</span>
            <span class="c1"># Summarise the distribution over classes in each proposed fold</span>
            <span class="n">std_per_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y_counts_per_fold</span> <span class="o">/</span> <span class="n">y_cnt</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">y_counts_per_fold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">group_y_counts</span>
            <span class="n">fold_eval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">std_per_class</span><span class="p">)</span>
            <span class="n">samples_in_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_counts_per_fold</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">is_current_fold_better</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">fold_eval</span> <span class="o">&lt;</span> <span class="n">min_eval</span>
                <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">fold_eval</span><span class="p">,</span> <span class="n">min_eval</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">samples_in_fold</span> <span class="o">&lt;</span> <span class="n">min_samples_in_fold</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">is_current_fold_better</span><span class="p">:</span>
                <span class="n">min_eval</span> <span class="o">=</span> <span class="n">fold_eval</span>
                <span class="n">min_samples_in_fold</span> <span class="o">=</span> <span class="n">samples_in_fold</span>
                <span class="n">best_fold</span> <span class="o">=</span> <span class="n">i</span>
        <span class="k">return</span> <span class="n">best_fold</span>


<span class="k">class</span><span class="w"> </span><span class="nc">TimeSeriesSplit</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Time Series cross-validator.</span>

<span class="sd">    Provides train/test indices to split time series data samples</span>
<span class="sd">    that are observed at fixed time intervals, in train/test sets.</span>
<span class="sd">    In each split, test indices must be higher than before, and thus shuffling</span>
<span class="sd">    in cross validator is inappropriate.</span>

<span class="sd">    This cross-validation object is a variation of :class:`KFold`.</span>
<span class="sd">    In the kth split, it returns first k folds as train set and the</span>
<span class="sd">    (k+1)th fold as test set.</span>

<span class="sd">    Note that unlike standard cross-validation methods, successive</span>
<span class="sd">    training sets are supersets of those that come before them.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;time_series_split&gt;`.</span>

<span class="sd">    For visualisation of cross-validation behaviour and</span>
<span class="sd">    comparison between common scikit-learn split methods</span>
<span class="sd">    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of splits. Must be at least 2.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``n_splits`` default value changed from 3 to 5.</span>

<span class="sd">    max_train_size : int, default=None</span>
<span class="sd">        Maximum size for a single training set.</span>

<span class="sd">    test_size : int, default=None</span>
<span class="sd">        Used to limit the size of the test set. Defaults to</span>
<span class="sd">        ``n_samples // (n_splits + 1)``, which is the maximum allowed value</span>
<span class="sd">        with ``gap=0``.</span>

<span class="sd">        .. versionadded:: 0.24</span>

<span class="sd">    gap : int, default=0</span>
<span class="sd">        Number of samples to exclude from the end of each train set before</span>
<span class="sd">        the test set.</span>

<span class="sd">        .. versionadded:: 0.24</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5, 6])</span>
<span class="sd">    &gt;&gt;&gt; tscv = TimeSeriesSplit()</span>
<span class="sd">    &gt;&gt;&gt; print(tscv)</span>
<span class="sd">    TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(tscv.split(X)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[0]</span>
<span class="sd">      Test:  index=[1]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0 1]</span>
<span class="sd">      Test:  index=[2]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[0 1 2]</span>
<span class="sd">      Test:  index=[3]</span>
<span class="sd">    Fold 3:</span>
<span class="sd">      Train: index=[0 1 2 3]</span>
<span class="sd">      Test:  index=[4]</span>
<span class="sd">    Fold 4:</span>
<span class="sd">      Train: index=[0 1 2 3 4]</span>
<span class="sd">      Test:  index=[5]</span>
<span class="sd">    &gt;&gt;&gt; # Fix test_size to 2 with 12 samples</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.randn(12, 2)</span>
<span class="sd">    &gt;&gt;&gt; y = np.random.randint(0, 2, 12)</span>
<span class="sd">    &gt;&gt;&gt; tscv = TimeSeriesSplit(n_splits=3, test_size=2)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(tscv.split(X)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[0 1 2 3 4 5]</span>
<span class="sd">      Test:  index=[6 7]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0 1 2 3 4 5 6 7]</span>
<span class="sd">      Test:  index=[8 9]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[0 1 2 3 4 5 6 7 8 9]</span>
<span class="sd">      Test:  index=[10 11]</span>
<span class="sd">    &gt;&gt;&gt; # Add in a 2 period gap</span>
<span class="sd">    &gt;&gt;&gt; tscv = TimeSeriesSplit(n_splits=3, test_size=2, gap=2)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(tscv.split(X)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[0 1 2 3]</span>
<span class="sd">      Test:  index=[6 7]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0 1 2 3 4 5]</span>
<span class="sd">      Test:  index=[8 9]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[0 1 2 3 4 5 6 7]</span>
<span class="sd">      Test:  index=[10 11]</span>

<span class="sd">    For a more extended example see</span>
<span class="sd">    :ref:`sphx_glr_auto_examples_applications_plot_cyclical_feature_engineering.py`.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The training set has size ``i * n_samples // (n_splits + 1)</span>
<span class="sd">    + n_samples % (n_splits + 1)`` in the ``i`` th split,</span>
<span class="sd">    with a test set of size ``n_samples//(n_splits + 1)`` by default,</span>
<span class="sd">    where ``n_samples`` is the number of samples. Note that this</span>
<span class="sd">    formula is only valid when ``test_size`` and ``max_train_size`` are</span>
<span class="sd">    left to their default values.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">max_train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gap</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_train_size</span> <span class="o">=</span> <span class="n">max_train_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="o">=</span> <span class="n">test_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gap</span> <span class="o">=</span> <span class="n">gap</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The groups parameter is ignored by </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="ne">UserWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">X</span><span class="p">,)</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span>
        <span class="n">n_folds</span> <span class="o">=</span> <span class="n">n_splits</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">gap</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gap</span>
        <span class="n">test_size</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="n">n_folds</span>
        <span class="p">)</span>

        <span class="c1"># Make sure we have enough samples for the given split parameters</span>
        <span class="k">if</span> <span class="n">n_folds</span> <span class="o">&gt;</span> <span class="n">n_samples</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot have number of folds=</span><span class="si">{</span><span class="n">n_folds</span><span class="si">}</span><span class="s2"> greater&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; than the number of samples=</span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">gap</span> <span class="o">-</span> <span class="p">(</span><span class="n">test_size</span> <span class="o">*</span> <span class="n">n_splits</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Too many splits=</span><span class="si">{</span><span class="n">n_splits</span><span class="si">}</span><span class="s2"> for number of samples&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2"> with test_size=</span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2"> and gap=</span><span class="si">{</span><span class="n">gap</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
        <span class="n">test_starts</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_splits</span> <span class="o">*</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">test_size</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">test_start</span> <span class="ow">in</span> <span class="n">test_starts</span><span class="p">:</span>
            <span class="n">train_end</span> <span class="o">=</span> <span class="n">test_start</span> <span class="o">-</span> <span class="n">gap</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_train_size</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_train_size</span> <span class="o">&lt;</span> <span class="n">train_end</span><span class="p">:</span>
                <span class="k">yield</span> <span class="p">(</span>
                    <span class="n">indices</span><span class="p">[</span><span class="n">train_end</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_train_size</span> <span class="p">:</span> <span class="n">train_end</span><span class="p">],</span>
                    <span class="n">indices</span><span class="p">[</span><span class="n">test_start</span> <span class="p">:</span> <span class="n">test_start</span> <span class="o">+</span> <span class="n">test_size</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="p">(</span>
                    <span class="n">indices</span><span class="p">[:</span><span class="n">train_end</span><span class="p">],</span>
                    <span class="n">indices</span><span class="p">[</span><span class="n">test_start</span> <span class="p">:</span> <span class="n">test_start</span> <span class="o">+</span> <span class="n">test_size</span><span class="p">],</span>
                <span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">LeaveOneGroupOut</span><span class="p">(</span><span class="n">GroupsConsumerMixin</span><span class="p">,</span> <span class="n">BaseCrossValidator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Leave One Group Out cross-validator.</span>

<span class="sd">    Provides train/test indices to split data such that each training set is</span>
<span class="sd">    comprised of all samples except ones belonging to one specific group.</span>
<span class="sd">    Arbitrary domain specific group information is provided as an array of integers</span>
<span class="sd">    that encodes the group of each sample.</span>

<span class="sd">    For instance the groups could be the year of collection of the samples</span>
<span class="sd">    and thus allow for cross-validation against time-based splits.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;leave_one_group_out&gt;`.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Splits are ordered according to the index of the group left out. The first</span>
<span class="sd">    split has testing set consisting of the group whose index in `groups` is</span>
<span class="sd">    lowest, and so on.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import LeaveOneGroupOut</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 1, 2])</span>
<span class="sd">    &gt;&gt;&gt; groups = np.array([1, 1, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; logo = LeaveOneGroupOut()</span>
<span class="sd">    &gt;&gt;&gt; logo.get_n_splits(X, y, groups)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; logo.get_n_splits(groups=groups)  # &#39;groups&#39; is always required</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(logo)</span>
<span class="sd">    LeaveOneGroupOut()</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(logo.split(X, y, groups)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}, group={groups[train_index]}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}, group={groups[test_index]}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[2 3], group=[2 2]</span>
<span class="sd">      Test:  index=[0 1], group=[1 1]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0 1], group=[1 1]</span>
<span class="sd">      Test:  index=[2 3], group=[2 2]</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    GroupKFold: K-fold iterator variant with non-overlapping groups.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="c1"># We make a copy of groups to avoid side-effects during iteration</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span>
            <span class="n">groups</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;groups&quot;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>
        <span class="n">unique_groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The groups parameter contains fewer than 2 unique groups &quot;</span>
                <span class="s2">&quot;(</span><span class="si">%s</span><span class="s2">). LeaveOneGroupOut expects at least 2.&quot;</span> <span class="o">%</span> <span class="n">unique_groups</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">unique_groups</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">groups</span> <span class="o">==</span> <span class="n">i</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set. This &#39;groups&#39; parameter must always be specified to</span>
<span class="sd">            calculate the number of splits, though the other parameters can be</span>
<span class="sd">            omitted.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;groups&quot;</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">LeavePGroupsOut</span><span class="p">(</span><span class="n">GroupsConsumerMixin</span><span class="p">,</span> <span class="n">BaseCrossValidator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Leave P Group(s) Out cross-validator.</span>

<span class="sd">    Provides train/test indices to split data according to a third-party</span>
<span class="sd">    provided group. This group information can be used to encode arbitrary</span>
<span class="sd">    domain specific stratifications of the samples as integers.</span>

<span class="sd">    For instance the groups could be the year of collection of the samples</span>
<span class="sd">    and thus allow for cross-validation against time-based splits.</span>

<span class="sd">    The difference between LeavePGroupsOut and LeaveOneGroupOut is that</span>
<span class="sd">    the former builds the test sets with all the samples assigned to</span>
<span class="sd">    ``p`` different values of the groups while the latter uses samples</span>
<span class="sd">    all assigned the same groups.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;leave_p_groups_out&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_groups : int</span>
<span class="sd">        Number of groups (``p``) to leave out in the test split.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import LeavePGroupsOut</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 1])</span>
<span class="sd">    &gt;&gt;&gt; groups = np.array([1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; lpgo = LeavePGroupsOut(n_groups=2)</span>
<span class="sd">    &gt;&gt;&gt; lpgo.get_n_splits(X, y, groups)</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; lpgo.get_n_splits(groups=groups)  # &#39;groups&#39; is always required</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; print(lpgo)</span>
<span class="sd">    LeavePGroupsOut(n_groups=2)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(lpgo.split(X, y, groups)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}, group={groups[train_index]}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}, group={groups[test_index]}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[2], group=[3]</span>
<span class="sd">      Test:  index=[0 1], group=[1 2]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[1], group=[2]</span>
<span class="sd">      Test:  index=[0 2], group=[1 3]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[0], group=[1]</span>
<span class="sd">      Test:  index=[1 2], group=[2 3]</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    GroupKFold : K-fold iterator variant with non-overlapping groups.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_groups</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">=</span> <span class="n">n_groups</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span>
            <span class="n">groups</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;groups&quot;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>
        <span class="n">unique_groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The groups parameter contains fewer than (or equal to) &quot;</span>
                <span class="s2">&quot;n_groups (</span><span class="si">%d</span><span class="s2">) numbers of unique groups (</span><span class="si">%s</span><span class="s2">). LeavePGroupsOut &quot;</span>
                <span class="s2">&quot;expects that at least n_groups + 1 (</span><span class="si">%d</span><span class="s2">) unique groups be &quot;</span>
                <span class="s2">&quot;present&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">,</span> <span class="n">unique_groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">combi</span> <span class="o">=</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">indices</span> <span class="ow">in</span> <span class="n">combi</span><span class="p">:</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">unique_groups</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices</span><span class="p">)]:</span>
                <span class="n">test_index</span><span class="p">[</span><span class="n">groups</span> <span class="o">==</span> <span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">yield</span> <span class="n">test_index</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set. This &#39;groups&#39; parameter must always be specified to</span>
<span class="sd">            calculate the number of splits, though the other parameters can be</span>
<span class="sd">            omitted.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;groups&quot;</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">comb</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">,</span> <span class="n">exact</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_RepeatedSplits</span><span class="p">(</span><span class="n">_MetadataRequester</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Repeated splits for an arbitrary randomized CV splitter.</span>

<span class="sd">    Repeats splits for cross-validators n times with different randomization</span>
<span class="sd">    in each repetition.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cv : callable</span>
<span class="sd">        Cross-validator class.</span>

<span class="sd">    n_repeats : int, default=10</span>
<span class="sd">        Number of times cross-validator needs to be repeated.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Passes `random_state` to the arbitrary repeating cross validator.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    **cvargs : additional params</span>
<span class="sd">        Constructor parameters for cv. Must not contain random_state</span>
<span class="sd">        and shuffle.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># This indicates that by default CV splitters don&#39;t have a &quot;groups&quot; kwarg,</span>
    <span class="c1"># unless indicated by inheriting from ``GroupsConsumerMixin``.</span>
    <span class="c1"># This also prevents ``set_split_request`` to be generated for splitters</span>
    <span class="c1"># which don&#39;t support ``groups``.</span>
    <span class="n">__metadata_request__split</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="n">metadata_routing</span><span class="o">.</span><span class="n">UNUSED</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cv</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">cvargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Number of repetitions must be of Integral type.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_repeats</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Number of repetitions must be greater than 0.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">key</span> <span class="ow">in</span> <span class="n">cvargs</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;random_state&quot;</span><span class="p">,</span> <span class="s2">&quot;shuffle&quot;</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cvargs must not contain random_state or shuffle.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span> <span class="o">=</span> <span class="n">n_repeats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cvargs</span> <span class="o">=</span> <span class="n">cvargs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generates indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_repeats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">):</span>
            <span class="n">cv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">cvargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>
<span class="sd">            ``np.zeros(n_samples)`` may be used as a placeholder.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>
<span class="sd">            ``np.zeros(n_samples)`` may be used as a placeholder.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">cvargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_build_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">RepeatedKFold</span><span class="p">(</span><span class="n">_UnsupportedGroupCVMixin</span><span class="p">,</span> <span class="n">_RepeatedSplits</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Repeated K-Fold cross validator.</span>

<span class="sd">    Repeats K-Fold n times with different randomization in each repetition.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;repeated_k_fold&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">    n_repeats : int, default=10</span>
<span class="sd">        Number of times cross-validator needs to be repeated.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the randomness of each repeated cross-validation instance.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import RepeatedKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)</span>
<span class="sd">    &gt;&gt;&gt; rkf.get_n_splits(X, y)</span>
<span class="sd">    4</span>
<span class="sd">    &gt;&gt;&gt; print(rkf)</span>
<span class="sd">    RepeatedKFold(n_repeats=2, n_splits=2, random_state=2652124)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(rkf.split(X)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    ...</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[0 1]</span>
<span class="sd">      Test:  index=[2 3]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[2 3]</span>
<span class="sd">      Test:  index=[0 1]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[1 2]</span>
<span class="sd">      Test:  index=[0 3]</span>
<span class="sd">    Fold 3:</span>
<span class="sd">      Train: index=[0 3]</span>
<span class="sd">      Test:  index=[1 2]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Randomized CV splitters may return different results for each call of</span>
<span class="sd">    split. You can make the results identical by setting `random_state`</span>
<span class="sd">    to an integer.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    RepeatedStratifiedKFold : Repeats Stratified K-Fold n times.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">KFold</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span>
        <span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">_UnsupportedGroupCVMixin</span><span class="p">,</span> <span class="n">_RepeatedSplits</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Repeated Stratified K-Fold cross validator.</span>

<span class="sd">    Repeats Stratified K-Fold n times with different randomization in each</span>
<span class="sd">    repetition.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;repeated_k_fold&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">    n_repeats : int, default=10</span>
<span class="sd">        Number of times cross-validator needs to be repeated.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the generation of the random states for each repetition.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import RepeatedStratifiedKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,</span>
<span class="sd">    ...     random_state=36851234)</span>
<span class="sd">    &gt;&gt;&gt; rskf.get_n_splits(X, y)</span>
<span class="sd">    4</span>
<span class="sd">    &gt;&gt;&gt; print(rskf)</span>
<span class="sd">    RepeatedStratifiedKFold(n_repeats=2, n_splits=2, random_state=36851234)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(rskf.split(X, y)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    ...</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[1 2]</span>
<span class="sd">      Test:  index=[0 3]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0 3]</span>
<span class="sd">      Test:  index=[1 2]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[1 3]</span>
<span class="sd">      Test:  index=[0 2]</span>
<span class="sd">    Fold 3:</span>
<span class="sd">      Train: index=[0 2]</span>
<span class="sd">      Test:  index=[1 3]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Randomized CV splitters may return different results for each call of</span>
<span class="sd">    split. You can make the results identical by setting `random_state`</span>
<span class="sd">    to an integer.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    RepeatedKFold : Repeats K-Fold n times.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">StratifiedKFold</span><span class="p">,</span>
            <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">            Note that providing ``y`` is sufficient to generate the splits and</span>
<span class="sd">            hence ``np.zeros(n_samples)`` may be used as a placeholder for</span>
<span class="sd">            ``X`` instead of actual training data.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            The target variable for supervised learning problems.</span>
<span class="sd">            Stratification is done based on the y labels.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Randomized CV splitters may return different results for each call of</span>
<span class="sd">        split. You can make the results identical by setting `random_state`</span>
<span class="sd">        to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">BaseShuffleSplit</span><span class="p">(</span><span class="n">_MetadataRequester</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for *ShuffleSplit.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=10</span>
<span class="sd">        Number of re-shuffling &amp; splitting iterations.</span>

<span class="sd">    test_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the proportion</span>
<span class="sd">        of the dataset to include in the test split. If int, represents the</span>
<span class="sd">        absolute number of test samples. If None, the value is set to the</span>
<span class="sd">        complement of the train size. If ``train_size`` is also None, it will</span>
<span class="sd">        be set to 0.1.</span>

<span class="sd">    train_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the randomness of the training and testing indices produced.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># This indicates that by default CV splitters don&#39;t have a &quot;groups&quot; kwarg,</span>
    <span class="c1"># unless indicated by inheriting from ``GroupsConsumerMixin``.</span>
    <span class="c1"># This also prevents ``set_split_request`` to be generated for splitters</span>
    <span class="c1"># which don&#39;t support ``groups``.</span>
    <span class="n">__metadata_request__split</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="n">metadata_routing</span><span class="o">.</span><span class="n">UNUSED</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">=</span> <span class="n">n_splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="o">=</span> <span class="n">test_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span> <span class="o">=</span> <span class="n">train_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Randomized CV splitters may return different results for each call of</span>
<span class="sd">        split. You can make the results identical by setting `random_state`</span>
<span class="sd">        to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_indices</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate (train, test) indices&quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span> <span class="o">=</span> <span class="n">_validate_shuffle_split</span><span class="p">(</span>
            <span class="n">n_samples</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">default_test_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">):</span>
            <span class="c1"># random partition</span>
            <span class="n">permutation</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
            <span class="n">ind_test</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
            <span class="n">ind_train</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">n_test</span> <span class="p">:</span> <span class="p">(</span><span class="n">n_test</span> <span class="o">+</span> <span class="n">n_train</span><span class="p">)]</span>
            <span class="k">yield</span> <span class="n">ind_train</span><span class="p">,</span> <span class="n">ind_test</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_build_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">ShuffleSplit</span><span class="p">(</span><span class="n">_UnsupportedGroupCVMixin</span><span class="p">,</span> <span class="n">BaseShuffleSplit</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Random permutation cross-validator.</span>

<span class="sd">    Yields indices to split data into training and test sets.</span>

<span class="sd">    Note: contrary to other cross-validation strategies, random splits</span>
<span class="sd">    do not guarantee that test sets across all folds will be mutually exclusive,</span>
<span class="sd">    and might include overlapping samples. However, this is still very likely for</span>
<span class="sd">    sizeable datasets.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;ShuffleSplit&gt;`.</span>

<span class="sd">    For visualisation of cross-validation behaviour and</span>
<span class="sd">    comparison between common scikit-learn split methods</span>
<span class="sd">    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=10</span>
<span class="sd">        Number of re-shuffling &amp; splitting iterations.</span>

<span class="sd">    test_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the proportion</span>
<span class="sd">        of the dataset to include in the test split. If int, represents the</span>
<span class="sd">        absolute number of test samples. If None, the value is set to the</span>
<span class="sd">        complement of the train size. If ``train_size`` is also None, it will</span>
<span class="sd">        be set to 0.1.</span>

<span class="sd">    train_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the randomness of the training and testing indices produced.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import ShuffleSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 1, 2, 1, 2])</span>
<span class="sd">    &gt;&gt;&gt; rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; rs.get_n_splits(X)</span>
<span class="sd">    5</span>
<span class="sd">    &gt;&gt;&gt; print(rs)</span>
<span class="sd">    ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(rs.split(X)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[1 3 0 4]</span>
<span class="sd">      Test:  index=[5 2]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[4 0 2 5]</span>
<span class="sd">      Test:  index=[1 3]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[1 2 4 0]</span>
<span class="sd">      Test:  index=[3 5]</span>
<span class="sd">    Fold 3:</span>
<span class="sd">      Train: index=[3 4 1 0]</span>
<span class="sd">      Test:  index=[5 2]</span>
<span class="sd">    Fold 4:</span>
<span class="sd">      Train: index=[3 5 1 0]</span>
<span class="sd">      Test:  index=[2 4]</span>
<span class="sd">    &gt;&gt;&gt; # Specify train and test size</span>
<span class="sd">    &gt;&gt;&gt; rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,</span>
<span class="sd">    ...                   random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(rs.split(X)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[1 3 0]</span>
<span class="sd">      Test:  index=[5 2]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[4 0 2]</span>
<span class="sd">      Test:  index=[1 3]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[1 2 4]</span>
<span class="sd">      Test:  index=[3 5]</span>
<span class="sd">    Fold 3:</span>
<span class="sd">      Train: index=[3 4 1]</span>
<span class="sd">      Test:  index=[5 2]</span>
<span class="sd">    Fold 4:</span>
<span class="sd">      Train: index=[3 5 1]</span>
<span class="sd">      Test:  index=[2 4]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
            <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
            <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span> <span class="o">=</span> <span class="mf">0.1</span>


<span class="k">class</span><span class="w"> </span><span class="nc">GroupShuffleSplit</span><span class="p">(</span><span class="n">GroupsConsumerMixin</span><span class="p">,</span> <span class="n">BaseShuffleSplit</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Shuffle-Group(s)-Out cross-validation iterator.</span>

<span class="sd">    Provides randomized train/test indices to split data according to a</span>
<span class="sd">    third-party provided group. This group information can be used to encode</span>
<span class="sd">    arbitrary domain specific stratifications of the samples as integers.</span>

<span class="sd">    For instance the groups could be the year of collection of the samples</span>
<span class="sd">    and thus allow for cross-validation against time-based splits.</span>

<span class="sd">    The difference between :class:`LeavePGroupsOut` and ``GroupShuffleSplit`` is that</span>
<span class="sd">    the former generates splits using all subsets of size ``p`` unique groups,</span>
<span class="sd">    whereas ``GroupShuffleSplit`` generates a user-determined number of random</span>
<span class="sd">    test splits, each with a user-determined fraction of unique groups.</span>

<span class="sd">    For example, a less computationally intensive alternative to</span>
<span class="sd">    ``LeavePGroupsOut(p=10)`` would be</span>
<span class="sd">    ``GroupShuffleSplit(test_size=10, n_splits=100)``.</span>

<span class="sd">    Contrary to other cross-validation strategies, the random splits</span>
<span class="sd">    do not guarantee that test sets across all folds will be mutually exclusive,</span>
<span class="sd">    and might include overlapping samples. However, this is still very likely for</span>
<span class="sd">    sizeable datasets.</span>

<span class="sd">    Note: The parameters ``test_size`` and ``train_size`` refer to groups, and</span>
<span class="sd">    not to samples as in :class:`ShuffleSplit`.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;group_shuffle_split&gt;`.</span>

<span class="sd">    For visualisation of cross-validation behaviour and</span>
<span class="sd">    comparison between common scikit-learn split methods</span>
<span class="sd">    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of re-shuffling &amp; splitting iterations.</span>

<span class="sd">    test_size : float, int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the proportion</span>
<span class="sd">        of groups to include in the test split (rounded up). If int,</span>
<span class="sd">        represents the absolute number of test groups. If None, the value is</span>
<span class="sd">        set to the complement of the train size. If ``train_size`` is also None,</span>
<span class="sd">        it will be set to 0.2.</span>

<span class="sd">    train_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the groups to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train groups. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the randomness of the training and testing indices produced.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import GroupShuffleSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.ones(shape=(8, 2))</span>
<span class="sd">    &gt;&gt;&gt; y = np.ones(shape=(8, 1))</span>
<span class="sd">    &gt;&gt;&gt; groups = np.array([1, 1, 2, 2, 2, 3, 3, 3])</span>
<span class="sd">    &gt;&gt;&gt; print(groups.shape)</span>
<span class="sd">    (8,)</span>
<span class="sd">    &gt;&gt;&gt; gss = GroupShuffleSplit(n_splits=2, train_size=.7, random_state=42)</span>
<span class="sd">    &gt;&gt;&gt; gss.get_n_splits()</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(gss)</span>
<span class="sd">    GroupShuffleSplit(n_splits=2, random_state=42, test_size=None, train_size=0.7)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(gss.split(X, y, groups)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}, group={groups[train_index]}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}, group={groups[test_index]}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[2 3 4 5 6 7], group=[2 2 2 3 3 3]</span>
<span class="sd">      Test:  index=[0 1], group=[1 1]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0 1 5 6 7], group=[1 1 3 3 3]</span>
<span class="sd">      Test:  index=[2 3 4], group=[2 2 2]</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ShuffleSplit : Shuffles samples to create independent test/train sets.</span>

<span class="sd">    LeavePGroupsOut : Train set leaves out all possible subsets of `p` groups.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
            <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
            <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span> <span class="o">=</span> <span class="mf">0.2</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;groups&quot;</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">classes</span><span class="p">,</span> <span class="n">group_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">group_train</span><span class="p">,</span> <span class="n">group_test</span> <span class="ow">in</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_iter_indices</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">classes</span><span class="p">):</span>
            <span class="c1"># these are the indices of classes in the partition</span>
            <span class="c1"># invert them into data indices</span>

            <span class="n">train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">group_indices</span><span class="p">,</span> <span class="n">group_train</span><span class="p">))</span>
            <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">group_indices</span><span class="p">,</span> <span class="n">group_test</span><span class="p">))</span>

            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Randomized CV splitters may return different results for each call of</span>
<span class="sd">        split. You can make the results identical by setting `random_state`</span>
<span class="sd">        to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">BaseShuffleSplit</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Stratified ShuffleSplit cross-validator.</span>

<span class="sd">    Provides train/test indices to split data in train/test sets.</span>

<span class="sd">    This cross-validation object is a merge of :class:`StratifiedKFold` and</span>
<span class="sd">    :class:`ShuffleSplit`, which returns stratified randomized folds. The folds</span>
<span class="sd">    are made by preserving the percentage of samples for each class.</span>

<span class="sd">    Note: like the :class:`ShuffleSplit` strategy, stratified random splits</span>
<span class="sd">    do not guarantee that test sets across all folds will be mutually exclusive,</span>
<span class="sd">    and might include overlapping samples. However, this is still very likely for</span>
<span class="sd">    sizeable datasets.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;stratified_shuffle_split&gt;`.</span>

<span class="sd">    For visualisation of cross-validation behaviour and</span>
<span class="sd">    comparison between common scikit-learn split methods</span>
<span class="sd">    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=10</span>
<span class="sd">        Number of re-shuffling &amp; splitting iterations.</span>

<span class="sd">    test_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the proportion</span>
<span class="sd">        of the dataset to include in the test split. If int, represents the</span>
<span class="sd">        absolute number of test samples. If None, the value is set to the</span>
<span class="sd">        complement of the train size. If ``train_size`` is also None, it will</span>
<span class="sd">        be set to 0.1.</span>

<span class="sd">    train_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the randomness of the training and testing indices produced.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import StratifiedShuffleSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 0, 1, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; sss.get_n_splits(X, y)</span>
<span class="sd">    5</span>
<span class="sd">    &gt;&gt;&gt; print(sss)</span>
<span class="sd">    StratifiedShuffleSplit(n_splits=5, random_state=0, ...)</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(sss.split(X, y)):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[5 2 3]</span>
<span class="sd">      Test:  index=[4 1 0]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[5 1 4]</span>
<span class="sd">      Test:  index=[0 2 3]</span>
<span class="sd">    Fold 2:</span>
<span class="sd">      Train: index=[5 0 2]</span>
<span class="sd">      Test:  index=[4 3 1]</span>
<span class="sd">    Fold 3:</span>
<span class="sd">      Train: index=[4 1 0]</span>
<span class="sd">      Test:  index=[2 3 5]</span>
<span class="sd">    Fold 4:</span>
<span class="sd">      Train: index=[0 5 1]</span>
<span class="sd">      Test:  index=[3 4 2]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
            <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
            <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span> <span class="o">=</span> <span class="n">_validate_shuffle_split</span><span class="p">(</span>
            <span class="n">n_samples</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">default_test_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Convert to numpy as not all operations are supported by the Array API.</span>
        <span class="c1"># `y` is probably never a very large array, which means that converting it</span>
        <span class="c1"># should be cheap</span>
        <span class="n">xp</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_namespace</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">_convert_to_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">xp</span><span class="o">=</span><span class="n">xp</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># for multi-label y, map each distinct row to a string repr</span>
            <span class="c1"># using join because str(row) uses an ellipsis if len(row) &gt; 1000</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;str&quot;</span><span class="p">))</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">y</span><span class="p">])</span>

        <span class="n">classes</span><span class="p">,</span> <span class="n">y_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">n_classes</span> <span class="o">=</span> <span class="n">classes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">class_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_indices</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">class_counts</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The least populated class in y has only 1&quot;</span>
                <span class="s2">&quot; member, which is too few. The minimum&quot;</span>
                <span class="s2">&quot; number of groups for any class cannot&quot;</span>
                <span class="s2">&quot; be less than 2.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">n_train</span> <span class="o">&lt;</span> <span class="n">n_classes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The train_size = </span><span class="si">%d</span><span class="s2"> should be greater or &quot;</span>
                <span class="s2">&quot;equal to the number of classes = </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">n_test</span> <span class="o">&lt;</span> <span class="n">n_classes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The test_size = </span><span class="si">%d</span><span class="s2"> should be greater or &quot;</span>
                <span class="s2">&quot;equal to the number of classes = </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_test</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># Find the sorted list of instances for each class:</span>
        <span class="c1"># (np.unique above performs a sort, so code is O(n logn) already)</span>
        <span class="n">class_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y_indices</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;mergesort&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">class_counts</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">):</span>
            <span class="c1"># if there are ties in the class-counts, we want</span>
            <span class="c1"># to make sure to break them anew in each iteration</span>
            <span class="n">n_i</span> <span class="o">=</span> <span class="n">_approximate_mode</span><span class="p">(</span><span class="n">class_counts</span><span class="p">,</span> <span class="n">n_train</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>
            <span class="n">class_counts_remaining</span> <span class="o">=</span> <span class="n">class_counts</span> <span class="o">-</span> <span class="n">n_i</span>
            <span class="n">t_i</span> <span class="o">=</span> <span class="n">_approximate_mode</span><span class="p">(</span><span class="n">class_counts_remaining</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>

            <span class="n">train</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">test</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
                <span class="n">permutation</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">class_counts</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">perm_indices_class_i</span> <span class="o">=</span> <span class="n">class_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">permutation</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;clip&quot;</span><span class="p">)</span>

                <span class="n">train</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">perm_indices_class_i</span><span class="p">[:</span> <span class="n">n_i</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
                <span class="n">test</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">perm_indices_class_i</span><span class="p">[</span><span class="n">n_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">:</span> <span class="n">n_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">t_i</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>

            <span class="n">train</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
            <span class="n">test</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where `n_samples` is the number of samples</span>
<span class="sd">            and `n_features` is the number of features.</span>

<span class="sd">            Note that providing ``y`` is sufficient to generate the splits and</span>
<span class="sd">            hence ``np.zeros(n_samples)`` may be used as a placeholder for</span>
<span class="sd">            ``X`` instead of actual training data.</span>

<span class="sd">        y : array-like of shape (n_samples,) or (n_samples, n_labels)</span>
<span class="sd">            The target variable for supervised learning problems.</span>
<span class="sd">            Stratification is done based on the y labels.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Randomized CV splitters may return different results for each call of</span>
<span class="sd">        split. You can make the results identical by setting `random_state`</span>
<span class="sd">        to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The groups parameter is ignored by </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="ne">UserWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_validate_shuffle_split</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">train_size</span><span class="p">,</span> <span class="n">default_test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validation helper to check if the train/test sizes are meaningful w.r.t. the</span>
<span class="sd">    size of the data (n_samples).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">test_size</span> <span class="o">=</span> <span class="n">default_test_size</span>

    <span class="n">test_size_type</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span>
    <span class="n">train_size_type</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span>

    <span class="k">if</span> <span class="p">(</span>
        <span class="n">test_size_type</span> <span class="o">==</span> <span class="s2">&quot;i&quot;</span>
        <span class="ow">and</span> <span class="p">(</span><span class="n">test_size</span> <span class="o">&gt;=</span> <span class="n">n_samples</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">test_size_type</span> <span class="o">==</span> <span class="s2">&quot;f&quot;</span>
        <span class="ow">and</span> <span class="p">(</span><span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;test_size=</span><span class="si">{0}</span><span class="s2"> should be either positive and smaller&quot;</span>
            <span class="s2">&quot; than the number of samples </span><span class="si">{1}</span><span class="s2"> or a float in the &quot;</span>
            <span class="s2">&quot;(0, 1) range&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span>
        <span class="n">train_size_type</span> <span class="o">==</span> <span class="s2">&quot;i&quot;</span>
        <span class="ow">and</span> <span class="p">(</span><span class="n">train_size</span> <span class="o">&gt;=</span> <span class="n">n_samples</span> <span class="ow">or</span> <span class="n">train_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">train_size_type</span> <span class="o">==</span> <span class="s2">&quot;f&quot;</span>
        <span class="ow">and</span> <span class="p">(</span><span class="n">train_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">train_size</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;train_size=</span><span class="si">{0}</span><span class="s2"> should be either positive and smaller&quot;</span>
            <span class="s2">&quot; than the number of samples </span><span class="si">{1}</span><span class="s2"> or a float in the &quot;</span>
            <span class="s2">&quot;(0, 1) range&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">train_size_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid value for train_size: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_size</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">test_size_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid value for test_size: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_size</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">train_size_type</span> <span class="o">==</span> <span class="s2">&quot;f&quot;</span> <span class="ow">and</span> <span class="n">test_size_type</span> <span class="o">==</span> <span class="s2">&quot;f&quot;</span> <span class="ow">and</span> <span class="n">train_size</span> <span class="o">+</span> <span class="n">test_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The sum of test_size and train_size = </span><span class="si">{}</span><span class="s2">, should be in the (0, 1)&quot;</span>
            <span class="s2">&quot; range. Reduce test_size and/or train_size.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_size</span> <span class="o">+</span> <span class="n">test_size</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">test_size_type</span> <span class="o">==</span> <span class="s2">&quot;f&quot;</span><span class="p">:</span>
        <span class="n">n_test</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">test_size</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">test_size_type</span> <span class="o">==</span> <span class="s2">&quot;i&quot;</span><span class="p">:</span>
        <span class="n">n_test</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">train_size_type</span> <span class="o">==</span> <span class="s2">&quot;f&quot;</span><span class="p">:</span>
        <span class="n">n_train</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">train_size</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">train_size_type</span> <span class="o">==</span> <span class="s2">&quot;i&quot;</span><span class="p">:</span>
        <span class="n">n_train</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_train</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_test</span>
    <span class="k">elif</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_test</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_train</span>

    <span class="k">if</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span> <span class="o">&gt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The sum of train_size and test_size = </span><span class="si">%d</span><span class="s2">, &quot;</span>
            <span class="s2">&quot;should be smaller than the number of &quot;</span>
            <span class="s2">&quot;samples </span><span class="si">%d</span><span class="s2">. Reduce test_size and/or &quot;</span>
            <span class="s2">&quot;train_size.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_train</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_test</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_train</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;With n_samples=</span><span class="si">{}</span><span class="s2">, test_size=</span><span class="si">{}</span><span class="s2"> and train_size=</span><span class="si">{}</span><span class="s2">, the &quot;</span>
            <span class="s2">&quot;resulting train set will be empty. Adjust any of the &quot;</span>
            <span class="s2">&quot;aforementioned parameters.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">train_size</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span>


<span class="k">class</span><span class="w"> </span><span class="nc">PredefinedSplit</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Predefined split cross-validator.</span>

<span class="sd">    Provides train/test indices to split data into train/test sets using a</span>
<span class="sd">    predefined scheme specified by the user with the ``test_fold`` parameter.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;predefined_split&gt;`.</span>

<span class="sd">    .. versionadded:: 0.16</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    test_fold : array-like of shape (n_samples,)</span>
<span class="sd">        The entry ``test_fold[i]`` represents the index of the test set that</span>
<span class="sd">        sample ``i`` belongs to. It is possible to exclude sample ``i`` from</span>
<span class="sd">        any test set (i.e. include sample ``i`` in every training set) by</span>
<span class="sd">        setting ``test_fold[i]`` equal to -1.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import PredefinedSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; test_fold = [0, 1, -1, 1]</span>
<span class="sd">    &gt;&gt;&gt; ps = PredefinedSplit(test_fold)</span>
<span class="sd">    &gt;&gt;&gt; ps.get_n_splits()</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(ps)</span>
<span class="sd">    PredefinedSplit(test_fold=array([ 0,  1, -1,  1]))</span>
<span class="sd">    &gt;&gt;&gt; for i, (train_index, test_index) in enumerate(ps.split()):</span>
<span class="sd">    ...     print(f&quot;Fold {i}:&quot;)</span>
<span class="sd">    ...     print(f&quot;  Train: index={train_index}&quot;)</span>
<span class="sd">    ...     print(f&quot;  Test:  index={test_index}&quot;)</span>
<span class="sd">    Fold 0:</span>
<span class="sd">      Train: index=[1 2 3]</span>
<span class="sd">      Test:  index=[0]</span>
<span class="sd">    Fold 1:</span>
<span class="sd">      Train: index=[0 2]</span>
<span class="sd">      Test:  index=[1 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_fold</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_fold</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The groups parameter is ignored by </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="ne">UserWarning</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_split</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_test_masks</span><span class="p">():</span>
            <span class="n">train_index</span> <span class="o">=</span> <span class="n">ind</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">test_index</span><span class="p">)]</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="n">ind</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
            <span class="k">yield</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generates boolean masks corresponding to test sets.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span><span class="p">:</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span> <span class="o">==</span> <span class="n">f</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">test_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="n">test_mask</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">yield</span> <span class="n">test_mask</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_CVIterableWrapper</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrapper class for old style cv objects and iterables.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cv</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>


<span class="k">def</span><span class="w"> </span><span class="nf">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Input checker utility for building a cross-validator.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cv : int, cross-validation generator, iterable or None, default=5</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>
<span class="sd">        - None, to use the default 5-fold cross validation,</span>
<span class="sd">        - integer, to specify the number of folds.</span>
<span class="sd">        - :term:`CV splitter`,</span>
<span class="sd">        - An iterable that generates (train, test) splits as arrays of indices.</span>

<span class="sd">        For integer/None inputs, if classifier is True and ``y`` is either</span>
<span class="sd">        binary or multiclass, :class:`StratifiedKFold` is used. In all other</span>
<span class="sd">        cases, :class:`KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``cv`` default value changed from 3-fold to 5-fold.</span>

<span class="sd">    y : array-like, default=None</span>
<span class="sd">        The target variable for supervised learning problems.</span>

<span class="sd">    classifier : bool, default=False</span>
<span class="sd">        Whether the task is a classification task, in which case</span>
<span class="sd">        stratified KFold will be used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    checked_cv : a cross-validator instance.</span>
<span class="sd">        The return value is a cross-validator which generates the train/test</span>
<span class="sd">        splits via the ``split`` method.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import check_cv</span>
<span class="sd">    &gt;&gt;&gt; check_cv(cv=5, y=None, classifier=False)</span>
<span class="sd">    KFold(...)</span>
<span class="sd">    &gt;&gt;&gt; check_cv(cv=5, y=[1, 1, 0, 0, 0, 0], classifier=True)</span>
<span class="sd">    StratifiedKFold(...)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span> <span class="k">if</span> <span class="n">cv</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">cv</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">classifier</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">type_of_target</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">))</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">KFold</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="s2">&quot;split&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Expected cv as an integer, cross-validation &quot;</span>
                <span class="s2">&quot;object (from sklearn.model_selection) &quot;</span>
                <span class="s2">&quot;or an iterable. Got </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">cv</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">_CVIterableWrapper</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cv</span>  <span class="c1"># New style cv objects are passed without any modification</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;test_size&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">Interval</span><span class="p">(</span><span class="n">RealNotInt</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;neither&quot;</span><span class="p">),</span>
            <span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">),</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;train_size&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">Interval</span><span class="p">(</span><span class="n">RealNotInt</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;neither&quot;</span><span class="p">),</span>
            <span class="n">Interval</span><span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">),</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">],</span>
        <span class="s2">&quot;shuffle&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;stratify&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_test_split</span><span class="p">(</span>
    <span class="o">*</span><span class="n">arrays</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">stratify</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Split arrays or matrices into random train and test subsets.</span>

<span class="sd">    Quick utility that wraps input validation,</span>
<span class="sd">    ``next(ShuffleSplit().split(X, y))``, and application to input data</span>
<span class="sd">    into a single call for splitting (and optionally subsampling) data into a</span>
<span class="sd">    one-liner.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    *arrays : sequence of indexables with same length / shape[0]</span>
<span class="sd">        Allowed inputs are lists, numpy arrays, scipy-sparse</span>
<span class="sd">        matrices or pandas dataframes.</span>

<span class="sd">    test_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the proportion</span>
<span class="sd">        of the dataset to include in the test split. If int, represents the</span>
<span class="sd">        absolute number of test samples. If None, the value is set to the</span>
<span class="sd">        complement of the train size. If ``train_size`` is also None, it will</span>
<span class="sd">        be set to 0.25.</span>

<span class="sd">    train_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the shuffling applied to the data before applying the split.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    shuffle : bool, default=True</span>
<span class="sd">        Whether or not to shuffle the data before splitting. If shuffle=False</span>
<span class="sd">        then stratify must be None.</span>

<span class="sd">    stratify : array-like, default=None</span>
<span class="sd">        If not None, data is split in a stratified fashion, using this as</span>
<span class="sd">        the class labels.</span>
<span class="sd">        Read more in the :ref:`User Guide &lt;stratification&gt;`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    splitting : list, length=2 * len(arrays)</span>
<span class="sd">        List containing train-test split of inputs.</span>

<span class="sd">        .. versionadded:: 0.16</span>
<span class="sd">            If the input is sparse, the output will be a</span>
<span class="sd">            ``scipy.sparse.csr_matrix``. Else, output type is the same as the</span>
<span class="sd">            input type.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import train_test_split</span>
<span class="sd">    &gt;&gt;&gt; X, y = np.arange(10).reshape((5, 2)), range(5)</span>
<span class="sd">    &gt;&gt;&gt; X</span>
<span class="sd">    array([[0, 1],</span>
<span class="sd">           [2, 3],</span>
<span class="sd">           [4, 5],</span>
<span class="sd">           [6, 7],</span>
<span class="sd">           [8, 9]])</span>
<span class="sd">    &gt;&gt;&gt; list(y)</span>
<span class="sd">    [0, 1, 2, 3, 4]</span>

<span class="sd">    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(</span>
<span class="sd">    ...     X, y, test_size=0.33, random_state=42)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; X_train</span>
<span class="sd">    array([[4, 5],</span>
<span class="sd">           [0, 1],</span>
<span class="sd">           [6, 7]])</span>
<span class="sd">    &gt;&gt;&gt; y_train</span>
<span class="sd">    [2, 0, 3]</span>
<span class="sd">    &gt;&gt;&gt; X_test</span>
<span class="sd">    array([[2, 3],</span>
<span class="sd">           [8, 9]])</span>
<span class="sd">    &gt;&gt;&gt; y_test</span>
<span class="sd">    [1, 4]</span>

<span class="sd">    &gt;&gt;&gt; train_test_split(y, shuffle=False)</span>
<span class="sd">    [[0, 1, 2], [3, 4]]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_arrays</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">arrays</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_arrays</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At least one array required as input&quot;</span><span class="p">)</span>

    <span class="n">arrays</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="o">*</span><span class="n">arrays</span><span class="p">)</span>

    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span> <span class="o">=</span> <span class="n">_validate_shuffle_split</span><span class="p">(</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">train_size</span><span class="p">,</span> <span class="n">default_test_size</span><span class="o">=</span><span class="mf">0.25</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">shuffle</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">stratify</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Stratified train/test split is not implemented for shuffle=False&quot;</span>
            <span class="p">)</span>

        <span class="n">train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_train</span><span class="p">)</span>
        <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">stratify</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">CVClass</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">CVClass</span> <span class="o">=</span> <span class="n">ShuffleSplit</span>

        <span class="n">cv</span> <span class="o">=</span> <span class="n">CVClass</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="n">n_test</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

        <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">stratify</span><span class="p">))</span>

    <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">ensure_common_namespace_device</span><span class="p">(</span><span class="n">arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span>
        <span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span>
            <span class="p">(</span><span class="n">_safe_indexing</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">train</span><span class="p">),</span> <span class="n">_safe_indexing</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">arrays</span>
        <span class="p">)</span>
    <span class="p">)</span>


<span class="c1"># Tell nose that train_test_split is not a test.</span>
<span class="c1"># (Needed for external libraries that may use nose.)</span>
<span class="c1"># Use setattr to avoid mypy errors when monkeypatching.</span>
<span class="nb">setattr</span><span class="p">(</span><span class="n">train_test_split</span><span class="p">,</span> <span class="s2">&quot;__test__&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_pprint</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">printer</span><span class="o">=</span><span class="nb">repr</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Pretty print the dictionary &#39;params&#39;</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    params : dict</span>
<span class="sd">        The dictionary to pretty print</span>

<span class="sd">    offset : int, default=0</span>
<span class="sd">        The offset in characters to add at the begin of each line.</span>

<span class="sd">    printer : callable, default=repr</span>
<span class="sd">        The function to convert entries to strings, typically</span>
<span class="sd">        the builtin str or repr</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Do a multi-line justified repr:</span>
    <span class="n">options</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">get_printoptions</span><span class="p">()</span>
    <span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">edgeitems</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">params_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="n">this_line_length</span> <span class="o">=</span> <span class="n">offset</span>
    <span class="n">line_sep</span> <span class="o">=</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">offset</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">())):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="c1"># use str for representing floating point numbers</span>
            <span class="c1"># this way we get consistent representation across</span>
            <span class="c1"># architectures and versions.</span>
            <span class="n">this_repr</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">=</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># use repr of the rest</span>
            <span class="n">this_repr</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">=</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">printer</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">this_repr</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">500</span><span class="p">:</span>
            <span class="n">this_repr</span> <span class="o">=</span> <span class="n">this_repr</span><span class="p">[:</span><span class="mi">300</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;...&quot;</span> <span class="o">+</span> <span class="n">this_repr</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:]</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">this_line_length</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">this_repr</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">75</span> <span class="ow">or</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">this_repr</span><span class="p">:</span>
                <span class="n">params_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line_sep</span><span class="p">)</span>
                <span class="n">this_line_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">line_sep</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">params_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="p">)</span>
                <span class="n">this_line_length</span> <span class="o">+=</span> <span class="mi">2</span>
        <span class="n">params_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">this_repr</span><span class="p">)</span>
        <span class="n">this_line_length</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">this_repr</span><span class="p">)</span>

    <span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="o">**</span><span class="n">options</span><span class="p">)</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">params_list</span><span class="p">)</span>
    <span class="c1"># Strip trailing space to avoid nightmare in doctests</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">lines</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_build_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># XXX This is copied from BaseEstimator&#39;s get_params</span>
    <span class="bp">cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span>
    <span class="n">init</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">,</span> <span class="s2">&quot;deprecated_original&quot;</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
    <span class="c1"># Ignore varargs, kw and default values and pop self</span>
    <span class="n">init_signature</span> <span class="o">=</span> <span class="n">signature</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="c1"># Consider the constructor parameters excluding &#39;self&#39;</span>
    <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="nb">object</span><span class="o">.</span><span class="fm">__init__</span><span class="p">:</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">args</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">p</span><span class="o">.</span><span class="n">name</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">init_signature</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;self&quot;</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">kind</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">VAR_KEYWORD</span>
            <span class="p">]</span>
        <span class="p">)</span>
    <span class="n">class_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">FutureWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;cvargs&quot;</span><span class="p">):</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cvargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="ow">is</span> <span class="ne">FutureWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">return</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">(</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">class_name</span><span class="p">,</span> <span class="n">_pprint</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">class_name</span><span class="p">)))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_yields_constant_splits</span><span class="p">(</span><span class="n">cv</span><span class="p">):</span>
    <span class="c1"># Return True if calling cv.split() always returns the same splits</span>
    <span class="c1"># We assume that if a cv doesn&#39;t have a shuffle parameter, it shuffles by</span>
    <span class="c1"># default (e.g. ShuffleSplit). If it actually doesn&#39;t shuffle (e.g.</span>
    <span class="c1"># LeaveOneOut), then it won&#39;t have a random_state parameter anyway, in</span>
    <span class="c1"># which case it will default to 0, leading to output=True</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="s2">&quot;shuffle&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="s2">&quot;random_state&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">random_state</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">shuffle</span>
</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright 2023-2025, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>