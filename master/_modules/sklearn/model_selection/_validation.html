
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sklearn.model_selection._validation &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=8fec244e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/sklearn/model_selection/_validation';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://www.bayesflow.org/_modules/sklearn/model_selection/_validation.html" />
    <link rel="icon" href="../../../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/bayesflow_hex.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <img src="../../../_static/bayesflow_hex.png" class="logo__image only-dark pst-js-only" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">BayesFlow</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../examples.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Intro_Amortized_Posterior_Estimation.html">1. Quickstart: Amortized Posterior Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/TwoMoons_Bimodal_Posterior.html">2. Two Moons: Tackling Bimodal Posteriors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Model_Misspecification.html">3. Detecting Model Misspecification in Amortized Posterior Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/LCA_Model_Posterior_Estimation.html">4. Principled Amortized Bayesian Workflow for Cognitive Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Linear_ODE_system.html">5. Posterior Estimation for ODEs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Covid19_Initial_Posterior_Estimation.html">6. Posterior Estimation for SIR-like Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Model_Comparison_MPT.html">7. Model Comparison for Cognitive Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Hierarchical_Model_Comparison_MPT.html">8. Hierarchical Model Comparison for Cognitive Models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api/bayesflow.html">Public API: bayesflow package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/bayesflow.benchmarks.html">bayesflow.benchmarks package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.bernoulli_glm.html">bayesflow.benchmarks.bernoulli_glm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.bernoulli_glm_raw.html">bayesflow.benchmarks.bernoulli_glm_raw module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.gaussian_linear.html">bayesflow.benchmarks.gaussian_linear module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.gaussian_linear_uniform.html">bayesflow.benchmarks.gaussian_linear_uniform module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.gaussian_mixture.html">bayesflow.benchmarks.gaussian_mixture module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.inverse_kinematics.html">bayesflow.benchmarks.inverse_kinematics module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.lotka_volterra.html">bayesflow.benchmarks.lotka_volterra module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.sir.html">bayesflow.benchmarks.sir module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.slcp.html">bayesflow.benchmarks.slcp module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.slcp_distractors.html">bayesflow.benchmarks.slcp_distractors module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.two_moons.html">bayesflow.benchmarks.two_moons module</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.amortizers.html">bayesflow.amortizers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.attention.html">bayesflow.attention module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.coupling_networks.html">bayesflow.coupling_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.diagnostics.html">bayesflow.diagnostics module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.inference_networks.html">bayesflow.inference_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.losses.html">bayesflow.losses module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.networks.html">bayesflow.networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.sensitivity.html">bayesflow.sensitivity module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.simulation.html">bayesflow.simulation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.summary_networks.html">bayesflow.summary_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.trainers.html">bayesflow.trainers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.configuration.html">bayesflow.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.default_settings.html">bayesflow.default_settings module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.computational_utilities.html">bayesflow.computational_utilities module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.helper_classes.html">bayesflow.helper_classes module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.helper_functions.html">bayesflow.helper_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.helper_networks.html">bayesflow.helper_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.exceptions.html">bayesflow.exceptions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.mcmc.html">bayesflow.mcmc module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.version.html">bayesflow.version module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.wrappers.html">bayesflow.wrappers module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/bayesflow.experimental.html">bayesflow.experimental package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.experimental.rectifiers.html">bayesflow.experimental.rectifiers module</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Full Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../about.html">About us</a></li>
</ul>

    </div>
</nav></div>
        <div class="sidebar-primary-item">
<div class="rst-versions">
   
  <p class="caption" aria-level="2" role="heading"><span class="caption-text">Tags</span></p>
  <ul>
      <li><a href="/v1.1.6/_modules/sklearn/model_selection/_validation.html" >v1.1.6</a></li>
  </ul>
  
   
  <p class="caption" aria-level="2" role="heading"><span class="caption-text">Branches</span></p>
  <ul>
      <li><a href="/dev/_modules/sklearn/model_selection/_validation.html" >dev</a></li>
      <li><a href="/master/_modules/sklearn/model_selection/_validation.html" class="current">master</a></li>
  </ul>
  
</div>
</div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/bayesflow-org/bayesflow" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/bayesflow-org/bayesflow/issues/new?title=Issue%20on%20page%20%2F_modules/sklearn/model_selection/_validation.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for sklearn.model_selection._validation</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The :mod:`sklearn.model_selection._validation` module includes classes and</span>
<span class="sd">functions to validate the model.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Authors: The scikit-learn developers</span>
<span class="c1"># SPDX-License-Identifier: BSD-3-Clause</span>


<span class="kn">import</span><span class="w"> </span><span class="nn">numbers</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">contextlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">suppress</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numbers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Real</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">traceback</span><span class="w"> </span><span class="kn">import</span> <span class="n">format_exc</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.sparse</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">joblib</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">..base</span><span class="w"> </span><span class="kn">import</span> <span class="n">clone</span><span class="p">,</span> <span class="n">is_classifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="n">FitFailedWarning</span><span class="p">,</span> <span class="n">UnsetMetadataPassedError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">check_scoring</span><span class="p">,</span> <span class="n">get_scorer_names</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..metrics._scorer</span><span class="w"> </span><span class="kn">import</span> <span class="n">_MultimetricScorer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">Bunch</span><span class="p">,</span> <span class="n">_safe_indexing</span><span class="p">,</span> <span class="n">check_random_state</span><span class="p">,</span> <span class="n">indexable</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils._array_api</span><span class="w"> </span><span class="kn">import</span> <span class="n">device</span><span class="p">,</span> <span class="n">get_namespace</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils._param_validation</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">HasMethods</span><span class="p">,</span>
    <span class="n">Integral</span><span class="p">,</span>
    <span class="n">Interval</span><span class="p">,</span>
    <span class="n">StrOptions</span><span class="p">,</span>
    <span class="n">validate_params</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.metadata_routing</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">MetadataRouter</span><span class="p">,</span>
    <span class="n">MethodMapping</span><span class="p">,</span>
    <span class="n">_routing_enabled</span><span class="p">,</span>
    <span class="n">process_routing</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.metaestimators</span><span class="w"> </span><span class="kn">import</span> <span class="n">_safe_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.parallel</span><span class="w"> </span><span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.validation</span><span class="w"> </span><span class="kn">import</span> <span class="n">_check_method_params</span><span class="p">,</span> <span class="n">_num_samples</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._split</span><span class="w"> </span><span class="kn">import</span> <span class="n">check_cv</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;cross_validate&quot;</span><span class="p">,</span>
    <span class="s2">&quot;cross_val_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;cross_val_predict&quot;</span><span class="p">,</span>
    <span class="s2">&quot;permutation_test_score&quot;</span><span class="p">,</span>
    <span class="s2">&quot;learning_curve&quot;</span><span class="p">,</span>
    <span class="s2">&quot;validation_curve&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_params_groups_deprecation</span><span class="p">(</span><span class="n">fit_params</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">version</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A helper function to check deprecations on `groups` and `fit_params`.</span>

<span class="sd">    # TODO(SLEP6): To be removed when set_config(enable_metadata_routing=False) is not</span>
<span class="sd">    # possible.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">fit_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;`params` and `fit_params` cannot both be provided. Pass parameters &quot;</span>
            <span class="s2">&quot;via `params`. `fit_params` is deprecated and will be removed in &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;version </span><span class="si">{</span><span class="n">version</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">fit_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="s2">&quot;`fit_params` is deprecated and will be removed in version </span><span class="si">{version}</span><span class="s2">. &quot;</span>
                <span class="s2">&quot;Pass parameters via `params` instead.&quot;</span>
            <span class="p">),</span>
            <span class="ne">FutureWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">fit_params</span>

    <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">params</span>

    <span class="n">_check_groups_routing_disabled</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">params</span>


<span class="c1"># TODO(SLEP6): To be removed when set_config(enable_metadata_routing=False) is not</span>
<span class="c1"># possible.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_check_groups_routing_disabled</span><span class="p">(</span><span class="n">groups</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_routing_enabled</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;`groups` can only be passed if metadata routing is not enabled via&quot;</span>
            <span class="s2">&quot; `sklearn.set_config(enable_metadata_routing=True)`. When routing is&quot;</span>
            <span class="s2">&quot; enabled, pass `groups` alongside other metadata via the `params` argument&quot;</span>
            <span class="s2">&quot; instead.&quot;</span>
        <span class="p">)</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">HasMethods</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;scoring&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">StrOptions</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">get_scorer_names</span><span class="p">())),</span>
            <span class="nb">callable</span><span class="p">,</span>
            <span class="nb">list</span><span class="p">,</span>
            <span class="nb">tuple</span><span class="p">,</span>
            <span class="nb">dict</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s2">&quot;cv&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;cv_object&quot;</span><span class="p">],</span>
        <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">],</span>
        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pre_dispatch&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
        <span class="s2">&quot;return_train_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;return_estimator&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;return_indices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;error_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;raise&quot;</span><span class="p">}),</span> <span class="n">Real</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># estimator is not validated yet</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">cross_validate</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pre_dispatch</span><span class="o">=</span><span class="s2">&quot;2*n_jobs&quot;</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">error_score</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate metric(s) by cross-validation and also record fit/score times.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;multimetric_cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object implementing &#39;fit&#39;</span>
<span class="sd">        The object to use to fit the data.</span>

<span class="sd">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The data to fit. Can be for example a list, or an array.</span>

<span class="sd">    y : array-like of shape (n_samples,) or (n_samples, n_outputs), default=None</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Group labels for the samples used while splitting the dataset into</span>
<span class="sd">        train/test set. Only used in conjunction with a &quot;Group&quot; :term:`cv`</span>
<span class="sd">        instance (e.g., :class:`GroupKFold`).</span>

<span class="sd">        .. versionchanged:: 1.4</span>
<span class="sd">            ``groups`` can only be passed if metadata routing is not enabled</span>
<span class="sd">            via ``sklearn.set_config(enable_metadata_routing=True)``. When routing</span>
<span class="sd">            is enabled, pass ``groups`` alongside other metadata via the ``params``</span>
<span class="sd">            argument instead. E.g.:</span>
<span class="sd">            ``cross_validate(..., params={&#39;groups&#39;: groups})``.</span>

<span class="sd">    scoring : str, callable, list, tuple, or dict, default=None</span>
<span class="sd">        Strategy to evaluate the performance of the cross-validated model on</span>
<span class="sd">        the test set. If `None`, the</span>
<span class="sd">        :ref:`default evaluation criterion &lt;scoring_api_overview&gt;` of the estimator</span>
<span class="sd">        is used.</span>

<span class="sd">        If `scoring` represents a single score, one can use:</span>

<span class="sd">        - a single string (see :ref:`scoring_parameter`);</span>
<span class="sd">        - a callable (see :ref:`scoring_callable`) that returns a single value.</span>

<span class="sd">        If `scoring` represents multiple scores, one can use:</span>

<span class="sd">        - a list or tuple of unique strings;</span>
<span class="sd">        - a callable returning a dictionary where the keys are the metric</span>
<span class="sd">          names and the values are the metric scores;</span>
<span class="sd">        - a dictionary with metric names as keys and callables a values.</span>

<span class="sd">        See :ref:`multimetric_grid_search` for an example.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - None, to use the default 5-fold cross validation,</span>
<span class="sd">        - int, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">        - :term:`CV splitter`,</span>
<span class="sd">        - An iterable yielding (train, test) splits as arrays of indices.</span>

<span class="sd">        For int/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used. These splitters are instantiated</span>
<span class="sd">        with `shuffle=False` so the splits will be the same across calls.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``cv`` default value if None changed from 3-fold to 5-fold.</span>

<span class="sd">    n_jobs : int, default=None</span>
<span class="sd">        Number of jobs to run in parallel. Training the estimator and computing</span>
<span class="sd">        the score are parallelized over the cross-validation splits.</span>
<span class="sd">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    params : dict, default=None</span>
<span class="sd">        Parameters to pass to the underlying estimator&#39;s ``fit``, the scorer,</span>
<span class="sd">        and the CV splitter.</span>

<span class="sd">        .. versionadded:: 1.4</span>

<span class="sd">    pre_dispatch : int or str, default=&#39;2*n_jobs&#39;</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">        - An int, giving the exact number of total jobs that are spawned</span>
<span class="sd">        - A str, giving an expression as a function of n_jobs, as in &#39;2*n_jobs&#39;</span>

<span class="sd">    return_train_score : bool, default=False</span>
<span class="sd">        Whether to include train scores.</span>
<span class="sd">        Computing training scores is used to get insights on how different</span>
<span class="sd">        parameter settings impact the overfitting/underfitting trade-off.</span>
<span class="sd">        However computing the scores on the training set can be computationally</span>
<span class="sd">        expensive and is not strictly required to select the parameters that</span>
<span class="sd">        yield the best generalization performance.</span>

<span class="sd">        .. versionadded:: 0.19</span>

<span class="sd">        .. versionchanged:: 0.21</span>
<span class="sd">            Default value was changed from ``True`` to ``False``</span>

<span class="sd">    return_estimator : bool, default=False</span>
<span class="sd">        Whether to return the estimators fitted on each split.</span>

<span class="sd">        .. versionadded:: 0.20</span>

<span class="sd">    return_indices : bool, default=False</span>
<span class="sd">        Whether to return the train-test indices selected for each split.</span>

<span class="sd">        .. versionadded:: 1.3</span>

<span class="sd">    error_score : &#39;raise&#39; or numeric, default=np.nan</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised.</span>
<span class="sd">        If a numeric value is given, FitFailedWarning is raised.</span>

<span class="sd">        .. versionadded:: 0.20</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    scores : dict of float arrays of shape (n_splits,)</span>
<span class="sd">        Array of scores of the estimator for each run of the cross validation.</span>

<span class="sd">        A dict of arrays containing the score/time arrays for each scorer is</span>
<span class="sd">        returned. The possible keys for this ``dict`` are:</span>

<span class="sd">        ``test_score``</span>
<span class="sd">            The score array for test scores on each cv split.</span>
<span class="sd">            Suffix ``_score`` in ``test_score`` changes to a specific</span>
<span class="sd">            metric like ``test_r2`` or ``test_auc`` if there are</span>
<span class="sd">            multiple scoring metrics in the scoring parameter.</span>
<span class="sd">        ``train_score``</span>
<span class="sd">            The score array for train scores on each cv split.</span>
<span class="sd">            Suffix ``_score`` in ``train_score`` changes to a specific</span>
<span class="sd">            metric like ``train_r2`` or ``train_auc`` if there are</span>
<span class="sd">            multiple scoring metrics in the scoring parameter.</span>
<span class="sd">            This is available only if ``return_train_score`` parameter</span>
<span class="sd">            is ``True``.</span>
<span class="sd">        ``fit_time``</span>
<span class="sd">            The time for fitting the estimator on the train</span>
<span class="sd">            set for each cv split.</span>
<span class="sd">        ``score_time``</span>
<span class="sd">            The time for scoring the estimator on the test set for each</span>
<span class="sd">            cv split. (Note time for scoring on the train set is not</span>
<span class="sd">            included even if ``return_train_score`` is set to ``True``</span>
<span class="sd">        ``estimator``</span>
<span class="sd">            The estimator objects for each cv split.</span>
<span class="sd">            This is available only if ``return_estimator`` parameter</span>
<span class="sd">            is set to ``True``.</span>
<span class="sd">        ``indices``</span>
<span class="sd">            The train/test positional indices for each cv split. A dictionary</span>
<span class="sd">            is returned where the keys are either `&quot;train&quot;` or `&quot;test&quot;`</span>
<span class="sd">            and the associated values are a list of integer-dtyped NumPy</span>
<span class="sd">            arrays with the indices. Available only if `return_indices=True`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    cross_val_score : Run cross-validation for single metric evaluation.</span>

<span class="sd">    cross_val_predict : Get predictions from each split of cross-validation for</span>
<span class="sd">        diagnostic purposes.</span>

<span class="sd">    sklearn.metrics.make_scorer : Make a scorer from a performance metric or</span>
<span class="sd">        loss function.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import datasets, linear_model</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import cross_validate</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import make_scorer</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.metrics import confusion_matrix</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.svm import LinearSVC</span>
<span class="sd">    &gt;&gt;&gt; diabetes = datasets.load_diabetes()</span>
<span class="sd">    &gt;&gt;&gt; X = diabetes.data[:150]</span>
<span class="sd">    &gt;&gt;&gt; y = diabetes.target[:150]</span>
<span class="sd">    &gt;&gt;&gt; lasso = linear_model.Lasso()</span>

<span class="sd">    Single metric evaluation using ``cross_validate``</span>

<span class="sd">    &gt;&gt;&gt; cv_results = cross_validate(lasso, X, y, cv=3)</span>
<span class="sd">    &gt;&gt;&gt; sorted(cv_results.keys())</span>
<span class="sd">    [&#39;fit_time&#39;, &#39;score_time&#39;, &#39;test_score&#39;]</span>
<span class="sd">    &gt;&gt;&gt; cv_results[&#39;test_score&#39;]</span>
<span class="sd">    array([0.3315057 , 0.08022103, 0.03531816])</span>

<span class="sd">    Multiple metric evaluation using ``cross_validate``</span>
<span class="sd">    (please refer the ``scoring`` parameter doc for more information)</span>

<span class="sd">    &gt;&gt;&gt; scores = cross_validate(lasso, X, y, cv=3,</span>
<span class="sd">    ...                         scoring=(&#39;r2&#39;, &#39;neg_mean_squared_error&#39;),</span>
<span class="sd">    ...                         return_train_score=True)</span>
<span class="sd">    &gt;&gt;&gt; print(scores[&#39;test_neg_mean_squared_error&#39;])</span>
<span class="sd">    [-3635.5... -3573.3... -6114.7...]</span>
<span class="sd">    &gt;&gt;&gt; print(scores[&#39;train_r2&#39;])</span>
<span class="sd">    [0.28009951 0.3908844  0.22784907]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_groups_routing_disabled</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">params</span>
    <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>

    <span class="n">scorers</span> <span class="o">=</span> <span class="n">check_scoring</span><span class="p">(</span>
        <span class="n">estimator</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">raise_exc</span><span class="o">=</span><span class="p">(</span><span class="n">error_score</span> <span class="o">==</span> <span class="s2">&quot;raise&quot;</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">_routing_enabled</span><span class="p">():</span>
        <span class="c1"># For estimators, a MetadataRouter is created in get_metadata_routing</span>
        <span class="c1"># methods. For these router methods, we create the router to use</span>
        <span class="c1"># `process_routing` on it.</span>
        <span class="n">router</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">MetadataRouter</span><span class="p">(</span><span class="n">owner</span><span class="o">=</span><span class="s2">&quot;cross_validate&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;split&quot;</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                <span class="c1"># TODO(SLEP6): also pass metadata to the predict method for</span>
                <span class="c1"># scoring?</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">scorer</span><span class="o">=</span><span class="n">scorers</span><span class="p">,</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;score&quot;</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">routed_params</span> <span class="o">=</span> <span class="n">process_routing</span><span class="p">(</span><span class="n">router</span><span class="p">,</span> <span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">UnsetMetadataPassedError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># The default exception would mention `fit` since in the above</span>
            <span class="c1"># `process_routing` code, we pass `fit` as the caller. However,</span>
            <span class="c1"># the user is not calling `fit` directly, so we change the message</span>
            <span class="c1"># to make it more suitable for this case.</span>
            <span class="n">unrequested_params</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">unrequested_params</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">UnsetMetadataPassedError</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">unrequested_params</span><span class="si">}</span><span class="s2"> are passed to cross validation but are not&quot;</span>
                    <span class="s2">&quot; explicitly set as requested or not requested for cross_validate&#39;s&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; estimator: </span><span class="si">{</span><span class="n">estimator</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. Call&quot;</span>
                    <span class="s2">&quot; `.set_fit_request({{metadata}}=True)` on the estimator for&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; each metadata in </span><span class="si">{</span><span class="n">unrequested_params</span><span class="si">}</span><span class="s2"> that you&quot;</span>
                    <span class="s2">&quot; want to use and `metadata=False` for not using it. See the&quot;</span>
                    <span class="s2">&quot; Metadata Routing User guide&quot;</span>
                    <span class="s2">&quot; &lt;https://scikit-learn.org/stable/metadata_routing.html&gt; for more&quot;</span>
                    <span class="s2">&quot; information.&quot;</span>
                <span class="p">),</span>
                <span class="n">unrequested_params</span><span class="o">=</span><span class="n">e</span><span class="o">.</span><span class="n">unrequested_params</span><span class="p">,</span>
                <span class="n">routed_params</span><span class="o">=</span><span class="n">e</span><span class="o">.</span><span class="n">routed_params</span><span class="p">,</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">routed_params</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">()</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="n">groups</span><span class="p">})</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">fit</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">score</span><span class="o">=</span><span class="p">{})</span>

    <span class="n">indices</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span><span class="o">.</span><span class="n">split</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_indices</span><span class="p">:</span>
        <span class="c1"># materialize the indices since we need to store them in the returned dict</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

    <span class="c1"># We clone the estimator to make sure that all the folds are</span>
    <span class="c1"># independent, and that it is pickle-able.</span>
    <span class="n">parallel</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span>
        <span class="n">delayed</span><span class="p">(</span><span class="n">_fit_and_score</span><span class="p">)(</span>
            <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">scorer</span><span class="o">=</span><span class="n">scorers</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
            <span class="n">test</span><span class="o">=</span><span class="n">test</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">fit_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span>
            <span class="n">score_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">,</span>
            <span class="n">return_train_score</span><span class="o">=</span><span class="n">return_train_score</span><span class="p">,</span>
            <span class="n">return_times</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_estimator</span><span class="o">=</span><span class="n">return_estimator</span><span class="p">,</span>
            <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">indices</span>
    <span class="p">)</span>

    <span class="n">_warn_or_raise_about_fit_failures</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">error_score</span><span class="p">)</span>

    <span class="c1"># For callable scoring, the return type is only know after calling. If the</span>
    <span class="c1"># return type is a dictionary, the error scores can now be inserted with</span>
    <span class="c1"># the correct key.</span>
    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">scoring</span><span class="p">):</span>
        <span class="n">_insert_error_scores</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">error_score</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="n">_aggregate_score_dicts</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

    <span class="n">ret</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">ret</span><span class="p">[</span><span class="s2">&quot;fit_time&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;fit_time&quot;</span><span class="p">]</span>
    <span class="n">ret</span><span class="p">[</span><span class="s2">&quot;score_time&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;score_time&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">return_estimator</span><span class="p">:</span>
        <span class="n">ret</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">return_indices</span><span class="p">:</span>
        <span class="n">ret</span><span class="p">[</span><span class="s2">&quot;indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">ret</span><span class="p">[</span><span class="s2">&quot;indices&quot;</span><span class="p">][</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">ret</span><span class="p">[</span><span class="s2">&quot;indices&quot;</span><span class="p">][</span><span class="s2">&quot;test&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">indices</span><span class="p">)</span>

    <span class="n">test_scores_dict</span> <span class="o">=</span> <span class="n">_normalize_score_results</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;test_scores&quot;</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
        <span class="n">train_scores_dict</span> <span class="o">=</span> <span class="n">_normalize_score_results</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;train_scores&quot;</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">test_scores_dict</span><span class="p">:</span>
        <span class="n">ret</span><span class="p">[</span><span class="s2">&quot;test_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_scores_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="s2">&quot;train_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">name</span>
            <span class="n">ret</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_scores_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">ret</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_insert_error_scores</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">error_score</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Insert error in `results` by replacing them inplace with `error_score`.</span>

<span class="sd">    This only applies to multimetric scores because `_fit_and_score` will</span>
<span class="sd">    handle the single metric case.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">successful_score</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">failed_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;fit_error&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">failed_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">successful_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">successful_score</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;test_scores&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">successful_score</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">formatted_error</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">error_score</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">successful_score</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">failed_indices</span><span class="p">:</span>
            <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;test_scores&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">formatted_error</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">if</span> <span class="s2">&quot;train_scores&quot;</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;train_scores&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">formatted_error</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_normalize_score_results</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">scaler_score_key</span><span class="o">=</span><span class="s2">&quot;score&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a scoring dictionary based on the type of `scores`&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="c1"># multimetric scoring</span>
        <span class="k">return</span> <span class="n">_aggregate_score_dicts</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="c1"># scaler</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">scaler_score_key</span><span class="p">:</span> <span class="n">scores</span><span class="p">}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_warn_or_raise_about_fit_failures</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">error_score</span><span class="p">):</span>
    <span class="n">fit_errors</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;fit_error&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;fit_error&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="n">fit_errors</span><span class="p">:</span>
        <span class="n">num_failed_fits</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">fit_errors</span><span class="p">)</span>
        <span class="n">num_fits</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
        <span class="n">fit_errors_counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">fit_errors</span><span class="p">)</span>
        <span class="n">delimiter</span> <span class="o">=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">80</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">fit_errors_summary</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">delimiter</span><span class="si">}{</span><span class="n">n</span><span class="si">}</span><span class="s2"> fits failed with the following error:</span><span class="se">\n</span><span class="si">{</span><span class="n">error</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">for</span> <span class="n">error</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">fit_errors_counter</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">num_failed_fits</span> <span class="o">==</span> <span class="n">num_fits</span><span class="p">:</span>
            <span class="n">all_fits_failed_message</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">All the </span><span class="si">{</span><span class="n">num_fits</span><span class="si">}</span><span class="s2"> fits failed.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;It is very likely that your model is misconfigured.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;You can try to debug the error by setting error_score=&#39;raise&#39;.</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Below are more details about the failures:</span><span class="se">\n</span><span class="si">{</span><span class="n">fit_errors_summary</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">all_fits_failed_message</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">some_fits_failed_message</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">num_failed_fits</span><span class="si">}</span><span class="s2"> fits failed out of a total of </span><span class="si">{</span><span class="n">num_fits</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;The score on these train-test partitions for these parameters&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; will be set to </span><span class="si">{</span><span class="n">error_score</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;If these failures are not expected, you can try to debug them &quot;</span>
                <span class="s2">&quot;by setting error_score=&#39;raise&#39;.</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Below are more details about the failures:</span><span class="se">\n</span><span class="si">{</span><span class="n">fit_errors_summary</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">some_fits_failed_message</span><span class="p">,</span> <span class="n">FitFailedWarning</span><span class="p">)</span>


<div class="viewcode-block" id="cross_val_score">
<a class="viewcode-back" href="../../../api/bayesflow.computational_utilities.html#bayesflow.computational_utilities.cross_val_score">[docs]</a>
<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">HasMethods</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;scoring&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">get_scorer_names</span><span class="p">())),</span> <span class="nb">callable</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;cv&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;cv_object&quot;</span><span class="p">],</span>
        <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">],</span>
        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pre_dispatch&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;error_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;raise&quot;</span><span class="p">}),</span> <span class="n">Real</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># estimator is not validated yet</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">cross_val_score</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pre_dispatch</span><span class="o">=</span><span class="s2">&quot;2*n_jobs&quot;</span><span class="p">,</span>
    <span class="n">error_score</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate a score by cross-validation.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object implementing &#39;fit&#39;</span>
<span class="sd">        The object to use to fit the data.</span>

<span class="sd">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The data to fit. Can be for example a list, or an array.</span>

<span class="sd">    y : array-like of shape (n_samples,) or (n_samples, n_outputs), \</span>
<span class="sd">            default=None</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Group labels for the samples used while splitting the dataset into</span>
<span class="sd">        train/test set. Only used in conjunction with a &quot;Group&quot; :term:`cv`</span>
<span class="sd">        instance (e.g., :class:`GroupKFold`).</span>

<span class="sd">        .. versionchanged:: 1.4</span>
<span class="sd">            ``groups`` can only be passed if metadata routing is not enabled</span>
<span class="sd">            via ``sklearn.set_config(enable_metadata_routing=True)``. When routing</span>
<span class="sd">            is enabled, pass ``groups`` alongside other metadata via the ``params``</span>
<span class="sd">            argument instead. E.g.:</span>
<span class="sd">            ``cross_val_score(..., params={&#39;groups&#39;: groups})``.</span>

<span class="sd">    scoring : str or callable, default=None</span>
<span class="sd">        A str (see :ref:`scoring_parameter`) or a scorer callable object / function with</span>
<span class="sd">        signature ``scorer(estimator, X, y)`` which should return only a single value.</span>

<span class="sd">        Similar to :func:`cross_validate`</span>
<span class="sd">        but only a single metric is permitted.</span>

<span class="sd">        If `None`, the estimator&#39;s default scorer (if available) is used.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - `None`, to use the default 5-fold cross validation,</span>
<span class="sd">        - int, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">        - :term:`CV splitter`,</span>
<span class="sd">        - An iterable that generates (train, test) splits as arrays of indices.</span>

<span class="sd">        For `int`/`None` inputs, if the estimator is a classifier and `y` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used. These splitters are instantiated</span>
<span class="sd">        with `shuffle=False` so the splits will be the same across calls.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            `cv` default value if `None` changed from 3-fold to 5-fold.</span>

<span class="sd">    n_jobs : int, default=None</span>
<span class="sd">        Number of jobs to run in parallel. Training the estimator and computing</span>
<span class="sd">        the score are parallelized over the cross-validation splits.</span>
<span class="sd">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    params : dict, default=None</span>
<span class="sd">        Parameters to pass to the underlying estimator&#39;s ``fit``, the scorer,</span>
<span class="sd">        and the CV splitter.</span>

<span class="sd">        .. versionadded:: 1.4</span>

<span class="sd">    pre_dispatch : int or str, default=&#39;2*n_jobs&#39;</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">        - ``None``, in which case all the jobs are immediately created and spawned. Use</span>
<span class="sd">          this for lightweight and fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">          spawning of the jobs</span>
<span class="sd">        - An int, giving the exact number of total jobs that are spawned</span>
<span class="sd">        - A str, giving an expression as a function of n_jobs, as in &#39;2*n_jobs&#39;</span>

<span class="sd">    error_score : &#39;raise&#39; or numeric, default=np.nan</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised.</span>
<span class="sd">        If a numeric value is given, FitFailedWarning is raised.</span>

<span class="sd">        .. versionadded:: 0.20</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    scores : ndarray of float of shape=(len(list(cv)),)</span>
<span class="sd">        Array of scores of the estimator for each run of the cross validation.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    cross_validate : To run cross-validation on multiple metrics and also to</span>
<span class="sd">        return train scores, fit times and score times.</span>

<span class="sd">    cross_val_predict : Get predictions from each split of cross-validation for</span>
<span class="sd">        diagnostic purposes.</span>

<span class="sd">    sklearn.metrics.make_scorer : Make a scorer from a performance metric or</span>
<span class="sd">        loss function.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import datasets, linear_model</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import cross_val_score</span>
<span class="sd">    &gt;&gt;&gt; diabetes = datasets.load_diabetes()</span>
<span class="sd">    &gt;&gt;&gt; X = diabetes.data[:150]</span>
<span class="sd">    &gt;&gt;&gt; y = diabetes.target[:150]</span>
<span class="sd">    &gt;&gt;&gt; lasso = linear_model.Lasso()</span>
<span class="sd">    &gt;&gt;&gt; print(cross_val_score(lasso, X, y, cv=3))</span>
<span class="sd">    [0.3315057  0.08022103 0.03531816]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># To ensure multimetric format is not supported</span>
    <span class="n">scorer</span> <span class="o">=</span> <span class="n">check_scoring</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>

    <span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">scorer</span><span class="p">},</span>
        <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
        <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">,</span>
        <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_fit_and_score</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">scorer</span><span class="p">,</span>
    <span class="n">train</span><span class="p">,</span>
    <span class="n">test</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">,</span>
    <span class="n">fit_params</span><span class="p">,</span>
    <span class="n">score_params</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_parameters</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_n_test_samples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_times</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">split_progress</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">candidate_progress</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">error_score</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fit estimator and compute scores for a given dataset split.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object implementing &#39;fit&#39;</span>
<span class="sd">        The object to use to fit the data.</span>

<span class="sd">    X : array-like of shape (n_samples, n_features)</span>
<span class="sd">        The data to fit.</span>

<span class="sd">    y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    scorer : A single callable or dict mapping scorer name to the callable</span>
<span class="sd">        If it is a single callable, the return value for ``train_scores`` and</span>
<span class="sd">        ``test_scores`` is a single float.</span>

<span class="sd">        For a dict, it should be one mapping the scorer name to the scorer</span>
<span class="sd">        callable object / function.</span>

<span class="sd">        The callable object / fn should have signature</span>
<span class="sd">        ``scorer(estimator, X, y)``.</span>

<span class="sd">    train : array-like of shape (n_train_samples,)</span>
<span class="sd">        Indices of training samples.</span>

<span class="sd">    test : array-like of shape (n_test_samples,)</span>
<span class="sd">        Indices of test samples.</span>

<span class="sd">    verbose : int</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    error_score : &#39;raise&#39; or numeric, default=np.nan</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised.</span>
<span class="sd">        If a numeric value is given, FitFailedWarning is raised.</span>

<span class="sd">    parameters : dict or None</span>
<span class="sd">        Parameters to be set on the estimator.</span>

<span class="sd">    fit_params : dict or None</span>
<span class="sd">        Parameters that will be passed to ``estimator.fit``.</span>

<span class="sd">    score_params : dict or None</span>
<span class="sd">        Parameters that will be passed to the scorer.</span>

<span class="sd">    return_train_score : bool, default=False</span>
<span class="sd">        Compute and return score on training set.</span>

<span class="sd">    return_parameters : bool, default=False</span>
<span class="sd">        Return parameters that has been used for the estimator.</span>

<span class="sd">    split_progress : {list, tuple} of int, default=None</span>
<span class="sd">        A list or tuple of format (&lt;current_split_id&gt;, &lt;total_num_of_splits&gt;).</span>

<span class="sd">    candidate_progress : {list, tuple} of int, default=None</span>
<span class="sd">        A list or tuple of format</span>
<span class="sd">        (&lt;current_candidate_id&gt;, &lt;total_number_of_candidates&gt;).</span>

<span class="sd">    return_n_test_samples : bool, default=False</span>
<span class="sd">        Whether to return the ``n_test_samples``.</span>

<span class="sd">    return_times : bool, default=False</span>
<span class="sd">        Whether to return the fit/score times.</span>

<span class="sd">    return_estimator : bool, default=False</span>
<span class="sd">        Whether to return the fitted estimator.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : dict with the following attributes</span>
<span class="sd">        train_scores : dict of scorer name -&gt; float</span>
<span class="sd">            Score on training set (for all the scorers),</span>
<span class="sd">            returned only if `return_train_score` is `True`.</span>
<span class="sd">        test_scores : dict of scorer name -&gt; float</span>
<span class="sd">            Score on testing set (for all the scorers).</span>
<span class="sd">        n_test_samples : int</span>
<span class="sd">            Number of test samples.</span>
<span class="sd">        fit_time : float</span>
<span class="sd">            Time spent for fitting in seconds.</span>
<span class="sd">        score_time : float</span>
<span class="sd">            Time spent for scoring in seconds.</span>
<span class="sd">        parameters : dict or None</span>
<span class="sd">            The parameters that have been evaluated.</span>
<span class="sd">        estimator : estimator object</span>
<span class="sd">            The fitted estimator.</span>
<span class="sd">        fit_error : str or None</span>
<span class="sd">            Traceback str if the fit failed, None if the fit succeeded.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xp</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_namespace</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X_device</span> <span class="o">=</span> <span class="n">device</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># Make sure that we can fancy index X even if train and test are provided</span>
    <span class="c1"># as NumPy arrays by NumPy only cross-validation splitters.</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">xp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X_device</span><span class="p">),</span> <span class="n">xp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X_device</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">error_score</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">)</span> <span class="ow">and</span> <span class="n">error_score</span> <span class="o">!=</span> <span class="s2">&quot;raise&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;error_score must be the string &#39;raise&#39; or a numeric value. &quot;</span>
            <span class="s2">&quot;(Hint: if using &#39;raise&#39;, please make sure that it has been &quot;</span>
            <span class="s2">&quot;spelled correctly.)&quot;</span>
        <span class="p">)</span>

    <span class="n">progress_msg</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">split_progress</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">progress_msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">split_progress</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">split_progress</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">candidate_progress</span> <span class="ow">and</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">9</span><span class="p">:</span>
            <span class="n">progress_msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;; </span><span class="si">{</span><span class="n">candidate_progress</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">candidate_progress</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">params_msg</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sorted_keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>  <span class="c1"># Ensure deterministic o/p</span>
            <span class="n">params_msg</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">parameters</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">sorted_keys</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">9</span><span class="p">:</span>
        <span class="n">start_msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;[CV</span><span class="si">{</span><span class="n">progress_msg</span><span class="si">}</span><span class="s2">] START </span><span class="si">{</span><span class="n">params_msg</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">start_msg</span><span class="si">}{</span><span class="p">(</span><span class="mi">80</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">start_msg</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="s1">&#39;.&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Adjust length of sample weights</span>
    <span class="n">fit_params</span> <span class="o">=</span> <span class="n">fit_params</span> <span class="k">if</span> <span class="n">fit_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">fit_params</span> <span class="o">=</span> <span class="n">_check_method_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
    <span class="n">score_params</span> <span class="o">=</span> <span class="n">score_params</span> <span class="k">if</span> <span class="n">score_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">score_params_train</span> <span class="o">=</span> <span class="n">_check_method_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">score_params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
    <span class="n">score_params_test</span> <span class="o">=</span> <span class="n">_check_method_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">score_params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># here we clone the parameters, since sometimes the parameters</span>
        <span class="c1"># themselves might be estimators, e.g. when we search over different</span>
        <span class="c1"># estimators in a pipeline.</span>
        <span class="c1"># ref: https://github.com/scikit-learn/scikit-learn/pull/26786</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">clone</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>
    <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">y_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="c1"># Note fit time as time until error</span>
        <span class="n">fit_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
        <span class="n">score_time</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">if</span> <span class="n">error_score</span> <span class="o">==</span> <span class="s2">&quot;raise&quot;</span><span class="p">:</span>
            <span class="k">raise</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">error_score</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scorer</span><span class="p">,</span> <span class="n">_MultimetricScorer</span><span class="p">):</span>
                <span class="n">test_scores</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">error_score</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">scorer</span><span class="o">.</span><span class="n">_scorers</span><span class="p">}</span>
                <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
                    <span class="n">train_scores</span> <span class="o">=</span> <span class="n">test_scores</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">test_scores</span> <span class="o">=</span> <span class="n">error_score</span>
                <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
                    <span class="n">train_scores</span> <span class="o">=</span> <span class="n">error_score</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;fit_error&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">format_exc</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;fit_error&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">fit_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">_score</span><span class="p">(</span>
            <span class="n">estimator</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">scorer</span><span class="p">,</span> <span class="n">score_params_test</span><span class="p">,</span> <span class="n">error_score</span>
        <span class="p">)</span>
        <span class="n">score_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span> <span class="o">-</span> <span class="n">fit_time</span>
        <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
            <span class="n">train_scores</span> <span class="o">=</span> <span class="n">_score</span><span class="p">(</span>
                <span class="n">estimator</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scorer</span><span class="p">,</span> <span class="n">score_params_train</span><span class="p">,</span> <span class="n">error_score</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">total_time</span> <span class="o">=</span> <span class="n">score_time</span> <span class="o">+</span> <span class="n">fit_time</span>
        <span class="n">end_msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;[CV</span><span class="si">{</span><span class="n">progress_msg</span><span class="si">}</span><span class="s2">] END &quot;</span>
        <span class="n">result_msg</span> <span class="o">=</span> <span class="n">params_msg</span> <span class="o">+</span> <span class="p">(</span><span class="s2">&quot;;&quot;</span> <span class="k">if</span> <span class="n">params_msg</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">scorer_name</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">test_scores</span><span class="p">):</span>
                    <span class="n">result_msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">scorer_name</span><span class="si">}</span><span class="s2">: (&quot;</span>
                    <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
                        <span class="n">scorer_scores</span> <span class="o">=</span> <span class="n">train_scores</span><span class="p">[</span><span class="n">scorer_name</span><span class="p">]</span>
                        <span class="n">result_msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;train=</span><span class="si">{</span><span class="n">scorer_scores</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="n">result_msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;test=</span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="n">scorer_name</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result_msg</span> <span class="o">+=</span> <span class="s2">&quot;, score=&quot;</span>
                <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
                    <span class="n">result_msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;(train=</span><span class="si">{</span><span class="n">train_scores</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, test=</span><span class="si">{</span><span class="n">test_scores</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">result_msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">test_scores</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">result_msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; total time=</span><span class="si">{</span><span class="n">logger</span><span class="o">.</span><span class="n">short_format_time</span><span class="p">(</span><span class="n">total_time</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="c1"># Right align the result_msg</span>
        <span class="n">end_msg</span> <span class="o">+=</span> <span class="s2">&quot;.&quot;</span> <span class="o">*</span> <span class="p">(</span><span class="mi">80</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">end_msg</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">result_msg</span><span class="p">))</span>
        <span class="n">end_msg</span> <span class="o">+=</span> <span class="n">result_msg</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">end_msg</span><span class="p">)</span>

    <span class="n">result</span><span class="p">[</span><span class="s2">&quot;test_scores&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_scores</span>
    <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;train_scores&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_scores</span>
    <span class="k">if</span> <span class="n">return_n_test_samples</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;n_test_samples&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_times</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;fit_time&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit_time</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;score_time&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">score_time</span>
    <span class="k">if</span> <span class="n">return_parameters</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">parameters</span>
    <span class="k">if</span> <span class="n">return_estimator</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">estimator</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">scorer</span><span class="p">,</span> <span class="n">score_params</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="s2">&quot;raise&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the score(s) of an estimator on a given test set.</span>

<span class="sd">    Will return a dict of floats if `scorer` is a _MultiMetricScorer, otherwise a single</span>
<span class="sd">    float is returned.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">score_params</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">score_params</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">score_params</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">y_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">scorer</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="o">**</span><span class="n">score_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">scorer</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="o">**</span><span class="n">score_params</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scorer</span><span class="p">,</span> <span class="n">_MultimetricScorer</span><span class="p">):</span>
            <span class="c1"># If `_MultimetricScorer` raises exception, the `error_score`</span>
            <span class="c1"># parameter is equal to &quot;raise&quot;.</span>
            <span class="k">raise</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">error_score</span> <span class="o">==</span> <span class="s2">&quot;raise&quot;</span><span class="p">:</span>
                <span class="k">raise</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">scores</span> <span class="o">=</span> <span class="n">error_score</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="s2">&quot;Scoring failed. The score on this train-test partition for &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;these parameters will be set to </span><span class="si">{</span><span class="n">error_score</span><span class="si">}</span><span class="s2">. Details: </span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">format_exc</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">),</span>
                    <span class="ne">UserWarning</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="c1"># Check non-raised error messages in `_MultimetricScorer`</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scorer</span><span class="p">,</span> <span class="n">_MultimetricScorer</span><span class="p">):</span>
        <span class="n">exception_messages</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">str_e</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">str_e</span> <span class="ow">in</span> <span class="n">scores</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">str_e</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="n">exception_messages</span><span class="p">:</span>
            <span class="c1"># error_score != &quot;raise&quot;</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">str_e</span> <span class="ow">in</span> <span class="n">exception_messages</span><span class="p">:</span>
                <span class="n">scores</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">error_score</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="s2">&quot;Scoring failed. The score on this train-test partition for &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;these parameters will be set to </span><span class="si">{</span><span class="n">error_score</span><span class="si">}</span><span class="s2">. Details: </span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">str_e</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">),</span>
                    <span class="ne">UserWarning</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="n">error_msg</span> <span class="o">=</span> <span class="s2">&quot;scoring must return a number, got </span><span class="si">%s</span><span class="s2"> (</span><span class="si">%s</span><span class="s2">) instead. (scorer=</span><span class="si">%s</span><span class="s2">)&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="s2">&quot;item&quot;</span><span class="p">):</span>
                <span class="k">with</span> <span class="n">suppress</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">):</span>
                    <span class="c1"># e.g. unwrap memmapped scalars</span>
                    <span class="n">score</span> <span class="o">=</span> <span class="n">score</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error_msg</span> <span class="o">%</span> <span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">score</span><span class="p">),</span> <span class="n">name</span><span class="p">))</span>
            <span class="n">scores</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># scalar</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="s2">&quot;item&quot;</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">suppress</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">):</span>
                <span class="c1"># e.g. unwrap memmapped scalars</span>
                <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">error_msg</span> <span class="o">%</span> <span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">scorer</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">scores</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">HasMethods</span><span class="p">([</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="s2">&quot;predict&quot;</span><span class="p">])],</span>
        <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;cv&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;cv_object&quot;</span><span class="p">],</span>
        <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">],</span>
        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pre_dispatch&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="n">StrOptions</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;predict&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;predict_proba&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;predict_log_proba&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;decision_function&quot;</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">)</span>
        <span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># estimator is not validated yet</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pre_dispatch</span><span class="o">=</span><span class="s2">&quot;2*n_jobs&quot;</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate cross-validated estimates for each input data point.</span>

<span class="sd">    The data is split according to the cv parameter. Each sample belongs</span>
<span class="sd">    to exactly one test set, and its prediction is computed with an</span>
<span class="sd">    estimator fitted on the corresponding training set.</span>

<span class="sd">    Passing these predictions into an evaluation metric may not be a valid</span>
<span class="sd">    way to measure generalization performance. Results can differ from</span>
<span class="sd">    :func:`cross_validate` and :func:`cross_val_score` unless all tests sets</span>
<span class="sd">    have equal size and the metric decomposes over samples.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator</span>
<span class="sd">        The estimator instance to use to fit the data. It must implement a `fit`</span>
<span class="sd">        method and the method given by the `method` parameter.</span>

<span class="sd">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The data to fit. Can be, for example a list, or an array at least 2d.</span>

<span class="sd">    y : {array-like, sparse matrix} of shape (n_samples,) or (n_samples, n_outputs), \</span>
<span class="sd">            default=None</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Group labels for the samples used while splitting the dataset into</span>
<span class="sd">        train/test set. Only used in conjunction with a &quot;Group&quot; :term:`cv`</span>
<span class="sd">        instance (e.g., :class:`GroupKFold`).</span>

<span class="sd">        .. versionchanged:: 1.4</span>
<span class="sd">            ``groups`` can only be passed if metadata routing is not enabled</span>
<span class="sd">            via ``sklearn.set_config(enable_metadata_routing=True)``. When routing</span>
<span class="sd">            is enabled, pass ``groups`` alongside other metadata via the ``params``</span>
<span class="sd">            argument instead. E.g.:</span>
<span class="sd">            ``cross_val_predict(..., params={&#39;groups&#39;: groups})``.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - None, to use the default 5-fold cross validation,</span>
<span class="sd">        - int, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">        - :term:`CV splitter`,</span>
<span class="sd">        - An iterable that generates (train, test) splits as arrays of indices.</span>

<span class="sd">        For int/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used. These splitters are instantiated</span>
<span class="sd">        with `shuffle=False` so the splits will be the same across calls.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``cv`` default value if None changed from 3-fold to 5-fold.</span>

<span class="sd">    n_jobs : int, default=None</span>
<span class="sd">        Number of jobs to run in parallel. Training the estimator and</span>
<span class="sd">        predicting are parallelized over the cross-validation splits.</span>
<span class="sd">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    params : dict, default=None</span>
<span class="sd">        Parameters to pass to the underlying estimator&#39;s ``fit`` and the CV</span>
<span class="sd">        splitter.</span>

<span class="sd">        .. versionadded:: 1.4</span>

<span class="sd">    pre_dispatch : int or str, default=&#39;2*n_jobs&#39;</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">        - None, in which case all the jobs are immediately created and spawned. Use</span>
<span class="sd">          this for lightweight and fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">          spawning of the jobs</span>
<span class="sd">        - An int, giving the exact number of total jobs that are spawned</span>
<span class="sd">        - A str, giving an expression as a function of n_jobs, as in &#39;2*n_jobs&#39;</span>

<span class="sd">    method : {&#39;predict&#39;, &#39;predict_proba&#39;, &#39;predict_log_proba&#39;, \</span>
<span class="sd">              &#39;decision_function&#39;}, default=&#39;predict&#39;</span>
<span class="sd">        The method to be invoked by `estimator`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    predictions : ndarray</span>
<span class="sd">        This is the result of calling `method`. Shape:</span>

<span class="sd">        - When `method` is &#39;predict&#39; and in special case where `method` is</span>
<span class="sd">          &#39;decision_function&#39; and the target is binary: (n_samples,)</span>
<span class="sd">        - When `method` is one of {&#39;predict_proba&#39;, &#39;predict_log_proba&#39;,</span>
<span class="sd">          &#39;decision_function&#39;} (unless special case above):</span>
<span class="sd">          (n_samples, n_classes)</span>
<span class="sd">        - If `estimator` is :term:`multioutput`, an extra dimension</span>
<span class="sd">          &#39;n_outputs&#39; is added to the end of each shape above.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    cross_val_score : Calculate score for each CV split.</span>
<span class="sd">    cross_validate : Calculate one or more scores and timings for each CV</span>
<span class="sd">        split.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    In the case that one or more classes are absent in a training portion, a</span>
<span class="sd">    default score needs to be assigned to all instances for that class if</span>
<span class="sd">    ``method`` produces columns per class, as in {&#39;decision_function&#39;,</span>
<span class="sd">    &#39;predict_proba&#39;, &#39;predict_log_proba&#39;}.  For ``predict_proba`` this value is</span>
<span class="sd">    0.  In order to ensure finite output, we approximate negative infinity by</span>
<span class="sd">    the minimum finite float value for the dtype in other cases.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import datasets, linear_model</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import cross_val_predict</span>
<span class="sd">    &gt;&gt;&gt; diabetes = datasets.load_diabetes()</span>
<span class="sd">    &gt;&gt;&gt; X = diabetes.data[:150]</span>
<span class="sd">    &gt;&gt;&gt; y = diabetes.target[:150]</span>
<span class="sd">    &gt;&gt;&gt; lasso = linear_model.Lasso()</span>
<span class="sd">    &gt;&gt;&gt; y_pred = cross_val_predict(lasso, X, y, cv=3)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_groups_routing_disabled</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">params</span>

    <span class="k">if</span> <span class="n">_routing_enabled</span><span class="p">():</span>
        <span class="c1"># For estimators, a MetadataRouter is created in get_metadata_routing</span>
        <span class="c1"># methods. For these router methods, we create the router to use</span>
        <span class="c1"># `process_routing` on it.</span>
        <span class="n">router</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">MetadataRouter</span><span class="p">(</span><span class="n">owner</span><span class="o">=</span><span class="s2">&quot;cross_validate&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;split&quot;</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                <span class="c1"># TODO(SLEP6): also pass metadata for the predict method.</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">routed_params</span> <span class="o">=</span> <span class="n">process_routing</span><span class="p">(</span><span class="n">router</span><span class="p">,</span> <span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">UnsetMetadataPassedError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># The default exception would mention `fit` since in the above</span>
            <span class="c1"># `process_routing` code, we pass `fit` as the caller. However,</span>
            <span class="c1"># the user is not calling `fit` directly, so we change the message</span>
            <span class="c1"># to make it more suitable for this case.</span>
            <span class="n">unrequested_params</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">unrequested_params</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">UnsetMetadataPassedError</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">unrequested_params</span><span class="si">}</span><span class="s2"> are passed to `cross_val_predict` but are&quot;</span>
                    <span class="s2">&quot; not explicitly set as requested or not requested for&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; cross_validate&#39;s estimator: </span><span class="si">{</span><span class="n">estimator</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> Call&quot;</span>
                    <span class="s2">&quot; `.set_fit_request({{metadata}}=True)` on the estimator for&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; each metadata in </span><span class="si">{</span><span class="n">unrequested_params</span><span class="si">}</span><span class="s2"> that you want to use and&quot;</span>
                    <span class="s2">&quot; `metadata=False` for not using it. See the Metadata Routing User&quot;</span>
                    <span class="s2">&quot; guide &lt;https://scikit-learn.org/stable/metadata_routing.html&gt;&quot;</span>
                    <span class="s2">&quot; for more information.&quot;</span>
                <span class="p">),</span>
                <span class="n">unrequested_params</span><span class="o">=</span><span class="n">e</span><span class="o">.</span><span class="n">unrequested_params</span><span class="p">,</span>
                <span class="n">routed_params</span><span class="o">=</span><span class="n">e</span><span class="o">.</span><span class="n">routed_params</span><span class="p">,</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">routed_params</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">()</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="n">groups</span><span class="p">})</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">fit</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

    <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>
    <span class="n">splits</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span><span class="o">.</span><span class="n">split</span><span class="p">))</span>

    <span class="n">test_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">test</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">])</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_is_permutation</span><span class="p">(</span><span class="n">test_indices</span><span class="p">,</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;cross_val_predict only works for partitions&quot;</span><span class="p">)</span>

    <span class="c1"># If classification methods produce multiple columns of output,</span>
    <span class="c1"># we need to manually encode classes to ensure consistent column ordering.</span>
    <span class="n">encode</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;decision_function&quot;</span><span class="p">,</span> <span class="s2">&quot;predict_proba&quot;</span><span class="p">,</span> <span class="s2">&quot;predict_log_proba&quot;</span><span class="p">]</span>
        <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">encode</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">y_enc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i_label</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">y_enc</span><span class="p">[:,</span> <span class="n">i_label</span><span class="p">]</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="n">i_label</span><span class="p">])</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y_enc</span>

    <span class="c1"># We clone the estimator to make sure that all the folds are</span>
    <span class="c1"># independent, and that it is pickle-able.</span>
    <span class="n">parallel</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span>
        <span class="n">delayed</span><span class="p">(</span><span class="n">_fit_and_predict</span><span class="p">)(</span>
            <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">train</span><span class="p">,</span>
            <span class="n">test</span><span class="p">,</span>
            <span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span>
            <span class="n">method</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">splits</span>
    <span class="p">)</span>

    <span class="n">inv_test_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_indices</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">inv_test_indices</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_indices</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">encode</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
        <span class="c1"># `predictions` is a list of method outputs from each fold.</span>
        <span class="c1"># If each of those is also a list, then treat this as a</span>
        <span class="c1"># multioutput-multiclass task. We need to separately concatenate</span>
        <span class="c1"># the method outputs for each label into an `n_labels` long list.</span>
        <span class="n">n_labels</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">concat_pred</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i_label</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_labels</span><span class="p">):</span>
            <span class="n">label_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="n">i_label</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">])</span>
            <span class="n">concat_pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_preds</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">concat_pred</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">p</span><span class="p">[</span><span class="n">inv_test_indices</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">predictions</span><span class="p">[</span><span class="n">inv_test_indices</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_fit_and_predict</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">fit_params</span><span class="p">,</span> <span class="n">method</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fit estimator and predict values for a given dataset split.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object implementing &#39;fit&#39; and &#39;predict&#39;</span>
<span class="sd">        The object to use to fit the data.</span>

<span class="sd">    X : array-like of shape (n_samples, n_features)</span>
<span class="sd">        The data to fit.</span>

<span class="sd">        .. versionchanged:: 0.20</span>
<span class="sd">            X is only required to be an object with finite length or shape now</span>

<span class="sd">    y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    train : array-like of shape (n_train_samples,)</span>
<span class="sd">        Indices of training samples.</span>

<span class="sd">    test : array-like of shape (n_test_samples,)</span>
<span class="sd">        Indices of test samples.</span>

<span class="sd">    fit_params : dict or None</span>
<span class="sd">        Parameters that will be passed to ``estimator.fit``.</span>

<span class="sd">    method : str</span>
<span class="sd">        Invokes the passed method name of the passed estimator.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    predictions : sequence</span>
<span class="sd">        Result of calling &#39;estimator.method&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Adjust length of sample weights</span>
    <span class="n">fit_params</span> <span class="o">=</span> <span class="n">fit_params</span> <span class="k">if</span> <span class="n">fit_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">fit_params</span> <span class="o">=</span> <span class="n">_check_method_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>
    <span class="n">X_test</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
    <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">method</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="n">encode</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;decision_function&quot;</span><span class="p">,</span> <span class="s2">&quot;predict_proba&quot;</span><span class="p">,</span> <span class="s2">&quot;predict_log_proba&quot;</span><span class="p">]</span>
        <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">encode</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">_enforce_prediction_order</span><span class="p">(</span>
                    <span class="n">estimator</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="n">i_label</span><span class="p">],</span>
                    <span class="n">predictions</span><span class="p">[</span><span class="n">i_label</span><span class="p">],</span>
                    <span class="n">n_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="n">i_label</span><span class="p">])),</span>
                    <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i_label</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">))</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># A 2D y array should be a binary label indicator matrix</span>
            <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">_enforce_prediction_order</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">method</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">predictions</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_enforce_prediction_order</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">method</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Ensure that prediction arrays have correct column order</span>

<span class="sd">    When doing cross-validation, if one or more classes are</span>
<span class="sd">    not present in the subset of data used for training,</span>
<span class="sd">    then the output prediction array might not have the same</span>
<span class="sd">    columns as other folds. Use the list of class names</span>
<span class="sd">    (assumed to be ints) to enforce the correct column order.</span>

<span class="sd">    Note that `classes` is the list of classes in this fold</span>
<span class="sd">    (a subset of the classes in the full training set)</span>
<span class="sd">    and `n_classes` is the number of classes in the full training set.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">n_classes</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">):</span>
        <span class="n">recommendation</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;To fix this, use a cross-validation &quot;</span>
            <span class="s2">&quot;technique resulting in properly &quot;</span>
            <span class="s2">&quot;stratified folds&quot;</span>
        <span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Number of classes in training fold (</span><span class="si">{}</span><span class="s2">) does &quot;</span>
            <span class="s2">&quot;not match total number of classes (</span><span class="si">{}</span><span class="s2">). &quot;</span>
            <span class="s2">&quot;Results may not be appropriate for your use case. &quot;</span>
            <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">),</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">recommendation</span><span class="p">),</span>
            <span class="ne">RuntimeWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;decision_function&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">predictions</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">):</span>
                <span class="c1"># This handles the case when the shape of predictions</span>
                <span class="c1"># does not match the number of classes used to train</span>
                <span class="c1"># it with. This case is found when sklearn.svm.SVC is</span>
                <span class="c1"># set to `decision_function_shape=&#39;ovo&#39;`.</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Output shape </span><span class="si">{}</span><span class="s2"> of </span><span class="si">{}</span><span class="s2"> does not match &quot;</span>
                    <span class="s2">&quot;number of classes (</span><span class="si">{}</span><span class="s2">) in fold. &quot;</span>
                    <span class="s2">&quot;Irregular decision_function outputs &quot;</span>
                    <span class="s2">&quot;are not currently supported by &quot;</span>
                    <span class="s2">&quot;cross_val_predict&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">))</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># In this special case, `predictions` contains a 1D array.</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Only </span><span class="si">{}</span><span class="s2"> class/es in training fold, but </span><span class="si">{}</span><span class="s2"> &quot;</span>
                    <span class="s2">&quot;in overall dataset. This &quot;</span>
                    <span class="s2">&quot;is not supported for decision_function &quot;</span>
                    <span class="s2">&quot;with imbalanced folds. </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">),</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">recommendation</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="n">float_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span>
        <span class="n">default_values</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;decision_function&quot;</span><span class="p">:</span> <span class="n">float_min</span><span class="p">,</span>
            <span class="s2">&quot;predict_log_proba&quot;</span><span class="p">:</span> <span class="n">float_min</span><span class="p">,</span>
            <span class="s2">&quot;predict_proba&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">predictions_for_all_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
            <span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">predictions</span><span class="p">),</span> <span class="n">n_classes</span><span class="p">),</span>
            <span class="n">default_values</span><span class="p">[</span><span class="n">method</span><span class="p">],</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">predictions</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">predictions_for_all_classes</span><span class="p">[:,</span> <span class="n">classes</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictions</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions_for_all_classes</span>
    <span class="k">return</span> <span class="n">predictions</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_is_permutation</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check whether indices is a reordering of the array np.arange(n_samples)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    indices : ndarray</span>
<span class="sd">        int array to test</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        number of expected elements</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    is_partition : bool</span>
<span class="sd">        True iff sorted(indices) is np.arange(n)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">!=</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="n">hit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="n">hit</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">hit</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">HasMethods</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;cv&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;cv_object&quot;</span><span class="p">],</span>
        <span class="s2">&quot;n_permutations&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">],</span>
        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">],</span>
        <span class="s2">&quot;scoring&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">get_scorer_names</span><span class="p">())),</span> <span class="nb">callable</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;fit_params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># estimator is not validated yet</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">permutation_test_score</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">n_permutations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate the significance of a cross-validated score with permutations.</span>

<span class="sd">    Permutes targets to generate &#39;randomized data&#39; and compute the empirical</span>
<span class="sd">    p-value against the null hypothesis that features and targets are</span>
<span class="sd">    independent.</span>

<span class="sd">    The p-value represents the fraction of randomized data sets where the</span>
<span class="sd">    estimator performed as well or better than in the original data. A small</span>
<span class="sd">    p-value suggests that there is a real dependency between features and</span>
<span class="sd">    targets which has been used by the estimator to give good predictions.</span>
<span class="sd">    A large p-value may be due to lack of real dependency between features</span>
<span class="sd">    and targets or the estimator was not able to use the dependency to</span>
<span class="sd">    give good predictions.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;permutation_test_score&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object implementing &#39;fit&#39;</span>
<span class="sd">        The object to use to fit the data.</span>

<span class="sd">    X : array-like of shape at least 2D</span>
<span class="sd">        The data to fit.</span>

<span class="sd">    y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Labels to constrain permutation within groups, i.e. ``y`` values</span>
<span class="sd">        are permuted among samples with the same group identifier.</span>
<span class="sd">        When not specified, ``y`` values are permuted among all samples.</span>

<span class="sd">        When a grouped cross-validator is used, the group labels are</span>
<span class="sd">        also passed on to the ``split`` method of the cross-validator. The</span>
<span class="sd">        cross-validator uses them for grouping the samples  while splitting</span>
<span class="sd">        the dataset into train/test set.</span>

<span class="sd">        .. versionchanged:: 1.6</span>
<span class="sd">            ``groups`` can only be passed if metadata routing is not enabled</span>
<span class="sd">            via ``sklearn.set_config(enable_metadata_routing=True)``. When routing</span>
<span class="sd">            is enabled, pass ``groups`` alongside other metadata via the ``params``</span>
<span class="sd">            argument instead. E.g.:</span>
<span class="sd">            ``permutation_test_score(..., params={&#39;groups&#39;: groups})``.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - `None`, to use the default 5-fold cross validation,</span>
<span class="sd">        - int, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">        - :term:`CV splitter`,</span>
<span class="sd">        - An iterable yielding (train, test) splits as arrays of indices.</span>

<span class="sd">        For `int`/`None` inputs, if the estimator is a classifier and `y` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used. These splitters are instantiated</span>
<span class="sd">        with `shuffle=False` so the splits will be the same across calls.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            `cv` default value if `None` changed from 3-fold to 5-fold.</span>

<span class="sd">    n_permutations : int, default=100</span>
<span class="sd">        Number of times to permute ``y``.</span>

<span class="sd">    n_jobs : int, default=None</span>
<span class="sd">        Number of jobs to run in parallel. Training the estimator and computing</span>
<span class="sd">        the cross-validated score are parallelized over the permutations.</span>
<span class="sd">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=0</span>
<span class="sd">        Pass an int for reproducible output for permutation of</span>
<span class="sd">        ``y`` values among samples. See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    scoring : str or callable, default=None</span>
<span class="sd">        A single str (see :ref:`scoring_parameter`) or a callable</span>
<span class="sd">        (see :ref:`scoring_callable`) to evaluate the predictions on the test set.</span>

<span class="sd">        If `None` the estimator&#39;s score method is used.</span>

<span class="sd">    fit_params : dict, default=None</span>
<span class="sd">        Parameters to pass to the fit method of the estimator.</span>

<span class="sd">        .. deprecated:: 1.6</span>
<span class="sd">            This parameter is deprecated and will be removed in version 1.6. Use</span>
<span class="sd">            ``params`` instead.</span>

<span class="sd">    params : dict, default=None</span>
<span class="sd">        Parameters to pass to the `fit` method of the estimator, the scorer</span>
<span class="sd">        and the cv splitter.</span>

<span class="sd">        - If `enable_metadata_routing=False` (default): Parameters directly passed to</span>
<span class="sd">          the `fit` method of the estimator.</span>

<span class="sd">        - If `enable_metadata_routing=True`: Parameters safely routed to the `fit`</span>
<span class="sd">          method of the estimator, `cv` object and `scorer`. See :ref:`Metadata Routing</span>
<span class="sd">          User Guide &lt;metadata_routing&gt;` for more details.</span>

<span class="sd">        .. versionadded:: 1.6</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The true score without permuting targets.</span>

<span class="sd">    permutation_scores : array of shape (n_permutations,)</span>
<span class="sd">        The scores obtained for each permutations.</span>

<span class="sd">    pvalue : float</span>
<span class="sd">        The p-value, which approximates the probability that the score would</span>
<span class="sd">        be obtained by chance. This is calculated as:</span>

<span class="sd">        `(C + 1) / (n_permutations + 1)`</span>

<span class="sd">        Where C is the number of permutations whose score &gt;= the true score.</span>

<span class="sd">        The best possible p-value is 1/(n_permutations + 1), the worst is 1.0.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function implements Test 1 in:</span>

<span class="sd">    Ojala and Garriga. `Permutation Tests for Studying Classifier Performance</span>
<span class="sd">    &lt;http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf&gt;`_. The</span>
<span class="sd">    Journal of Machine Learning Research (2010) vol. 11</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.datasets import make_classification</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import permutation_test_score</span>
<span class="sd">    &gt;&gt;&gt; X, y = make_classification(random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; estimator = LogisticRegression()</span>
<span class="sd">    &gt;&gt;&gt; score, permutation_scores, pvalue = permutation_test_score(</span>
<span class="sd">    ...     estimator, X, y, random_state=0</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; print(f&quot;Original Score: {score:.3f}&quot;)</span>
<span class="sd">    Original Score: 0.810</span>
<span class="sd">    &gt;&gt;&gt; print(</span>
<span class="sd">    ...     f&quot;Permutation Scores: {permutation_scores.mean():.3f} +/- &quot;</span>
<span class="sd">    ...     f&quot;{permutation_scores.std():.3f}&quot;</span>
<span class="sd">    ... )</span>
<span class="sd">    Permutation Scores: 0.505 +/- 0.057</span>
<span class="sd">    &gt;&gt;&gt; print(f&quot;P-value: {pvalue:.3f}&quot;)</span>
<span class="sd">    P-value: 0.010</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">_check_params_groups_deprecation</span><span class="p">(</span><span class="n">fit_params</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="s2">&quot;1.8&quot;</span><span class="p">)</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>

    <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>
    <span class="n">scorer</span> <span class="o">=</span> <span class="n">check_scoring</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">_routing_enabled</span><span class="p">():</span>
        <span class="n">router</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">MetadataRouter</span><span class="p">(</span><span class="n">owner</span><span class="o">=</span><span class="s2">&quot;permutation_test_score&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                <span class="c1"># TODO(SLEP6): also pass metadata to the predict method for</span>
                <span class="c1"># scoring?</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;split&quot;</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">scorer</span><span class="o">=</span><span class="n">scorer</span><span class="p">,</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;score&quot;</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">routed_params</span> <span class="o">=</span> <span class="n">process_routing</span><span class="p">(</span><span class="n">router</span><span class="p">,</span> <span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">UnsetMetadataPassedError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># The default exception would mention `fit` since in the above</span>
            <span class="c1"># `process_routing` code, we pass `fit` as the caller. However,</span>
            <span class="c1"># the user is not calling `fit` directly, so we change the message</span>
            <span class="c1"># to make it more suitable for this case.</span>
            <span class="n">unrequested_params</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">unrequested_params</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">UnsetMetadataPassedError</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">unrequested_params</span><span class="si">}</span><span class="s2"> are passed to `permutation_test_score`&quot;</span>
                    <span class="s2">&quot; but are not explicitly set as requested or not requested&quot;</span>
                    <span class="s2">&quot; for permutation_test_score&#39;s&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; estimator: </span><span class="si">{</span><span class="n">estimator</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. Call&quot;</span>
                    <span class="s2">&quot; `.set_fit_request({{metadata}}=True)` on the estimator for&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; each metadata in </span><span class="si">{</span><span class="n">unrequested_params</span><span class="si">}</span><span class="s2"> that you&quot;</span>
                    <span class="s2">&quot; want to use and `metadata=False` for not using it. See the&quot;</span>
                    <span class="s2">&quot; Metadata Routing User guide&quot;</span>
                    <span class="s2">&quot; &lt;https://scikit-learn.org/stable/metadata_routing.html&gt; for more&quot;</span>
                    <span class="s2">&quot; information.&quot;</span>
                <span class="p">),</span>
                <span class="n">unrequested_params</span><span class="o">=</span><span class="n">e</span><span class="o">.</span><span class="n">unrequested_params</span><span class="p">,</span>
                <span class="n">routed_params</span><span class="o">=</span><span class="n">e</span><span class="o">.</span><span class="n">routed_params</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">routed_params</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">()</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">fit</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="n">groups</span><span class="p">})</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">score</span><span class="o">=</span><span class="p">{})</span>

    <span class="c1"># We clone the estimator to make sure that all the folds are</span>
    <span class="c1"># independent, and that it is pickle-able.</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">_permutation_test_score</span><span class="p">(</span>
        <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">cv</span><span class="p">,</span>
        <span class="n">scorer</span><span class="p">,</span>
        <span class="n">split_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
        <span class="n">fit_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span>
        <span class="n">score_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">permutation_scores</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)(</span>
        <span class="n">delayed</span><span class="p">(</span><span class="n">_permutation_test_score</span><span class="p">)(</span>
            <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">_shuffle</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">random_state</span><span class="p">),</span>
            <span class="n">cv</span><span class="p">,</span>
            <span class="n">scorer</span><span class="p">,</span>
            <span class="n">split_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span><span class="o">.</span><span class="n">split</span><span class="p">,</span>
            <span class="n">fit_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span>
            <span class="n">score_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_permutations</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">permutation_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">permutation_scores</span><span class="p">)</span>
    <span class="n">pvalue</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">permutation_scores</span> <span class="o">&gt;=</span> <span class="n">score</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_permutations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">score</span><span class="p">,</span> <span class="n">permutation_scores</span><span class="p">,</span> <span class="n">pvalue</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_permutation_test_score</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="p">,</span> <span class="n">scorer</span><span class="p">,</span> <span class="n">split_params</span><span class="p">,</span> <span class="n">fit_params</span><span class="p">,</span> <span class="n">score_params</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Auxiliary function for permutation_test_score&quot;&quot;&quot;</span>
    <span class="c1"># Adjust length of sample weights</span>
    <span class="n">fit_params</span> <span class="o">=</span> <span class="n">fit_params</span> <span class="k">if</span> <span class="n">fit_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">score_params</span> <span class="o">=</span> <span class="n">score_params</span> <span class="k">if</span> <span class="n">score_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>

    <span class="n">avg_score</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">split_params</span><span class="p">):</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>
        <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>
        <span class="n">fit_params_train</span> <span class="o">=</span> <span class="n">_check_method_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
        <span class="n">score_params_test</span> <span class="o">=</span> <span class="n">_check_method_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">score_params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params_train</span><span class="p">)</span>
        <span class="n">avg_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scorer</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="o">**</span><span class="n">score_params_test</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">avg_score</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_shuffle</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return a shuffled copy of y eventually shuffle among same groups.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">groups</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">):</span>
            <span class="n">this_mask</span> <span class="o">=</span> <span class="n">groups</span> <span class="o">==</span> <span class="n">group</span>
            <span class="n">indices</span><span class="p">[</span><span class="n">this_mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">this_mask</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">_safe_indexing</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">HasMethods</span><span class="p">([</span><span class="s2">&quot;fit&quot;</span><span class="p">])],</span>
        <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;train_sizes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;cv&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;cv_object&quot;</span><span class="p">],</span>
        <span class="s2">&quot;scoring&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">get_scorer_names</span><span class="p">())),</span> <span class="nb">callable</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;exploit_incremental_learning&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pre_dispatch&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">],</span>
        <span class="s2">&quot;shuffle&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">],</span>
        <span class="s2">&quot;error_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;raise&quot;</span><span class="p">}),</span> <span class="n">Real</span><span class="p">],</span>
        <span class="s2">&quot;return_times&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;fit_params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># estimator is not validated yet</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">learning_curve</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">train_sizes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">exploit_incremental_learning</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pre_dispatch</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">error_score</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
    <span class="n">return_times</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Learning curve.</span>

<span class="sd">    Determines cross-validated training and test scores for different training</span>
<span class="sd">    set sizes.</span>

<span class="sd">    A cross-validation generator splits the whole dataset k times in training</span>
<span class="sd">    and test data. Subsets of the training set with varying sizes will be used</span>
<span class="sd">    to train the estimator and a score for each training subset size and the</span>
<span class="sd">    test set will be computed. Afterwards, the scores will be averaged over</span>
<span class="sd">    all k runs for each training subset size.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;learning_curve&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : object type that implements the &quot;fit&quot; method</span>
<span class="sd">        An object of that type which is cloned for each validation. It must</span>
<span class="sd">        also implement &quot;predict&quot; unless `scoring` is a callable that doesn&#39;t</span>
<span class="sd">        rely on &quot;predict&quot; to compute a score.</span>

<span class="sd">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        Training vector, where `n_samples` is the number of samples and</span>
<span class="sd">        `n_features` is the number of features.</span>

<span class="sd">    y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None</span>
<span class="sd">        Target relative to X for classification or regression;</span>
<span class="sd">        None for unsupervised learning.</span>

<span class="sd">    groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Group labels for the samples used while splitting the dataset into</span>
<span class="sd">        train/test set. Only used in conjunction with a &quot;Group&quot; :term:`cv`</span>
<span class="sd">        instance (e.g., :class:`GroupKFold`).</span>

<span class="sd">        .. versionchanged:: 1.6</span>
<span class="sd">            ``groups`` can only be passed if metadata routing is not enabled</span>
<span class="sd">            via ``sklearn.set_config(enable_metadata_routing=True)``. When routing</span>
<span class="sd">            is enabled, pass ``groups`` alongside other metadata via the ``params``</span>
<span class="sd">            argument instead. E.g.:</span>
<span class="sd">            ``learning_curve(..., params={&#39;groups&#39;: groups})``.</span>

<span class="sd">    train_sizes : array-like of shape (n_ticks,), \</span>
<span class="sd">            default=np.linspace(0.1, 1.0, 5)</span>
<span class="sd">        Relative or absolute numbers of training examples that will be used to</span>
<span class="sd">        generate the learning curve. If the dtype is float, it is regarded as a</span>
<span class="sd">        fraction of the maximum size of the training set (that is determined</span>
<span class="sd">        by the selected validation method), i.e. it has to be within (0, 1].</span>
<span class="sd">        Otherwise it is interpreted as absolute sizes of the training sets.</span>
<span class="sd">        Note that for classification the number of samples usually has to</span>
<span class="sd">        be big enough to contain at least one sample from each class.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - None, to use the default 5-fold cross validation,</span>
<span class="sd">        - int, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">        - :term:`CV splitter`,</span>
<span class="sd">        - An iterable yielding (train, test) splits as arrays of indices.</span>

<span class="sd">        For int/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used. These splitters are instantiated</span>
<span class="sd">        with `shuffle=False` so the splits will be the same across calls.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``cv`` default value if None changed from 3-fold to 5-fold.</span>

<span class="sd">    scoring : str or callable, default=None</span>
<span class="sd">        A str (see :ref:`scoring_parameter`) or a scorer callable object / function with</span>
<span class="sd">        signature ``scorer(estimator, X, y)``.</span>

<span class="sd">    exploit_incremental_learning : bool, default=False</span>
<span class="sd">        If the estimator supports incremental learning, this will be</span>
<span class="sd">        used to speed up fitting for different training set sizes.</span>

<span class="sd">    n_jobs : int, default=None</span>
<span class="sd">        Number of jobs to run in parallel. Training the estimator and computing</span>
<span class="sd">        the score are parallelized over the different training and test sets.</span>
<span class="sd">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">    pre_dispatch : int or str, default=&#39;all&#39;</span>
<span class="sd">        Number of predispatched jobs for parallel execution (default is</span>
<span class="sd">        all). The option can reduce the allocated memory. The str can</span>
<span class="sd">        be an expression like &#39;2*n_jobs&#39;.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        Controls the verbosity: the higher, the more messages.</span>

<span class="sd">    shuffle : bool, default=False</span>
<span class="sd">        Whether to shuffle training data before taking prefixes of it</span>
<span class="sd">        based on``train_sizes``.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Used when ``shuffle`` is True. Pass an int for reproducible</span>
<span class="sd">        output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    error_score : &#39;raise&#39; or numeric, default=np.nan</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised.</span>
<span class="sd">        If a numeric value is given, FitFailedWarning is raised.</span>

<span class="sd">        .. versionadded:: 0.20</span>

<span class="sd">    return_times : bool, default=False</span>
<span class="sd">        Whether to return the fit and score times.</span>

<span class="sd">    fit_params : dict, default=None</span>
<span class="sd">        Parameters to pass to the fit method of the estimator.</span>

<span class="sd">        .. deprecated:: 1.6</span>
<span class="sd">            This parameter is deprecated and will be removed in version 1.8. Use</span>
<span class="sd">            ``params`` instead.</span>

<span class="sd">    params : dict, default=None</span>
<span class="sd">        Parameters to pass to the `fit` method of the estimator and to the scorer.</span>

<span class="sd">        - If `enable_metadata_routing=False` (default): Parameters directly passed to</span>
<span class="sd">          the `fit` method of the estimator.</span>

<span class="sd">        - If `enable_metadata_routing=True`: Parameters safely routed to the `fit`</span>
<span class="sd">          method of the estimator. See :ref:`Metadata Routing User Guide</span>
<span class="sd">          &lt;metadata_routing&gt;` for more details.</span>

<span class="sd">        .. versionadded:: 1.6</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    train_sizes_abs : array of shape (n_unique_ticks,)</span>
<span class="sd">        Numbers of training examples that has been used to generate the</span>
<span class="sd">        learning curve. Note that the number of ticks might be less</span>
<span class="sd">        than n_ticks because duplicate entries will be removed.</span>

<span class="sd">    train_scores : array of shape (n_ticks, n_cv_folds)</span>
<span class="sd">        Scores on training sets.</span>

<span class="sd">    test_scores : array of shape (n_ticks, n_cv_folds)</span>
<span class="sd">        Scores on test set.</span>

<span class="sd">    fit_times : array of shape (n_ticks, n_cv_folds)</span>
<span class="sd">        Times spent for fitting in seconds. Only present if ``return_times``</span>
<span class="sd">        is True.</span>

<span class="sd">    score_times : array of shape (n_ticks, n_cv_folds)</span>
<span class="sd">        Times spent for scoring in seconds. Only present if ``return_times``</span>
<span class="sd">        is True.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.datasets import make_classification</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.tree import DecisionTreeClassifier</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import learning_curve</span>
<span class="sd">    &gt;&gt;&gt; X, y = make_classification(n_samples=100, n_features=10, random_state=42)</span>
<span class="sd">    &gt;&gt;&gt; tree = DecisionTreeClassifier(max_depth=4, random_state=42)</span>
<span class="sd">    &gt;&gt;&gt; train_size_abs, train_scores, test_scores = learning_curve(</span>
<span class="sd">    ...     tree, X, y, train_sizes=[0.3, 0.6, 0.9]</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; for train_size, cv_train_scores, cv_test_scores in zip(</span>
<span class="sd">    ...     train_size_abs, train_scores, test_scores</span>
<span class="sd">    ... ):</span>
<span class="sd">    ...     print(f&quot;{train_size} samples were used to train the model&quot;)</span>
<span class="sd">    ...     print(f&quot;The average train accuracy is {cv_train_scores.mean():.2f}&quot;)</span>
<span class="sd">    ...     print(f&quot;The average test accuracy is {cv_test_scores.mean():.2f}&quot;)</span>
<span class="sd">    24 samples were used to train the model</span>
<span class="sd">    The average train accuracy is 1.00</span>
<span class="sd">    The average test accuracy is 0.85</span>
<span class="sd">    48 samples were used to train the model</span>
<span class="sd">    The average train accuracy is 1.00</span>
<span class="sd">    The average test accuracy is 0.90</span>
<span class="sd">    72 samples were used to train the model</span>
<span class="sd">    The average train accuracy is 1.00</span>
<span class="sd">    The average test accuracy is 0.93</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">exploit_incremental_learning</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;partial_fit&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;An estimator must support the partial_fit interface &quot;</span>
            <span class="s2">&quot;to exploit incremental learning&quot;</span>
        <span class="p">)</span>

    <span class="n">params</span> <span class="o">=</span> <span class="n">_check_params_groups_deprecation</span><span class="p">(</span><span class="n">fit_params</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="s2">&quot;1.8&quot;</span><span class="p">)</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>

    <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>

    <span class="n">scorer</span> <span class="o">=</span> <span class="n">check_scoring</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">_routing_enabled</span><span class="p">():</span>
        <span class="n">router</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">MetadataRouter</span><span class="p">(</span><span class="n">owner</span><span class="o">=</span><span class="s2">&quot;learning_curve&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                <span class="c1"># TODO(SLEP6): also pass metadata to the predict method for</span>
                <span class="c1"># scoring?</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span>
                <span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">)</span>
                <span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;partial_fit&quot;</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;split&quot;</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">scorer</span><span class="o">=</span><span class="n">scorer</span><span class="p">,</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;score&quot;</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">routed_params</span> <span class="o">=</span> <span class="n">process_routing</span><span class="p">(</span><span class="n">router</span><span class="p">,</span> <span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">UnsetMetadataPassedError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># The default exception would mention `fit` since in the above</span>
            <span class="c1"># `process_routing` code, we pass `fit` as the caller. However,</span>
            <span class="c1"># the user is not calling `fit` directly, so we change the message</span>
            <span class="c1"># to make it more suitable for this case.</span>
            <span class="n">unrequested_params</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">unrequested_params</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">UnsetMetadataPassedError</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">unrequested_params</span><span class="si">}</span><span class="s2"> are passed to `learning_curve` but are not&quot;</span>
                    <span class="s2">&quot; explicitly set as requested or not requested for learning_curve&#39;s&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; estimator: </span><span class="si">{</span><span class="n">estimator</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. Call&quot;</span>
                    <span class="s2">&quot; `.set_fit_request({{metadata}}=True)` on the estimator for&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; each metadata in </span><span class="si">{</span><span class="n">unrequested_params</span><span class="si">}</span><span class="s2"> that you&quot;</span>
                    <span class="s2">&quot; want to use and `metadata=False` for not using it. See the&quot;</span>
                    <span class="s2">&quot; Metadata Routing User guide&quot;</span>
                    <span class="s2">&quot; &lt;https://scikit-learn.org/stable/metadata_routing.html&gt; for more&quot;</span>
                    <span class="s2">&quot; information.&quot;</span>
                <span class="p">),</span>
                <span class="n">unrequested_params</span><span class="o">=</span><span class="n">e</span><span class="o">.</span><span class="n">unrequested_params</span><span class="p">,</span>
                <span class="n">routed_params</span><span class="o">=</span><span class="n">e</span><span class="o">.</span><span class="n">routed_params</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">routed_params</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">()</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">fit</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">partial_fit</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="n">groups</span><span class="p">})</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">score</span><span class="o">=</span><span class="p">{})</span>

    <span class="c1"># Store cv as list as we will be iterating over the list multiple times</span>
    <span class="n">cv_iter</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span><span class="o">.</span><span class="n">split</span><span class="p">))</span>

    <span class="n">n_max_training_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cv_iter</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1"># Because the lengths of folds can be significantly different, it is</span>
    <span class="c1"># not guaranteed that we use all of the available training data when we</span>
    <span class="c1"># use the first &#39;n_max_training_samples&#39; samples.</span>
    <span class="n">train_sizes_abs</span> <span class="o">=</span> <span class="n">_translate_train_sizes</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">n_max_training_samples</span><span class="p">)</span>
    <span class="n">n_unique_ticks</span> <span class="o">=</span> <span class="n">train_sizes_abs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[learning_curve] Training set sizes: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_sizes_abs</span><span class="p">))</span>

    <span class="n">parallel</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">cv_iter</span> <span class="o">=</span> <span class="p">((</span><span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">train</span><span class="p">),</span> <span class="n">test</span><span class="p">)</span> <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv_iter</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">exploit_incremental_learning</span><span class="p">:</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span>
            <span class="n">delayed</span><span class="p">(</span><span class="n">_incremental_fit_estimator</span><span class="p">)(</span>
                <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="n">classes</span><span class="p">,</span>
                <span class="n">train</span><span class="p">,</span>
                <span class="n">test</span><span class="p">,</span>
                <span class="n">train_sizes_abs</span><span class="p">,</span>
                <span class="n">scorer</span><span class="p">,</span>
                <span class="n">return_times</span><span class="p">,</span>
                <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
                <span class="n">fit_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">,</span>
                <span class="n">score_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv_iter</span>
        <span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_test_proportions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv_iter</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">n_train_samples</span> <span class="ow">in</span> <span class="n">train_sizes_abs</span><span class="p">:</span>
                <span class="n">train_test_proportions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">train</span><span class="p">[:</span><span class="n">n_train_samples</span><span class="p">],</span> <span class="n">test</span><span class="p">))</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span>
            <span class="n">delayed</span><span class="p">(</span><span class="n">_fit_and_score</span><span class="p">)(</span>
                <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="n">scorer</span><span class="o">=</span><span class="n">scorer</span><span class="p">,</span>
                <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
                <span class="n">test</span><span class="o">=</span><span class="n">test</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">fit_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span>
                <span class="n">score_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">,</span>
                <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
                <span class="n">return_times</span><span class="o">=</span><span class="n">return_times</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">train_test_proportions</span>
        <span class="p">)</span>
        <span class="n">_warn_or_raise_about_fit_failures</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">error_score</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">_aggregate_score_dicts</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
        <span class="n">train_scores</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;train_scores&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_unique_ticks</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;test_scores&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_unique_ticks</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">return_times</span><span class="p">:</span>
            <span class="n">fit_times</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;fit_time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_unique_ticks</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="n">score_times</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;score_time&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_unique_ticks</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="n">out</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">fit_times</span><span class="p">,</span> <span class="n">score_times</span><span class="p">])</span>

    <span class="n">ret</span> <span class="o">=</span> <span class="n">train_sizes_abs</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">return_times</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">ret</span> <span class="o">+</span> <span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">out</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">ret</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_translate_train_sizes</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">n_max_training_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Determine absolute sizes of training subsets and validate &#39;train_sizes&#39;.</span>

<span class="sd">    Examples:</span>
<span class="sd">        _translate_train_sizes([0.5, 1.0], 10) -&gt; [5, 10]</span>
<span class="sd">        _translate_train_sizes([5, 10], 10) -&gt; [5, 10]</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    train_sizes : array-like of shape (n_ticks,)</span>
<span class="sd">        Numbers of training examples that will be used to generate the</span>
<span class="sd">        learning curve. If the dtype is float, it is regarded as a</span>
<span class="sd">        fraction of &#39;n_max_training_samples&#39;, i.e. it has to be within (0, 1].</span>

<span class="sd">    n_max_training_samples : int</span>
<span class="sd">        Maximum number of training samples (upper bound of &#39;train_sizes&#39;).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    train_sizes_abs : array of shape (n_unique_ticks,)</span>
<span class="sd">        Numbers of training examples that will be used to generate the</span>
<span class="sd">        learning curve. Note that the number of ticks might be less</span>
<span class="sd">        than n_ticks because duplicate entries will be removed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train_sizes_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">)</span>
    <span class="n">n_ticks</span> <span class="o">=</span> <span class="n">train_sizes_abs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_min_required_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">train_sizes_abs</span><span class="p">)</span>
    <span class="n">n_max_required_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">train_sizes_abs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">train_sizes_abs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">n_min_required_samples</span> <span class="o">&lt;=</span> <span class="mf">0.0</span> <span class="ow">or</span> <span class="n">n_max_required_samples</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;train_sizes has been interpreted as fractions &quot;</span>
                <span class="s2">&quot;of the maximum number of training samples and &quot;</span>
                <span class="s2">&quot;must be within (0, 1], but is within [</span><span class="si">%f</span><span class="s2">, </span><span class="si">%f</span><span class="s2">].&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="n">n_min_required_samples</span><span class="p">,</span> <span class="n">n_max_required_samples</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">train_sizes_abs</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_sizes_abs</span> <span class="o">*</span> <span class="n">n_max_training_samples</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
            <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">train_sizes_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">train_sizes_abs</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_max_training_samples</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">n_min_required_samples</span> <span class="o">&lt;=</span> <span class="mi">0</span>
            <span class="ow">or</span> <span class="n">n_max_required_samples</span> <span class="o">&gt;</span> <span class="n">n_max_training_samples</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;train_sizes has been interpreted as absolute &quot;</span>
                <span class="s2">&quot;numbers of training samples and must be within &quot;</span>
                <span class="s2">&quot;(0, </span><span class="si">%d</span><span class="s2">], but is within [</span><span class="si">%d</span><span class="s2">, </span><span class="si">%d</span><span class="s2">].&quot;</span>
                <span class="o">%</span> <span class="p">(</span>
                    <span class="n">n_max_training_samples</span><span class="p">,</span>
                    <span class="n">n_min_required_samples</span><span class="p">,</span>
                    <span class="n">n_max_required_samples</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

    <span class="n">train_sizes_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_sizes_abs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_ticks</span> <span class="o">&gt;</span> <span class="n">train_sizes_abs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Removed duplicate entries from &#39;train_sizes&#39;. Number &quot;</span>
            <span class="s2">&quot;of ticks will be less than the size of &quot;</span>
            <span class="s2">&quot;&#39;train_sizes&#39;: </span><span class="si">%d</span><span class="s2"> instead of </span><span class="si">%d</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_sizes_abs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_ticks</span><span class="p">),</span>
            <span class="ne">RuntimeWarning</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">train_sizes_abs</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_incremental_fit_estimator</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">classes</span><span class="p">,</span>
    <span class="n">train</span><span class="p">,</span>
    <span class="n">test</span><span class="p">,</span>
    <span class="n">train_sizes</span><span class="p">,</span>
    <span class="n">scorer</span><span class="p">,</span>
    <span class="n">return_times</span><span class="p">,</span>
    <span class="n">error_score</span><span class="p">,</span>
    <span class="n">fit_params</span><span class="p">,</span>
    <span class="n">score_params</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train estimator on training subsets incrementally and compute scores.&quot;&quot;&quot;</span>
    <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">,</span> <span class="n">fit_times</span><span class="p">,</span> <span class="n">score_times</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">partitions</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">train_sizes</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">fit_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fit_params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">classes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">partial_fit_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">estimator</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">partial_fit_func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">estimator</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
    <span class="n">score_params</span> <span class="o">=</span> <span class="n">score_params</span> <span class="k">if</span> <span class="n">score_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">score_params_train</span> <span class="o">=</span> <span class="n">_check_method_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">score_params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
    <span class="n">score_params_test</span> <span class="o">=</span> <span class="n">_check_method_params</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">score_params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">n_train_samples</span><span class="p">,</span> <span class="n">partial_train</span> <span class="ow">in</span> <span class="n">partitions</span><span class="p">:</span>
        <span class="n">train_subset</span> <span class="o">=</span> <span class="n">train</span><span class="p">[:</span><span class="n">n_train_samples</span><span class="p">]</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_subset</span><span class="p">)</span>
        <span class="n">X_partial_train</span><span class="p">,</span> <span class="n">y_partial_train</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">partial_train</span><span class="p">)</span>
        <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">train_subset</span><span class="p">)</span>
        <span class="n">start_fit</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">y_partial_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">partial_fit_func</span><span class="p">(</span><span class="n">X_partial_train</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">partial_fit_func</span><span class="p">(</span><span class="n">X_partial_train</span><span class="p">,</span> <span class="n">y_partial_train</span><span class="p">)</span>
        <span class="n">fit_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_fit</span>
        <span class="n">fit_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fit_time</span><span class="p">)</span>

        <span class="n">start_score</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="n">test_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">_score</span><span class="p">(</span>
                <span class="n">estimator</span><span class="p">,</span>
                <span class="n">X_test</span><span class="p">,</span>
                <span class="n">y_test</span><span class="p">,</span>
                <span class="n">scorer</span><span class="p">,</span>
                <span class="n">score_params</span><span class="o">=</span><span class="n">score_params_test</span><span class="p">,</span>
                <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">train_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">_score</span><span class="p">(</span>
                <span class="n">estimator</span><span class="p">,</span>
                <span class="n">X_train</span><span class="p">,</span>
                <span class="n">y_train</span><span class="p">,</span>
                <span class="n">scorer</span><span class="p">,</span>
                <span class="n">score_params</span><span class="o">=</span><span class="n">score_params_train</span><span class="p">,</span>
                <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">score_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_score</span>
        <span class="n">score_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_time</span><span class="p">)</span>

    <span class="n">ret</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">,</span> <span class="n">fit_times</span><span class="p">,</span> <span class="n">score_times</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_times</span>
        <span class="k">else</span> <span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">HasMethods</span><span class="p">([</span><span class="s2">&quot;fit&quot;</span><span class="p">])],</span>
        <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;param_name&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="s2">&quot;param_range&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
        <span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;cv&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;cv_object&quot;</span><span class="p">],</span>
        <span class="s2">&quot;scoring&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">get_scorer_names</span><span class="p">())),</span> <span class="nb">callable</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;pre_dispatch&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Integral</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span>
        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;verbose&quot;</span><span class="p">],</span>
        <span class="s2">&quot;error_score&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;raise&quot;</span><span class="p">}),</span> <span class="n">Real</span><span class="p">],</span>
        <span class="s2">&quot;fit_params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># estimator is not validated yet</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">validation_curve</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">param_name</span><span class="p">,</span>
    <span class="n">param_range</span><span class="p">,</span>
    <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">pre_dispatch</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">error_score</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
    <span class="n">fit_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Validation curve.</span>

<span class="sd">    Determine training and test scores for varying parameter values.</span>

<span class="sd">    Compute scores for an estimator with different values of a specified</span>
<span class="sd">    parameter. This is similar to grid search with one parameter. However, this</span>
<span class="sd">    will also compute training scores and is merely a utility for plotting the</span>
<span class="sd">    results.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;validation_curve&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : object type that implements the &quot;fit&quot; method</span>
<span class="sd">        An object of that type which is cloned for each validation. It must</span>
<span class="sd">        also implement &quot;predict&quot; unless `scoring` is a callable that doesn&#39;t</span>
<span class="sd">        rely on &quot;predict&quot; to compute a score.</span>

<span class="sd">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        Training vector, where `n_samples` is the number of samples and</span>
<span class="sd">        `n_features` is the number of features.</span>

<span class="sd">    y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None</span>
<span class="sd">        Target relative to X for classification or regression;</span>
<span class="sd">        None for unsupervised learning.</span>

<span class="sd">    param_name : str</span>
<span class="sd">        Name of the parameter that will be varied.</span>

<span class="sd">    param_range : array-like of shape (n_values,)</span>
<span class="sd">        The values of the parameter that will be evaluated.</span>

<span class="sd">    groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">        Group labels for the samples used while splitting the dataset into</span>
<span class="sd">        train/test set. Only used in conjunction with a &quot;Group&quot; :term:`cv`</span>
<span class="sd">        instance (e.g., :class:`GroupKFold`).</span>

<span class="sd">        .. versionchanged:: 1.6</span>
<span class="sd">            ``groups`` can only be passed if metadata routing is not enabled</span>
<span class="sd">            via ``sklearn.set_config(enable_metadata_routing=True)``. When routing</span>
<span class="sd">            is enabled, pass ``groups`` alongside other metadata via the ``params``</span>
<span class="sd">            argument instead. E.g.:</span>
<span class="sd">            ``validation_curve(..., params={&#39;groups&#39;: groups})``.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - None, to use the default 5-fold cross validation,</span>
<span class="sd">        - int, to specify the number of folds in a `(Stratified)KFold`,</span>
<span class="sd">        - :term:`CV splitter`,</span>
<span class="sd">        - An iterable yielding (train, test) splits as arrays of indices.</span>

<span class="sd">        For int/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">        either binary or multiclass, :class:`StratifiedKFold` is used. In all</span>
<span class="sd">        other cases, :class:`KFold` is used. These splitters are instantiated</span>
<span class="sd">        with `shuffle=False` so the splits will be the same across calls.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``cv`` default value if None changed from 3-fold to 5-fold.</span>

<span class="sd">    scoring : str or callable, default=None</span>
<span class="sd">        A str (see :ref:`scoring_parameter`) or a scorer callable object / function with</span>
<span class="sd">        signature ``scorer(estimator, X, y)``.</span>

<span class="sd">    n_jobs : int, default=None</span>
<span class="sd">        Number of jobs to run in parallel. Training the estimator and computing</span>
<span class="sd">        the score are parallelized over the combinations of each parameter</span>
<span class="sd">        value and each cross-validation split.</span>
<span class="sd">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">    pre_dispatch : int or str, default=&#39;all&#39;</span>
<span class="sd">        Number of predispatched jobs for parallel execution (default is</span>
<span class="sd">        all). The option can reduce the allocated memory. The str can</span>
<span class="sd">        be an expression like &#39;2*n_jobs&#39;.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        Controls the verbosity: the higher, the more messages.</span>

<span class="sd">    error_score : &#39;raise&#39; or numeric, default=np.nan</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised.</span>
<span class="sd">        If a numeric value is given, FitFailedWarning is raised.</span>

<span class="sd">        .. versionadded:: 0.20</span>

<span class="sd">    fit_params : dict, default=None</span>
<span class="sd">        Parameters to pass to the fit method of the estimator.</span>

<span class="sd">        .. deprecated:: 1.6</span>
<span class="sd">            This parameter is deprecated and will be removed in version 1.8. Use</span>
<span class="sd">            ``params`` instead.</span>

<span class="sd">    params : dict, default=None</span>
<span class="sd">        Parameters to pass to the estimator, scorer and cross-validation object.</span>

<span class="sd">        - If `enable_metadata_routing=False` (default): Parameters directly passed to</span>
<span class="sd">          the `fit` method of the estimator.</span>

<span class="sd">        - If `enable_metadata_routing=True`: Parameters safely routed to the `fit`</span>
<span class="sd">          method of the estimator, to the scorer and to the cross-validation object.</span>
<span class="sd">          See :ref:`Metadata Routing User Guide &lt;metadata_routing&gt;` for more details.</span>

<span class="sd">        .. versionadded:: 1.6</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    train_scores : array of shape (n_ticks, n_cv_folds)</span>
<span class="sd">        Scores on training sets.</span>

<span class="sd">    test_scores : array of shape (n_ticks, n_cv_folds)</span>
<span class="sd">        Scores on test set.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    See :ref:`sphx_glr_auto_examples_model_selection_plot_train_error_vs_test_error.py`</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.datasets import make_classification</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import validation_curve</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression</span>
<span class="sd">    &gt;&gt;&gt; X, y = make_classification(n_samples=1_000, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; logistic_regression = LogisticRegression()</span>
<span class="sd">    &gt;&gt;&gt; param_name, param_range = &quot;C&quot;, np.logspace(-8, 3, 10)</span>
<span class="sd">    &gt;&gt;&gt; train_scores, test_scores = validation_curve(</span>
<span class="sd">    ...     logistic_regression, X, y, param_name=param_name, param_range=param_range</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; print(f&quot;The average train accuracy is {train_scores.mean():.2f}&quot;)</span>
<span class="sd">    The average train accuracy is 0.81</span>
<span class="sd">    &gt;&gt;&gt; print(f&quot;The average test accuracy is {test_scores.mean():.2f}&quot;)</span>
<span class="sd">    The average test accuracy is 0.81</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">_check_params_groups_deprecation</span><span class="p">(</span><span class="n">fit_params</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="s2">&quot;1.8&quot;</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>

    <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>
    <span class="n">scorer</span> <span class="o">=</span> <span class="n">check_scoring</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">_routing_enabled</span><span class="p">():</span>
        <span class="n">router</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">MetadataRouter</span><span class="p">(</span><span class="n">owner</span><span class="o">=</span><span class="s2">&quot;validation_curve&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">splitter</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;split&quot;</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">scorer</span><span class="o">=</span><span class="n">scorer</span><span class="p">,</span>
                <span class="n">method_mapping</span><span class="o">=</span><span class="n">MethodMapping</span><span class="p">()</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">caller</span><span class="o">=</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="n">callee</span><span class="o">=</span><span class="s2">&quot;score&quot;</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">routed_params</span> <span class="o">=</span> <span class="n">process_routing</span><span class="p">(</span><span class="n">router</span><span class="p">,</span> <span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">UnsetMetadataPassedError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># The default exception would mention `fit` since in the above</span>
            <span class="c1"># `process_routing` code, we pass `fit` as the caller. However,</span>
            <span class="c1"># the user is not calling `fit` directly, so we change the message</span>
            <span class="c1"># to make it more suitable for this case.</span>
            <span class="n">unrequested_params</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">unrequested_params</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">UnsetMetadataPassedError</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">unrequested_params</span><span class="si">}</span><span class="s2"> are passed to `validation_curve` but are not&quot;</span>
                    <span class="s2">&quot; explicitly set as requested or not requested for&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; validation_curve&#39;s estimator: </span><span class="si">{</span><span class="n">estimator</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="s2">&quot; Call `.set_fit_request({{metadata}}=True)` on the estimator for&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; each metadata in </span><span class="si">{</span><span class="n">unrequested_params</span><span class="si">}</span><span class="s2"> that you&quot;</span>
                    <span class="s2">&quot; want to use and `metadata=False` for not using it. See the&quot;</span>
                    <span class="s2">&quot; Metadata Routing User guide&quot;</span>
                    <span class="s2">&quot; &lt;https://scikit-learn.org/stable/metadata_routing.html&gt; for more&quot;</span>
                    <span class="s2">&quot; information.&quot;</span>
                <span class="p">),</span>
                <span class="n">unrequested_params</span><span class="o">=</span><span class="n">e</span><span class="o">.</span><span class="n">unrequested_params</span><span class="p">,</span>
                <span class="n">routed_params</span><span class="o">=</span><span class="n">e</span><span class="o">.</span><span class="n">routed_params</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">routed_params</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">()</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">fit</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="n">groups</span><span class="p">})</span>
        <span class="n">routed_params</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">(</span><span class="n">score</span><span class="o">=</span><span class="p">{})</span>

    <span class="n">parallel</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span>
        <span class="n">delayed</span><span class="p">(</span><span class="n">_fit_and_score</span><span class="p">)(</span>
            <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">scorer</span><span class="o">=</span><span class="n">scorer</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
            <span class="n">test</span><span class="o">=</span><span class="n">test</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="p">{</span><span class="n">param_name</span><span class="p">:</span> <span class="n">v</span><span class="p">},</span>
            <span class="n">fit_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span>
            <span class="n">score_params</span><span class="o">=</span><span class="n">routed_params</span><span class="o">.</span><span class="n">scorer</span><span class="o">.</span><span class="n">score</span><span class="p">,</span>
            <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">error_score</span><span class="o">=</span><span class="n">error_score</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># NOTE do not change order of iteration to allow one time cv splitters</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">routed_params</span><span class="o">.</span><span class="n">splitter</span><span class="o">.</span><span class="n">split</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">param_range</span>
    <span class="p">)</span>
    <span class="n">n_params</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">param_range</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="n">_aggregate_score_dicts</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="n">train_scores</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;train_scores&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_params</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">test_scores</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;test_scores&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_params</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="k">return</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_aggregate_score_dicts</span><span class="p">(</span><span class="n">scores</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Aggregate the list of dict to dict of np ndarray</span>

<span class="sd">    The aggregated output of _aggregate_score_dicts will be a list of dict</span>
<span class="sd">    of form [{&#39;prec&#39;: 0.1, &#39;acc&#39;:1.0}, {&#39;prec&#39;: 0.1, &#39;acc&#39;:1.0}, ...]</span>
<span class="sd">    Convert it to a dict of array {&#39;prec&#39;: np.array([0.1 ...]), ...}</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    scores : list of dict</span>
<span class="sd">        List of dicts of the scores for all scorers. This is a flat list,</span>
<span class="sd">        assumed originally to be of row major order.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; scores = [{&#39;a&#39;: 1, &#39;b&#39;:10}, {&#39;a&#39;: 2, &#39;b&#39;:2}, {&#39;a&#39;: 3, &#39;b&#39;:3},</span>
<span class="sd">    ...           {&#39;a&#39;: 10, &#39;b&#39;: 10}]                         # doctest: +SKIP</span>
<span class="sd">    &gt;&gt;&gt; _aggregate_score_dicts(scores)                        # doctest: +SKIP</span>
<span class="sd">    {&#39;a&#39;: array([1, 2, 3, 10]),</span>
<span class="sd">     &#39;b&#39;: array([10, 2, 3, 10])}</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="n">key</span><span class="p">:</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">score</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">key</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">)</span>
            <span class="k">else</span> <span class="p">[</span><span class="n">score</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">}</span>
</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The BayesFlow authors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2023-2025, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>