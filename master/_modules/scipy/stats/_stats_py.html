
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>scipy.stats._stats_py &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=8fec244e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/scipy/stats/_stats_py';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://www.bayesflow.org/_modules/scipy/stats/_stats_py.html" />
    <link rel="icon" href="../../../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/bayesflow_hex.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <img src="../../../_static/bayesflow_hex.png" class="logo__image only-dark pst-js-only" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">BayesFlow</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../examples.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Intro_Amortized_Posterior_Estimation.html">1. Quickstart: Amortized Posterior Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/TwoMoons_Bimodal_Posterior.html">2. Two Moons: Tackling Bimodal Posteriors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Model_Misspecification.html">3. Detecting Model Misspecification in Amortized Posterior Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/LCA_Model_Posterior_Estimation.html">4. Principled Amortized Bayesian Workflow for Cognitive Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Linear_ODE_system.html">5. Posterior Estimation for ODEs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Covid19_Initial_Posterior_Estimation.html">6. Posterior Estimation for SIR-like Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Model_Comparison_MPT.html">7. Model Comparison for Cognitive Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../_examples/Hierarchical_Model_Comparison_MPT.html">8. Hierarchical Model Comparison for Cognitive Models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api/bayesflow.html">Public API: bayesflow package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/bayesflow.benchmarks.html">bayesflow.benchmarks package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.bernoulli_glm.html">bayesflow.benchmarks.bernoulli_glm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.bernoulli_glm_raw.html">bayesflow.benchmarks.bernoulli_glm_raw module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.gaussian_linear.html">bayesflow.benchmarks.gaussian_linear module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.gaussian_linear_uniform.html">bayesflow.benchmarks.gaussian_linear_uniform module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.gaussian_mixture.html">bayesflow.benchmarks.gaussian_mixture module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.inverse_kinematics.html">bayesflow.benchmarks.inverse_kinematics module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.lotka_volterra.html">bayesflow.benchmarks.lotka_volterra module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.sir.html">bayesflow.benchmarks.sir module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.slcp.html">bayesflow.benchmarks.slcp module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.slcp_distractors.html">bayesflow.benchmarks.slcp_distractors module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.benchmarks.two_moons.html">bayesflow.benchmarks.two_moons module</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.amortizers.html">bayesflow.amortizers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.attention.html">bayesflow.attention module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.coupling_networks.html">bayesflow.coupling_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.diagnostics.html">bayesflow.diagnostics module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.inference_networks.html">bayesflow.inference_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.losses.html">bayesflow.losses module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.networks.html">bayesflow.networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.sensitivity.html">bayesflow.sensitivity module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.simulation.html">bayesflow.simulation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.summary_networks.html">bayesflow.summary_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.trainers.html">bayesflow.trainers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.configuration.html">bayesflow.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.default_settings.html">bayesflow.default_settings module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.computational_utilities.html">bayesflow.computational_utilities module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.helper_classes.html">bayesflow.helper_classes module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.helper_functions.html">bayesflow.helper_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.helper_networks.html">bayesflow.helper_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.exceptions.html">bayesflow.exceptions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.mcmc.html">bayesflow.mcmc module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.version.html">bayesflow.version module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/bayesflow.wrappers.html">bayesflow.wrappers module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../api/bayesflow.experimental.html">bayesflow.experimental package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/bayesflow.experimental.rectifiers.html">bayesflow.experimental.rectifiers module</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Full Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../about.html">About us</a></li>
</ul>

    </div>
</nav></div>
        <div class="sidebar-primary-item">
<div class="rst-versions">
   
  <p class="caption" aria-level="2" role="heading"><span class="caption-text">Tags</span></p>
  <ul>
      <li><a href="/v1.1.6/_modules/scipy/stats/_stats_py.html" >v1.1.6</a></li>
  </ul>
  
   
  <p class="caption" aria-level="2" role="heading"><span class="caption-text">Branches</span></p>
  <ul>
      <li><a href="/dev/_modules/scipy/stats/_stats_py.html" >dev</a></li>
      <li><a href="/master/_modules/scipy/stats/_stats_py.html" class="current">master</a></li>
  </ul>
  
</div>
</div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/bayesflow-org/bayesflow" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/bayesflow-org/bayesflow/issues/new?title=Issue%20on%20page%20%2F_modules/scipy/stats/_stats_py.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for scipy.stats._stats_py</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2002 Gary Strangman.  All rights reserved</span>
<span class="c1"># Copyright 2002-2016 The SciPy Developers</span>
<span class="c1">#</span>
<span class="c1"># The original code from Gary Strangman was heavily adapted for</span>
<span class="c1"># use in SciPy by Travis Oliphant.  The original code came with the</span>
<span class="c1"># following disclaimer:</span>
<span class="c1">#</span>
<span class="c1"># This software is provided &quot;as-is&quot;.  There are no expressed or implied</span>
<span class="c1"># warranties of any kind, including, but not limited to, the warranties</span>
<span class="c1"># of merchantability and fitness for a given application.  In no event</span>
<span class="c1"># shall Gary Strangman be liable for any direct, indirect, incidental,</span>
<span class="c1"># special, exemplary or consequential damages (including, but not limited</span>
<span class="c1"># to, loss of use, data or profits, or business interruption) however</span>
<span class="c1"># caused and on any theory of liability, whether in contract, strict</span>
<span class="c1"># liability or tort (including negligence or otherwise) arising in any way</span>
<span class="c1"># out of the use of this software, even if advised of the possibility of</span>
<span class="c1"># such damage.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A collection of basic statistical functions for Python.</span>

<span class="sd">References</span>
<span class="sd">----------</span>
<span class="sd">.. [CRCProbStat2000] Zwillinger, D. and Kokoska, S. (2000). CRC Standard</span>
<span class="sd">   Probability and Statistics Tables and Formulae. Chapman &amp; Hall: New</span>
<span class="sd">   York. 2000.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">gcd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">namedtuple</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="kn">import</span> <span class="n">array</span><span class="p">,</span> <span class="n">asarray</span><span class="p">,</span> <span class="n">ma</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.spatial.distance</span><span class="w"> </span><span class="kn">import</span> <span class="n">cdist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.ndimage</span><span class="w"> </span><span class="kn">import</span> <span class="n">_measurements</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy._lib._util</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">check_random_state</span><span class="p">,</span> <span class="n">MapWrapper</span><span class="p">,</span> <span class="n">_get_nan</span><span class="p">,</span>
                              <span class="n">rng_integers</span><span class="p">,</span> <span class="n">_rename_parameter</span><span class="p">,</span> <span class="n">_contains_nan</span><span class="p">,</span>
                              <span class="n">AxisError</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.special</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">special</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">linalg</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.</span><span class="w"> </span><span class="kn">import</span> <span class="n">distributions</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.</span><span class="w"> </span><span class="kn">import</span> <span class="n">_mstats_basic</span> <span class="k">as</span> <span class="n">mstats_basic</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._stats_mstats_common</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">_find_repeats</span><span class="p">,</span> <span class="n">linregress</span><span class="p">,</span> <span class="n">theilslopes</span><span class="p">,</span>
                                   <span class="n">siegelslopes</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._stats</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">_kendall_dis</span><span class="p">,</span> <span class="n">_toint64</span><span class="p">,</span> <span class="n">_weightedrankedtau</span><span class="p">,</span>
                     <span class="n">_local_correlations</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._hypotests</span><span class="w"> </span><span class="kn">import</span> <span class="n">_all_partitions</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._stats_pythran</span><span class="w"> </span><span class="kn">import</span> <span class="n">_compute_outer_prob_inside_method</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._resampling</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">MonteCarloMethod</span><span class="p">,</span> <span class="n">PermutationMethod</span><span class="p">,</span> <span class="n">BootstrapMethod</span><span class="p">,</span>
                          <span class="n">monte_carlo_test</span><span class="p">,</span> <span class="n">permutation_test</span><span class="p">,</span> <span class="n">bootstrap</span><span class="p">,</span>
                          <span class="n">_batch_generator</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._axis_nan_policy</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">_axis_nan_policy_factory</span><span class="p">,</span>
                               <span class="n">_broadcast_concatenate</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._binomtest</span><span class="w"> </span><span class="kn">import</span> <span class="n">_binary_search_for_binom_tst</span> <span class="k">as</span> <span class="n">_binary_search</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy._lib._bunch</span><span class="w"> </span><span class="kn">import</span> <span class="n">_make_tuple_bunch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">root_scalar</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy._lib.deprecation</span><span class="w"> </span><span class="kn">import</span> <span class="n">_NoValue</span><span class="p">,</span> <span class="n">_deprecate_positional_args</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy._lib._util</span><span class="w"> </span><span class="kn">import</span> <span class="n">normalize_axis_index</span>

<span class="c1"># In __all__ but deprecated for removal in SciPy 1.13.0</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy._lib._util</span><span class="w"> </span><span class="kn">import</span> <span class="n">float_factorial</span>  <span class="c1"># noqa: F401</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats._mstats_basic</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>  <span class="c1"># noqa: F401</span>
    <span class="n">PointbiserialrResult</span><span class="p">,</span> <span class="n">Ttest_1sampResult</span><span class="p">,</span>  <span class="n">Ttest_relResult</span>
<span class="p">)</span>


<span class="c1"># Functions/classes in other files should be added in `__init__.py`, not here</span>
<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;find_repeats&#39;</span><span class="p">,</span> <span class="s1">&#39;gmean&#39;</span><span class="p">,</span> <span class="s1">&#39;hmean&#39;</span><span class="p">,</span> <span class="s1">&#39;pmean&#39;</span><span class="p">,</span> <span class="s1">&#39;mode&#39;</span><span class="p">,</span> <span class="s1">&#39;tmean&#39;</span><span class="p">,</span> <span class="s1">&#39;tvar&#39;</span><span class="p">,</span>
           <span class="s1">&#39;tmin&#39;</span><span class="p">,</span> <span class="s1">&#39;tmax&#39;</span><span class="p">,</span> <span class="s1">&#39;tstd&#39;</span><span class="p">,</span> <span class="s1">&#39;tsem&#39;</span><span class="p">,</span> <span class="s1">&#39;moment&#39;</span><span class="p">,</span>
           <span class="s1">&#39;skew&#39;</span><span class="p">,</span> <span class="s1">&#39;kurtosis&#39;</span><span class="p">,</span> <span class="s1">&#39;describe&#39;</span><span class="p">,</span> <span class="s1">&#39;skewtest&#39;</span><span class="p">,</span> <span class="s1">&#39;kurtosistest&#39;</span><span class="p">,</span>
           <span class="s1">&#39;normaltest&#39;</span><span class="p">,</span> <span class="s1">&#39;jarque_bera&#39;</span><span class="p">,</span>
           <span class="s1">&#39;scoreatpercentile&#39;</span><span class="p">,</span> <span class="s1">&#39;percentileofscore&#39;</span><span class="p">,</span>
           <span class="s1">&#39;cumfreq&#39;</span><span class="p">,</span> <span class="s1">&#39;relfreq&#39;</span><span class="p">,</span> <span class="s1">&#39;obrientransform&#39;</span><span class="p">,</span>
           <span class="s1">&#39;sem&#39;</span><span class="p">,</span> <span class="s1">&#39;zmap&#39;</span><span class="p">,</span> <span class="s1">&#39;zscore&#39;</span><span class="p">,</span> <span class="s1">&#39;gzscore&#39;</span><span class="p">,</span> <span class="s1">&#39;iqr&#39;</span><span class="p">,</span> <span class="s1">&#39;gstd&#39;</span><span class="p">,</span>
           <span class="s1">&#39;median_abs_deviation&#39;</span><span class="p">,</span>
           <span class="s1">&#39;sigmaclip&#39;</span><span class="p">,</span> <span class="s1">&#39;trimboth&#39;</span><span class="p">,</span> <span class="s1">&#39;trim1&#39;</span><span class="p">,</span> <span class="s1">&#39;trim_mean&#39;</span><span class="p">,</span>
           <span class="s1">&#39;f_oneway&#39;</span><span class="p">,</span> <span class="s1">&#39;pearsonr&#39;</span><span class="p">,</span> <span class="s1">&#39;fisher_exact&#39;</span><span class="p">,</span>
           <span class="s1">&#39;spearmanr&#39;</span><span class="p">,</span> <span class="s1">&#39;pointbiserialr&#39;</span><span class="p">,</span>
           <span class="s1">&#39;kendalltau&#39;</span><span class="p">,</span> <span class="s1">&#39;weightedtau&#39;</span><span class="p">,</span> <span class="s1">&#39;multiscale_graphcorr&#39;</span><span class="p">,</span>
           <span class="s1">&#39;linregress&#39;</span><span class="p">,</span> <span class="s1">&#39;siegelslopes&#39;</span><span class="p">,</span> <span class="s1">&#39;theilslopes&#39;</span><span class="p">,</span> <span class="s1">&#39;ttest_1samp&#39;</span><span class="p">,</span>
           <span class="s1">&#39;ttest_ind&#39;</span><span class="p">,</span> <span class="s1">&#39;ttest_ind_from_stats&#39;</span><span class="p">,</span> <span class="s1">&#39;ttest_rel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;kstest&#39;</span><span class="p">,</span> <span class="s1">&#39;ks_1samp&#39;</span><span class="p">,</span> <span class="s1">&#39;ks_2samp&#39;</span><span class="p">,</span>
           <span class="s1">&#39;chisquare&#39;</span><span class="p">,</span> <span class="s1">&#39;power_divergence&#39;</span><span class="p">,</span>
           <span class="s1">&#39;tiecorrect&#39;</span><span class="p">,</span> <span class="s1">&#39;ranksums&#39;</span><span class="p">,</span> <span class="s1">&#39;kruskal&#39;</span><span class="p">,</span> <span class="s1">&#39;friedmanchisquare&#39;</span><span class="p">,</span>
           <span class="s1">&#39;rankdata&#39;</span><span class="p">,</span> <span class="s1">&#39;combine_pvalues&#39;</span><span class="p">,</span> <span class="s1">&#39;quantile_test&#39;</span><span class="p">,</span>
           <span class="s1">&#39;wasserstein_distance&#39;</span><span class="p">,</span> <span class="s1">&#39;energy_distance&#39;</span><span class="p">,</span>
           <span class="s1">&#39;brunnermunzel&#39;</span><span class="p">,</span> <span class="s1">&#39;alexandergovern&#39;</span><span class="p">,</span>
           <span class="s1">&#39;expectile&#39;</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">outaxis</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">outaxis</span> <span class="o">=</span> <span class="n">axis</span>

    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">a</span><span class="p">,</span> <span class="n">outaxis</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_chk2_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="n">outaxis</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="n">outaxis</span> <span class="o">=</span> <span class="n">axis</span>

    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">outaxis</span>


<span class="n">SignificanceResult</span> <span class="o">=</span> <span class="n">_make_tuple_bunch</span><span class="p">(</span><span class="s1">&#39;SignificanceResult&#39;</span><span class="p">,</span>
                                       <span class="p">[</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">],</span> <span class="p">[])</span>


<span class="c1"># note that `weights` are paired with `x`</span>
<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">too_small</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">paired</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">kwd_samples</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;weights&#39;</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">gmean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the weighted geometric mean along the specified axis.</span>

<span class="sd">    The weighted geometric mean of the array :math:`a_i` associated to weights</span>
<span class="sd">    :math:`w_i` is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \exp \left( \frac{ \sum_{i=1}^n w_i \ln a_i }{ \sum_{i=1}^n w_i }</span>
<span class="sd">                   \right) \, ,</span>

<span class="sd">    and, with equal weights, it gives:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \sqrt[n]{ \prod_{i=1}^n a_i } \, .</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Input array or object that can be converted to an array.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which the geometric mean is computed. Default is 0.</span>
<span class="sd">        If None, compute over the whole array `a`.</span>
<span class="sd">    dtype : dtype, optional</span>
<span class="sd">        Type to which the input arrays are cast before the calculation is</span>
<span class="sd">        performed.</span>
<span class="sd">    weights : array_like, optional</span>
<span class="sd">        The `weights` array must be broadcastable to the same shape as `a`.</span>
<span class="sd">        Default is None, which gives each value a weight of 1.0.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gmean : ndarray</span>
<span class="sd">        See `dtype` parameter above.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.mean : Arithmetic average</span>
<span class="sd">    numpy.average : Weighted average</span>
<span class="sd">    hmean : Harmonic mean</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Weighted Geometric Mean&quot;, *Wikipedia*,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Weighted_geometric_mean.</span>
<span class="sd">    .. [2] Grossman, J., Grossman, M., Katz, R., &quot;Averages: A New Approach&quot;,</span>
<span class="sd">           Archimedes Foundation, 1983</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import gmean</span>
<span class="sd">    &gt;&gt;&gt; gmean([1, 4])</span>
<span class="sd">    2.0</span>
<span class="sd">    &gt;&gt;&gt; gmean([1, 2, 3, 4, 5, 6, 7])</span>
<span class="sd">    3.3800151591412964</span>
<span class="sd">    &gt;&gt;&gt; gmean([1, 4, 7], weights=[3, 1, 3])</span>
<span class="sd">    2.80668351922014</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
        <span class="n">log_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">log_a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">))</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">too_small</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">paired</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">kwd_samples</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;weights&#39;</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">hmean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculate the weighted harmonic mean along the specified axis.</span>

<span class="sd">    The weighted harmonic mean of the array :math:`a_i` associated to weights</span>
<span class="sd">    :math:`w_i` is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{ \sum_{i=1}^n w_i }{ \sum_{i=1}^n \frac{w_i}{a_i} } \, ,</span>

<span class="sd">    and, with equal weights, it gives:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \frac{ n }{ \sum_{i=1}^n \frac{1}{a_i} } \, .</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Input array, masked array or object that can be converted to an array.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which the harmonic mean is computed. Default is 0.</span>
<span class="sd">        If None, compute over the whole array `a`.</span>
<span class="sd">    dtype : dtype, optional</span>
<span class="sd">        Type of the returned array and of the accumulator in which the</span>
<span class="sd">        elements are summed. If `dtype` is not specified, it defaults to the</span>
<span class="sd">        dtype of `a`, unless `a` has an integer `dtype` with a precision less</span>
<span class="sd">        than that of the default platform integer. In that case, the default</span>
<span class="sd">        platform integer is used.</span>
<span class="sd">    weights : array_like, optional</span>
<span class="sd">        The weights array can either be 1-D (in which case its length must be</span>
<span class="sd">        the size of `a` along the given `axis`) or of the same shape as `a`.</span>
<span class="sd">        Default is None, which gives each value a weight of 1.0.</span>

<span class="sd">        .. versionadded:: 1.9</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    hmean : ndarray</span>
<span class="sd">        See `dtype` parameter above.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.mean : Arithmetic average</span>
<span class="sd">    numpy.average : Weighted average</span>
<span class="sd">    gmean : Geometric mean</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The harmonic mean is computed over a single dimension of the input</span>
<span class="sd">    array, axis=0 by default, or all values in the array if axis=None.</span>
<span class="sd">    float64 intermediate and return values are used for integer inputs.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Weighted Harmonic Mean&quot;, *Wikipedia*,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Harmonic_mean#Weighted_harmonic_mean</span>
<span class="sd">    .. [2] Ferger, F., &quot;The nature and use of the harmonic mean&quot;, Journal of</span>
<span class="sd">           the American Statistical Association, vol. 26, pp. 36-40, 1931</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import hmean</span>
<span class="sd">    &gt;&gt;&gt; hmean([1, 4])</span>
<span class="sd">    1.6000000000000001</span>
<span class="sd">    &gt;&gt;&gt; hmean([1, 2, 3, 4, 5, 6, 7])</span>
<span class="sd">    2.6997245179063363</span>
<span class="sd">    &gt;&gt;&gt; hmean([1, 4, 7], weights=[3, 1, 3])</span>
<span class="sd">    1.9029126213592233</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dtype</span><span class="p">:</span>
        <span class="c1"># Must change the default dtype allowing array type</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">MaskedArray</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">a</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="c1"># Harmonic mean only defined if greater than or equal to zero.</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Harmonic mean only defined if all elements greater &quot;</span>
                         <span class="s2">&quot;than or equal to zero&quot;</span><span class="p">)</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">too_small</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">paired</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">kwd_samples</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;weights&#39;</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">pmean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculate the weighted power mean along the specified axis.</span>

<span class="sd">    The weighted power mean of the array :math:`a_i` associated to weights</span>
<span class="sd">    :math:`w_i` is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \left( \frac{ \sum_{i=1}^n w_i a_i^p }{ \sum_{i=1}^n w_i }</span>
<span class="sd">              \right)^{ 1 / p } \, ,</span>

<span class="sd">    and, with equal weights, it gives:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \left( \frac{ 1 }{ n } \sum_{i=1}^n a_i^p \right)^{ 1 / p }  \, .</span>

<span class="sd">    When ``p=0``, it returns the geometric mean.</span>

<span class="sd">    This mean is also called generalized mean or Hlder mean, and must not be</span>
<span class="sd">    confused with the Kolmogorov generalized mean, also called</span>
<span class="sd">    quasi-arithmetic mean or generalized f-mean [3]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Input array, masked array or object that can be converted to an array.</span>
<span class="sd">    p : int or float</span>
<span class="sd">        Exponent.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which the power mean is computed. Default is 0.</span>
<span class="sd">        If None, compute over the whole array `a`.</span>
<span class="sd">    dtype : dtype, optional</span>
<span class="sd">        Type of the returned array and of the accumulator in which the</span>
<span class="sd">        elements are summed. If `dtype` is not specified, it defaults to the</span>
<span class="sd">        dtype of `a`, unless `a` has an integer `dtype` with a precision less</span>
<span class="sd">        than that of the default platform integer. In that case, the default</span>
<span class="sd">        platform integer is used.</span>
<span class="sd">    weights : array_like, optional</span>
<span class="sd">        The weights array can either be 1-D (in which case its length must be</span>
<span class="sd">        the size of `a` along the given `axis`) or of the same shape as `a`.</span>
<span class="sd">        Default is None, which gives each value a weight of 1.0.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pmean : ndarray, see `dtype` parameter above.</span>
<span class="sd">        Output array containing the power mean values.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.average : Weighted average</span>
<span class="sd">    gmean : Geometric mean</span>
<span class="sd">    hmean : Harmonic mean</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The power mean is computed over a single dimension of the input</span>
<span class="sd">    array, ``axis=0`` by default, or all values in the array if ``axis=None``.</span>
<span class="sd">    float64 intermediate and return values are used for integer inputs.</span>

<span class="sd">    .. versionadded:: 1.9</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Generalized Mean&quot;, *Wikipedia*,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Generalized_mean</span>
<span class="sd">    .. [2] Norris, N., &quot;Convexity properties of generalized mean value</span>
<span class="sd">           functions&quot;, The Annals of Mathematical Statistics, vol. 8,</span>
<span class="sd">           pp. 118-120, 1937</span>
<span class="sd">    .. [3] Bullen, P.S., Handbook of Means and Their Inequalities, 2003</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import pmean, hmean, gmean</span>
<span class="sd">    &gt;&gt;&gt; pmean([1, 4], 1.3)</span>
<span class="sd">    2.639372938300652</span>
<span class="sd">    &gt;&gt;&gt; pmean([1, 2, 3, 4, 5, 6, 7], 1.3)</span>
<span class="sd">    4.157111214492084</span>
<span class="sd">    &gt;&gt;&gt; pmean([1, 4, 7], -2, weights=[3, 1, 3])</span>
<span class="sd">    1.4969684896631954</span>

<span class="sd">    For p=-1, power mean is equal to harmonic mean:</span>

<span class="sd">    &gt;&gt;&gt; pmean([1, 4, 7], -1, weights=[3, 1, 3])</span>
<span class="sd">    1.9029126213592233</span>
<span class="sd">    &gt;&gt;&gt; hmean([1, 4, 7], weights=[3, 1, 3])</span>
<span class="sd">    1.9029126213592233</span>

<span class="sd">    For p=0, power mean is defined as the geometric mean:</span>

<span class="sd">    &gt;&gt;&gt; pmean([1, 4, 7], 0, weights=[3, 1, 3])</span>
<span class="sd">    2.80668351922014</span>
<span class="sd">    &gt;&gt;&gt; gmean([1, 4, 7], weights=[3, 1, 3])</span>
<span class="sd">    2.80668351922014</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Power mean only defined for exponent of type int or &quot;</span>
                         <span class="s2">&quot;float.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gmean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dtype</span><span class="p">:</span>
        <span class="c1"># Must change the default dtype allowing array type</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">MaskedArray</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">a</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="c1"># Power mean only defined if greater than or equal to zero</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">float_power</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float_power</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">),</span>
                <span class="mi">1</span><span class="o">/</span><span class="n">p</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Power mean only defined if all elements greater &quot;</span>
                         <span class="s2">&quot;than or equal to zero&quot;</span><span class="p">)</span>


<span class="n">ModeResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;ModeResult&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;mode&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_mode_result</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
    <span class="c1"># When a slice is empty, `_axis_nan_policy` automatically produces</span>
    <span class="c1"># NaN for `mode` and `count`. This is a reasonable convention for `mode`,</span>
    <span class="c1"># but `count` should not be NaN; it should be zero.</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">():</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">count</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="k">else</span> <span class="n">count</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">count</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">ModeResult</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span><span class="n">_mode_result</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;vectorization&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                                  <span class="s1">&#39;nan_propagation&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>
<span class="k">def</span><span class="w"> </span><span class="nf">mode</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return an array of the modal (most common) value in the passed array.</span>

<span class="sd">    If there is more than one such value, only one is returned.</span>
<span class="sd">    The bin-count for the modal bins is also returned.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Numeric, n-dimensional array of which to find mode(s).</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to operate. Default is 0. If None, compute over</span>
<span class="sd">        the whole array `a`.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: treats nan as it would treat any other value</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>
<span class="sd">    keepdims : bool, optional</span>
<span class="sd">        If set to ``False``, the `axis` over which the statistic is taken</span>
<span class="sd">        is consumed (eliminated from the output array). If set to ``True``,</span>
<span class="sd">        the `axis` is retained with size one, and the result will broadcast</span>
<span class="sd">        correctly against the input array.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mode : ndarray</span>
<span class="sd">        Array of modal values.</span>
<span class="sd">    count : ndarray</span>
<span class="sd">        Array of counts for each mode.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The mode  is calculated using `numpy.unique`.</span>
<span class="sd">    In NumPy versions 1.21 and after, all NaNs - even those with different</span>
<span class="sd">    binary representations - are treated as equivalent and counted as separate</span>
<span class="sd">    instances of the same value.</span>

<span class="sd">    By convention, the mode of an empty array is NaN, and the associated count</span>
<span class="sd">    is zero.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; a = np.array([[3, 0, 3, 7],</span>
<span class="sd">    ...               [3, 2, 6, 2],</span>
<span class="sd">    ...               [1, 7, 2, 8],</span>
<span class="sd">    ...               [3, 0, 6, 1],</span>
<span class="sd">    ...               [3, 2, 5, 5]])</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; stats.mode(a, keepdims=True)</span>
<span class="sd">    ModeResult(mode=array([[3, 0, 6, 1]]), count=array([[4, 2, 2, 1]]))</span>

<span class="sd">    To get mode of whole array, specify ``axis=None``:</span>

<span class="sd">    &gt;&gt;&gt; stats.mode(a, axis=None, keepdims=True)</span>
<span class="sd">    ModeResult(mode=[[3]], count=[[5]])</span>
<span class="sd">    &gt;&gt;&gt; stats.mode(a, axis=None, keepdims=False)</span>
<span class="sd">    ModeResult(mode=3, count=5)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># `axis`, `nan_policy`, and `keepdims` are handled by `_axis_nan_policy`</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">):</span>
        <span class="n">message</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Argument `a` is not recognized as numeric. &quot;</span>
                   <span class="s2">&quot;Support for input that cannot be coerced to a numeric &quot;</span>
                   <span class="s2">&quot;array was deprecated in SciPy 1.9.0 and removed in SciPy &quot;</span>
                   <span class="s2">&quot;1.11.0. Please consider `np.unique`.&quot;</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">NaN</span> <span class="o">=</span> <span class="n">_get_nan</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ModeResult</span><span class="p">(</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">NaN</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">NaN</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

    <span class="n">vals</span><span class="p">,</span> <span class="n">cnts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">modes</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">vals</span><span class="p">[</span><span class="n">cnts</span><span class="o">.</span><span class="n">argmax</span><span class="p">()],</span> <span class="n">cnts</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ModeResult</span><span class="p">(</span><span class="n">modes</span><span class="p">[()],</span> <span class="n">counts</span><span class="p">[()])</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_put_nan_to_limits</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">limits</span><span class="p">,</span> <span class="n">inclusive</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Put NaNs in an array for values outside of given limits.</span>

<span class="sd">    This is primarily a utility function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array</span>
<span class="sd">    limits : (float or None, float or None)</span>
<span class="sd">        A tuple consisting of the (lower limit, upper limit).  Values in the</span>
<span class="sd">        input array less than the lower limit or greater than the upper limit</span>
<span class="sd">        will be replaced with `np.nan`. None implies no limit.</span>
<span class="sd">    inclusive : (bool, bool)</span>
<span class="sd">        A tuple consisting of the (lower flag, upper flag).  These flags</span>
<span class="sd">        determine whether values exactly equal to lower or upper are allowed.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">limits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">a</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
    <span class="n">lower_limit</span><span class="p">,</span> <span class="n">upper_limit</span> <span class="o">=</span> <span class="n">limits</span>
    <span class="n">lower_include</span><span class="p">,</span> <span class="n">upper_include</span> <span class="o">=</span> <span class="n">inclusive</span>
    <span class="k">if</span> <span class="n">lower_limit</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">|=</span> <span class="p">(</span><span class="n">a</span> <span class="o">&lt;</span> <span class="n">lower_limit</span><span class="p">)</span> <span class="k">if</span> <span class="n">lower_include</span> <span class="k">else</span> <span class="n">a</span> <span class="o">&lt;=</span> <span class="n">lower_limit</span>
    <span class="k">if</span> <span class="n">upper_limit</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">|=</span> <span class="p">(</span><span class="n">a</span> <span class="o">&gt;</span> <span class="n">upper_limit</span><span class="p">)</span> <span class="k">if</span> <span class="n">upper_include</span> <span class="k">else</span> <span class="n">a</span> <span class="o">&gt;=</span> <span class="n">upper_limit</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No array values within given limits&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inexact</span><span class="p">)</span> <span class="k">else</span> <span class="n">a</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">a</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">return</span> <span class="n">a</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">default_axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">tmean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">limits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the trimmed mean.</span>

<span class="sd">    This function finds the arithmetic mean of given values, ignoring values</span>
<span class="sd">    outside the given `limits`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array of values.</span>
<span class="sd">    limits : None or (lower limit, upper limit), optional</span>
<span class="sd">        Values in the input array less than the lower limit or greater than the</span>
<span class="sd">        upper limit will be ignored.  When limits is None (default), then all</span>
<span class="sd">        values are used.  Either of the limit values in the tuple can also be</span>
<span class="sd">        None representing a half-open interval.</span>
<span class="sd">    inclusive : (bool, bool), optional</span>
<span class="sd">        A tuple consisting of the (lower flag, upper flag).  These flags</span>
<span class="sd">        determine whether values exactly equal to the lower or upper limits</span>
<span class="sd">        are included.  The default value is (True, True).</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to compute test. Default is None.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tmean : ndarray</span>
<span class="sd">        Trimmed mean.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    trim_mean : Returns mean after trimming a proportion from both tails.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x = np.arange(20)</span>
<span class="sd">    &gt;&gt;&gt; stats.tmean(x)</span>
<span class="sd">    9.5</span>
<span class="sd">    &gt;&gt;&gt; stats.tmean(x, (3,17))</span>
<span class="sd">    10.0</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">_put_nan_to_limits</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">limits</span><span class="p">,</span> <span class="n">inclusive</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">tvar</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">limits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the trimmed variance.</span>

<span class="sd">    This function computes the sample variance of an array of values,</span>
<span class="sd">    while ignoring values which are outside of given `limits`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array of values.</span>
<span class="sd">    limits : None or (lower limit, upper limit), optional</span>
<span class="sd">        Values in the input array less than the lower limit or greater than the</span>
<span class="sd">        upper limit will be ignored. When limits is None, then all values are</span>
<span class="sd">        used. Either of the limit values in the tuple can also be None</span>
<span class="sd">        representing a half-open interval.  The default value is None.</span>
<span class="sd">    inclusive : (bool, bool), optional</span>
<span class="sd">        A tuple consisting of the (lower flag, upper flag).  These flags</span>
<span class="sd">        determine whether values exactly equal to the lower or upper limits</span>
<span class="sd">        are included.  The default value is (True, True).</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to operate. Default is 0. If None, compute over the</span>
<span class="sd">        whole array `a`.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        Delta degrees of freedom.  Default is 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tvar : float</span>
<span class="sd">        Trimmed variance.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    `tvar` computes the unbiased sample variance, i.e. it uses a correction</span>
<span class="sd">    factor ``n / (n - 1)``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x = np.arange(20)</span>
<span class="sd">    &gt;&gt;&gt; stats.tvar(x)</span>
<span class="sd">    35.0</span>
<span class="sd">    &gt;&gt;&gt; stats.tvar(x, (3,17))</span>
<span class="sd">    20.0</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">_put_nan_to_limits</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">limits</span><span class="p">,</span> <span class="n">inclusive</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nanvar</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">tmin</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">lowerlimit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the trimmed minimum.</span>

<span class="sd">    This function finds the minimum value of an array `a` along the</span>
<span class="sd">    specified axis, but only considering values greater than a specified</span>
<span class="sd">    lower limit.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array of values.</span>
<span class="sd">    lowerlimit : None or float, optional</span>
<span class="sd">        Values in the input array less than the given limit will be ignored.</span>
<span class="sd">        When lowerlimit is None, then all values are used. The default value</span>
<span class="sd">        is None.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to operate. Default is 0. If None, compute over the</span>
<span class="sd">        whole array `a`.</span>
<span class="sd">    inclusive : {True, False}, optional</span>
<span class="sd">        This flag determines whether values exactly equal to the lower limit</span>
<span class="sd">        are included.  The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tmin : float, int or ndarray</span>
<span class="sd">        Trimmed minimum.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x = np.arange(20)</span>
<span class="sd">    &gt;&gt;&gt; stats.tmin(x)</span>
<span class="sd">    0</span>

<span class="sd">    &gt;&gt;&gt; stats.tmin(x, 13)</span>
<span class="sd">    13</span>

<span class="sd">    &gt;&gt;&gt; stats.tmin(x, 13, inclusive=False)</span>
<span class="sd">    14</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">_put_nan_to_limits</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="n">lowerlimit</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="p">(</span><span class="n">inclusive</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmin</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">res</span><span class="p">)):</span>
        <span class="c1"># needed if input is of integer dtype</span>
        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">tmax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">upperlimit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the trimmed maximum.</span>

<span class="sd">    This function computes the maximum value of an array along a given axis,</span>
<span class="sd">    while ignoring values larger than a specified upper limit.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array of values.</span>
<span class="sd">    upperlimit : None or float, optional</span>
<span class="sd">        Values in the input array greater than the given limit will be ignored.</span>
<span class="sd">        When upperlimit is None, then all values are used. The default value</span>
<span class="sd">        is None.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to operate. Default is 0. If None, compute over the</span>
<span class="sd">        whole array `a`.</span>
<span class="sd">    inclusive : {True, False}, optional</span>
<span class="sd">        This flag determines whether values exactly equal to the upper limit</span>
<span class="sd">        are included.  The default value is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tmax : float, int or ndarray</span>
<span class="sd">        Trimmed maximum.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x = np.arange(20)</span>
<span class="sd">    &gt;&gt;&gt; stats.tmax(x)</span>
<span class="sd">    19</span>

<span class="sd">    &gt;&gt;&gt; stats.tmax(x, 13)</span>
<span class="sd">    13</span>

<span class="sd">    &gt;&gt;&gt; stats.tmax(x, 13, inclusive=False)</span>
<span class="sd">    12</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">_put_nan_to_limits</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">upperlimit</span><span class="p">),</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">inclusive</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">res</span><span class="p">)):</span>
        <span class="c1"># needed if input is of integer dtype</span>
        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">tstd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">limits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the trimmed sample standard deviation.</span>

<span class="sd">    This function finds the sample standard deviation of given values,</span>
<span class="sd">    ignoring values outside the given `limits`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array of values.</span>
<span class="sd">    limits : None or (lower limit, upper limit), optional</span>
<span class="sd">        Values in the input array less than the lower limit or greater than the</span>
<span class="sd">        upper limit will be ignored. When limits is None, then all values are</span>
<span class="sd">        used. Either of the limit values in the tuple can also be None</span>
<span class="sd">        representing a half-open interval.  The default value is None.</span>
<span class="sd">    inclusive : (bool, bool), optional</span>
<span class="sd">        A tuple consisting of the (lower flag, upper flag).  These flags</span>
<span class="sd">        determine whether values exactly equal to the lower or upper limits</span>
<span class="sd">        are included.  The default value is (True, True).</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to operate. Default is 0. If None, compute over the</span>
<span class="sd">        whole array `a`.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        Delta degrees of freedom.  Default is 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tstd : float</span>
<span class="sd">        Trimmed sample standard deviation.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    `tstd` computes the unbiased sample standard deviation, i.e. it uses a</span>
<span class="sd">    correction factor ``n / (n - 1)``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x = np.arange(20)</span>
<span class="sd">    &gt;&gt;&gt; stats.tstd(x)</span>
<span class="sd">    5.9160797830996161</span>
<span class="sd">    &gt;&gt;&gt; stats.tstd(x, (3,17))</span>
<span class="sd">    4.4721359549995796</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tvar</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">limits</span><span class="p">,</span> <span class="n">inclusive</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="p">,</span> <span class="n">_no_deco</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">tsem</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">limits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the trimmed standard error of the mean.</span>

<span class="sd">    This function finds the standard error of the mean for given</span>
<span class="sd">    values, ignoring values outside the given `limits`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array of values.</span>
<span class="sd">    limits : None or (lower limit, upper limit), optional</span>
<span class="sd">        Values in the input array less than the lower limit or greater than the</span>
<span class="sd">        upper limit will be ignored. When limits is None, then all values are</span>
<span class="sd">        used. Either of the limit values in the tuple can also be None</span>
<span class="sd">        representing a half-open interval.  The default value is None.</span>
<span class="sd">    inclusive : (bool, bool), optional</span>
<span class="sd">        A tuple consisting of the (lower flag, upper flag).  These flags</span>
<span class="sd">        determine whether values exactly equal to the lower or upper limits</span>
<span class="sd">        are included.  The default value is (True, True).</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to operate. Default is 0. If None, compute over the</span>
<span class="sd">        whole array `a`.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        Delta degrees of freedom.  Default is 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tsem : float</span>
<span class="sd">        Trimmed standard error of the mean.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    `tsem` uses unbiased sample standard deviation, i.e. it uses a</span>
<span class="sd">    correction factor ``n / (n - 1)``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x = np.arange(20)</span>
<span class="sd">    &gt;&gt;&gt; stats.tsem(x)</span>
<span class="sd">    1.3228756555322954</span>
<span class="sd">    &gt;&gt;&gt; stats.tsem(x, (3,17))</span>
<span class="sd">    1.1547005383792515</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">_put_nan_to_limits</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">limits</span><span class="p">,</span> <span class="n">inclusive</span><span class="p">)</span>
    <span class="n">sd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nanvar</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">))</span>
    <span class="n">n_obs</span> <span class="o">=</span> <span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">a</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sd</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">sd</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>


<span class="c1">#####################################</span>
<span class="c1">#              MOMENTS              #</span>
<span class="c1">#####################################</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_moment_outputs</span><span class="p">(</span><span class="n">kwds</span><span class="p">):</span>
    <span class="n">moment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">kwds</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;moment&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">moment</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&#39;moment&#39; must be a scalar or a non-empty 1D &quot;</span>
                         <span class="s2">&quot;list/array.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">moment</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_moment_result_object</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>

<span class="c1"># `moment` fits into the `_axis_nan_policy` pattern, but it is a bit unusual</span>
<span class="c1"># because the number of outputs is variable. Specifically,</span>
<span class="c1"># `result_to_tuple=lambda x: (x,)` may be surprising for a function that</span>
<span class="c1"># can produce more than one output, but it is intended here.</span>
<span class="c1"># When `moment is called to produce the output:</span>
<span class="c1"># - `result_to_tuple` packs the returned array into a single-element tuple,</span>
<span class="c1"># - `_moment_result_object` extracts and returns that single element.</span>
<span class="c1"># However, when the input array is empty, `moment` is never called. Instead,</span>
<span class="c1"># - `_check_empty_inputs` is used to produce an empty array with the</span>
<span class="c1">#   appropriate dimensions.</span>
<span class="c1"># - A list comprehension creates the appropriate number of copies of this</span>
<span class="c1">#   array, depending on `n_outputs`.</span>
<span class="c1"># - This list - which may have multiple elements - is passed into</span>
<span class="c1">#   `_moment_result_object`.</span>
<span class="c1"># - If there is a single output, `_moment_result_object` extracts and returns</span>
<span class="c1">#   the single output from the list.</span>
<span class="c1"># - If there are multiple outputs, and therefore multiple elements in the list,</span>
<span class="c1">#   `_moment_result_object` converts the list of arrays to a single array and</span>
<span class="c1">#   returns it.</span>
<span class="c1"># Currently this leads to a slight inconsistency: when the input array is</span>
<span class="c1"># empty, there is no distinction between the `moment` function being called</span>
<span class="c1"># with parameter `moments=1` and `moments=[1]`; the latter *should* produce</span>
<span class="c1"># the same as the former but with a singleton zeroth dimension.</span>
<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>  <span class="c1"># noqa: E302</span>
    <span class="n">_moment_result_object</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span>
    <span class="n">n_outputs</span><span class="o">=</span><span class="n">_moment_outputs</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">moment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">moment</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculate the nth moment about the mean for a sample.</span>

<span class="sd">    A moment is a specific quantitative measure of the shape of a set of</span>
<span class="sd">    points. It is often used to calculate coefficients of skewness and kurtosis</span>
<span class="sd">    due to its close relationship with them.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">       Input array.</span>
<span class="sd">    moment : int or array_like of ints, optional</span>
<span class="sd">       Order of central moment that is returned. Default is 1.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">       Axis along which the central moment is computed. Default is 0.</span>
<span class="sd">       If None, compute over the whole array `a`.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    center : float or None, optional</span>
<span class="sd">       The point about which moments are taken. This can be the sample mean,</span>
<span class="sd">       the origin, or any other be point. If `None` (default) compute the</span>
<span class="sd">       center as the sample mean.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    n-th moment about the `center` : ndarray or float</span>
<span class="sd">       The appropriate moment along the given axis or over all values if axis</span>
<span class="sd">       is None. The denominator for the moment calculation is the number of</span>
<span class="sd">       observations, no degrees of freedom correction is done.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    kurtosis, skew, describe</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The k-th moment of a data sample is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        m_k = \frac{1}{n} \sum_{i = 1}^n (x_i - c)^k</span>

<span class="sd">    Where `n` is the number of samples, and `c` is the center around which the</span>
<span class="sd">    moment is calculated. This function uses exponentiation by squares [1]_ for</span>
<span class="sd">    efficiency.</span>

<span class="sd">    Note that, if `a` is an empty array (``a.size == 0``), array `moment` with</span>
<span class="sd">    one element (`moment.size == 1`) is treated the same as scalar `moment`</span>
<span class="sd">    (``np.isscalar(moment)``). This might produce arrays of unexpected shape.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] https://eli.thegreenplace.net/2009/03/21/efficient-integer-exponentiation-algorithms</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import moment</span>
<span class="sd">    &gt;&gt;&gt; moment([1, 2, 3, 4, 5], moment=1)</span>
<span class="sd">    0.0</span>
<span class="sd">    &gt;&gt;&gt; moment([1, 2, 3, 4, 5], moment=2)</span>
<span class="sd">    2.0</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="c1"># for array_like moment input, return a value for each.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">moment</span><span class="p">):</span>
        <span class="c1"># Calculated the mean once at most, and only if it will be used</span>
        <span class="n">calculate_mean</span> <span class="o">=</span> <span class="n">center</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">moment</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">calculate_mean</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">mmnt</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">moment</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">center</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">mmnt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_moment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">mmnt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_moment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">center</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mmnt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_moment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">moment</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">center</span><span class="p">)</span>


<span class="c1"># Moment with optional pre-computed mean, equal to a.mean(axis, keepdims=True)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_moment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">moment</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">moment</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">moment</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;All moment parameters must be integers&quot;</span><span class="p">)</span>

    <span class="c1"># moment of empty array is the same regardless of order</span>
    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">type</span> <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="ow">in</span> <span class="s1">&#39;fc&#39;</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span>

    <span class="k">if</span> <span class="n">moment</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span><span class="n">moment</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
        <span class="c1"># By definition the zeroth moment is always 1, and the first *central*</span>
        <span class="c1"># moment is 0.</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">dtype</span><span class="p">(</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">moment</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span> <span class="k">if</span> <span class="n">moment</span> <span class="o">==</span> <span class="mi">0</span>
                    <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Exponentiation by squares: form exponent sequence</span>
        <span class="n">n_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">moment</span><span class="p">]</span>
        <span class="n">current_n</span> <span class="o">=</span> <span class="n">moment</span>
        <span class="k">while</span> <span class="n">current_n</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">current_n</span> <span class="o">%</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">current_n</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">current_n</span> <span class="o">/=</span> <span class="mi">2</span>
            <span class="n">n_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_n</span><span class="p">)</span>

        <span class="c1"># Starting point for exponentiation by squares</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)[()])</span>
        <span class="n">a_zero_mean</span> <span class="o">=</span> <span class="n">a</span> <span class="o">-</span> <span class="n">mean</span>

        <span class="n">eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">a_zero_mean</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">resolution</span> <span class="o">*</span> <span class="mi">10</span>
        <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">invalid</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
            <span class="n">rel_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a_zero_mean</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                              <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">invalid</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
            <span class="n">precision_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">rel_diff</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span>
        <span class="k">if</span> <span class="n">precision_loss</span> <span class="ow">and</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Precision loss occurred in moment calculation due to &quot;</span>
                       <span class="s2">&quot;catastrophic cancellation. This occurs when the data &quot;</span>
                       <span class="s2">&quot;are nearly identical. Results may be unreliable.&quot;</span><span class="p">)</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">a_zero_mean</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">a_zero_mean</span><span class="o">**</span><span class="mi">2</span>

        <span class="c1"># Perform multiplications</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">n_list</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">**</span><span class="mi">2</span>
            <span class="k">if</span> <span class="n">n</span> <span class="o">%</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">s</span> <span class="o">*=</span> <span class="n">a_zero_mean</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># Calculate variance of sample, warning if precision is lost</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">_moment</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ddof</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span>
        <span class="n">var</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="o">-</span><span class="n">ddof</span><span class="p">)</span>  <span class="c1"># to avoid error on division by zero</span>
    <span class="k">return</span> <span class="n">var</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">skew</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the sample skewness of a data set.</span>

<span class="sd">    For normally distributed data, the skewness should be about zero. For</span>
<span class="sd">    unimodal continuous distributions, a skewness value greater than zero means</span>
<span class="sd">    that there is more weight in the right tail of the distribution. The</span>
<span class="sd">    function `skewtest` can be used to determine if the skewness value</span>
<span class="sd">    is close enough to zero, statistically speaking.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : ndarray</span>
<span class="sd">        Input array.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which skewness is calculated. Default is 0.</span>
<span class="sd">        If None, compute over the whole array `a`.</span>
<span class="sd">    bias : bool, optional</span>
<span class="sd">        If False, then the calculations are corrected for statistical bias.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    skewness : ndarray</span>
<span class="sd">        The skewness of values along an axis, returning NaN where all values</span>
<span class="sd">        are equal.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The sample skewness is computed as the Fisher-Pearson coefficient</span>
<span class="sd">    of skewness, i.e.</span>

<span class="sd">    .. math::</span>

<span class="sd">        g_1=\frac{m_3}{m_2^{3/2}}</span>

<span class="sd">    where</span>

<span class="sd">    .. math::</span>

<span class="sd">        m_i=\frac{1}{N}\sum_{n=1}^N(x[n]-\bar{x})^i</span>

<span class="sd">    is the biased sample :math:`i\texttt{th}` central moment, and</span>
<span class="sd">    :math:`\bar{x}` is</span>
<span class="sd">    the sample mean.  If ``bias`` is False, the calculations are</span>
<span class="sd">    corrected for bias and the value computed is the adjusted</span>
<span class="sd">    Fisher-Pearson standardized moment coefficient, i.e.</span>

<span class="sd">    .. math::</span>

<span class="sd">        G_1=\frac{k_3}{k_2^{3/2}}=</span>
<span class="sd">            \frac{\sqrt{N(N-1)}}{N-2}\frac{m_3}{m_2^{3/2}}.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard</span>
<span class="sd">       Probability and Statistics Tables and Formulae. Chapman &amp; Hall: New</span>
<span class="sd">       York. 2000.</span>
<span class="sd">       Section 2.2.24.1</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import skew</span>
<span class="sd">    &gt;&gt;&gt; skew([1, 2, 3, 4, 5])</span>
<span class="sd">    0.0</span>
<span class="sd">    &gt;&gt;&gt; skew([2, 8, 0, 4, 1, 9, 9, 0])</span>
<span class="sd">    0.2650554122698573</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>

    <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>

    <span class="n">mean</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">m2</span> <span class="o">=</span> <span class="n">_moment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>
    <span class="n">m3</span> <span class="o">=</span> <span class="n">_moment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="nb">all</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
        <span class="n">zero</span> <span class="o">=</span> <span class="p">(</span><span class="n">m2</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">m2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">resolution</span> <span class="o">*</span> <span class="n">mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">axis</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">zero</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">m3</span> <span class="o">/</span> <span class="n">m2</span><span class="o">**</span><span class="mf">1.5</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">bias</span><span class="p">:</span>
        <span class="n">can_correct</span> <span class="o">=</span> <span class="o">~</span><span class="n">zero</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">n</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">can_correct</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">m2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">can_correct</span><span class="p">,</span> <span class="n">m2</span><span class="p">)</span>
            <span class="n">m3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">can_correct</span><span class="p">,</span> <span class="n">m3</span><span class="p">)</span>
            <span class="n">nval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">m3</span> <span class="o">/</span> <span class="n">m2</span><span class="o">**</span><span class="mf">1.5</span>
            <span class="n">np</span><span class="o">.</span><span class="n">place</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="n">can_correct</span><span class="p">,</span> <span class="n">nval</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">vals</span><span class="p">[()]</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kurtosis</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fisher</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the kurtosis (Fisher or Pearson) of a dataset.</span>

<span class="sd">    Kurtosis is the fourth central moment divided by the square of the</span>
<span class="sd">    variance. If Fisher&#39;s definition is used, then 3.0 is subtracted from</span>
<span class="sd">    the result to give 0.0 for a normal distribution.</span>

<span class="sd">    If bias is False then the kurtosis is calculated using k statistics to</span>
<span class="sd">    eliminate bias coming from biased moment estimators</span>

<span class="sd">    Use `kurtosistest` to see if result is close enough to normal.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array</span>
<span class="sd">        Data for which the kurtosis is calculated.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which the kurtosis is calculated. Default is 0.</span>
<span class="sd">        If None, compute over the whole array `a`.</span>
<span class="sd">    fisher : bool, optional</span>
<span class="sd">        If True, Fisher&#39;s definition is used (normal ==&gt; 0.0). If False,</span>
<span class="sd">        Pearson&#39;s definition is used (normal ==&gt; 3.0).</span>
<span class="sd">    bias : bool, optional</span>
<span class="sd">        If False, then the calculations are corrected for statistical bias.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan. &#39;propagate&#39; returns nan,</span>
<span class="sd">        &#39;raise&#39; throws an error, &#39;omit&#39; performs the calculations ignoring nan</span>
<span class="sd">        values. Default is &#39;propagate&#39;.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    kurtosis : array</span>
<span class="sd">        The kurtosis of values along an axis, returning NaN where all values</span>
<span class="sd">        are equal.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard</span>
<span class="sd">       Probability and Statistics Tables and Formulae. Chapman &amp; Hall: New</span>
<span class="sd">       York. 2000.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    In Fisher&#39;s definition, the kurtosis of the normal distribution is zero.</span>
<span class="sd">    In the following example, the kurtosis is close to zero, because it was</span>
<span class="sd">    calculated from the dataset, not from the continuous distribution.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import norm, kurtosis</span>
<span class="sd">    &gt;&gt;&gt; data = norm.rvs(size=1000, random_state=3)</span>
<span class="sd">    &gt;&gt;&gt; kurtosis(data)</span>
<span class="sd">    -0.06928694200380558</span>

<span class="sd">    The distribution with a higher kurtosis has a heavier tail.</span>
<span class="sd">    The zero valued kurtosis of the normal distribution in Fisher&#39;s definition</span>
<span class="sd">    can serve as a reference point.</span>

<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; import scipy.stats as stats</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import kurtosis</span>

<span class="sd">    &gt;&gt;&gt; x = np.linspace(-5, 5, 100)</span>
<span class="sd">    &gt;&gt;&gt; ax = plt.subplot()</span>
<span class="sd">    &gt;&gt;&gt; distnames = [&#39;laplace&#39;, &#39;norm&#39;, &#39;uniform&#39;]</span>

<span class="sd">    &gt;&gt;&gt; for distname in distnames:</span>
<span class="sd">    ...     if distname == &#39;uniform&#39;:</span>
<span class="sd">    ...         dist = getattr(stats, distname)(loc=-2, scale=4)</span>
<span class="sd">    ...     else:</span>
<span class="sd">    ...         dist = getattr(stats, distname)</span>
<span class="sd">    ...     data = dist.rvs(size=1000)</span>
<span class="sd">    ...     kur = kurtosis(data, fisher=True)</span>
<span class="sd">    ...     y = dist.pdf(x)</span>
<span class="sd">    ...     ax.plot(x, y, label=&quot;{}, {}&quot;.format(distname, round(kur, 3)))</span>
<span class="sd">    ...     ax.legend()</span>

<span class="sd">    The Laplace distribution has a heavier tail than the normal distribution.</span>
<span class="sd">    The uniform distribution (which has negative kurtosis) has the thinnest</span>
<span class="sd">    tail.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">fisher</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">m2</span> <span class="o">=</span> <span class="n">_moment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>
    <span class="n">m4</span> <span class="o">=</span> <span class="n">_moment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="nb">all</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
        <span class="n">zero</span> <span class="o">=</span> <span class="p">(</span><span class="n">m2</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">m2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">resolution</span> <span class="o">*</span> <span class="n">mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">axis</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">zero</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">m4</span> <span class="o">/</span> <span class="n">m2</span><span class="o">**</span><span class="mf">2.0</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">bias</span><span class="p">:</span>
        <span class="n">can_correct</span> <span class="o">=</span> <span class="o">~</span><span class="n">zero</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">n</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">can_correct</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">m2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">can_correct</span><span class="p">,</span> <span class="n">m2</span><span class="p">)</span>
            <span class="n">m4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">can_correct</span><span class="p">,</span> <span class="n">m4</span><span class="p">)</span>
            <span class="n">nval</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span><span class="o">*</span><span class="n">m4</span><span class="o">/</span><span class="n">m2</span><span class="o">**</span><span class="mf">2.0</span> <span class="o">-</span> <span class="mi">3</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mf">2.0</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">place</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="n">can_correct</span><span class="p">,</span> <span class="n">nval</span> <span class="o">+</span> <span class="mf">3.0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">vals</span><span class="p">[()]</span> <span class="o">-</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">fisher</span> <span class="k">else</span> <span class="n">vals</span><span class="p">[()]</span>


<span class="n">DescribeResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;DescribeResult&#39;</span><span class="p">,</span>
                            <span class="p">(</span><span class="s1">&#39;nobs&#39;</span><span class="p">,</span> <span class="s1">&#39;minmax&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;variance&#39;</span><span class="p">,</span> <span class="s1">&#39;skewness&#39;</span><span class="p">,</span>
                             <span class="s1">&#39;kurtosis&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">describe</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute several descriptive statistics of the passed array.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Input data.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which statistics are calculated. Default is 0.</span>
<span class="sd">        If None, compute over the whole array `a`.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        Delta degrees of freedom (only for variance).  Default is 1.</span>
<span class="sd">    bias : bool, optional</span>
<span class="sd">        If False, then the skewness and kurtosis calculations are corrected</span>
<span class="sd">        for statistical bias.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">        * &#39;propagate&#39;: returns nan</span>
<span class="sd">        * &#39;raise&#39;: throws an error</span>
<span class="sd">        * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    nobs : int or ndarray of ints</span>
<span class="sd">        Number of observations (length of data along `axis`).</span>
<span class="sd">        When &#39;omit&#39; is chosen as nan_policy, the length along each axis</span>
<span class="sd">        slice is counted separately.</span>
<span class="sd">    minmax: tuple of ndarrays or floats</span>
<span class="sd">        Minimum and maximum value of `a` along the given axis.</span>
<span class="sd">    mean : ndarray or float</span>
<span class="sd">        Arithmetic mean of `a` along the given axis.</span>
<span class="sd">    variance : ndarray or float</span>
<span class="sd">        Unbiased variance of `a` along the given axis; denominator is number</span>
<span class="sd">        of observations minus one.</span>
<span class="sd">    skewness : ndarray or float</span>
<span class="sd">        Skewness of `a` along the given axis, based on moment calculations</span>
<span class="sd">        with denominator equal to the number of observations, i.e. no degrees</span>
<span class="sd">        of freedom correction.</span>
<span class="sd">    kurtosis : ndarray or float</span>
<span class="sd">        Kurtosis (Fisher) of `a` along the given axis.  The kurtosis is</span>
<span class="sd">        normalized so that it is zero for the normal distribution.  No</span>
<span class="sd">        degrees of freedom are used.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    skew, kurtosis</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; a = np.arange(10)</span>
<span class="sd">    &gt;&gt;&gt; stats.describe(a)</span>
<span class="sd">    DescribeResult(nobs=10, minmax=(0, 9), mean=4.5,</span>
<span class="sd">                   variance=9.166666666666666, skewness=0.0,</span>
<span class="sd">                   kurtosis=-1.2242424242424244)</span>
<span class="sd">    &gt;&gt;&gt; b = [[1, 2], [3, 4]]</span>
<span class="sd">    &gt;&gt;&gt; stats.describe(b)</span>
<span class="sd">    DescribeResult(nobs=2, minmax=(array([1, 2]), array([3, 4])),</span>
<span class="sd">                   mean=array([2., 3.]), variance=array([2., 2.]),</span>
<span class="sd">                   skewness=array([0., 0.]), kurtosis=array([-2., -2.]))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The input must not be empty.&quot;</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">mm</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">))</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">_var</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span>
    <span class="n">sk</span> <span class="o">=</span> <span class="n">skew</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
    <span class="n">kurt</span> <span class="o">=</span> <span class="n">kurtosis</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">DescribeResult</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">mm</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">sk</span><span class="p">,</span> <span class="n">kurt</span><span class="p">)</span>

<span class="c1">#####################################</span>
<span class="c1">#         NORMALITY TESTS           #</span>
<span class="c1">#####################################</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_normtest_finish</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">alternative</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Common code between all the normality-test functions.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;less&#39;</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;greater&#39;</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;two-sided&#39;</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">distributions</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;alternative must be &quot;</span>
                         <span class="s2">&quot;&#39;less&#39;, &#39;greater&#39; or &#39;two-sided&#39;&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="p">[()]</span>

    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">prob</span>


<span class="n">SkewtestResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;SkewtestResult&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">skewtest</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Test whether the skew is different from the normal distribution.</span>

<span class="sd">    This function tests the null hypothesis that the skewness of</span>
<span class="sd">    the population that the sample was drawn from is the same</span>
<span class="sd">    as that of a corresponding normal distribution.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array</span>
<span class="sd">        The data to be tested.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">       Axis along which statistics are calculated. Default is 0.</span>
<span class="sd">       If None, compute over the whole array `a`.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">        * &#39;propagate&#39;: returns nan</span>
<span class="sd">        * &#39;raise&#39;: throws an error</span>
<span class="sd">        * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis. Default is &#39;two-sided&#39;.</span>
<span class="sd">        The following options are available:</span>

<span class="sd">        * &#39;two-sided&#39;: the skewness of the distribution underlying the sample</span>
<span class="sd">          is different from that of the normal distribution (i.e. 0)</span>
<span class="sd">        * &#39;less&#39;: the skewness of the distribution underlying the sample</span>
<span class="sd">          is less than that of the normal distribution</span>
<span class="sd">        * &#39;greater&#39;: the skewness of the distribution underlying the sample</span>
<span class="sd">          is greater than that of the normal distribution</span>

<span class="sd">        .. versionadded:: 1.7.0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float</span>
<span class="sd">        The computed z-score for this test.</span>
<span class="sd">    pvalue : float</span>
<span class="sd">        The p-value for the hypothesis test.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The sample size must be at least 8.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] R. B. D&#39;Agostino, A. J. Belanger and R. B. D&#39;Agostino Jr.,</span>
<span class="sd">            &quot;A suggestion for using powerful and informative tests of</span>
<span class="sd">            normality&quot;, American Statistician 44, pp. 316-321, 1990.</span>
<span class="sd">    .. [2] Shapiro, S. S., &amp; Wilk, M. B. (1965). An analysis of variance test</span>
<span class="sd">           for normality (complete samples). Biometrika, 52(3/4), 591-611.</span>
<span class="sd">    .. [3] B. Phipson and G. K. Smyth. &quot;Permutation P-values Should Never Be</span>
<span class="sd">           Zero: Calculating Exact P-values When Permutations Are Randomly</span>
<span class="sd">           Drawn.&quot; Statistical Applications in Genetics and Molecular Biology</span>
<span class="sd">           9.1 (2010).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Suppose we wish to infer from measurements whether the weights of adult</span>
<span class="sd">    human males in a medical study are not normally distributed [2]_.</span>
<span class="sd">    The weights (lbs) are recorded in the array ``x`` below.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([148, 154, 158, 160, 161, 162, 166, 170, 182, 195, 236])</span>

<span class="sd">    The skewness test from [1]_ begins by computing a statistic based on the</span>
<span class="sd">    sample skewness.</span>

<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; res = stats.skewtest(x)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    2.7788579769903414</span>

<span class="sd">    Because normal distributions have zero skewness, the magnitude of this</span>
<span class="sd">    statistic tends to be low for samples drawn from a normal distribution.</span>

<span class="sd">    The test is performed by comparing the observed value of the</span>
<span class="sd">    statistic against the null distribution: the distribution of statistic</span>
<span class="sd">    values derived under the null hypothesis that the weights were drawn from</span>
<span class="sd">    a normal distribution.</span>

<span class="sd">    For this test, the null distribution of the statistic for very large</span>
<span class="sd">    samples is the standard normal distribution.</span>

<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; dist = stats.norm()</span>
<span class="sd">    &gt;&gt;&gt; st_val = np.linspace(-5, 5, 100)</span>
<span class="sd">    &gt;&gt;&gt; pdf = dist.pdf(st_val)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; def st_plot(ax):  # we&#39;ll reuse this</span>
<span class="sd">    ...     ax.plot(st_val, pdf)</span>
<span class="sd">    ...     ax.set_title(&quot;Skew Test Null Distribution&quot;)</span>
<span class="sd">    ...     ax.set_xlabel(&quot;statistic&quot;)</span>
<span class="sd">    ...     ax.set_ylabel(&quot;probability density&quot;)</span>
<span class="sd">    &gt;&gt;&gt; st_plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    The comparison is quantified by the p-value: the proportion of values in</span>
<span class="sd">    the null distribution as extreme or more extreme than the observed</span>
<span class="sd">    value of the statistic. In a two-sided test, elements of the null</span>
<span class="sd">    distribution greater than the observed statistic and elements of the null</span>
<span class="sd">    distribution less than the negative of the observed statistic are both</span>
<span class="sd">    considered &quot;more extreme&quot;.</span>

<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; st_plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; pvalue = dist.cdf(-res.statistic) + dist.sf(res.statistic)</span>
<span class="sd">    &gt;&gt;&gt; annotation = (f&#39;p-value={pvalue:.3f}\n(shaded area)&#39;)</span>
<span class="sd">    &gt;&gt;&gt; props = dict(facecolor=&#39;black&#39;, width=1, headwidth=5, headlength=8)</span>
<span class="sd">    &gt;&gt;&gt; _ = ax.annotate(annotation, (3, 0.005), (3.25, 0.02), arrowprops=props)</span>
<span class="sd">    &gt;&gt;&gt; i = st_val &gt;= res.statistic</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(st_val[i], y1=0, y2=pdf[i], color=&#39;C0&#39;)</span>
<span class="sd">    &gt;&gt;&gt; i = st_val &lt;= -res.statistic</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(st_val[i], y1=0, y2=pdf[i], color=&#39;C0&#39;)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_xlim(-5, 5)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_ylim(0, 0.1)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.005455036974740185</span>

<span class="sd">    If the p-value is &quot;small&quot; - that is, if there is a low probability of</span>
<span class="sd">    sampling data from a normally distributed population that produces such an</span>
<span class="sd">    extreme value of the statistic - this may be taken as evidence against</span>
<span class="sd">    the null hypothesis in favor of the alternative: the weights were not</span>
<span class="sd">    drawn from a normal distribution. Note that:</span>

<span class="sd">    - The inverse is not true; that is, the test is not used to provide</span>
<span class="sd">      evidence for the null hypothesis.</span>
<span class="sd">    - The threshold for values that will be considered &quot;small&quot; is a choice that</span>
<span class="sd">      should be made before the data is analyzed [3]_ with consideration of the</span>
<span class="sd">      risks of both false positives (incorrectly rejecting the null hypothesis)</span>
<span class="sd">      and false negatives (failure to reject a false null hypothesis).</span>

<span class="sd">    Note that the standard normal distribution provides an asymptotic</span>
<span class="sd">    approximation of the null distribution; it is only accurate for samples</span>
<span class="sd">    with many observations. For small samples like ours,</span>
<span class="sd">    `scipy.stats.monte_carlo_test` may provide a more accurate, albeit</span>
<span class="sd">    stochastic, approximation of the exact p-value.</span>

<span class="sd">    &gt;&gt;&gt; def statistic(x, axis):</span>
<span class="sd">    ...     # get just the skewtest statistic; ignore the p-value</span>
<span class="sd">    ...     return stats.skewtest(x, axis=axis).statistic</span>
<span class="sd">    &gt;&gt;&gt; res = stats.monte_carlo_test(x, stats.norm.rvs, statistic)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; st_plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; ax.hist(res.null_distribution, np.linspace(-5, 5, 50),</span>
<span class="sd">    ...         density=True)</span>
<span class="sd">    &gt;&gt;&gt; ax.legend([&#39;aymptotic approximation\n(many observations)&#39;,</span>
<span class="sd">    ...            &#39;Monte Carlo approximation\n(11 observations)&#39;])</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.0062  # may vary</span>

<span class="sd">    In this case, the asymptotic approximation and Monte Carlo approximation</span>
<span class="sd">    agree fairly closely, even for our small sample.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">skewtest</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">skew</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;skewtest is not valid with less than 8 samples; </span><span class="si">%i</span><span class="s2"> samples&quot;</span>
            <span class="s2">&quot; were given.&quot;</span> <span class="o">%</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">b2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(((</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">3</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mf">6.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">beta2</span> <span class="o">=</span> <span class="p">(</span><span class="mf">3.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">27</span><span class="o">*</span><span class="n">n</span> <span class="o">-</span> <span class="mi">70</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span> <span class="o">/</span>
             <span class="p">((</span><span class="n">n</span><span class="o">-</span><span class="mf">2.0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">5</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">7</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">9</span><span class="p">)))</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">beta2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">W2</span><span class="p">))</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">W2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span> <span class="o">/</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">y</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">SkewtestResult</span><span class="p">(</span><span class="o">*</span><span class="n">_normtest_finish</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">alternative</span><span class="p">))</span>


<span class="n">KurtosistestResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;KurtosistestResult&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">kurtosistest</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Test whether a dataset has normal kurtosis.</span>

<span class="sd">    This function tests the null hypothesis that the kurtosis</span>
<span class="sd">    of the population from which the sample was drawn is that</span>
<span class="sd">    of the normal distribution.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array</span>
<span class="sd">        Array of the sample data.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">       Axis along which to compute test. Default is 0. If None,</span>
<span class="sd">       compute over the whole array `a`.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">        * &#39;propagate&#39;: returns nan</span>
<span class="sd">        * &#39;raise&#39;: throws an error</span>
<span class="sd">        * &#39;omit&#39;: performs the calculations ignoring nan values</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis.</span>
<span class="sd">        The following options are available (default is &#39;two-sided&#39;):</span>

<span class="sd">        * &#39;two-sided&#39;: the kurtosis of the distribution underlying the sample</span>
<span class="sd">          is different from that of the normal distribution</span>
<span class="sd">        * &#39;less&#39;: the kurtosis of the distribution underlying the sample</span>
<span class="sd">          is less than that of the normal distribution</span>
<span class="sd">        * &#39;greater&#39;: the kurtosis of the distribution underlying the sample</span>
<span class="sd">          is greater than that of the normal distribution</span>

<span class="sd">        .. versionadded:: 1.7.0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float</span>
<span class="sd">        The computed z-score for this test.</span>
<span class="sd">    pvalue : float</span>
<span class="sd">        The p-value for the hypothesis test.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Valid only for n&gt;20. This function uses the method described in [1]_.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] see e.g. F. J. Anscombe, W. J. Glynn, &quot;Distribution of the kurtosis</span>
<span class="sd">       statistic b2 for normal samples&quot;, Biometrika, vol. 70, pp. 227-234, 1983.</span>
<span class="sd">    .. [2] Shapiro, S. S., &amp; Wilk, M. B. (1965). An analysis of variance test</span>
<span class="sd">           for normality (complete samples). Biometrika, 52(3/4), 591-611.</span>
<span class="sd">    .. [3] B. Phipson and G. K. Smyth. &quot;Permutation P-values Should Never Be</span>
<span class="sd">           Zero: Calculating Exact P-values When Permutations Are Randomly</span>
<span class="sd">           Drawn.&quot; Statistical Applications in Genetics and Molecular Biology</span>
<span class="sd">           9.1 (2010).</span>
<span class="sd">    .. [4] Panagiotakos, D. B. (2008). The value of p-value in biomedical</span>
<span class="sd">           research. The open cardiovascular medicine journal, 2, 97.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Suppose we wish to infer from measurements whether the weights of adult</span>
<span class="sd">    human males in a medical study are not normally distributed [2]_.</span>
<span class="sd">    The weights (lbs) are recorded in the array ``x`` below.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([148, 154, 158, 160, 161, 162, 166, 170, 182, 195, 236])</span>

<span class="sd">    The kurtosis test from [1]_ begins by computing a statistic based on the</span>
<span class="sd">    sample (excess/Fisher) kurtosis.</span>

<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; res = stats.kurtosistest(x)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    2.3048235214240873</span>

<span class="sd">    (The test warns that our sample has too few observations to perform the</span>
<span class="sd">    test. We&#39;ll return to this at the end of the example.)</span>
<span class="sd">    Because normal distributions have zero excess kurtosis (by definition),</span>
<span class="sd">    the magnitude of this statistic tends to be low for samples drawn from a</span>
<span class="sd">    normal distribution.</span>

<span class="sd">    The test is performed by comparing the observed value of the</span>
<span class="sd">    statistic against the null distribution: the distribution of statistic</span>
<span class="sd">    values derived under the null hypothesis that the weights were drawn from</span>
<span class="sd">    a normal distribution.</span>

<span class="sd">    For this test, the null distribution of the statistic for very large</span>
<span class="sd">    samples is the standard normal distribution.</span>

<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; dist = stats.norm()</span>
<span class="sd">    &gt;&gt;&gt; kt_val = np.linspace(-5, 5, 100)</span>
<span class="sd">    &gt;&gt;&gt; pdf = dist.pdf(kt_val)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; def kt_plot(ax):  # we&#39;ll reuse this</span>
<span class="sd">    ...     ax.plot(kt_val, pdf)</span>
<span class="sd">    ...     ax.set_title(&quot;Kurtosis Test Null Distribution&quot;)</span>
<span class="sd">    ...     ax.set_xlabel(&quot;statistic&quot;)</span>
<span class="sd">    ...     ax.set_ylabel(&quot;probability density&quot;)</span>
<span class="sd">    &gt;&gt;&gt; kt_plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    The comparison is quantified by the p-value: the proportion of values in</span>
<span class="sd">    the null distribution as extreme or more extreme than the observed</span>
<span class="sd">    value of the statistic. In a two-sided test in which the statistic is</span>
<span class="sd">    positive, elements of the null distribution greater than the observed</span>
<span class="sd">    statistic and elements of the null distribution less than the negative of</span>
<span class="sd">    the observed statistic are both considered &quot;more extreme&quot;.</span>

<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; kt_plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; pvalue = dist.cdf(-res.statistic) + dist.sf(res.statistic)</span>
<span class="sd">    &gt;&gt;&gt; annotation = (f&#39;p-value={pvalue:.3f}\n(shaded area)&#39;)</span>
<span class="sd">    &gt;&gt;&gt; props = dict(facecolor=&#39;black&#39;, width=1, headwidth=5, headlength=8)</span>
<span class="sd">    &gt;&gt;&gt; _ = ax.annotate(annotation, (3, 0.005), (3.25, 0.02), arrowprops=props)</span>
<span class="sd">    &gt;&gt;&gt; i = kt_val &gt;= res.statistic</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(kt_val[i], y1=0, y2=pdf[i], color=&#39;C0&#39;)</span>
<span class="sd">    &gt;&gt;&gt; i = kt_val &lt;= -res.statistic</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(kt_val[i], y1=0, y2=pdf[i], color=&#39;C0&#39;)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_xlim(-5, 5)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_ylim(0, 0.1)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.0211764592113868</span>

<span class="sd">    If the p-value is &quot;small&quot; - that is, if there is a low probability of</span>
<span class="sd">    sampling data from a normally distributed population that produces such an</span>
<span class="sd">    extreme value of the statistic - this may be taken as evidence against</span>
<span class="sd">    the null hypothesis in favor of the alternative: the weights were not</span>
<span class="sd">    drawn from a normal distribution. Note that:</span>

<span class="sd">    - The inverse is not true; that is, the test is not used to provide</span>
<span class="sd">      evidence for the null hypothesis.</span>
<span class="sd">    - The threshold for values that will be considered &quot;small&quot; is a choice that</span>
<span class="sd">      should be made before the data is analyzed [3]_ with consideration of the</span>
<span class="sd">      risks of both false positives (incorrectly rejecting the null hypothesis)</span>
<span class="sd">      and false negatives (failure to reject a false null hypothesis).</span>

<span class="sd">    Note that the standard normal distribution provides an asymptotic</span>
<span class="sd">    approximation of the null distribution; it is only accurate for samples</span>
<span class="sd">    with many observations. This is the reason we received a warning at the</span>
<span class="sd">    beginning of the example; our sample is quite small. In this case,</span>
<span class="sd">    `scipy.stats.monte_carlo_test` may provide a more accurate, albeit</span>
<span class="sd">    stochastic, approximation of the exact p-value.</span>

<span class="sd">    &gt;&gt;&gt; def statistic(x, axis):</span>
<span class="sd">    ...     # get just the skewtest statistic; ignore the p-value</span>
<span class="sd">    ...     return stats.kurtosistest(x, axis=axis).statistic</span>
<span class="sd">    &gt;&gt;&gt; res = stats.monte_carlo_test(x, stats.norm.rvs, statistic)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; kt_plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; ax.hist(res.null_distribution, np.linspace(-5, 5, 50),</span>
<span class="sd">    ...         density=True)</span>
<span class="sd">    &gt;&gt;&gt; ax.legend([&#39;aymptotic approximation\n(many observations)&#39;,</span>
<span class="sd">    ...            &#39;Monte Carlo approximation\n(11 observations)&#39;])</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.0272  # may vary</span>

<span class="sd">    Furthermore, despite their stochastic nature, p-values computed in this way</span>
<span class="sd">    can be used to exactly control the rate of false rejections of the null</span>
<span class="sd">    hypothesis [4]_.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">kurtosistest</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;kurtosistest requires at least 5 observations; </span><span class="si">%i</span><span class="s2"> observations&quot;</span>
            <span class="s2">&quot; were given.&quot;</span> <span class="o">%</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;kurtosistest only valid for n&gt;=20 ... continuing &quot;</span>
                      <span class="s2">&quot;anyway, n=</span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">),</span>
                      <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">kurtosis</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">fisher</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">E</span> <span class="o">=</span> <span class="mf">3.0</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">varb2</span> <span class="o">=</span> <span class="mf">24.0</span><span class="o">*</span><span class="n">n</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mf">1.</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">5</span><span class="p">))</span>  <span class="c1"># [1]_ Eq. 1</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">b2</span><span class="o">-</span><span class="n">E</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">varb2</span><span class="p">)</span>  <span class="c1"># [1]_ Eq. 4</span>
    <span class="c1"># [1]_ Eq. 2:</span>
    <span class="n">sqrtbeta1</span> <span class="o">=</span> <span class="mf">6.0</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">n</span><span class="o">-</span><span class="mi">5</span><span class="o">*</span><span class="n">n</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">((</span><span class="n">n</span><span class="o">+</span><span class="mi">7</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">9</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="mf">6.0</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">5</span><span class="p">))</span> <span class="o">/</span>
                                                        <span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">3</span><span class="p">)))</span>
    <span class="c1"># [1]_ Eq. 3:</span>
    <span class="n">A</span> <span class="o">=</span> <span class="mf">6.0</span> <span class="o">+</span> <span class="mf">8.0</span><span class="o">/</span><span class="n">sqrtbeta1</span> <span class="o">*</span> <span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="n">sqrtbeta1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="mf">4.0</span><span class="o">/</span><span class="p">(</span><span class="n">sqrtbeta1</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
    <span class="n">term1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mf">9.0</span><span class="o">*</span><span class="n">A</span><span class="p">)</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">A</span><span class="o">-</span><span class="mf">4.0</span><span class="p">))</span>
    <span class="n">term2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">denom</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">denom</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
                                      <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="mf">2.0</span><span class="o">/</span><span class="n">A</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">denom</span><span class="p">),</span> <span class="mi">1</span><span class="o">/</span><span class="mf">3.0</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">denom</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Test statistic not defined in some cases due to division by &quot;</span>
               <span class="s2">&quot;zero. Return nan in that case...&quot;</span><span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">term1</span> <span class="o">-</span> <span class="n">term2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mf">9.0</span><span class="o">*</span><span class="n">A</span><span class="p">))</span>  <span class="c1"># [1]_ Eq. 5</span>

    <span class="c1"># zprob uses upper tail, so Z needs to be positive</span>
    <span class="k">return</span> <span class="n">KurtosistestResult</span><span class="p">(</span><span class="o">*</span><span class="n">_normtest_finish</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">alternative</span><span class="p">))</span>


<span class="n">NormaltestResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;NormaltestResult&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">normaltest</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Test whether a sample differs from a normal distribution.</span>

<span class="sd">    This function tests the null hypothesis that a sample comes</span>
<span class="sd">    from a normal distribution.  It is based on D&#39;Agostino and</span>
<span class="sd">    Pearson&#39;s [1]_, [2]_ test that combines skew and kurtosis to</span>
<span class="sd">    produce an omnibus test of normality.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        The array containing the sample to be tested.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to compute test. Default is 0. If None,</span>
<span class="sd">        compute over the whole array `a`.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float or array</span>
<span class="sd">        ``s^2 + k^2``, where ``s`` is the z-score returned by `skewtest` and</span>
<span class="sd">        ``k`` is the z-score returned by `kurtosistest`.</span>
<span class="sd">    pvalue : float or array</span>
<span class="sd">       A 2-sided chi squared probability for the hypothesis test.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] D&#39;Agostino, R. B. (1971), &quot;An omnibus test of normality for</span>
<span class="sd">           moderate and large sample size&quot;, Biometrika, 58, 341-348</span>
<span class="sd">    .. [2] D&#39;Agostino, R. and Pearson, E. S. (1973), &quot;Tests for departure from</span>
<span class="sd">           normality&quot;, Biometrika, 60, 613-622</span>
<span class="sd">    .. [3] Shapiro, S. S., &amp; Wilk, M. B. (1965). An analysis of variance test</span>
<span class="sd">           for normality (complete samples). Biometrika, 52(3/4), 591-611.</span>
<span class="sd">    .. [4] B. Phipson and G. K. Smyth. &quot;Permutation P-values Should Never Be</span>
<span class="sd">           Zero: Calculating Exact P-values When Permutations Are Randomly</span>
<span class="sd">           Drawn.&quot; Statistical Applications in Genetics and Molecular Biology</span>
<span class="sd">           9.1 (2010).</span>
<span class="sd">    .. [5] Panagiotakos, D. B. (2008). The value of p-value in biomedical</span>
<span class="sd">           research. The open cardiovascular medicine journal, 2, 97.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Suppose we wish to infer from measurements whether the weights of adult</span>
<span class="sd">    human males in a medical study are not normally distributed [3]_.</span>
<span class="sd">    The weights (lbs) are recorded in the array ``x`` below.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([148, 154, 158, 160, 161, 162, 166, 170, 182, 195, 236])</span>

<span class="sd">    The normality test of [1]_ and [2]_ begins by computing a statistic based</span>
<span class="sd">    on the sample skewness and kurtosis.</span>

<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; res = stats.normaltest(x)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    13.034263121192582</span>

<span class="sd">    (The test warns that our sample has too few observations to perform the</span>
<span class="sd">    test. We&#39;ll return to this at the end of the example.)</span>
<span class="sd">    Because the normal distribution has zero skewness and zero</span>
<span class="sd">    (&quot;excess&quot; or &quot;Fisher&quot;) kurtosis, the value of this statistic tends to be</span>
<span class="sd">    low for samples drawn from a normal distribution.</span>

<span class="sd">    The test is performed by comparing the observed value of the statistic</span>
<span class="sd">    against the null distribution: the distribution of statistic values derived</span>
<span class="sd">    under the null hypothesis that the weights were drawn from a normal</span>
<span class="sd">    distribution.</span>
<span class="sd">    For this normality test, the null distribution for very large samples is</span>
<span class="sd">    the chi-squared distribution with two degrees of freedom.</span>

<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; dist = stats.chi2(df=2)</span>
<span class="sd">    &gt;&gt;&gt; stat_vals = np.linspace(0, 16, 100)</span>
<span class="sd">    &gt;&gt;&gt; pdf = dist.pdf(stat_vals)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; def plot(ax):  # we&#39;ll reuse this</span>
<span class="sd">    ...     ax.plot(stat_vals, pdf)</span>
<span class="sd">    ...     ax.set_title(&quot;Normality Test Null Distribution&quot;)</span>
<span class="sd">    ...     ax.set_xlabel(&quot;statistic&quot;)</span>
<span class="sd">    ...     ax.set_ylabel(&quot;probability density&quot;)</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    The comparison is quantified by the p-value: the proportion of values in</span>
<span class="sd">    the null distribution greater than or equal to the observed value of the</span>
<span class="sd">    statistic.</span>

<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; pvalue = dist.sf(res.statistic)</span>
<span class="sd">    &gt;&gt;&gt; annotation = (f&#39;p-value={pvalue:.6f}\n(shaded area)&#39;)</span>
<span class="sd">    &gt;&gt;&gt; props = dict(facecolor=&#39;black&#39;, width=1, headwidth=5, headlength=8)</span>
<span class="sd">    &gt;&gt;&gt; _ = ax.annotate(annotation, (13.5, 5e-4), (14, 5e-3), arrowprops=props)</span>
<span class="sd">    &gt;&gt;&gt; i = stat_vals &gt;= res.statistic  # index more extreme statistic values</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(stat_vals[i], y1=0, y2=pdf[i])</span>
<span class="sd">    &gt;&gt;&gt; ax.set_xlim(8, 16)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_ylim(0, 0.01)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.0014779023013100172</span>

<span class="sd">    If the p-value is &quot;small&quot; - that is, if there is a low probability of</span>
<span class="sd">    sampling data from a normally distributed population that produces such an</span>
<span class="sd">    extreme value of the statistic - this may be taken as evidence against</span>
<span class="sd">    the null hypothesis in favor of the alternative: the weights were not</span>
<span class="sd">    drawn from a normal distribution. Note that:</span>

<span class="sd">    - The inverse is not true; that is, the test is not used to provide</span>
<span class="sd">      evidence for the null hypothesis.</span>
<span class="sd">    - The threshold for values that will be considered &quot;small&quot; is a choice that</span>
<span class="sd">      should be made before the data is analyzed [4]_ with consideration of the</span>
<span class="sd">      risks of both false positives (incorrectly rejecting the null hypothesis)</span>
<span class="sd">      and false negatives (failure to reject a false null hypothesis).</span>

<span class="sd">    Note that the chi-squared distribution provides an asymptotic</span>
<span class="sd">    approximation of the null distribution; it is only accurate for samples</span>
<span class="sd">    with many observations. This is the reason we received a warning at the</span>
<span class="sd">    beginning of the example; our sample is quite small. In this case,</span>
<span class="sd">    `scipy.stats.monte_carlo_test` may provide a more accurate, albeit</span>
<span class="sd">    stochastic, approximation of the exact p-value.</span>

<span class="sd">    &gt;&gt;&gt; def statistic(x, axis):</span>
<span class="sd">    ...     # Get only the `normaltest` statistic; ignore approximate p-value</span>
<span class="sd">    ...     return stats.normaltest(x, axis=axis).statistic</span>
<span class="sd">    &gt;&gt;&gt; res = stats.monte_carlo_test(x, stats.norm.rvs, statistic,</span>
<span class="sd">    ...                              alternative=&#39;greater&#39;)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; ax.hist(res.null_distribution, np.linspace(0, 25, 50),</span>
<span class="sd">    ...         density=True)</span>
<span class="sd">    &gt;&gt;&gt; ax.legend([&#39;aymptotic approximation (many observations)&#39;,</span>
<span class="sd">    ...            &#39;Monte Carlo approximation (11 observations)&#39;])</span>
<span class="sd">    &gt;&gt;&gt; ax.set_xlim(0, 14)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.0082  # may vary</span>

<span class="sd">    Furthermore, despite their stochastic nature, p-values computed in this way</span>
<span class="sd">    can be used to exactly control the rate of false rejections of the null</span>
<span class="sd">    hypothesis [5]_.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">normaltest</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">s</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">skewtest</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="n">k</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">kurtosistest</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="n">k2</span> <span class="o">=</span> <span class="n">s</span><span class="o">*</span><span class="n">s</span> <span class="o">+</span> <span class="n">k</span><span class="o">*</span><span class="n">k</span>

    <span class="k">return</span> <span class="n">NormaltestResult</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span> <span class="n">distributions</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span><span class="n">SignificanceResult</span><span class="p">,</span> <span class="n">default_axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">jarque_bera</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform the Jarque-Bera goodness of fit test on sample data.</span>

<span class="sd">    The Jarque-Bera test tests whether the sample data has the skewness and</span>
<span class="sd">    kurtosis matching a normal distribution.</span>

<span class="sd">    Note that this test only works for a large enough number of data samples</span>
<span class="sd">    (&gt;2000) as the test statistic asymptotically has a Chi-squared distribution</span>
<span class="sd">    with 2 degrees of freedom.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : array_like</span>
<span class="sd">        Observations of a random variable.</span>
<span class="sd">    axis : int or None, default: 0</span>
<span class="sd">        If an int, the axis of the input along which to compute the statistic.</span>
<span class="sd">        The statistic of each axis-slice (e.g. row) of the input will appear in</span>
<span class="sd">        a corresponding element of the output.</span>
<span class="sd">        If ``None``, the input will be raveled before computing the statistic.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : SignificanceResult</span>
<span class="sd">        An object with the following attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            The test statistic.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            The p-value for the hypothesis test.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Jarque, C. and Bera, A. (1980) &quot;Efficient tests for normality,</span>
<span class="sd">           homoscedasticity and serial independence of regression residuals&quot;,</span>
<span class="sd">           6 Econometric Letters 255-259.</span>
<span class="sd">    .. [2] Shapiro, S. S., &amp; Wilk, M. B. (1965). An analysis of variance test</span>
<span class="sd">           for normality (complete samples). Biometrika, 52(3/4), 591-611.</span>
<span class="sd">    .. [3] B. Phipson and G. K. Smyth. &quot;Permutation P-values Should Never Be</span>
<span class="sd">           Zero: Calculating Exact P-values When Permutations Are Randomly</span>
<span class="sd">           Drawn.&quot; Statistical Applications in Genetics and Molecular Biology</span>
<span class="sd">           9.1 (2010).</span>
<span class="sd">    .. [4] Panagiotakos, D. B. (2008). The value of p-value in biomedical</span>
<span class="sd">           research. The open cardiovascular medicine journal, 2, 97.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Suppose we wish to infer from measurements whether the weights of adult</span>
<span class="sd">    human males in a medical study are not normally distributed [2]_.</span>
<span class="sd">    The weights (lbs) are recorded in the array ``x`` below.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([148, 154, 158, 160, 161, 162, 166, 170, 182, 195, 236])</span>

<span class="sd">    The Jarque-Bera test begins by computing a statistic based on the sample</span>
<span class="sd">    skewness and kurtosis.</span>

<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; res = stats.jarque_bera(x)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    6.982848237344646</span>

<span class="sd">    Because the normal distribution has zero skewness and zero</span>
<span class="sd">    (&quot;excess&quot; or &quot;Fisher&quot;) kurtosis, the value of this statistic tends to be</span>
<span class="sd">    low for samples drawn from a normal distribution.</span>

<span class="sd">    The test is performed by comparing the observed value of the statistic</span>
<span class="sd">    against the null distribution: the distribution of statistic values derived</span>
<span class="sd">    under the null hypothesis that the weights were drawn from a normal</span>
<span class="sd">    distribution.</span>
<span class="sd">    For the Jarque-Bera test, the null distribution for very large samples is</span>
<span class="sd">    the chi-squared distribution with two degrees of freedom.</span>

<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; dist = stats.chi2(df=2)</span>
<span class="sd">    &gt;&gt;&gt; jb_val = np.linspace(0, 11, 100)</span>
<span class="sd">    &gt;&gt;&gt; pdf = dist.pdf(jb_val)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; def jb_plot(ax):  # we&#39;ll reuse this</span>
<span class="sd">    ...     ax.plot(jb_val, pdf)</span>
<span class="sd">    ...     ax.set_title(&quot;Jarque-Bera Null Distribution&quot;)</span>
<span class="sd">    ...     ax.set_xlabel(&quot;statistic&quot;)</span>
<span class="sd">    ...     ax.set_ylabel(&quot;probability density&quot;)</span>
<span class="sd">    &gt;&gt;&gt; jb_plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    The comparison is quantified by the p-value: the proportion of values in</span>
<span class="sd">    the null distribution greater than or equal to the observed value of the</span>
<span class="sd">    statistic.</span>

<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; jb_plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; pvalue = dist.sf(res.statistic)</span>
<span class="sd">    &gt;&gt;&gt; annotation = (f&#39;p-value={pvalue:.6f}\n(shaded area)&#39;)</span>
<span class="sd">    &gt;&gt;&gt; props = dict(facecolor=&#39;black&#39;, width=1, headwidth=5, headlength=8)</span>
<span class="sd">    &gt;&gt;&gt; _ = ax.annotate(annotation, (7.5, 0.01), (8, 0.05), arrowprops=props)</span>
<span class="sd">    &gt;&gt;&gt; i = jb_val &gt;= res.statistic  # indices of more extreme statistic values</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(jb_val[i], y1=0, y2=pdf[i])</span>
<span class="sd">    &gt;&gt;&gt; ax.set_xlim(0, 11)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_ylim(0, 0.3)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.03045746622458189</span>

<span class="sd">    If the p-value is &quot;small&quot; - that is, if there is a low probability of</span>
<span class="sd">    sampling data from a normally distributed population that produces such an</span>
<span class="sd">    extreme value of the statistic - this may be taken as evidence against</span>
<span class="sd">    the null hypothesis in favor of the alternative: the weights were not</span>
<span class="sd">    drawn from a normal distribution. Note that:</span>

<span class="sd">    - The inverse is not true; that is, the test is not used to provide</span>
<span class="sd">      evidence for the null hypothesis.</span>
<span class="sd">    - The threshold for values that will be considered &quot;small&quot; is a choice that</span>
<span class="sd">      should be made before the data is analyzed [3]_ with consideration of the</span>
<span class="sd">      risks of both false positives (incorrectly rejecting the null hypothesis)</span>
<span class="sd">      and false negatives (failure to reject a false null hypothesis).</span>

<span class="sd">    Note that the chi-squared distribution provides an asymptotic approximation</span>
<span class="sd">    of the null distribution; it is only accurate for samples with many</span>
<span class="sd">    observations. For small samples like ours, `scipy.stats.monte_carlo_test`</span>
<span class="sd">    may provide a more accurate, albeit stochastic, approximation of the</span>
<span class="sd">    exact p-value.</span>

<span class="sd">    &gt;&gt;&gt; def statistic(x, axis):</span>
<span class="sd">    ...     # underlying calculation of the Jarque Bera statistic</span>
<span class="sd">    ...     s = stats.skew(x, axis=axis)</span>
<span class="sd">    ...     k = stats.kurtosis(x, axis=axis)</span>
<span class="sd">    ...     return x.shape[axis]/6 * (s**2 + k**2/4)</span>
<span class="sd">    &gt;&gt;&gt; res = stats.monte_carlo_test(x, stats.norm.rvs, statistic,</span>
<span class="sd">    ...                              alternative=&#39;greater&#39;)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; jb_plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; ax.hist(res.null_distribution, np.linspace(0, 10, 50),</span>
<span class="sd">    ...         density=True)</span>
<span class="sd">    &gt;&gt;&gt; ax.legend([&#39;aymptotic approximation (many observations)&#39;,</span>
<span class="sd">    ...            &#39;Monte Carlo approximation (11 observations)&#39;])</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.0097  # may vary</span>

<span class="sd">    Furthermore, despite their stochastic nature, p-values computed in this way</span>
<span class="sd">    can be used to exactly control the rate of false rejections of the null</span>
<span class="sd">    hypothesis [4]_.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;At least one observation is required.&#39;</span><span class="p">)</span>

    <span class="n">mu</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">diffx</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">mu</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">skew</span><span class="p">(</span><span class="n">diffx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">_no_deco</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">kurtosis</span><span class="p">(</span><span class="n">diffx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">_no_deco</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">statistic</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="mi">6</span> <span class="o">*</span> <span class="p">(</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">k</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">pvalue</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">)</span>


<span class="c1">#####################################</span>
<span class="c1">#        FREQUENCY FUNCTIONS        #</span>
<span class="c1">#####################################</span>


<span class="k">def</span><span class="w"> </span><span class="nf">scoreatpercentile</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">per</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="p">(),</span> <span class="n">interpolation_method</span><span class="o">=</span><span class="s1">&#39;fraction&#39;</span><span class="p">,</span>
                      <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate the score at a given percentile of the input sequence.</span>

<span class="sd">    For example, the score at `per=50` is the median. If the desired quantile</span>
<span class="sd">    lies between two data points, we interpolate between them, according to</span>
<span class="sd">    the value of `interpolation`. If the parameter `limit` is provided, it</span>
<span class="sd">    should be a tuple (lower, upper) of two values.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        A 1-D array of values from which to extract score.</span>
<span class="sd">    per : array_like</span>
<span class="sd">        Percentile(s) at which to extract score.  Values should be in range</span>
<span class="sd">        [0,100].</span>
<span class="sd">    limit : tuple, optional</span>
<span class="sd">        Tuple of two scalars, the lower and upper limits within which to</span>
<span class="sd">        compute the percentile. Values of `a` outside</span>
<span class="sd">        this (closed) interval will be ignored.</span>
<span class="sd">    interpolation_method : {&#39;fraction&#39;, &#39;lower&#39;, &#39;higher&#39;}, optional</span>
<span class="sd">        Specifies the interpolation method to use,</span>
<span class="sd">        when the desired quantile lies between two data points `i` and `j`</span>
<span class="sd">        The following options are available (default is &#39;fraction&#39;):</span>

<span class="sd">          * &#39;fraction&#39;: ``i + (j - i) * fraction`` where ``fraction`` is the</span>
<span class="sd">            fractional part of the index surrounded by ``i`` and ``j``</span>
<span class="sd">          * &#39;lower&#39;: ``i``</span>
<span class="sd">          * &#39;higher&#39;: ``j``</span>

<span class="sd">    axis : int, optional</span>
<span class="sd">        Axis along which the percentiles are computed. Default is None. If</span>
<span class="sd">        None, compute over the whole array `a`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float or ndarray</span>
<span class="sd">        Score at percentile(s).</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    percentileofscore, numpy.percentile</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function will become obsolete in the future.</span>
<span class="sd">    For NumPy 1.9 and higher, `numpy.percentile` provides all the functionality</span>
<span class="sd">    that `scoreatpercentile` provides.  And it&#39;s significantly faster.</span>
<span class="sd">    Therefore it&#39;s recommended to use `numpy.percentile` for users that have</span>
<span class="sd">    numpy &gt;= 1.9.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; a = np.arange(100)</span>
<span class="sd">    &gt;&gt;&gt; stats.scoreatpercentile(a, 50)</span>
<span class="sd">    49.5</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># adapted from NumPy&#39;s percentile function.  When we require numpy &gt;= 1.8,</span>
    <span class="c1"># the implementation of this function can be replaced by np.percentile.</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># empty array, return nan(s) with shape matching `per`</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">per</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">per</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">limit</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[(</span><span class="n">limit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">a</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">a</span> <span class="o">&lt;=</span> <span class="n">limit</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>

    <span class="n">sorted_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">return</span> <span class="n">_compute_qth_percentile</span><span class="p">(</span><span class="n">sorted_</span><span class="p">,</span> <span class="n">per</span><span class="p">,</span> <span class="n">interpolation_method</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>


<span class="c1"># handle sequence of per&#39;s without calling sort multiple times</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_compute_qth_percentile</span><span class="p">(</span><span class="n">sorted_</span><span class="p">,</span> <span class="n">per</span><span class="p">,</span> <span class="n">interpolation_method</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">per</span><span class="p">):</span>
        <span class="n">score</span> <span class="o">=</span> <span class="p">[</span><span class="n">_compute_qth_percentile</span><span class="p">(</span><span class="n">sorted_</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span>
                                         <span class="n">interpolation_method</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
                 <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">per</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">per</span> <span class="o">&lt;=</span> <span class="mi">100</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;percentile must be in the range [0, 100]&quot;</span><span class="p">)</span>

    <span class="n">indexer</span> <span class="o">=</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)]</span> <span class="o">*</span> <span class="n">sorted_</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">per</span> <span class="o">/</span> <span class="mf">100.</span> <span class="o">*</span> <span class="p">(</span><span class="n">sorted_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">!=</span> <span class="n">idx</span><span class="p">:</span>
        <span class="c1"># round fractional indices according to interpolation method</span>
        <span class="k">if</span> <span class="n">interpolation_method</span> <span class="o">==</span> <span class="s1">&#39;lower&#39;</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">interpolation_method</span> <span class="o">==</span> <span class="s1">&#39;higher&#39;</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">interpolation_method</span> <span class="o">==</span> <span class="s1">&#39;fraction&#39;</span><span class="p">:</span>
            <span class="k">pass</span>  <span class="c1"># keep idx as fraction and interpolate</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;interpolation_method can only be &#39;fraction&#39;, &quot;</span>
                             <span class="s2">&quot;&#39;lower&#39; or &#39;higher&#39;&quot;</span><span class="p">)</span>

    <span class="n">i</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">idx</span><span class="p">:</span>
        <span class="n">indexer</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">sumval</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">indexer</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">array</span><span class="p">([(</span><span class="n">j</span> <span class="o">-</span> <span class="n">idx</span><span class="p">),</span> <span class="p">(</span><span class="n">idx</span> <span class="o">-</span> <span class="n">i</span><span class="p">)],</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">wshape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">sorted_</span><span class="o">.</span><span class="n">ndim</span>
        <span class="n">wshape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">weights</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">wshape</span>
        <span class="n">sumval</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Use np.add.reduce (== np.sum but a little faster) to coerce data type</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">sorted_</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">indexer</span><span class="p">)]</span> <span class="o">*</span> <span class="n">weights</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span> <span class="o">/</span> <span class="n">sumval</span>


<span class="k">def</span><span class="w"> </span><span class="nf">percentileofscore</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;rank&#39;</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the percentile rank of a score relative to a list of scores.</span>

<span class="sd">    A `percentileofscore` of, for example, 80% means that 80% of the</span>
<span class="sd">    scores in `a` are below the given score. In the case of gaps or</span>
<span class="sd">    ties, the exact definition depends on the optional keyword, `kind`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array to which `score` is compared.</span>
<span class="sd">    score : array_like</span>
<span class="sd">        Scores to compute percentiles for.</span>
<span class="sd">    kind : {&#39;rank&#39;, &#39;weak&#39;, &#39;strict&#39;, &#39;mean&#39;}, optional</span>
<span class="sd">        Specifies the interpretation of the resulting score.</span>
<span class="sd">        The following options are available (default is &#39;rank&#39;):</span>

<span class="sd">          * &#39;rank&#39;: Average percentage ranking of score.  In case of multiple</span>
<span class="sd">            matches, average the percentage rankings of all matching scores.</span>
<span class="sd">          * &#39;weak&#39;: This kind corresponds to the definition of a cumulative</span>
<span class="sd">            distribution function.  A percentileofscore of 80% means that 80%</span>
<span class="sd">            of values are less than or equal to the provided score.</span>
<span class="sd">          * &#39;strict&#39;: Similar to &quot;weak&quot;, except that only values that are</span>
<span class="sd">            strictly less than the given score are counted.</span>
<span class="sd">          * &#39;mean&#39;: The average of the &quot;weak&quot; and &quot;strict&quot; scores, often used</span>
<span class="sd">            in testing.  See https://en.wikipedia.org/wiki/Percentile_rank</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Specifies how to treat `nan` values in `a`.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan (for each value in `score`).</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pcos : float</span>
<span class="sd">        Percentile-position of score (0-100) relative to `a`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.percentile</span>
<span class="sd">    scipy.stats.scoreatpercentile, scipy.stats.rankdata</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Three-quarters of the given values lie below a given score:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; stats.percentileofscore([1, 2, 3, 4], 3)</span>
<span class="sd">    75.0</span>

<span class="sd">    With multiple matches, note how the scores of the two matches, 0.6</span>
<span class="sd">    and 0.8 respectively, are averaged:</span>

<span class="sd">    &gt;&gt;&gt; stats.percentileofscore([1, 2, 3, 3, 4], 3)</span>
<span class="sd">    70.0</span>

<span class="sd">    Only 2/5 values are strictly less than 3:</span>

<span class="sd">    &gt;&gt;&gt; stats.percentileofscore([1, 2, 3, 3, 4], 3, kind=&#39;strict&#39;)</span>
<span class="sd">    40.0</span>

<span class="sd">    But 4/5 values are less than or equal to 3:</span>

<span class="sd">    &gt;&gt;&gt; stats.percentileofscore([1, 2, 3, 3, 4], 3, kind=&#39;weak&#39;)</span>
<span class="sd">    80.0</span>

<span class="sd">    The average between the weak and the strict scores is:</span>

<span class="sd">    &gt;&gt;&gt; stats.percentileofscore([1, 2, 3, 3, 4], 3, kind=&#39;mean&#39;)</span>
<span class="sd">    60.0</span>

<span class="sd">    Score arrays (of any dimensionality) are supported:</span>

<span class="sd">    &gt;&gt;&gt; stats.percentileofscore([1, 2, 3, 3, 4], [2, 3])</span>
<span class="sd">    array([40., 70.])</span>

<span class="sd">    The inputs can be infinite:</span>

<span class="sd">    &gt;&gt;&gt; stats.percentileofscore([-np.inf, 0, 1, np.inf], [1, 2, np.inf])</span>
<span class="sd">    array([75., 75., 100.])</span>

<span class="sd">    If `a` is empty, then the resulting percentiles are all `nan`:</span>

<span class="sd">    &gt;&gt;&gt; stats.percentileofscore([], [1, 2])</span>
<span class="sd">    array([nan, nan])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

    <span class="c1"># Nan treatment</span>
    <span class="n">cna</span><span class="p">,</span> <span class="n">npa</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">,</span> <span class="n">use_summation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">cns</span><span class="p">,</span> <span class="n">nps</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">,</span> <span class="n">use_summation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">cna</span> <span class="ow">or</span> <span class="n">cns</span><span class="p">)</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;raise&#39;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The input contains nan values&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cns</span><span class="p">:</span>
        <span class="c1"># If a score is nan, then the output should be nan</span>
        <span class="c1"># (also if nan_policy is &quot;omit&quot;, because it only applies to `a`)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">score</span><span class="p">),</span> <span class="n">score</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cna</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s2">&quot;omit&quot;</span><span class="p">:</span>
            <span class="c1"># Don&#39;t count nans</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">a</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s2">&quot;propagate&quot;</span><span class="p">:</span>
            <span class="c1"># All outputs should be nans</span>
            <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Cannot compare to empty list ==&gt; nan</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">perct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Prepare broadcasting</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">score</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">count</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Main computations/logic</span>
        <span class="k">if</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;rank&#39;</span><span class="p">:</span>
            <span class="n">left</span> <span class="o">=</span> <span class="n">count</span><span class="p">(</span><span class="n">a</span> <span class="o">&lt;</span> <span class="n">score</span><span class="p">)</span>
            <span class="n">right</span> <span class="o">=</span> <span class="n">count</span><span class="p">(</span><span class="n">a</span> <span class="o">&lt;=</span> <span class="n">score</span><span class="p">)</span>
            <span class="n">plus1</span> <span class="o">=</span> <span class="n">left</span> <span class="o">&lt;</span> <span class="n">right</span>
            <span class="n">perct</span> <span class="o">=</span> <span class="p">(</span><span class="n">left</span> <span class="o">+</span> <span class="n">right</span> <span class="o">+</span> <span class="n">plus1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">50.0</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;strict&#39;</span><span class="p">:</span>
            <span class="n">perct</span> <span class="o">=</span> <span class="n">count</span><span class="p">(</span><span class="n">a</span> <span class="o">&lt;</span> <span class="n">score</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;weak&#39;</span><span class="p">:</span>
            <span class="n">perct</span> <span class="o">=</span> <span class="n">count</span><span class="p">(</span><span class="n">a</span> <span class="o">&lt;=</span> <span class="n">score</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;mean&#39;</span><span class="p">:</span>
            <span class="n">left</span> <span class="o">=</span> <span class="n">count</span><span class="p">(</span><span class="n">a</span> <span class="o">&lt;</span> <span class="n">score</span><span class="p">)</span>
            <span class="n">right</span> <span class="o">=</span> <span class="n">count</span><span class="p">(</span><span class="n">a</span> <span class="o">&lt;=</span> <span class="n">score</span><span class="p">)</span>
            <span class="n">perct</span> <span class="o">=</span> <span class="p">(</span><span class="n">left</span> <span class="o">+</span> <span class="n">right</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">50.0</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;kind can only be &#39;rank&#39;, &#39;strict&#39;, &#39;weak&#39; or &#39;mean&#39;&quot;</span><span class="p">)</span>

    <span class="c1"># Re-insert nan values</span>
    <span class="n">perct</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">filled</span><span class="p">(</span><span class="n">perct</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">perct</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">perct</span><span class="p">[()]</span>
    <span class="k">return</span> <span class="n">perct</span>


<span class="n">HistogramResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;HistogramResult&#39;</span><span class="p">,</span>
                             <span class="p">(</span><span class="s1">&#39;count&#39;</span><span class="p">,</span> <span class="s1">&#39;lowerlimit&#39;</span><span class="p">,</span> <span class="s1">&#39;binsize&#39;</span><span class="p">,</span> <span class="s1">&#39;extrapoints&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_histogram</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">numbins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">defaultlimits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">printextras</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a histogram.</span>

<span class="sd">    Separate the range into several bins and return the number of instances</span>
<span class="sd">    in each bin.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array of scores which will be put into bins.</span>
<span class="sd">    numbins : int, optional</span>
<span class="sd">        The number of bins to use for the histogram. Default is 10.</span>
<span class="sd">    defaultlimits : tuple (lower, upper), optional</span>
<span class="sd">        The lower and upper values for the range of the histogram.</span>
<span class="sd">        If no value is given, a range slightly larger than the range of the</span>
<span class="sd">        values in a is used. Specifically ``(a.min() - s, a.max() + s)``,</span>
<span class="sd">        where ``s = (1/2)(a.max() - a.min()) / (numbins - 1)``.</span>
<span class="sd">    weights : array_like, optional</span>
<span class="sd">        The weights for each value in `a`. Default is None, which gives each</span>
<span class="sd">        value a weight of 1.0</span>
<span class="sd">    printextras : bool, optional</span>
<span class="sd">        If True, if there are extra points (i.e. the points that fall outside</span>
<span class="sd">        the bin limits) a warning is raised saying how many of those points</span>
<span class="sd">        there are.  Default is False.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    count : ndarray</span>
<span class="sd">        Number of points (or sum of weights) in each bin.</span>
<span class="sd">    lowerlimit : float</span>
<span class="sd">        Lowest value of histogram, the lower limit of the first bin.</span>
<span class="sd">    binsize : float</span>
<span class="sd">        The size of the bins (all bins have the same size).</span>
<span class="sd">    extrapoints : int</span>
<span class="sd">        The number of points outside the range of the histogram.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.histogram</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This histogram is based on numpy&#39;s histogram but has a larger range by</span>
<span class="sd">    default if default limits is not set.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">defaultlimits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># handle empty arrays. Undetermined range, so use 0-1.</span>
            <span class="n">defaultlimits</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># no range given, so use values in `a`</span>
            <span class="n">data_min</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
            <span class="n">data_max</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
            <span class="c1"># Have bins extend past min and max values slightly</span>
            <span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_max</span> <span class="o">-</span> <span class="n">data_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="p">(</span><span class="n">numbins</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">))</span>
            <span class="n">defaultlimits</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_min</span> <span class="o">-</span> <span class="n">s</span><span class="p">,</span> <span class="n">data_max</span> <span class="o">+</span> <span class="n">s</span><span class="p">)</span>

    <span class="c1"># use numpy&#39;s histogram method to compute bins</span>
    <span class="n">hist</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">numbins</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">defaultlimits</span><span class="p">,</span>
                                   <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="c1"># hist are not always floats, convert to keep with old output</span>
    <span class="n">hist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hist</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="c1"># fixed width for bins is assumed, as numpy&#39;s histogram gives</span>
    <span class="c1"># fixed width bins for int values for &#39;bins&#39;</span>
    <span class="n">binsize</span> <span class="o">=</span> <span class="n">bin_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># calculate number of extra points</span>
    <span class="n">extrapoints</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">a</span>
                       <span class="k">if</span> <span class="n">defaultlimits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">v</span> <span class="ow">or</span> <span class="n">v</span> <span class="o">&gt;</span> <span class="n">defaultlimits</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <span class="k">if</span> <span class="n">extrapoints</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">printextras</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Points outside given histogram range = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">extrapoints</span><span class="p">,</span>
                      <span class="n">stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,)</span>

    <span class="k">return</span> <span class="n">HistogramResult</span><span class="p">(</span><span class="n">hist</span><span class="p">,</span> <span class="n">defaultlimits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">binsize</span><span class="p">,</span> <span class="n">extrapoints</span><span class="p">)</span>


<span class="n">CumfreqResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;CumfreqResult&#39;</span><span class="p">,</span>
                           <span class="p">(</span><span class="s1">&#39;cumcount&#39;</span><span class="p">,</span> <span class="s1">&#39;lowerlimit&#39;</span><span class="p">,</span> <span class="s1">&#39;binsize&#39;</span><span class="p">,</span>
                            <span class="s1">&#39;extrapoints&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">cumfreq</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">numbins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">defaultreallimits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return a cumulative frequency histogram, using the histogram function.</span>

<span class="sd">    A cumulative histogram is a mapping that counts the cumulative number of</span>
<span class="sd">    observations in all of the bins up to the specified bin.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Input array.</span>
<span class="sd">    numbins : int, optional</span>
<span class="sd">        The number of bins to use for the histogram. Default is 10.</span>
<span class="sd">    defaultreallimits : tuple (lower, upper), optional</span>
<span class="sd">        The lower and upper values for the range of the histogram.</span>
<span class="sd">        If no value is given, a range slightly larger than the range of the</span>
<span class="sd">        values in `a` is used. Specifically ``(a.min() - s, a.max() + s)``,</span>
<span class="sd">        where ``s = (1/2)(a.max() - a.min()) / (numbins - 1)``.</span>
<span class="sd">    weights : array_like, optional</span>
<span class="sd">        The weights for each value in `a`. Default is None, which gives each</span>
<span class="sd">        value a weight of 1.0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    cumcount : ndarray</span>
<span class="sd">        Binned values of cumulative frequency.</span>
<span class="sd">    lowerlimit : float</span>
<span class="sd">        Lower real limit</span>
<span class="sd">    binsize : float</span>
<span class="sd">        Width of each bin.</span>
<span class="sd">    extrapoints : int</span>
<span class="sd">        Extra points.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">    &gt;&gt;&gt; x = [1, 4, 2, 1, 3, 1]</span>
<span class="sd">    &gt;&gt;&gt; res = stats.cumfreq(x, numbins=4, defaultreallimits=(1.5, 5))</span>
<span class="sd">    &gt;&gt;&gt; res.cumcount</span>
<span class="sd">    array([ 1.,  2.,  3.,  3.])</span>
<span class="sd">    &gt;&gt;&gt; res.extrapoints</span>
<span class="sd">    3</span>

<span class="sd">    Create a normal distribution with 1000 random values</span>

<span class="sd">    &gt;&gt;&gt; samples = stats.norm.rvs(size=1000, random_state=rng)</span>

<span class="sd">    Calculate cumulative frequencies</span>

<span class="sd">    &gt;&gt;&gt; res = stats.cumfreq(samples, numbins=25)</span>

<span class="sd">    Calculate space of values for x</span>

<span class="sd">    &gt;&gt;&gt; x = res.lowerlimit + np.linspace(0, res.binsize*res.cumcount.size,</span>
<span class="sd">    ...                                  res.cumcount.size)</span>

<span class="sd">    Plot histogram and cumulative histogram</span>

<span class="sd">    &gt;&gt;&gt; fig = plt.figure(figsize=(10, 4))</span>
<span class="sd">    &gt;&gt;&gt; ax1 = fig.add_subplot(1, 2, 1)</span>
<span class="sd">    &gt;&gt;&gt; ax2 = fig.add_subplot(1, 2, 2)</span>
<span class="sd">    &gt;&gt;&gt; ax1.hist(samples, bins=25)</span>
<span class="sd">    &gt;&gt;&gt; ax1.set_title(&#39;Histogram&#39;)</span>
<span class="sd">    &gt;&gt;&gt; ax2.bar(x, res.cumcount, width=res.binsize)</span>
<span class="sd">    &gt;&gt;&gt; ax2.set_title(&#39;Cumulative histogram&#39;)</span>
<span class="sd">    &gt;&gt;&gt; ax2.set_xlim([x.min(), x.max()])</span>

<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">e</span> <span class="o">=</span> <span class="n">_histogram</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">numbins</span><span class="p">,</span> <span class="n">defaultreallimits</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">cumhist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">h</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">CumfreqResult</span><span class="p">(</span><span class="n">cumhist</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>


<span class="n">RelfreqResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;RelfreqResult&#39;</span><span class="p">,</span>
                           <span class="p">(</span><span class="s1">&#39;frequency&#39;</span><span class="p">,</span> <span class="s1">&#39;lowerlimit&#39;</span><span class="p">,</span> <span class="s1">&#39;binsize&#39;</span><span class="p">,</span>
                            <span class="s1">&#39;extrapoints&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">relfreq</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">numbins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">defaultreallimits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return a relative frequency histogram, using the histogram function.</span>

<span class="sd">    A relative frequency  histogram is a mapping of the number of</span>
<span class="sd">    observations in each of the bins relative to the total of observations.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Input array.</span>
<span class="sd">    numbins : int, optional</span>
<span class="sd">        The number of bins to use for the histogram. Default is 10.</span>
<span class="sd">    defaultreallimits : tuple (lower, upper), optional</span>
<span class="sd">        The lower and upper values for the range of the histogram.</span>
<span class="sd">        If no value is given, a range slightly larger than the range of the</span>
<span class="sd">        values in a is used. Specifically ``(a.min() - s, a.max() + s)``,</span>
<span class="sd">        where ``s = (1/2)(a.max() - a.min()) / (numbins - 1)``.</span>
<span class="sd">    weights : array_like, optional</span>
<span class="sd">        The weights for each value in `a`. Default is None, which gives each</span>
<span class="sd">        value a weight of 1.0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    frequency : ndarray</span>
<span class="sd">        Binned values of relative frequency.</span>
<span class="sd">    lowerlimit : float</span>
<span class="sd">        Lower real limit.</span>
<span class="sd">    binsize : float</span>
<span class="sd">        Width of each bin.</span>
<span class="sd">    extrapoints : int</span>
<span class="sd">        Extra points.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">    &gt;&gt;&gt; a = np.array([2, 4, 1, 2, 3, 2])</span>
<span class="sd">    &gt;&gt;&gt; res = stats.relfreq(a, numbins=4)</span>
<span class="sd">    &gt;&gt;&gt; res.frequency</span>
<span class="sd">    array([ 0.16666667, 0.5       , 0.16666667,  0.16666667])</span>
<span class="sd">    &gt;&gt;&gt; np.sum(res.frequency)  # relative frequencies should add up to 1</span>
<span class="sd">    1.0</span>

<span class="sd">    Create a normal distribution with 1000 random values</span>

<span class="sd">    &gt;&gt;&gt; samples = stats.norm.rvs(size=1000, random_state=rng)</span>

<span class="sd">    Calculate relative frequencies</span>

<span class="sd">    &gt;&gt;&gt; res = stats.relfreq(samples, numbins=25)</span>

<span class="sd">    Calculate space of values for x</span>

<span class="sd">    &gt;&gt;&gt; x = res.lowerlimit + np.linspace(0, res.binsize*res.frequency.size,</span>
<span class="sd">    ...                                  res.frequency.size)</span>

<span class="sd">    Plot relative frequency histogram</span>

<span class="sd">    &gt;&gt;&gt; fig = plt.figure(figsize=(5, 4))</span>
<span class="sd">    &gt;&gt;&gt; ax = fig.add_subplot(1, 1, 1)</span>
<span class="sd">    &gt;&gt;&gt; ax.bar(x, res.frequency, width=res.binsize)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_title(&#39;Relative frequency histogram&#39;)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_xlim([x.min(), x.max()])</span>

<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">e</span> <span class="o">=</span> <span class="n">_histogram</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">numbins</span><span class="p">,</span> <span class="n">defaultreallimits</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">h</span> <span class="o">/</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">RelfreqResult</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>


<span class="c1">#####################################</span>
<span class="c1">#        VARIABILITY FUNCTIONS      #</span>
<span class="c1">#####################################</span>

<span class="k">def</span><span class="w"> </span><span class="nf">obrientransform</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the O&#39;Brien transform on input data (any number of arrays).</span>

<span class="sd">    Used to test for homogeneity of variance prior to running one-way stats.</span>
<span class="sd">    Each array in ``*samples`` is one level of a factor.</span>
<span class="sd">    If `f_oneway` is run on the transformed data and found significant,</span>
<span class="sd">    the variances are unequal.  From Maxwell and Delaney [1]_, p.112.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sample1, sample2, ... : array_like</span>
<span class="sd">        Any number of arrays.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    obrientransform : ndarray</span>
<span class="sd">        Transformed data for use in an ANOVA.  The first dimension</span>
<span class="sd">        of the result corresponds to the sequence of transformed</span>
<span class="sd">        arrays.  If the arrays given are all 1-D of the same length,</span>
<span class="sd">        the return value is a 2-D array; otherwise it is a 1-D array</span>
<span class="sd">        of type object, with each element being an ndarray.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] S. E. Maxwell and H. D. Delaney, &quot;Designing Experiments and</span>
<span class="sd">           Analyzing Data: A Model Comparison Perspective&quot;, Wadsworth, 1990.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    We&#39;ll test the following data sets for differences in their variance.</span>

<span class="sd">    &gt;&gt;&gt; x = [10, 11, 13, 9, 7, 12, 12, 9, 10]</span>
<span class="sd">    &gt;&gt;&gt; y = [13, 21, 5, 10, 8, 14, 10, 12, 7, 15]</span>

<span class="sd">    Apply the O&#39;Brien transform to the data.</span>

<span class="sd">    &gt;&gt;&gt; from scipy.stats import obrientransform</span>
<span class="sd">    &gt;&gt;&gt; tx, ty = obrientransform(x, y)</span>

<span class="sd">    Use `scipy.stats.f_oneway` to apply a one-way ANOVA test to the</span>
<span class="sd">    transformed data.</span>

<span class="sd">    &gt;&gt;&gt; from scipy.stats import f_oneway</span>
<span class="sd">    &gt;&gt;&gt; F, p = f_oneway(tx, ty)</span>
<span class="sd">    &gt;&gt;&gt; p</span>
<span class="sd">    0.1314139477040335</span>

<span class="sd">    If we require that ``p &lt; 0.05`` for significance, we cannot conclude</span>
<span class="sd">    that the variances are different.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">TINY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>

    <span class="c1"># `arrays` will hold the transformed arguments.</span>
    <span class="n">arrays</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">sLast</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">sumsq</span> <span class="o">=</span> <span class="n">sq</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="c1"># The O&#39;Brien transform.</span>
        <span class="n">t</span> <span class="o">=</span> <span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="mf">1.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">n</span> <span class="o">*</span> <span class="n">sq</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">sumsq</span><span class="p">)</span> <span class="o">/</span> <span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">))</span>

        <span class="c1"># Check that the mean of the transformed data is equal to the</span>
        <span class="c1"># original variance.</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">sumsq</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">var</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">t</span><span class="p">))</span> <span class="o">&gt;</span> <span class="n">TINY</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Lack of convergence in obrientransform.&#39;</span><span class="p">)</span>

        <span class="n">arrays</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="n">sLast</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">sLast</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">arr</span> <span class="ow">in</span> <span class="n">arrays</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">sLast</span> <span class="o">!=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">arrays</span><span class="p">)</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">too_small</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sem</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute standard error of the mean.</span>

<span class="sd">    Calculate the standard error of the mean (or standard error of</span>
<span class="sd">    measurement) of the values in the input array.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        An array containing the values for which the standard error is</span>
<span class="sd">        returned.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to operate. Default is 0. If None, compute over</span>
<span class="sd">        the whole array `a`.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        Delta degrees-of-freedom. How many degrees of freedom to adjust</span>
<span class="sd">        for bias in limited samples relative to the population estimate</span>
<span class="sd">        of variance. Defaults to 1.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    s : ndarray or float</span>
<span class="sd">        The standard error of the mean in the sample(s), along the input axis.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The default value for `ddof` is different to the default (0) used by other</span>
<span class="sd">    ddof containing routines, such as np.std and np.nanstd.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Find standard error along the first axis:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; a = np.arange(20).reshape(5,4)</span>
<span class="sd">    &gt;&gt;&gt; stats.sem(a)</span>
<span class="sd">    array([ 2.8284,  2.8284,  2.8284,  2.8284])</span>

<span class="sd">    Find standard error across the whole array, using n degrees of freedom:</span>

<span class="sd">    &gt;&gt;&gt; stats.sem(a, axis=None, ddof=0)</span>
<span class="sd">    1.2893796958227628</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_isconst</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check if all values in x are the same.  nans are ignored.</span>

<span class="sd">    x must be a 1d array.</span>

<span class="sd">    The return value is a 1d array with length 1, so it can be used</span>
<span class="sd">    in np.apply_along_axis.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="kc">True</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_quiet_nanmean</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute nanmean for the 1d array x, but quietly return nan if x is all nan.</span>

<span class="sd">    The return value is a 1d array with length 1, so it can be used</span>
<span class="sd">    in np.apply_along_axis.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_quiet_nanstd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute nanstd for the 1d array x, but quietly return nan if x is all nan.</span>

<span class="sd">    The return value is a 1d array with length 1, so it can be used</span>
<span class="sd">    in np.apply_along_axis.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">zscore</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the z score.</span>

<span class="sd">    Compute the z score of each value in the sample, relative to the</span>
<span class="sd">    sample mean and standard deviation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        An array like object containing the sample data.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to operate. Default is 0. If None, compute over</span>
<span class="sd">        the whole array `a`.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        Degrees of freedom correction in the calculation of the</span>
<span class="sd">        standard deviation. Default is 0.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan. &#39;propagate&#39; returns nan,</span>
<span class="sd">        &#39;raise&#39; throws an error, &#39;omit&#39; performs the calculations ignoring nan</span>
<span class="sd">        values. Default is &#39;propagate&#39;.  Note that when the value is &#39;omit&#39;,</span>
<span class="sd">        nans in the input also propagate to the output, but they do not affect</span>
<span class="sd">        the z-scores computed for the non-nan values.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    zscore : array_like</span>
<span class="sd">        The z-scores, standardized by mean and standard deviation of</span>
<span class="sd">        input array `a`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.mean : Arithmetic average</span>
<span class="sd">    numpy.std : Arithmetic standard deviation</span>
<span class="sd">    scipy.stats.gzscore : Geometric standard score</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function preserves ndarray subclasses, and works also with</span>
<span class="sd">    matrices and masked arrays (it uses `asanyarray` instead of</span>
<span class="sd">    `asarray` for parameters).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Standard score&quot;, *Wikipedia*,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Standard_score.</span>
<span class="sd">    .. [2] Huck, S. W., Cross, T. L., Clark, S. B, &quot;Overcoming misconceptions</span>
<span class="sd">           about Z-scores&quot;, Teaching Statistics, vol. 8, pp. 38-40, 1986</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; a = np.array([ 0.7972,  0.0767,  0.4383,  0.7866,  0.8091,</span>
<span class="sd">    ...                0.1954,  0.6307,  0.6599,  0.1065,  0.0508])</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; stats.zscore(a)</span>
<span class="sd">    array([ 1.1273, -1.247 , -0.0552,  1.0923,  1.1664, -0.8559,  0.5786,</span>
<span class="sd">            0.6748, -1.1488, -1.3324])</span>

<span class="sd">    Computing along a specified axis, using n-1 degrees of freedom</span>
<span class="sd">    (``ddof=1``) to calculate the standard deviation:</span>

<span class="sd">    &gt;&gt;&gt; b = np.array([[ 0.3148,  0.0478,  0.6243,  0.4608],</span>
<span class="sd">    ...               [ 0.7149,  0.0775,  0.6072,  0.9656],</span>
<span class="sd">    ...               [ 0.6341,  0.1403,  0.9759,  0.4064],</span>
<span class="sd">    ...               [ 0.5918,  0.6948,  0.904 ,  0.3721],</span>
<span class="sd">    ...               [ 0.0921,  0.2481,  0.1188,  0.1366]])</span>
<span class="sd">    &gt;&gt;&gt; stats.zscore(b, axis=1, ddof=1)</span>
<span class="sd">    array([[-0.19264823, -1.28415119,  1.07259584,  0.40420358],</span>
<span class="sd">           [ 0.33048416, -1.37380874,  0.04251374,  1.00081084],</span>
<span class="sd">           [ 0.26796377, -1.12598418,  1.23283094, -0.37481053],</span>
<span class="sd">           [-0.22095197,  0.24468594,  1.19042819, -1.21416216],</span>
<span class="sd">           [-0.82780366,  1.4457416 , -0.43867764, -0.1792603 ]])</span>

<span class="sd">    An example with `nan_policy=&#39;omit&#39;`:</span>

<span class="sd">    &gt;&gt;&gt; x = np.array([[25.11, 30.10, np.nan, 32.02, 43.15],</span>
<span class="sd">    ...               [14.95, 16.06, 121.25, 94.35, 29.81]])</span>
<span class="sd">    &gt;&gt;&gt; stats.zscore(x, axis=1, nan_policy=&#39;omit&#39;)</span>
<span class="sd">    array([[-1.13490897, -0.37830299,         nan, -0.08718406,  1.60039602],</span>
<span class="sd">           [-0.91611681, -0.89090508,  1.4983032 ,  0.88731639, -0.5785977 ]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">zmap</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">gzscore</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the geometric standard score.</span>

<span class="sd">    Compute the geometric z score of each strictly positive value in the</span>
<span class="sd">    sample, relative to the geometric mean and standard deviation.</span>
<span class="sd">    Mathematically the geometric z score can be evaluated as::</span>

<span class="sd">        gzscore = log(a/gmu) / log(gsigma)</span>

<span class="sd">    where ``gmu`` (resp. ``gsigma``) is the geometric mean (resp. standard</span>
<span class="sd">    deviation).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Sample data.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to operate. Default is 0. If None, compute over</span>
<span class="sd">        the whole array `a`.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        Degrees of freedom correction in the calculation of the</span>
<span class="sd">        standard deviation. Default is 0.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan. &#39;propagate&#39; returns nan,</span>
<span class="sd">        &#39;raise&#39; throws an error, &#39;omit&#39; performs the calculations ignoring nan</span>
<span class="sd">        values. Default is &#39;propagate&#39;.  Note that when the value is &#39;omit&#39;,</span>
<span class="sd">        nans in the input also propagate to the output, but they do not affect</span>
<span class="sd">        the geometric z scores computed for the non-nan values.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gzscore : array_like</span>
<span class="sd">        The geometric z scores, standardized by geometric mean and geometric</span>
<span class="sd">        standard deviation of input array `a`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    gmean : Geometric mean</span>
<span class="sd">    gstd : Geometric standard deviation</span>
<span class="sd">    zscore : Standard score</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function preserves ndarray subclasses, and works also with</span>
<span class="sd">    matrices and masked arrays (it uses ``asanyarray`` instead of</span>
<span class="sd">    ``asarray`` for parameters).</span>

<span class="sd">    .. versionadded:: 1.8</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Geometric standard score&quot;, *Wikipedia*,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Geometric_standard_deviation#Geometric_standard_score.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Draw samples from a log-normal distribution:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import zscore, gzscore</span>
<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>

<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">    &gt;&gt;&gt; mu, sigma = 3., 1.  # mean and standard deviation</span>
<span class="sd">    &gt;&gt;&gt; x = rng.lognormal(mu, sigma, size=500)</span>

<span class="sd">    Display the histogram of the samples:</span>

<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots()</span>
<span class="sd">    &gt;&gt;&gt; ax.hist(x, 50)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    Display the histogram of the samples standardized by the classical zscore.</span>
<span class="sd">    Distribution is rescaled but its shape is unchanged.</span>

<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots()</span>
<span class="sd">    &gt;&gt;&gt; ax.hist(zscore(x), 50)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    Demonstrate that the distribution of geometric zscores is rescaled and</span>
<span class="sd">    quasinormal:</span>

<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots()</span>
<span class="sd">    &gt;&gt;&gt; ax.hist(gzscore(x), 50)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">log</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">log</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">ma</span><span class="o">.</span><span class="n">MaskedArray</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span>

    <span class="k">return</span> <span class="n">zscore</span><span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">zmap</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">compare</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the relative z-scores.</span>

<span class="sd">    Return an array of z-scores, i.e., scores that are standardized to</span>
<span class="sd">    zero mean and unit variance, where mean and variance are calculated</span>
<span class="sd">    from the comparison array.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    scores : array_like</span>
<span class="sd">        The input for which z-scores are calculated.</span>
<span class="sd">    compare : array_like</span>
<span class="sd">        The input from which the mean and standard deviation of the</span>
<span class="sd">        normalization are taken; assumed to have the same dimension as</span>
<span class="sd">        `scores`.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis over which mean and variance of `compare` are calculated.</span>
<span class="sd">        Default is 0. If None, compute over the whole array `scores`.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        Degrees of freedom correction in the calculation of the</span>
<span class="sd">        standard deviation. Default is 0.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle the occurrence of nans in `compare`.</span>
<span class="sd">        &#39;propagate&#39; returns nan, &#39;raise&#39; raises an exception, &#39;omit&#39;</span>
<span class="sd">        performs the calculations ignoring nan values. Default is</span>
<span class="sd">        &#39;propagate&#39;. Note that when the value is &#39;omit&#39;, nans in `scores`</span>
<span class="sd">        also propagate to the output, but they do not affect the z-scores</span>
<span class="sd">        computed for the non-nan values.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    zscore : array_like</span>
<span class="sd">        Z-scores, in the same shape as `scores`.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function preserves ndarray subclasses, and works also with</span>
<span class="sd">    matrices and masked arrays (it uses `asanyarray` instead of</span>
<span class="sd">    `asarray` for parameters).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import zmap</span>
<span class="sd">    &gt;&gt;&gt; a = [0.5, 2.0, 2.5, 3]</span>
<span class="sd">    &gt;&gt;&gt; b = [0, 1, 2, 3, 4]</span>
<span class="sd">    &gt;&gt;&gt; zmap(a, b)</span>
<span class="sd">    array([-1.06066017,  0.        ,  0.35355339,  0.70710678])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">compare</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mn</span> <span class="o">=</span> <span class="n">_quiet_nanmean</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">_quiet_nanstd</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span>
            <span class="n">isconst</span> <span class="o">=</span> <span class="n">_isconst</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">_quiet_nanmean</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">_quiet_nanstd</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span>
            <span class="n">isconst</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">_isconst</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">mn</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># The intent is to check whether all elements of `a` along `axis` are</span>
        <span class="c1"># identical. Due to finite precision arithmetic, comparing elements</span>
        <span class="c1"># against `mn` doesn&#39;t work. Previously, this compared elements to</span>
        <span class="c1"># `_first`, but that extracts the element at index 0 regardless of</span>
        <span class="c1"># whether it is masked. As a simple fix, compare against `min`.</span>
        <span class="n">a0</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">isconst</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">==</span> <span class="n">a0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Set std deviations that are 0 to 1 to avoid division by 0.</span>
    <span class="n">std</span><span class="p">[</span><span class="n">isconst</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">scores</span> <span class="o">-</span> <span class="n">mn</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
    <span class="c1"># Set the outputs associated with a constant input to nan.</span>
    <span class="n">z</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">isconst</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">return</span> <span class="n">z</span>


<span class="k">def</span><span class="w"> </span><span class="nf">gstd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the geometric standard deviation of an array.</span>

<span class="sd">    The geometric standard deviation describes the spread of a set of numbers</span>
<span class="sd">    where the geometric mean is preferred. It is a multiplicative factor, and</span>
<span class="sd">    so a dimensionless quantity.</span>

<span class="sd">    It is defined as the exponent of the standard deviation of ``log(a)``.</span>
<span class="sd">    Mathematically the population geometric standard deviation can be</span>
<span class="sd">    evaluated as::</span>

<span class="sd">        gstd = exp(std(log(a)))</span>

<span class="sd">    .. versionadded:: 1.3.0</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        An array like object containing the sample data.</span>
<span class="sd">    axis : int, tuple or None, optional</span>
<span class="sd">        Axis along which to operate. Default is 0. If None, compute over</span>
<span class="sd">        the whole array `a`.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        Degree of freedom correction in the calculation of the</span>
<span class="sd">        geometric standard deviation. Default is 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    gstd : ndarray or float</span>
<span class="sd">        An array of the geometric standard deviation. If `axis` is None or `a`</span>
<span class="sd">        is a 1d array a float is returned.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    gmean : Geometric mean</span>
<span class="sd">    numpy.std : Standard deviation</span>
<span class="sd">    gzscore : Geometric standard score</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    As the calculation requires the use of logarithms the geometric standard</span>
<span class="sd">    deviation only supports strictly positive values. Any non-positive or</span>
<span class="sd">    infinite values will raise a `ValueError`.</span>
<span class="sd">    The geometric standard deviation is sometimes confused with the exponent of</span>
<span class="sd">    the standard deviation, ``exp(std(a))``. Instead the geometric standard</span>
<span class="sd">    deviation is ``exp(std(log(a)))``.</span>
<span class="sd">    The default value for `ddof` is different to the default value (0) used</span>
<span class="sd">    by other ddof containing functions, such as ``np.std`` and ``np.nanstd``.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Geometric standard deviation&quot;, *Wikipedia*,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Geometric_standard_deviation.</span>
<span class="sd">    .. [2] Kirkwood, T. B., &quot;Geometric means and measures of dispersion&quot;,</span>
<span class="sd">           Biometrics, vol. 35, pp. 908-909, 1979</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Find the geometric standard deviation of a log-normally distributed sample.</span>
<span class="sd">    Note that the standard deviation of the distribution is one, on a</span>
<span class="sd">    log scale this evaluates to approximately ``exp(1)``.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import gstd</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">    &gt;&gt;&gt; sample = rng.lognormal(mean=0, sigma=1, size=1000)</span>
<span class="sd">    &gt;&gt;&gt; gstd(sample)</span>
<span class="sd">    2.810010162475324</span>

<span class="sd">    Compute the geometric standard deviation of a multidimensional array and</span>
<span class="sd">    of a given axis.</span>

<span class="sd">    &gt;&gt;&gt; a = np.arange(1, 25).reshape(2, 3, 4)</span>
<span class="sd">    &gt;&gt;&gt; gstd(a, axis=None)</span>
<span class="sd">    2.2944076136018947</span>
<span class="sd">    &gt;&gt;&gt; gstd(a, axis=2)</span>
<span class="sd">    array([[1.82424757, 1.22436866, 1.13183117],</span>
<span class="sd">           [1.09348306, 1.07244798, 1.05914985]])</span>
<span class="sd">    &gt;&gt;&gt; gstd(a, axis=(1,2))</span>
<span class="sd">    array([2.12939215, 1.22120169])</span>

<span class="sd">    The geometric standard deviation further handles masked arrays.</span>

<span class="sd">    &gt;&gt;&gt; a = np.arange(1, 25).reshape(2, 3, 4)</span>
<span class="sd">    &gt;&gt;&gt; ma = np.ma.masked_where(a &gt; 16, a)</span>
<span class="sd">    &gt;&gt;&gt; ma</span>
<span class="sd">    masked_array(</span>
<span class="sd">      data=[[[1, 2, 3, 4],</span>
<span class="sd">             [5, 6, 7, 8],</span>
<span class="sd">             [9, 10, 11, 12]],</span>
<span class="sd">            [[13, 14, 15, 16],</span>
<span class="sd">             [--, --, --, --],</span>
<span class="sd">             [--, --, --, --]]],</span>
<span class="sd">      mask=[[[False, False, False, False],</span>
<span class="sd">             [False, False, False, False],</span>
<span class="sd">             [False, False, False, False]],</span>
<span class="sd">            [[False, False, False, False],</span>
<span class="sd">             [ True,  True,  True,  True],</span>
<span class="sd">             [ True,  True,  True,  True]]],</span>
<span class="sd">      fill_value=999999)</span>
<span class="sd">    &gt;&gt;&gt; gstd(ma, axis=2)</span>
<span class="sd">    masked_array(</span>
<span class="sd">      data=[[1.8242475707663655, 1.2243686572447428, 1.1318311657788478],</span>
<span class="sd">            [1.0934830582350938, --, --]],</span>
<span class="sd">      mask=[[False, False, False],</span>
<span class="sd">            [False,  True,  True]],</span>
<span class="sd">      fill_value=999999)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">log</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">log</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">ma</span><span class="o">.</span><span class="n">MaskedArray</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;error&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">))</span>
    <span class="k">except</span> <span class="ne">RuntimeWarning</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Infinite value encountered. The geometric standard deviation &#39;</span>
                <span class="s1">&#39;is defined for strictly positive values only.&#39;</span>
            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">w</span>
        <span class="n">a_nan</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">a_nan_any</span> <span class="o">=</span> <span class="n">a_nan</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
        <span class="c1"># exclude NaN&#39;s from negativity check, but</span>
        <span class="c1"># avoid expensive masking for arrays with no NaN</span>
        <span class="k">if</span> <span class="p">((</span><span class="n">a_nan_any</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nanmin</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="mi">0</span><span class="p">))</span> <span class="ow">or</span>
                <span class="p">(</span><span class="ow">not</span> <span class="n">a_nan_any</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">())):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Non positive value encountered. The geometric standard &#39;</span>
                <span class="s1">&#39;deviation is defined for strictly positive values only.&#39;</span>
            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">w</span>
        <span class="k">elif</span> <span class="s1">&#39;Degrees of freedom &lt;= 0 for slice&#39;</span> <span class="o">==</span> <span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">w</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">#  Remaining warnings don&#39;t need to be exceptions.</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">where</span><span class="o">=~</span><span class="n">a_nan</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">))</span>
    <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;Invalid array input. The inputs could not be &#39;</span>
            <span class="s1">&#39;safely coerced to any supported types&#39;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>


<span class="c1"># Private dictionary initialized only once at module level</span>
<span class="c1"># See https://en.wikipedia.org/wiki/Robust_measures_of_scale</span>
<span class="n">_scale_conversions</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;normal&#39;</span><span class="p">:</span> <span class="n">special</span><span class="o">.</span><span class="n">erfinv</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)}</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">default_axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;nan_propagation&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">iqr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">75</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span>
        <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the interquartile range of the data along the specified axis.</span>

<span class="sd">    The interquartile range (IQR) is the difference between the 75th and</span>
<span class="sd">    25th percentile of the data. It is a measure of the dispersion</span>
<span class="sd">    similar to standard deviation or variance, but is much more robust</span>
<span class="sd">    against outliers [2]_.</span>

<span class="sd">    The ``rng`` parameter allows this function to compute other</span>
<span class="sd">    percentile ranges than the actual IQR. For example, setting</span>
<span class="sd">    ``rng=(0, 100)`` is equivalent to `numpy.ptp`.</span>

<span class="sd">    The IQR of an empty array is `np.nan`.</span>

<span class="sd">    .. versionadded:: 0.18.0</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : array_like</span>
<span class="sd">        Input array or object that can be converted to an array.</span>
<span class="sd">    axis : int or sequence of int, optional</span>
<span class="sd">        Axis along which the range is computed. The default is to</span>
<span class="sd">        compute the IQR for the entire array.</span>
<span class="sd">    rng : Two-element sequence containing floats in range of [0,100] optional</span>
<span class="sd">        Percentiles over which to compute the range. Each must be</span>
<span class="sd">        between 0 and 100, inclusive. The default is the true IQR:</span>
<span class="sd">        ``(25, 75)``. The order of the elements is not important.</span>
<span class="sd">    scale : scalar or str or array_like of reals, optional</span>
<span class="sd">        The numerical value of scale will be divided out of the final</span>
<span class="sd">        result. The following string value is also recognized:</span>

<span class="sd">          * &#39;normal&#39; : Scale by</span>
<span class="sd">            :math:`2 \sqrt{2} erf^{-1}(\frac{1}{2}) \approx 1.349`.</span>

<span class="sd">        The default is 1.0.</span>
<span class="sd">        Array-like `scale` of real dtype is also allowed, as long</span>
<span class="sd">        as it broadcasts correctly to the output such that</span>
<span class="sd">        ``out / scale`` is a valid operation. The output dimensions</span>
<span class="sd">        depend on the input array, `x`, the `axis` argument, and the</span>
<span class="sd">        `keepdims` flag.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>
<span class="sd">    interpolation : str, optional</span>

<span class="sd">        Specifies the interpolation method to use when the percentile</span>
<span class="sd">        boundaries lie between two data points ``i`` and ``j``.</span>
<span class="sd">        The following options are available (default is &#39;linear&#39;):</span>

<span class="sd">          * &#39;linear&#39;: ``i + (j - i)*fraction``, where ``fraction`` is the</span>
<span class="sd">            fractional part of the index surrounded by ``i`` and ``j``.</span>
<span class="sd">          * &#39;lower&#39;: ``i``.</span>
<span class="sd">          * &#39;higher&#39;: ``j``.</span>
<span class="sd">          * &#39;nearest&#39;: ``i`` or ``j`` whichever is nearest.</span>
<span class="sd">          * &#39;midpoint&#39;: ``(i + j)/2``.</span>

<span class="sd">        For NumPy &gt;= 1.22.0, the additional options provided by the ``method``</span>
<span class="sd">        keyword of `numpy.percentile` are also valid.</span>

<span class="sd">    keepdims : bool, optional</span>
<span class="sd">        If this is set to True, the reduced axes are left in the</span>
<span class="sd">        result as dimensions with size one. With this option, the result</span>
<span class="sd">        will broadcast correctly against the original array `x`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    iqr : scalar or ndarray</span>
<span class="sd">        If ``axis=None``, a scalar is returned. If the input contains</span>
<span class="sd">        integers or floats of smaller precision than ``np.float64``, then the</span>
<span class="sd">        output data-type is ``np.float64``. Otherwise, the output data-type is</span>
<span class="sd">        the same as that of the input.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.std, numpy.var</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Interquartile range&quot; https://en.wikipedia.org/wiki/Interquartile_range</span>
<span class="sd">    .. [2] &quot;Robust measures of scale&quot; https://en.wikipedia.org/wiki/Robust_measures_of_scale</span>
<span class="sd">    .. [3] &quot;Quantile&quot; https://en.wikipedia.org/wiki/Quantile</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import iqr</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([[10, 7, 4], [3, 2, 1]])</span>
<span class="sd">    &gt;&gt;&gt; x</span>
<span class="sd">    array([[10,  7,  4],</span>
<span class="sd">           [ 3,  2,  1]])</span>
<span class="sd">    &gt;&gt;&gt; iqr(x)</span>
<span class="sd">    4.0</span>
<span class="sd">    &gt;&gt;&gt; iqr(x, axis=0)</span>
<span class="sd">    array([ 3.5,  2.5,  1.5])</span>
<span class="sd">    &gt;&gt;&gt; iqr(x, axis=1)</span>
<span class="sd">    array([ 3.,  1.])</span>
<span class="sd">    &gt;&gt;&gt; iqr(x, axis=1, keepdims=True)</span>
<span class="sd">    array([[ 3.],</span>
<span class="sd">           [ 1.]])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># This check prevents percentile from raising an error later. Also, it is</span>
    <span class="c1"># consistent with `np.var` and `np.std`.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_get_nan</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># An error may be raised here, so fail-fast, before doing lengthy</span>
    <span class="c1"># computations, even though `scale` is not used until later</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">scale_key</span> <span class="o">=</span> <span class="n">scale</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">scale_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_scale_conversions</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scale</span><span class="si">}</span><span class="s2"> not a valid scale for `iqr`&quot;</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">_scale_conversions</span><span class="p">[</span><span class="n">scale_key</span><span class="p">]</span>

    <span class="c1"># Select the percentile function to use based on nans and policy</span>
    <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="n">percentile_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanpercentile</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">percentile_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;quantile range must be two element sequence&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;range must not contain NaNs&quot;</span><span class="p">)</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
    <span class="n">pct</span> <span class="o">=</span> <span class="n">percentile_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">interpolation</span><span class="p">,</span>
                          <span class="n">keepdims</span><span class="o">=</span><span class="n">keepdims</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">pct</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pct</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">scale</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">/=</span> <span class="n">scale</span>

    <span class="k">return</span> <span class="n">out</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_mad_1d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">center</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">):</span>
    <span class="c1"># Median absolute deviation for 1-d array x.</span>
    <span class="c1"># This is a helper function for `median_abs_deviation`; it assumes its</span>
    <span class="c1"># arguments have been validated already.  In particular,  x must be a</span>
    <span class="c1"># 1-d numpy array, center must be callable, and if nan_policy is not</span>
    <span class="c1"># &#39;propagate&#39;, it is assumed to be &#39;omit&#39;, because &#39;raise&#39; is handled</span>
    <span class="c1"># in `median_abs_deviation`.</span>
    <span class="c1"># No warning is generated if x is empty or all nan.</span>
    <span class="n">isnan</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">isnan</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;propagate&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">~</span><span class="n">isnan</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># MAD of an empty array is nan.</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="c1"># Edge cases have been handled, so do the basic MAD calculation.</span>
    <span class="n">med</span> <span class="o">=</span> <span class="n">center</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">mad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">med</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">mad</span>


<div class="viewcode-block" id="median_abs_deviation">
<a class="viewcode-back" href="../../../api/bayesflow.diagnostics.html#bayesflow.diagnostics.median_abs_deviation">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">median_abs_deviation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                         <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the median absolute deviation of the data along the given axis.</span>

<span class="sd">    The median absolute deviation (MAD, [1]_) computes the median over the</span>
<span class="sd">    absolute deviations from the median. It is a measure of dispersion</span>
<span class="sd">    similar to the standard deviation but more robust to outliers [2]_.</span>

<span class="sd">    The MAD of an empty array is ``np.nan``.</span>

<span class="sd">    .. versionadded:: 1.5.0</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : array_like</span>
<span class="sd">        Input array or object that can be converted to an array.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which the range is computed. Default is 0. If None, compute</span>
<span class="sd">        the MAD over the entire array.</span>
<span class="sd">    center : callable, optional</span>
<span class="sd">        A function that will return the central value. The default is to use</span>
<span class="sd">        np.median. Any user defined function used will need to have the</span>
<span class="sd">        function signature ``func(arr, axis)``.</span>
<span class="sd">    scale : scalar or str, optional</span>
<span class="sd">        The numerical value of scale will be divided out of the final</span>
<span class="sd">        result. The default is 1.0. The string &quot;normal&quot; is also accepted,</span>
<span class="sd">        and results in `scale` being the inverse of the standard normal</span>
<span class="sd">        quantile function at 0.75, which is approximately 0.67449.</span>
<span class="sd">        Array-like scale is also allowed, as long as it broadcasts correctly</span>
<span class="sd">        to the output such that ``out / scale`` is a valid operation. The</span>
<span class="sd">        output dimensions depend on the input array, `x`, and the `axis`</span>
<span class="sd">        argument.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">        * &#39;propagate&#39;: returns nan</span>
<span class="sd">        * &#39;raise&#39;: throws an error</span>
<span class="sd">        * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mad : scalar or ndarray</span>
<span class="sd">        If ``axis=None``, a scalar is returned. If the input contains</span>
<span class="sd">        integers or floats of smaller precision than ``np.float64``, then the</span>
<span class="sd">        output data-type is ``np.float64``. Otherwise, the output data-type is</span>
<span class="sd">        the same as that of the input.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.std, numpy.var, numpy.median, scipy.stats.iqr, scipy.stats.tmean,</span>
<span class="sd">    scipy.stats.tstd, scipy.stats.tvar</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The `center` argument only affects the calculation of the central value</span>
<span class="sd">    around which the MAD is calculated. That is, passing in ``center=np.mean``</span>
<span class="sd">    will calculate the MAD around the mean - it will not calculate the *mean*</span>
<span class="sd">    absolute deviation.</span>

<span class="sd">    The input array may contain `inf`, but if `center` returns `inf`, the</span>
<span class="sd">    corresponding MAD for that data will be `nan`.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Median absolute deviation&quot;,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Median_absolute_deviation</span>
<span class="sd">    .. [2] &quot;Robust measures of scale&quot;,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Robust_measures_of_scale</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    When comparing the behavior of `median_abs_deviation` with ``np.std``,</span>
<span class="sd">    the latter is affected when we change a single value of an array to have an</span>
<span class="sd">    outlier value while the MAD hardly changes:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x = stats.norm.rvs(size=100, scale=1, random_state=123456)</span>
<span class="sd">    &gt;&gt;&gt; x.std()</span>
<span class="sd">    0.9973906394005013</span>
<span class="sd">    &gt;&gt;&gt; stats.median_abs_deviation(x)</span>
<span class="sd">    0.82832610097857</span>
<span class="sd">    &gt;&gt;&gt; x[0] = 345.6</span>
<span class="sd">    &gt;&gt;&gt; x.std()</span>
<span class="sd">    34.42304872314415</span>
<span class="sd">    &gt;&gt;&gt; stats.median_abs_deviation(x)</span>
<span class="sd">    0.8323442311590675</span>

<span class="sd">    Axis handling example:</span>

<span class="sd">    &gt;&gt;&gt; x = np.array([[10, 7, 4], [3, 2, 1]])</span>
<span class="sd">    &gt;&gt;&gt; x</span>
<span class="sd">    array([[10,  7,  4],</span>
<span class="sd">           [ 3,  2,  1]])</span>
<span class="sd">    &gt;&gt;&gt; stats.median_abs_deviation(x)</span>
<span class="sd">    array([3.5, 2.5, 1.5])</span>
<span class="sd">    &gt;&gt;&gt; stats.median_abs_deviation(x, axis=None)</span>
<span class="sd">    2.0</span>

<span class="sd">    Scale normal example:</span>

<span class="sd">    &gt;&gt;&gt; x = stats.norm.rvs(size=1000000, scale=2, random_state=123456)</span>
<span class="sd">    &gt;&gt;&gt; stats.median_abs_deviation(x)</span>
<span class="sd">    1.3487398527041636</span>
<span class="sd">    &gt;&gt;&gt; stats.median_abs_deviation(x, scale=&#39;normal&#39;)</span>
<span class="sd">    1.9996446978061115</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">center</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The argument &#39;center&#39; must be callable. The given &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;value </span><span class="si">{</span><span class="nb">repr</span><span class="p">(</span><span class="n">center</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not callable.&quot;</span><span class="p">)</span>

    <span class="c1"># An error may be raised here, so fail-fast, before doing lengthy</span>
    <span class="c1"># computations, even though `scale` is not used until later</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">scale</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="mf">0.6744897501960817</span>  <span class="c1"># special.ndtri(0.75)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scale</span><span class="si">}</span><span class="s2"> is not a valid scale value.&quot;</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Consistent with `np.var` and `np.std`.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">nan_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">item</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">axis</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nan_shape</span> <span class="o">==</span> <span class="p">():</span>
            <span class="c1"># Return nan, not array(nan)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">nan_shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

    <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">contains_nan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mad</span> <span class="o">=</span> <span class="n">_mad_1d</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">center</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">_mad_1d</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">center</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">med</span> <span class="o">=</span> <span class="n">center</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">mad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">med</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Wrap the call to center() in expand_dims() so it acts like</span>
            <span class="c1"># keepdims=True was used.</span>
            <span class="n">med</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">center</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">),</span> <span class="n">axis</span><span class="p">)</span>
            <span class="n">mad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">med</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mad</span> <span class="o">/</span> <span class="n">scale</span></div>



<span class="c1">#####################################</span>
<span class="c1">#         TRIMMING FUNCTIONS        #</span>
<span class="c1">#####################################</span>


<span class="n">SigmaclipResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;SigmaclipResult&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;clipped&#39;</span><span class="p">,</span> <span class="s1">&#39;lower&#39;</span><span class="p">,</span> <span class="s1">&#39;upper&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">sigmaclip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">4.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">4.</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform iterative sigma-clipping of array elements.</span>

<span class="sd">    Starting from the full sample, all elements outside the critical range are</span>
<span class="sd">    removed, i.e. all elements of the input array `c` that satisfy either of</span>
<span class="sd">    the following conditions::</span>

<span class="sd">        c &lt; mean(c) - std(c)*low</span>
<span class="sd">        c &gt; mean(c) + std(c)*high</span>

<span class="sd">    The iteration continues with the updated sample until no</span>
<span class="sd">    elements are outside the (updated) range.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Data array, will be raveled if not 1-D.</span>
<span class="sd">    low : float, optional</span>
<span class="sd">        Lower bound factor of sigma clipping. Default is 4.</span>
<span class="sd">    high : float, optional</span>
<span class="sd">        Upper bound factor of sigma clipping. Default is 4.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    clipped : ndarray</span>
<span class="sd">        Input array with clipped elements removed.</span>
<span class="sd">    lower : float</span>
<span class="sd">        Lower threshold value use for clipping.</span>
<span class="sd">    upper : float</span>
<span class="sd">        Upper threshold value use for clipping.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import sigmaclip</span>
<span class="sd">    &gt;&gt;&gt; a = np.concatenate((np.linspace(9.5, 10.5, 31),</span>
<span class="sd">    ...                     np.linspace(0, 20, 5)))</span>
<span class="sd">    &gt;&gt;&gt; fact = 1.5</span>
<span class="sd">    &gt;&gt;&gt; c, low, upp = sigmaclip(a, fact, fact)</span>
<span class="sd">    &gt;&gt;&gt; c</span>
<span class="sd">    array([  9.96666667,  10.        ,  10.03333333,  10.        ])</span>
<span class="sd">    &gt;&gt;&gt; c.var(), c.std()</span>
<span class="sd">    (0.00055555555555555165, 0.023570226039551501)</span>
<span class="sd">    &gt;&gt;&gt; low, c.mean() - fact*c.std(), c.min()</span>
<span class="sd">    (9.9646446609406727, 9.9646446609406727, 9.9666666666666668)</span>
<span class="sd">    &gt;&gt;&gt; upp, c.mean() + fact*c.std(), c.max()</span>
<span class="sd">    (10.035355339059327, 10.035355339059327, 10.033333333333333)</span>

<span class="sd">    &gt;&gt;&gt; a = np.concatenate((np.linspace(9.5, 10.5, 11),</span>
<span class="sd">    ...                     np.linspace(-100, -50, 3)))</span>
<span class="sd">    &gt;&gt;&gt; c, low, upp = sigmaclip(a, 1.8, 1.8)</span>
<span class="sd">    &gt;&gt;&gt; (c == np.linspace(9.5, 10.5, 11)).all()</span>
<span class="sd">    True</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">while</span> <span class="n">delta</span><span class="p">:</span>
        <span class="n">c_std</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
        <span class="n">c_mean</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">size</span>
        <span class="n">critlower</span> <span class="o">=</span> <span class="n">c_mean</span> <span class="o">-</span> <span class="n">c_std</span> <span class="o">*</span> <span class="n">low</span>
        <span class="n">critupper</span> <span class="o">=</span> <span class="n">c_mean</span> <span class="o">+</span> <span class="n">c_std</span> <span class="o">*</span> <span class="n">high</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">c</span><span class="p">[(</span><span class="n">c</span> <span class="o">&gt;=</span> <span class="n">critlower</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">c</span> <span class="o">&lt;=</span> <span class="n">critupper</span><span class="p">)]</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">size</span> <span class="o">-</span> <span class="n">c</span><span class="o">.</span><span class="n">size</span>

    <span class="k">return</span> <span class="n">SigmaclipResult</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">critlower</span><span class="p">,</span> <span class="n">critupper</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">trimboth</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">proportiontocut</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Slice off a proportion of items from both ends of an array.</span>

<span class="sd">    Slice off the passed proportion of items from both ends of the passed</span>
<span class="sd">    array (i.e., with `proportiontocut` = 0.1, slices leftmost 10% **and**</span>
<span class="sd">    rightmost 10% of scores). The trimmed values are the lowest and</span>
<span class="sd">    highest ones.</span>
<span class="sd">    Slice off less if proportion results in a non-integer slice index (i.e.</span>
<span class="sd">    conservatively slices off `proportiontocut`).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Data to trim.</span>
<span class="sd">    proportiontocut : float</span>
<span class="sd">        Proportion (in range 0-1) of total data set to trim of each end.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to trim data. Default is 0. If None, compute over</span>
<span class="sd">        the whole array `a`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out : ndarray</span>
<span class="sd">        Trimmed version of array `a`. The order of the trimmed content</span>
<span class="sd">        is undefined.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    trim_mean</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Create an array of 10 values and trim 10% of those values from each end:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span>
<span class="sd">    &gt;&gt;&gt; stats.trimboth(a, 0.1)</span>
<span class="sd">    array([1, 3, 2, 4, 5, 6, 7, 8])</span>

<span class="sd">    Note that the elements of the input array are trimmed by value, but the</span>
<span class="sd">    output array is not necessarily sorted.</span>

<span class="sd">    The proportion to trim is rounded down to the nearest integer. For</span>
<span class="sd">    instance, trimming 25% of the values from each end of an array of 10</span>
<span class="sd">    values will return an array of 6 values:</span>

<span class="sd">    &gt;&gt;&gt; b = np.arange(10)</span>
<span class="sd">    &gt;&gt;&gt; stats.trimboth(b, 1/4).shape</span>
<span class="sd">    (6,)</span>

<span class="sd">    Multidimensional arrays can be trimmed along any axis or across the entire</span>
<span class="sd">    array:</span>

<span class="sd">    &gt;&gt;&gt; c = [2, 4, 6, 8, 0, 1, 3, 5, 7, 9]</span>
<span class="sd">    &gt;&gt;&gt; d = np.array([a, b, c])</span>
<span class="sd">    &gt;&gt;&gt; stats.trimboth(d, 0.4, axis=0).shape</span>
<span class="sd">    (1, 10)</span>
<span class="sd">    &gt;&gt;&gt; stats.trimboth(d, 0.4, axis=1).shape</span>
<span class="sd">    (3, 2)</span>
<span class="sd">    &gt;&gt;&gt; stats.trimboth(d, 0.4, axis=None).shape</span>
<span class="sd">    (6,)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">a</span>

    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">nobs</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">lowercut</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">proportiontocut</span> <span class="o">*</span> <span class="n">nobs</span><span class="p">)</span>
    <span class="n">uppercut</span> <span class="o">=</span> <span class="n">nobs</span> <span class="o">-</span> <span class="n">lowercut</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">lowercut</span> <span class="o">&gt;=</span> <span class="n">uppercut</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Proportion too big.&quot;</span><span class="p">)</span>

    <span class="n">atmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="n">lowercut</span><span class="p">,</span> <span class="n">uppercut</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">sl</span> <span class="o">=</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)]</span> <span class="o">*</span> <span class="n">atmp</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">sl</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">lowercut</span><span class="p">,</span> <span class="n">uppercut</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">atmp</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">sl</span><span class="p">)]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">trim1</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">proportiontocut</span><span class="p">,</span> <span class="n">tail</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Slice off a proportion from ONE end of the passed array distribution.</span>

<span class="sd">    If `proportiontocut` = 0.1, slices off &#39;leftmost&#39; or &#39;rightmost&#39;</span>
<span class="sd">    10% of scores. The lowest or highest values are trimmed (depending on</span>
<span class="sd">    the tail).</span>
<span class="sd">    Slice off less if proportion results in a non-integer slice index</span>
<span class="sd">    (i.e. conservatively slices off `proportiontocut` ).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Input array.</span>
<span class="sd">    proportiontocut : float</span>
<span class="sd">        Fraction to cut off of &#39;left&#39; or &#39;right&#39; of distribution.</span>
<span class="sd">    tail : {&#39;left&#39;, &#39;right&#39;}, optional</span>
<span class="sd">        Defaults to &#39;right&#39;.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to trim data. Default is 0. If None, compute over</span>
<span class="sd">        the whole array `a`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    trim1 : ndarray</span>
<span class="sd">        Trimmed version of array `a`. The order of the trimmed content is</span>
<span class="sd">        undefined.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Create an array of 10 values and trim 20% of its lowest values:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span>
<span class="sd">    &gt;&gt;&gt; stats.trim1(a, 0.2, &#39;left&#39;)</span>
<span class="sd">    array([2, 4, 3, 5, 6, 7, 8, 9])</span>

<span class="sd">    Note that the elements of the input array are trimmed by value, but the</span>
<span class="sd">    output array is not necessarily sorted.</span>

<span class="sd">    The proportion to trim is rounded down to the nearest integer. For</span>
<span class="sd">    instance, trimming 25% of the values from an array of 10 values will</span>
<span class="sd">    return an array of 8 values:</span>

<span class="sd">    &gt;&gt;&gt; b = np.arange(10)</span>
<span class="sd">    &gt;&gt;&gt; stats.trim1(b, 1/4).shape</span>
<span class="sd">    (8,)</span>

<span class="sd">    Multidimensional arrays can be trimmed along any axis or across the entire</span>
<span class="sd">    array:</span>

<span class="sd">    &gt;&gt;&gt; c = [2, 4, 6, 8, 0, 1, 3, 5, 7, 9]</span>
<span class="sd">    &gt;&gt;&gt; d = np.array([a, b, c])</span>
<span class="sd">    &gt;&gt;&gt; stats.trim1(d, 0.8, axis=0).shape</span>
<span class="sd">    (1, 10)</span>
<span class="sd">    &gt;&gt;&gt; stats.trim1(d, 0.8, axis=1).shape</span>
<span class="sd">    (3, 2)</span>
<span class="sd">    &gt;&gt;&gt; stats.trim1(d, 0.8, axis=None).shape</span>
<span class="sd">    (6,)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">nobs</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>

    <span class="c1"># avoid possible corner case</span>
    <span class="k">if</span> <span class="n">proportiontocut</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">tail</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;right&#39;</span><span class="p">:</span>
        <span class="n">lowercut</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">uppercut</span> <span class="o">=</span> <span class="n">nobs</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">proportiontocut</span> <span class="o">*</span> <span class="n">nobs</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">tail</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;left&#39;</span><span class="p">:</span>
        <span class="n">lowercut</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">proportiontocut</span> <span class="o">*</span> <span class="n">nobs</span><span class="p">)</span>
        <span class="n">uppercut</span> <span class="o">=</span> <span class="n">nobs</span>

    <span class="n">atmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="n">lowercut</span><span class="p">,</span> <span class="n">uppercut</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">sl</span> <span class="o">=</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)]</span> <span class="o">*</span> <span class="n">atmp</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">sl</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">lowercut</span><span class="p">,</span> <span class="n">uppercut</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">atmp</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">sl</span><span class="p">)]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">trim_mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">proportiontocut</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return mean of array after trimming distribution from both tails.</span>

<span class="sd">    If `proportiontocut` = 0.1, slices off &#39;leftmost&#39; and &#39;rightmost&#39; 10% of</span>
<span class="sd">    scores. The input is sorted before slicing. Slices off less if proportion</span>
<span class="sd">    results in a non-integer slice index (i.e., conservatively slices off</span>
<span class="sd">    `proportiontocut` ).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Input array.</span>
<span class="sd">    proportiontocut : float</span>
<span class="sd">        Fraction to cut off of both tails of the distribution.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which the trimmed means are computed. Default is 0.</span>
<span class="sd">        If None, compute over the whole array `a`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    trim_mean : ndarray</span>
<span class="sd">        Mean of trimmed array.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    trimboth</span>
<span class="sd">    tmean : Compute the trimmed mean ignoring values outside given `limits`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x = np.arange(20)</span>
<span class="sd">    &gt;&gt;&gt; stats.trim_mean(x, 0.1)</span>
<span class="sd">    9.5</span>
<span class="sd">    &gt;&gt;&gt; x2 = x.reshape(5, 4)</span>
<span class="sd">    &gt;&gt;&gt; x2</span>
<span class="sd">    array([[ 0,  1,  2,  3],</span>
<span class="sd">           [ 4,  5,  6,  7],</span>
<span class="sd">           [ 8,  9, 10, 11],</span>
<span class="sd">           [12, 13, 14, 15],</span>
<span class="sd">           [16, 17, 18, 19]])</span>
<span class="sd">    &gt;&gt;&gt; stats.trim_mean(x2, 0.25)</span>
<span class="sd">    array([  8.,   9.,  10.,  11.])</span>
<span class="sd">    &gt;&gt;&gt; stats.trim_mean(x2, 0.25, axis=1)</span>
<span class="sd">    array([  1.5,   5.5,   9.5,  13.5,  17.5])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">nobs</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">lowercut</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">proportiontocut</span> <span class="o">*</span> <span class="n">nobs</span><span class="p">)</span>
    <span class="n">uppercut</span> <span class="o">=</span> <span class="n">nobs</span> <span class="o">-</span> <span class="n">lowercut</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">lowercut</span> <span class="o">&gt;</span> <span class="n">uppercut</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Proportion too big.&quot;</span><span class="p">)</span>

    <span class="n">atmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="n">lowercut</span><span class="p">,</span> <span class="n">uppercut</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">sl</span> <span class="o">=</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)]</span> <span class="o">*</span> <span class="n">atmp</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">sl</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">lowercut</span><span class="p">,</span> <span class="n">uppercut</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">atmp</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">sl</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>


<span class="n">F_onewayResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;F_onewayResult&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_create_f_oneway_nan_result</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is a helper function for f_oneway for creating the return values</span>
<span class="sd">    in certain degenerate conditions.  It creates return values that are</span>
<span class="sd">    all nan with the appropriate shape for the given `shape` and `axis`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="n">normalize_axis_index</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">shp</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[:</span><span class="n">axis</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">if</span> <span class="n">shp</span> <span class="o">==</span> <span class="p">():</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shp</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">F_onewayResult</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_first</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return arr[..., 0:1, ...] where 0:1 is in the `axis` position.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="n">arr</span><span class="o">.</span><span class="n">ndim</span><span class="p">),</span> <span class="n">axis</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">f_oneway</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform one-way ANOVA.</span>

<span class="sd">    The one-way ANOVA tests the null hypothesis that two or more groups have</span>
<span class="sd">    the same population mean.  The test is applied to samples from two or</span>
<span class="sd">    more groups, possibly with differing sizes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sample1, sample2, ... : array_like</span>
<span class="sd">        The sample measurements for each group.  There must be at least</span>
<span class="sd">        two arguments.  If the arrays are multidimensional, then all the</span>
<span class="sd">        dimensions of the array must be the same except for `axis`.</span>
<span class="sd">    axis : int, optional</span>
<span class="sd">        Axis of the input arrays along which the test is applied.</span>
<span class="sd">        Default is 0.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float</span>
<span class="sd">        The computed F statistic of the test.</span>
<span class="sd">    pvalue : float</span>
<span class="sd">        The associated p-value from the F distribution.</span>

<span class="sd">    Warns</span>
<span class="sd">    -----</span>
<span class="sd">    `~scipy.stats.ConstantInputWarning`</span>
<span class="sd">        Raised if all values within each of the input arrays are identical.</span>
<span class="sd">        In this case the F statistic is either infinite or isn&#39;t defined,</span>
<span class="sd">        so ``np.inf`` or ``np.nan`` is returned.</span>

<span class="sd">    `~scipy.stats.DegenerateDataWarning`</span>
<span class="sd">        Raised if the length of any input array is 0, or if all the input</span>
<span class="sd">        arrays have length 1.  ``np.nan`` is returned for the F statistic</span>
<span class="sd">        and the p-value in these cases.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The ANOVA test has important assumptions that must be satisfied in order</span>
<span class="sd">    for the associated p-value to be valid.</span>

<span class="sd">    1. The samples are independent.</span>
<span class="sd">    2. Each sample is from a normally distributed population.</span>
<span class="sd">    3. The population standard deviations of the groups are all equal.  This</span>
<span class="sd">       property is known as homoscedasticity.</span>

<span class="sd">    If these assumptions are not true for a given set of data, it may still</span>
<span class="sd">    be possible to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`) or</span>
<span class="sd">    the Alexander-Govern test (`scipy.stats.alexandergovern`) although with</span>
<span class="sd">    some loss of power.</span>

<span class="sd">    The length of each group must be at least one, and there must be at</span>
<span class="sd">    least one group with length greater than one.  If these conditions</span>
<span class="sd">    are not satisfied, a warning is generated and (``np.nan``, ``np.nan``)</span>
<span class="sd">    is returned.</span>

<span class="sd">    If all values in each group are identical, and there exist at least two</span>
<span class="sd">    groups with different values, the function generates a warning and</span>
<span class="sd">    returns (``np.inf``, 0).</span>

<span class="sd">    If all values in all groups are the same, function generates a warning</span>
<span class="sd">    and returns (``np.nan``, ``np.nan``).</span>

<span class="sd">    The algorithm is from Heiman [2]_, pp.394-7.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] R. Lowry, &quot;Concepts and Applications of Inferential Statistics&quot;,</span>
<span class="sd">           Chapter 14, 2014, http://vassarstats.net/textbook/</span>

<span class="sd">    .. [2] G.W. Heiman, &quot;Understanding research methods and statistics: An</span>
<span class="sd">           integrated introduction for psychology&quot;, Houghton, Mifflin and</span>
<span class="sd">           Company, 2001.</span>

<span class="sd">    .. [3] G.H. McDonald, &quot;Handbook of Biological Statistics&quot;, One-way ANOVA.</span>
<span class="sd">           http://www.biostathandbook.com/onewayanova.html</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import f_oneway</span>

<span class="sd">    Here are some data [3]_ on a shell measurement (the length of the anterior</span>
<span class="sd">    adductor muscle scar, standardized by dividing by length) in the mussel</span>
<span class="sd">    Mytilus trossulus from five locations: Tillamook, Oregon; Newport, Oregon;</span>
<span class="sd">    Petersburg, Alaska; Magadan, Russia; and Tvarminne, Finland, taken from a</span>
<span class="sd">    much larger data set used in McDonald et al. (1991).</span>

<span class="sd">    &gt;&gt;&gt; tillamook = [0.0571, 0.0813, 0.0831, 0.0976, 0.0817, 0.0859, 0.0735,</span>
<span class="sd">    ...              0.0659, 0.0923, 0.0836]</span>
<span class="sd">    &gt;&gt;&gt; newport = [0.0873, 0.0662, 0.0672, 0.0819, 0.0749, 0.0649, 0.0835,</span>
<span class="sd">    ...            0.0725]</span>
<span class="sd">    &gt;&gt;&gt; petersburg = [0.0974, 0.1352, 0.0817, 0.1016, 0.0968, 0.1064, 0.105]</span>
<span class="sd">    &gt;&gt;&gt; magadan = [0.1033, 0.0915, 0.0781, 0.0685, 0.0677, 0.0697, 0.0764,</span>
<span class="sd">    ...            0.0689]</span>
<span class="sd">    &gt;&gt;&gt; tvarminne = [0.0703, 0.1026, 0.0956, 0.0973, 0.1039, 0.1045]</span>
<span class="sd">    &gt;&gt;&gt; f_oneway(tillamook, newport, petersburg, magadan, tvarminne)</span>
<span class="sd">    F_onewayResult(statistic=7.121019471642447, pvalue=0.0002812242314534544)</span>

<span class="sd">    `f_oneway` accepts multidimensional input arrays.  When the inputs</span>
<span class="sd">    are multidimensional and `axis` is not given, the test is performed</span>
<span class="sd">    along the first axis of the input arrays.  For the following data, the</span>
<span class="sd">    test is performed three times, once for each column.</span>

<span class="sd">    &gt;&gt;&gt; a = np.array([[9.87, 9.03, 6.81],</span>
<span class="sd">    ...               [7.18, 8.35, 7.00],</span>
<span class="sd">    ...               [8.39, 7.58, 7.68],</span>
<span class="sd">    ...               [7.45, 6.33, 9.35],</span>
<span class="sd">    ...               [6.41, 7.10, 9.33],</span>
<span class="sd">    ...               [8.00, 8.24, 8.44]])</span>
<span class="sd">    &gt;&gt;&gt; b = np.array([[6.35, 7.30, 7.16],</span>
<span class="sd">    ...               [6.65, 6.68, 7.63],</span>
<span class="sd">    ...               [5.72, 7.73, 6.72],</span>
<span class="sd">    ...               [7.01, 9.19, 7.41],</span>
<span class="sd">    ...               [7.75, 7.87, 8.30],</span>
<span class="sd">    ...               [6.90, 7.97, 6.97]])</span>
<span class="sd">    &gt;&gt;&gt; c = np.array([[3.31, 8.77, 1.01],</span>
<span class="sd">    ...               [8.25, 3.24, 3.62],</span>
<span class="sd">    ...               [6.32, 8.81, 5.19],</span>
<span class="sd">    ...               [7.48, 8.83, 8.91],</span>
<span class="sd">    ...               [8.59, 6.01, 6.07],</span>
<span class="sd">    ...               [3.07, 9.72, 7.48]])</span>
<span class="sd">    &gt;&gt;&gt; F, p = f_oneway(a, b, c)</span>
<span class="sd">    &gt;&gt;&gt; F</span>
<span class="sd">    array([1.75676344, 0.03701228, 3.76439349])</span>
<span class="sd">    &gt;&gt;&gt; p</span>
<span class="sd">    array([0.20630784, 0.96375203, 0.04733157])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;at least two inputs are required;&#39;</span>
                        <span class="sa">f</span><span class="s1">&#39; got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">]</span>

    <span class="c1"># ANOVA on N groups, each in its own array</span>
    <span class="n">num_groups</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

    <span class="c1"># We haven&#39;t explicitly validated axis, but if it is bad, this call of</span>
    <span class="c1"># np.concatenate will raise np.exceptions.AxisError. The call will raise</span>
    <span class="c1"># ValueError if the dimensions of all the arrays, except the axis</span>
    <span class="c1"># dimension, are not the same.</span>
    <span class="n">alldata</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">bign</span> <span class="o">=</span> <span class="n">alldata</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>

    <span class="c1"># Check this after forming alldata, so shape errors are detected</span>
    <span class="c1"># and reported before checking for 0 length inputs.</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;at least one input has length 0&#39;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">DegenerateDataWarning</span><span class="p">(</span><span class="n">msg</span><span class="p">),</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_create_f_oneway_nan_result</span><span class="p">(</span><span class="n">alldata</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="c1"># Must have at least one group with length greater than 1.</span>
    <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;all input arrays have length 1.  f_oneway requires that at &#39;</span>
               <span class="s1">&#39;least one input has length greater than 1.&#39;</span><span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">DegenerateDataWarning</span><span class="p">(</span><span class="n">msg</span><span class="p">),</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_create_f_oneway_nan_result</span><span class="p">(</span><span class="n">alldata</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="c1"># Check if all values within each group are identical, and if the common</span>
    <span class="c1"># value in at least one group is different from that in another group.</span>
    <span class="c1"># Based on https://github.com/scipy/scipy/issues/11669</span>

    <span class="c1"># If axis=0, say, and the groups have shape (n0, ...), (n1, ...), ...,</span>
    <span class="c1"># then is_const is a boolean array with shape (num_groups, ...).</span>
    <span class="c1"># It is True if the values within the groups along the axis slice are</span>
    <span class="c1"># identical. In the typical case where each input array is 1-d, is_const is</span>
    <span class="c1"># a 1-d array with length num_groups.</span>
    <span class="n">is_const</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
        <span class="p">[(</span><span class="n">_first</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span> <span class="o">==</span> <span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                                              <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
         <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">],</span>
        <span class="n">axis</span><span class="o">=</span><span class="n">axis</span>
    <span class="p">)</span>

    <span class="c1"># all_const is a boolean array with shape (...) (see previous comment).</span>
    <span class="c1"># It is True if the values within each group along the axis slice are</span>
    <span class="c1"># the same (e.g. [[3, 3, 3], [5, 5, 5, 5], [4, 4, 4]]).</span>
    <span class="n">all_const</span> <span class="o">=</span> <span class="n">is_const</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">all_const</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Each of the input arrays is constant; &quot;</span>
               <span class="s2">&quot;the F statistic is not defined or infinite&quot;</span><span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">ConstantInputWarning</span><span class="p">(</span><span class="n">msg</span><span class="p">),</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># all_same_const is True if all the values in the groups along the axis=0</span>
    <span class="c1"># slice are the same (e.g. [[3, 3, 3], [3, 3, 3, 3], [3, 3, 3]]).</span>
    <span class="n">all_same_const</span> <span class="o">=</span> <span class="p">(</span><span class="n">_first</span><span class="p">(</span><span class="n">alldata</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span> <span class="o">==</span> <span class="n">alldata</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

    <span class="c1"># Determine the mean of the data, and subtract that from all inputs to a</span>
    <span class="c1"># variance (via sum_of_sq / sq_of_sum) calculation.  Variance is invariant</span>
    <span class="c1"># to a shift in location, and centering all data around zero vastly</span>
    <span class="c1"># improves numerical stability.</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">alldata</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">alldata</span> <span class="o">-=</span> <span class="n">offset</span>

    <span class="n">normalized_ss</span> <span class="o">=</span> <span class="n">_square_of_sums</span><span class="p">(</span><span class="n">alldata</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span> <span class="o">/</span> <span class="n">bign</span>

    <span class="n">sstot</span> <span class="o">=</span> <span class="n">_sum_of_squares</span><span class="p">(</span><span class="n">alldata</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span> <span class="o">-</span> <span class="n">normalized_ss</span>

    <span class="n">ssbn</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
        <span class="n">ssbn</span> <span class="o">+=</span> <span class="n">_square_of_sums</span><span class="p">(</span><span class="n">sample</span> <span class="o">-</span> <span class="n">offset</span><span class="p">,</span>
                                <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span> <span class="o">/</span> <span class="n">sample</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>

    <span class="c1"># Naming: variables ending in bn/b are for &quot;between treatments&quot;, wn/w are</span>
    <span class="c1"># for &quot;within treatments&quot;</span>
    <span class="n">ssbn</span> <span class="o">-=</span> <span class="n">normalized_ss</span>
    <span class="n">sswn</span> <span class="o">=</span> <span class="n">sstot</span> <span class="o">-</span> <span class="n">ssbn</span>
    <span class="n">dfbn</span> <span class="o">=</span> <span class="n">num_groups</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">dfwn</span> <span class="o">=</span> <span class="n">bign</span> <span class="o">-</span> <span class="n">num_groups</span>
    <span class="n">msb</span> <span class="o">=</span> <span class="n">ssbn</span> <span class="o">/</span> <span class="n">dfbn</span>
    <span class="n">msw</span> <span class="o">=</span> <span class="n">sswn</span> <span class="o">/</span> <span class="n">dfwn</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">invalid</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">msb</span> <span class="o">/</span> <span class="n">msw</span>

    <span class="n">prob</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">fdtrc</span><span class="p">(</span><span class="n">dfbn</span><span class="p">,</span> <span class="n">dfwn</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>   <span class="c1"># equivalent to stats.f.sf</span>

    <span class="c1"># Fix any f values that should be inf or nan because the corresponding</span>
    <span class="c1"># inputs were constant.</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">all_same_const</span><span class="p">:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">all_const</span><span class="p">:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="n">prob</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">f</span><span class="p">[</span><span class="n">all_const</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">prob</span><span class="p">[</span><span class="n">all_const</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">f</span><span class="p">[</span><span class="n">all_same_const</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">prob</span><span class="p">[</span><span class="n">all_same_const</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="k">return</span> <span class="n">F_onewayResult</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">alexandergovern</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Performs the Alexander Govern test.</span>

<span class="sd">    The Alexander-Govern approximation tests the equality of k independent</span>
<span class="sd">    means in the face of heterogeneity of variance. The test is applied to</span>
<span class="sd">    samples from two or more groups, possibly with differing sizes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sample1, sample2, ... : array_like</span>
<span class="sd">        The sample measurements for each group.  There must be at least</span>
<span class="sd">        two samples.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">        * &#39;propagate&#39;: returns nan</span>
<span class="sd">        * &#39;raise&#39;: throws an error</span>
<span class="sd">        * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res : AlexanderGovernResult</span>
<span class="sd">        An object with attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            The computed A statistic of the test.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            The associated p-value from the chi-squared distribution.</span>

<span class="sd">    Warns</span>
<span class="sd">    -----</span>
<span class="sd">    `~scipy.stats.ConstantInputWarning`</span>
<span class="sd">        Raised if an input is a constant array.  The statistic is not defined</span>
<span class="sd">        in this case, so ``np.nan`` is returned.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    f_oneway : one-way ANOVA</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The use of this test relies on several assumptions.</span>

<span class="sd">    1. The samples are independent.</span>
<span class="sd">    2. Each sample is from a normally distributed population.</span>
<span class="sd">    3. Unlike `f_oneway`, this test does not assume on homoscedasticity,</span>
<span class="sd">       instead relaxing the assumption of equal variances.</span>

<span class="sd">    Input samples must be finite, one dimensional, and with size greater than</span>
<span class="sd">    one.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Alexander, Ralph A., and Diane M. Govern. &quot;A New and Simpler</span>
<span class="sd">           Approximation for ANOVA under Variance Heterogeneity.&quot; Journal</span>
<span class="sd">           of Educational Statistics, vol. 19, no. 2, 1994, pp. 91-101.</span>
<span class="sd">           JSTOR, www.jstor.org/stable/1165140. Accessed 12 Sept. 2020.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import alexandergovern</span>

<span class="sd">    Here are some data on annual percentage rate of interest charged on</span>
<span class="sd">    new car loans at nine of the largest banks in four American cities</span>
<span class="sd">    taken from the National Institute of Standards and Technology&#39;s</span>
<span class="sd">    ANOVA dataset.</span>

<span class="sd">    We use `alexandergovern` to test the null hypothesis that all cities</span>
<span class="sd">    have the same mean APR against the alternative that the cities do not</span>
<span class="sd">    all have the same mean APR. We decide that a significance level of 5%</span>
<span class="sd">    is required to reject the null hypothesis in favor of the alternative.</span>

<span class="sd">    &gt;&gt;&gt; atlanta = [13.75, 13.75, 13.5, 13.5, 13.0, 13.0, 13.0, 12.75, 12.5]</span>
<span class="sd">    &gt;&gt;&gt; chicago = [14.25, 13.0, 12.75, 12.5, 12.5, 12.4, 12.3, 11.9, 11.9]</span>
<span class="sd">    &gt;&gt;&gt; houston = [14.0, 14.0, 13.51, 13.5, 13.5, 13.25, 13.0, 12.5, 12.5]</span>
<span class="sd">    &gt;&gt;&gt; memphis = [15.0, 14.0, 13.75, 13.59, 13.25, 12.97, 12.5, 12.25,</span>
<span class="sd">    ...           11.89]</span>
<span class="sd">    &gt;&gt;&gt; alexandergovern(atlanta, chicago, houston, memphis)</span>
<span class="sd">    AlexanderGovernResult(statistic=4.65087071883494,</span>
<span class="sd">                          pvalue=0.19922132490385214)</span>

<span class="sd">    The p-value is 0.1992, indicating a nearly 20% chance of observing</span>
<span class="sd">    such an extreme value of the test statistic under the null hypothesis.</span>
<span class="sd">    This exceeds 5%, so we do not reject the null hypothesis in favor of</span>
<span class="sd">    the alternative.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">_alexandergovern_input_validation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">([(</span><span class="n">sample</span> <span class="o">==</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">]):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;An input array is constant; the statistic is not defined.&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">ConstantInputWarning</span><span class="p">(</span><span class="n">msg</span><span class="p">),</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">AlexanderGovernResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

    <span class="c1"># The following formula numbers reference the equation described on</span>
    <span class="c1"># page 92 by Alexander, Govern. Formulas 5, 6, and 7 describe other</span>
    <span class="c1"># tests that serve as the basis for equation (8) but are not needed</span>
    <span class="c1"># to perform the test.</span>

    <span class="c1"># precalculate mean and length of each sample</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ma</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span> <span class="k">if</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span>
                        <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span>

    <span class="c1"># (1) determine standard error of the mean for each sample</span>
    <span class="n">standard_errors</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">length</span><span class="p">)</span>
                       <span class="k">for</span> <span class="n">sample</span><span class="p">,</span> <span class="n">length</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)]</span>

    <span class="c1"># (2) define a weight for each sample</span>
    <span class="n">inv_sq_se</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">standard_errors</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">inv_sq_se</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">inv_sq_se</span><span class="p">)</span>

    <span class="c1"># (3) determine variance-weighted estimate of the common mean</span>
    <span class="n">var_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span> <span class="o">*</span> <span class="n">means</span><span class="p">)</span>

    <span class="c1"># (4) determine one-sample t statistic for each group</span>
    <span class="n">t_stats</span> <span class="o">=</span> <span class="p">(</span><span class="n">means</span> <span class="o">-</span> <span class="n">var_w</span><span class="p">)</span><span class="o">/</span><span class="n">standard_errors</span>

    <span class="c1"># calculate parameters to be used in transformation</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">lengths</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">v</span> <span class="o">-</span> <span class="mf">.5</span>
    <span class="n">b</span> <span class="o">=</span> <span class="mi">48</span> <span class="o">*</span> <span class="n">a</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">t_stats</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">v</span><span class="p">))</span><span class="o">**</span><span class="mf">.5</span>

    <span class="c1"># (8) perform a normalizing transformation on t statistic</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="p">((</span><span class="n">c</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">c</span><span class="p">)</span><span class="o">/</span><span class="n">b</span><span class="p">)</span> <span class="o">-</span>
         <span class="p">((</span><span class="mi">4</span><span class="o">*</span><span class="n">c</span><span class="o">**</span><span class="mi">7</span> <span class="o">+</span> <span class="mi">33</span><span class="o">*</span><span class="n">c</span><span class="o">**</span><span class="mi">5</span> <span class="o">+</span> <span class="mi">240</span><span class="o">*</span><span class="n">c</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">855</span><span class="o">*</span><span class="n">c</span><span class="p">)</span> <span class="o">/</span>
          <span class="p">(</span><span class="n">b</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="mi">10</span> <span class="o">+</span> <span class="mi">8</span><span class="o">*</span><span class="n">b</span><span class="o">*</span><span class="n">c</span><span class="o">**</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">1000</span><span class="o">*</span><span class="n">b</span><span class="p">)))</span>

    <span class="c1"># (9) calculate statistic</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>

    <span class="c1"># &quot;[the p value is determined from] central chi-square random deviates</span>
    <span class="c1"># with k - 1 degrees of freedom&quot;. Alexander, Govern (94)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">AlexanderGovernResult</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_alexandergovern_input_validation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;2 or more inputs required, got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># input arrays are flattened</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input sample size must be greater than one.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sample</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input samples must be one-dimensional&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input samples must be finite.&quot;</span><span class="p">)</span>

        <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span>
                                                 <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
            <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">samples</span>


<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">AlexanderGovernResult</span><span class="p">:</span>
    <span class="n">statistic</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">pvalue</span><span class="p">:</span> <span class="nb">float</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_pearsonr_fisher_ci</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">confidence_level</span><span class="p">,</span> <span class="n">alternative</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the confidence interval for Pearson&#39;s R.</span>

<span class="sd">    Fisher&#39;s transformation is used to compute the confidence interval</span>
<span class="sd">    (https://en.wikipedia.org/wiki/Fisher_transformation).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">zr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="k">elif</span> <span class="n">r</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">zr</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">zr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctanh</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">3</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s2">&quot;two-sided&quot;</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">ndtri</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">+</span> <span class="n">confidence_level</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">zlo</span> <span class="o">=</span> <span class="n">zr</span> <span class="o">-</span> <span class="n">h</span><span class="o">*</span><span class="n">se</span>
            <span class="n">zhi</span> <span class="o">=</span> <span class="n">zr</span> <span class="o">+</span> <span class="n">h</span><span class="o">*</span><span class="n">se</span>
            <span class="n">rlo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">zlo</span><span class="p">)</span>
            <span class="n">rhi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">zhi</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s2">&quot;less&quot;</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">ndtri</span><span class="p">(</span><span class="n">confidence_level</span><span class="p">)</span>
            <span class="n">zhi</span> <span class="o">=</span> <span class="n">zr</span> <span class="o">+</span> <span class="n">h</span><span class="o">*</span><span class="n">se</span>
            <span class="n">rhi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">zhi</span><span class="p">)</span>
            <span class="n">rlo</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># alternative == &quot;greater&quot;:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">ndtri</span><span class="p">(</span><span class="n">confidence_level</span><span class="p">)</span>
            <span class="n">zlo</span> <span class="o">=</span> <span class="n">zr</span> <span class="o">-</span> <span class="n">h</span><span class="o">*</span><span class="n">se</span>
            <span class="n">rlo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">zlo</span><span class="p">)</span>
            <span class="n">rhi</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rlo</span><span class="p">,</span> <span class="n">rhi</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span>

    <span class="k">return</span> <span class="n">ConfidenceInterval</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">rlo</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">rhi</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_pearsonr_bootstrap_ci</span><span class="p">(</span><span class="n">confidence_level</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alternative</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the confidence interval for Pearson&#39;s R using the bootstrap.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">statistic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">statistic</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">statistic</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">bootstrap</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">statistic</span><span class="p">,</span> <span class="n">confidence_level</span><span class="o">=</span><span class="n">confidence_level</span><span class="p">,</span>
                    <span class="n">paired</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span> <span class="o">**</span><span class="n">method</span><span class="o">.</span><span class="n">_asdict</span><span class="p">())</span>
    <span class="c1"># for one-sided confidence intervals, bootstrap gives +/- inf on one side</span>
    <span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ConfidenceInterval</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span><span class="p">)</span>


<span class="n">ConfidenceInterval</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;ConfidenceInterval&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;low&#39;</span><span class="p">,</span> <span class="s1">&#39;high&#39;</span><span class="p">])</span>

<span class="n">PearsonRResultBase</span> <span class="o">=</span> <span class="n">_make_tuple_bunch</span><span class="p">(</span><span class="s1">&#39;PearsonRResultBase&#39;</span><span class="p">,</span>
                                       <span class="p">[</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">],</span> <span class="p">[])</span>


<span class="k">class</span><span class="w"> </span><span class="nc">PearsonRResult</span><span class="p">(</span><span class="n">PearsonRResultBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Result of `scipy.stats.pearsonr`</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    statistic : float</span>
<span class="sd">        Pearson product-moment correlation coefficient.</span>
<span class="sd">    pvalue : float</span>
<span class="sd">        The p-value associated with the chosen alternative.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    confidence_interval</span>
<span class="sd">        Computes the confidence interval of the correlation</span>
<span class="sd">        coefficient `statistic` for the given confidence level.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">alternative</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_alternative</span> <span class="o">=</span> <span class="n">alternative</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_y</span> <span class="o">=</span> <span class="n">y</span>

        <span class="c1"># add alias for consistency with other correlation functions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">statistic</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">confidence_interval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The confidence interval for the correlation coefficient.</span>

<span class="sd">        Compute the confidence interval for the correlation coefficient</span>
<span class="sd">        ``statistic`` with the given confidence level.</span>

<span class="sd">        If `method` is not provided,</span>
<span class="sd">        The confidence interval is computed using the Fisher transformation</span>
<span class="sd">        F(r) = arctanh(r) [1]_.  When the sample pairs are drawn from a</span>
<span class="sd">        bivariate normal distribution, F(r) approximately follows a normal</span>
<span class="sd">        distribution with standard error ``1/sqrt(n - 3)``, where ``n`` is the</span>
<span class="sd">        length of the original samples along the calculation axis. When</span>
<span class="sd">        ``n &lt;= 3``, this approximation does not yield a finite, real standard</span>
<span class="sd">        error, so we define the confidence interval to be -1 to 1.</span>

<span class="sd">        If `method` is an instance of `BootstrapMethod`, the confidence</span>
<span class="sd">        interval is computed using `scipy.stats.bootstrap` with the provided</span>
<span class="sd">        configuration options and other appropriate settings. In some cases,</span>
<span class="sd">        confidence limits may be NaN due to a degenerate resample, and this is</span>
<span class="sd">        typical for very small samples (~6 observations).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        confidence_level : float</span>
<span class="sd">            The confidence level for the calculation of the correlation</span>
<span class="sd">            coefficient confidence interval. Default is 0.95.</span>

<span class="sd">        method : BootstrapMethod, optional</span>
<span class="sd">            Defines the method used to compute the confidence interval. See</span>
<span class="sd">            method description for details.</span>

<span class="sd">            .. versionadded:: 1.11.0</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ci : namedtuple</span>
<span class="sd">            The confidence interval is returned in a ``namedtuple`` with</span>
<span class="sd">            fields `low` and `high`.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        .. [1] &quot;Pearson correlation coefficient&quot;, Wikipedia,</span>
<span class="sd">               https://en.wikipedia.org/wiki/Pearson_correlation_coefficient</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">BootstrapMethod</span><span class="p">):</span>
            <span class="n">ci</span> <span class="o">=</span> <span class="n">_pearsonr_bootstrap_ci</span><span class="p">(</span><span class="n">confidence_level</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alternative</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ci</span> <span class="o">=</span> <span class="n">_pearsonr_fisher_ci</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n</span><span class="p">,</span> <span class="n">confidence_level</span><span class="p">,</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">_alternative</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;`method` must be an instance of `BootstrapMethod` &#39;</span>
                       <span class="s1">&#39;or None.&#39;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ci</span>

<span class="k">def</span><span class="w"> </span><span class="nf">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pearson correlation coefficient and p-value for testing non-correlation.</span>

<span class="sd">    The Pearson correlation coefficient [1]_ measures the linear relationship</span>
<span class="sd">    between two datasets. Like other correlation</span>
<span class="sd">    coefficients, this one varies between -1 and +1 with 0 implying no</span>
<span class="sd">    correlation. Correlations of -1 or +1 imply an exact linear relationship.</span>
<span class="sd">    Positive correlations imply that as x increases, so does y. Negative</span>
<span class="sd">    correlations imply that as x increases, y decreases.</span>

<span class="sd">    This function also performs a test of the null hypothesis that the</span>
<span class="sd">    distributions underlying the samples are uncorrelated and normally</span>
<span class="sd">    distributed. (See Kowalski [3]_</span>
<span class="sd">    for a discussion of the effects of non-normality of the input on the</span>
<span class="sd">    distribution of the correlation coefficient.)</span>
<span class="sd">    The p-value roughly indicates the probability of an uncorrelated system</span>
<span class="sd">    producing datasets that have a Pearson correlation at least as extreme</span>
<span class="sd">    as the one computed from these datasets.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : (N,) array_like</span>
<span class="sd">        Input array.</span>
<span class="sd">    y : (N,) array_like</span>
<span class="sd">        Input array.</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;greater&#39;, &#39;less&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis. Default is &#39;two-sided&#39;.</span>
<span class="sd">        The following options are available:</span>

<span class="sd">        * &#39;two-sided&#39;: the correlation is nonzero</span>
<span class="sd">        * &#39;less&#39;: the correlation is negative (less than zero)</span>
<span class="sd">        * &#39;greater&#39;:  the correlation is positive (greater than zero)</span>

<span class="sd">        .. versionadded:: 1.9.0</span>
<span class="sd">    method : ResamplingMethod, optional</span>
<span class="sd">        Defines the method used to compute the p-value. If `method` is an</span>
<span class="sd">        instance of `PermutationMethod`/`MonteCarloMethod`, the p-value is</span>
<span class="sd">        computed using</span>
<span class="sd">        `scipy.stats.permutation_test`/`scipy.stats.monte_carlo_test` with the</span>
<span class="sd">        provided configuration options and other appropriate settings.</span>
<span class="sd">        Otherwise, the p-value is computed as documented in the notes.</span>

<span class="sd">        .. versionadded:: 1.11.0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : `~scipy.stats._result_classes.PearsonRResult`</span>
<span class="sd">        An object with the following attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            Pearson product-moment correlation coefficient.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            The p-value associated with the chosen alternative.</span>

<span class="sd">        The object has the following method:</span>

<span class="sd">        confidence_interval(confidence_level, method)</span>
<span class="sd">            This computes the confidence interval of the correlation</span>
<span class="sd">            coefficient `statistic` for the given confidence level.</span>
<span class="sd">            The confidence interval is returned in a ``namedtuple`` with</span>
<span class="sd">            fields `low` and `high`. If `method` is not provided, the</span>
<span class="sd">            confidence interval is computed using the Fisher transformation</span>
<span class="sd">            [1]_. If `method` is an instance of `BootstrapMethod`, the</span>
<span class="sd">            confidence interval is computed using `scipy.stats.bootstrap` with</span>
<span class="sd">            the provided configuration options and other appropriate settings.</span>
<span class="sd">            In some cases, confidence limits may be NaN due to a degenerate</span>
<span class="sd">            resample, and this is typical for very small samples (~6</span>
<span class="sd">            observations).</span>

<span class="sd">    Warns</span>
<span class="sd">    -----</span>
<span class="sd">    `~scipy.stats.ConstantInputWarning`</span>
<span class="sd">        Raised if an input is a constant array.  The correlation coefficient</span>
<span class="sd">        is not defined in this case, so ``np.nan`` is returned.</span>

<span class="sd">    `~scipy.stats.NearConstantInputWarning`</span>
<span class="sd">        Raised if an input is &quot;nearly&quot; constant.  The array ``x`` is considered</span>
<span class="sd">        nearly constant if ``norm(x - mean(x)) &lt; 1e-13 * abs(mean(x))``.</span>
<span class="sd">        Numerical errors in the calculation ``x - mean(x)`` in this case might</span>
<span class="sd">        result in an inaccurate calculation of r.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    spearmanr : Spearman rank-order correlation coefficient.</span>
<span class="sd">    kendalltau : Kendall&#39;s tau, a correlation measure for ordinal data.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The correlation coefficient is calculated as follows:</span>

<span class="sd">    .. math::</span>

<span class="sd">        r = \frac{\sum (x - m_x) (y - m_y)}</span>
<span class="sd">                 {\sqrt{\sum (x - m_x)^2 \sum (y - m_y)^2}}</span>

<span class="sd">    where :math:`m_x` is the mean of the vector x and :math:`m_y` is</span>
<span class="sd">    the mean of the vector y.</span>

<span class="sd">    Under the assumption that x and y are drawn from</span>
<span class="sd">    independent normal distributions (so the population correlation coefficient</span>
<span class="sd">    is 0), the probability density function of the sample correlation</span>
<span class="sd">    coefficient r is ([1]_, [2]_):</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(r) = \frac{{(1-r^2)}^{n/2-2}}{\mathrm{B}(\frac{1}{2},\frac{n}{2}-1)}</span>

<span class="sd">    where n is the number of samples, and B is the beta function.  This</span>
<span class="sd">    is sometimes referred to as the exact distribution of r.  This is</span>
<span class="sd">    the distribution that is used in `pearsonr` to compute the p-value when</span>
<span class="sd">    the `method` parameter is left at its default value (None).</span>
<span class="sd">    The distribution is a beta distribution on the interval [-1, 1],</span>
<span class="sd">    with equal shape parameters a = b = n/2 - 1.  In terms of SciPy&#39;s</span>
<span class="sd">    implementation of the beta distribution, the distribution of r is::</span>

<span class="sd">        dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)</span>

<span class="sd">    The default p-value returned by `pearsonr` is a two-sided p-value. For a</span>
<span class="sd">    given sample with correlation coefficient r, the p-value is</span>
<span class="sd">    the probability that abs(r&#39;) of a random sample x&#39; and y&#39; drawn from</span>
<span class="sd">    the population with zero correlation would be greater than or equal</span>
<span class="sd">    to abs(r). In terms of the object ``dist`` shown above, the p-value</span>
<span class="sd">    for a given r and length n can be computed as::</span>

<span class="sd">        p = 2*dist.cdf(-abs(r))</span>

<span class="sd">    When n is 2, the above continuous distribution is not well-defined.</span>
<span class="sd">    One can interpret the limit of the beta distribution as the shape</span>
<span class="sd">    parameters a and b approach a = b = 0 as a discrete distribution with</span>
<span class="sd">    equal probability masses at r = 1 and r = -1.  More directly, one</span>
<span class="sd">    can observe that, given the data x = [x1, x2] and y = [y1, y2], and</span>
<span class="sd">    assuming x1 != x2 and y1 != y2, the only possible values for r are 1</span>
<span class="sd">    and -1.  Because abs(r&#39;) for any sample x&#39; and y&#39; with length 2 will</span>
<span class="sd">    be 1, the two-sided p-value for a sample of length 2 is always 1.</span>

<span class="sd">    For backwards compatibility, the object that is returned also behaves</span>
<span class="sd">    like a tuple of length two that holds the statistic and the p-value.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Pearson correlation coefficient&quot;, Wikipedia,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Pearson_correlation_coefficient</span>
<span class="sd">    .. [2] Student, &quot;Probable error of a correlation coefficient&quot;,</span>
<span class="sd">           Biometrika, Volume 6, Issue 2-3, 1 September 1908, pp. 302-310.</span>
<span class="sd">    .. [3] C. J. Kowalski, &quot;On the Effects of Non-Normality on the Distribution</span>
<span class="sd">           of the Sample Product-Moment Correlation Coefficient&quot;</span>
<span class="sd">           Journal of the Royal Statistical Society. Series C (Applied</span>
<span class="sd">           Statistics), Vol. 21, No. 1 (1972), pp. 1-12.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x, y = [1, 2, 3, 4, 5, 6, 7], [10, 9, 2.5, 6, 4, 3, 2]</span>
<span class="sd">    &gt;&gt;&gt; res = stats.pearsonr(x, y)</span>
<span class="sd">    &gt;&gt;&gt; res</span>
<span class="sd">    PearsonRResult(statistic=-0.828503883588428, pvalue=0.021280260007523286)</span>

<span class="sd">    To perform an exact permutation version of the test:</span>

<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng(7796654889291491997)</span>
<span class="sd">    &gt;&gt;&gt; method = stats.PermutationMethod(n_resamples=np.inf, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.pearsonr(x, y, method=method)</span>
<span class="sd">    PearsonRResult(statistic=-0.828503883588428, pvalue=0.028174603174603175)</span>

<span class="sd">    To perform the test under the null hypothesis that the data were drawn from</span>
<span class="sd">    *uniform* distributions:</span>

<span class="sd">    &gt;&gt;&gt; method = stats.MonteCarloMethod(rvs=(rng.uniform, rng.uniform))</span>
<span class="sd">    &gt;&gt;&gt; stats.pearsonr(x, y, method=method)</span>
<span class="sd">    PearsonRResult(statistic=-0.828503883588428, pvalue=0.0188)</span>

<span class="sd">    To produce an asymptotic 90% confidence interval:</span>

<span class="sd">    &gt;&gt;&gt; res.confidence_interval(confidence_level=0.9)</span>
<span class="sd">    ConfidenceInterval(low=-0.9644331982722841, high=-0.3460237473272273)</span>

<span class="sd">    And for a bootstrap confidence interval:</span>

<span class="sd">    &gt;&gt;&gt; method = stats.BootstrapMethod(method=&#39;BCa&#39;, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; res.confidence_interval(confidence_level=0.9, method=method)</span>
<span class="sd">    ConfidenceInterval(low=-0.9983163756488651, high=-0.22771001702132443)  # may vary</span>

<span class="sd">    There is a linear dependence between x and y if y = a + b*x + e, where</span>
<span class="sd">    a,b are constants and e is a random error term, assumed to be independent</span>
<span class="sd">    of x. For simplicity, assume that x is standard normal, a=0, b=1 and let</span>
<span class="sd">    e follow a normal distribution with mean zero and standard deviation s&gt;0.</span>

<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">    &gt;&gt;&gt; s = 0.5</span>
<span class="sd">    &gt;&gt;&gt; x = stats.norm.rvs(size=500, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; e = stats.norm.rvs(scale=s, size=500, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; y = x + e</span>
<span class="sd">    &gt;&gt;&gt; stats.pearsonr(x, y).statistic</span>
<span class="sd">    0.9001942438244763</span>

<span class="sd">    This should be close to the exact value given by</span>

<span class="sd">    &gt;&gt;&gt; 1/np.sqrt(1 + s**2)</span>
<span class="sd">    0.8944271909999159</span>

<span class="sd">    For s=0.5, we observe a high level of correlation. In general, a large</span>
<span class="sd">    variance of the noise reduces the correlation, while the correlation</span>
<span class="sd">    approaches one as the variance of the error goes to zero.</span>

<span class="sd">    It is important to keep in mind that no correlation does not imply</span>
<span class="sd">    independence unless (x, y) is jointly normal. Correlation can even be zero</span>
<span class="sd">    when there is a very simple dependence structure: if X follows a</span>
<span class="sd">    standard normal distribution, let y = abs(x). Note that the correlation</span>
<span class="sd">    between x and y is zero. Indeed, since the expectation of x is zero,</span>
<span class="sd">    cov(x, y) = E[x*y]. By definition, this equals E[x*abs(x)] which is zero</span>
<span class="sd">    by symmetry. The following lines of code illustrate this observation:</span>

<span class="sd">    &gt;&gt;&gt; y = np.abs(x)</span>
<span class="sd">    &gt;&gt;&gt; stats.pearsonr(x, y)</span>
<span class="sd">    PearsonRResult(statistic=-0.05444919272687482, pvalue=0.22422294836207743)</span>

<span class="sd">    A non-zero correlation coefficient can be misleading. For example, if X has</span>
<span class="sd">    a standard normal distribution, define y = x if x &lt; 0 and y = 0 otherwise.</span>
<span class="sd">    A simple calculation shows that corr(x, y) = sqrt(2/Pi) = 0.797...,</span>
<span class="sd">    implying a high level of correlation:</span>

<span class="sd">    &gt;&gt;&gt; y = np.where(x &lt; 0, x, 0)</span>
<span class="sd">    &gt;&gt;&gt; stats.pearsonr(x, y)</span>
<span class="sd">    PearsonRResult(statistic=0.861985781588, pvalue=4.813432002751103e-149)</span>

<span class="sd">    This is unintuitive since there is no dependence of x and y if x is larger</span>
<span class="sd">    than zero which happens in about half of the cases if we sample x and y.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;x and y must have the same length.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;x and y must have length at least 2.&#39;</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">complexfloating</span><span class="p">)</span>
            <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">complexfloating</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;This function does not support complex data&#39;</span><span class="p">)</span>

    <span class="c1"># If an input is constant, the correlation coefficient is not defined.</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="ow">or</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;An input array is constant; the correlation coefficient &quot;</span>
               <span class="s2">&quot;is not defined.&quot;</span><span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">ConstantInputWarning</span><span class="p">(</span><span class="n">msg</span><span class="p">),</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">PearsonRResult</span><span class="p">(</span><span class="n">statistic</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">pvalue</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                                <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">PermutationMethod</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">statistic</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">statistic</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">statistic</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">permutation_test</span><span class="p">((</span><span class="n">y</span><span class="p">,),</span> <span class="n">statistic</span><span class="p">,</span> <span class="n">permutation_type</span><span class="o">=</span><span class="s1">&#39;pairings&#39;</span><span class="p">,</span>
                               <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span> <span class="o">**</span><span class="n">method</span><span class="o">.</span><span class="n">_asdict</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">PearsonRResult</span><span class="p">(</span><span class="n">statistic</span><span class="o">=</span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="o">=</span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                              <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">MonteCarloMethod</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">statistic</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="n">statistic</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">statistic</span>

        <span class="k">if</span> <span class="n">method</span><span class="o">.</span><span class="n">rvs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
            <span class="n">method</span><span class="o">.</span><span class="n">rvs</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">monte_carlo_test</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,),</span> <span class="n">statistic</span><span class="o">=</span><span class="n">statistic</span><span class="p">,</span>
                               <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span> <span class="o">**</span><span class="n">method</span><span class="o">.</span><span class="n">_asdict</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">PearsonRResult</span><span class="p">(</span><span class="n">statistic</span><span class="o">=</span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="o">=</span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                              <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">message</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;`method` must be an instance of `PermutationMethod`,&#39;</span>
                   <span class="s1">&#39;`MonteCarloMethod`, or None.&#39;</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="c1"># dtype is the data type for the calculations.  This expression ensures</span>
    <span class="c1"># that the data type is at least 64 bit floating point.  It might have</span>
    <span class="c1"># more precision if the input is, for example, np.longdouble.</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">PearsonRResult</span><span class="p">(</span><span class="n">statistic</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">pvalue</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                                <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="n">xmean</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">ymean</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># By using `astype(dtype)`, we ensure that the intermediate calculations</span>
    <span class="c1"># use at least 64 bit floating point.</span>
    <span class="n">xm</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span> <span class="o">-</span> <span class="n">xmean</span>
    <span class="n">ym</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span> <span class="o">-</span> <span class="n">ymean</span>

    <span class="c1"># Unlike np.linalg.norm or the expression sqrt((xm*xm).sum()),</span>
    <span class="c1"># scipy.linalg.norm(xm) does not overflow if xm is, for example,</span>
    <span class="c1"># [-5e210, 5e210, 3e200, -3e200]</span>
    <span class="n">normxm</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">xm</span><span class="p">)</span>
    <span class="n">normym</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">ym</span><span class="p">)</span>

    <span class="n">threshold</span> <span class="o">=</span> <span class="mf">1e-13</span>
    <span class="k">if</span> <span class="n">normxm</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="o">*</span><span class="nb">abs</span><span class="p">(</span><span class="n">xmean</span><span class="p">)</span> <span class="ow">or</span> <span class="n">normym</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="o">*</span><span class="nb">abs</span><span class="p">(</span><span class="n">ymean</span><span class="p">):</span>
        <span class="c1"># If all the values in x (likewise y) are very close to the mean,</span>
        <span class="c1"># the loss of precision that occurs in the subtraction xm = x - xmean</span>
        <span class="c1"># might result in large errors in r.</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;An input array is nearly constant; the computed &quot;</span>
               <span class="s2">&quot;correlation coefficient may be inaccurate.&quot;</span><span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">NearConstantInputWarning</span><span class="p">(</span><span class="n">msg</span><span class="p">),</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">xm</span><span class="o">/</span><span class="n">normxm</span><span class="p">,</span> <span class="n">ym</span><span class="o">/</span><span class="n">normym</span><span class="p">)</span>

    <span class="c1"># Presumably, if abs(r) &gt; 1, then it is only some small artifact of</span>
    <span class="c1"># floating point arithmetic.</span>
    <span class="n">r</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># As explained in the docstring, the distribution of `r` under the null</span>
    <span class="c1"># hypothesis is the beta distribution on (-1, 1) with a = b = n/2 - 1.</span>
    <span class="n">ab</span> <span class="o">=</span> <span class="n">n</span><span class="o">/</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">ab</span><span class="p">,</span> <span class="n">ab</span><span class="p">,</span> <span class="n">loc</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;two-sided&#39;</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">dist</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;less&#39;</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;greater&#39;</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;alternative must be one of &#39;</span>
                         <span class="s1">&#39;[&quot;two-sided&quot;, &quot;less&quot;, &quot;greater&quot;]&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">PearsonRResult</span><span class="p">(</span><span class="n">statistic</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">pvalue</span><span class="o">=</span><span class="n">prob</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
                          <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">fisher_exact</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform a Fisher exact test on a 2x2 contingency table.</span>

<span class="sd">    The null hypothesis is that the true odds ratio of the populations</span>
<span class="sd">    underlying the observations is one, and the observations were sampled</span>
<span class="sd">    from these populations under a condition: the marginals of the</span>
<span class="sd">    resulting table must equal those of the observed table. The statistic</span>
<span class="sd">    returned is the unconditional maximum likelihood estimate of the odds</span>
<span class="sd">    ratio, and the p-value is the probability under the null hypothesis of</span>
<span class="sd">    obtaining a table at least as extreme as the one that was actually</span>
<span class="sd">    observed. There are other possible choices of statistic and two-sided</span>
<span class="sd">    p-value definition associated with Fisher&#39;s exact test; please see the</span>
<span class="sd">    Notes for more information.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    table : array_like of ints</span>
<span class="sd">        A 2x2 contingency table.  Elements must be non-negative integers.</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis.</span>
<span class="sd">        The following options are available (default is &#39;two-sided&#39;):</span>

<span class="sd">        * &#39;two-sided&#39;: the odds ratio of the underlying population is not one</span>
<span class="sd">        * &#39;less&#39;: the odds ratio of the underlying population is less than one</span>
<span class="sd">        * &#39;greater&#39;: the odds ratio of the underlying population is greater</span>
<span class="sd">          than one</span>

<span class="sd">        See the Notes for more details.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res : SignificanceResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            This is the prior odds ratio, not a posterior estimate.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            The probability under the null hypothesis of obtaining a</span>
<span class="sd">            table at least as extreme as the one that was actually observed.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    chi2_contingency : Chi-square test of independence of variables in a</span>
<span class="sd">        contingency table.  This can be used as an alternative to</span>
<span class="sd">        `fisher_exact` when the numbers in the table are large.</span>
<span class="sd">    contingency.odds_ratio : Compute the odds ratio (sample or conditional</span>
<span class="sd">        MLE) for a 2x2 contingency table.</span>
<span class="sd">    barnard_exact : Barnard&#39;s exact test, which is a more powerful alternative</span>
<span class="sd">        than Fisher&#39;s exact test for 2x2 contingency tables.</span>
<span class="sd">    boschloo_exact : Boschloo&#39;s exact test, which is a more powerful</span>
<span class="sd">        alternative than Fisher&#39;s exact test for 2x2 contingency tables.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    *Null hypothesis and p-values*</span>

<span class="sd">    The null hypothesis is that the true odds ratio of the populations</span>
<span class="sd">    underlying the observations is one, and the observations were sampled at</span>
<span class="sd">    random from these populations under a condition: the marginals of the</span>
<span class="sd">    resulting table must equal those of the observed table. Equivalently,</span>
<span class="sd">    the null hypothesis is that the input table is from the hypergeometric</span>
<span class="sd">    distribution with parameters (as used in `hypergeom`)</span>
<span class="sd">    ``M = a + b + c + d``, ``n = a + b`` and ``N = a + c``, where the</span>
<span class="sd">    input table is ``[[a, b], [c, d]]``.  This distribution has support</span>
<span class="sd">    ``max(0, N + n - M) &lt;= x &lt;= min(N, n)``, or, in terms of the values</span>
<span class="sd">    in the input table, ``min(0, a - d) &lt;= x &lt;= a + min(b, c)``.  ``x``</span>
<span class="sd">    can be interpreted as the upper-left element of a 2x2 table, so the</span>
<span class="sd">    tables in the distribution have form::</span>

<span class="sd">        [  x           n - x     ]</span>
<span class="sd">        [N - x    M - (n + N) + x]</span>

<span class="sd">    For example, if::</span>

<span class="sd">        table = [6  2]</span>
<span class="sd">                [1  4]</span>

<span class="sd">    then the support is ``2 &lt;= x &lt;= 7``, and the tables in the distribution</span>
<span class="sd">    are::</span>

<span class="sd">        [2 6]   [3 5]   [4 4]   [5 3]   [6 2]  [7 1]</span>
<span class="sd">        [5 0]   [4 1]   [3 2]   [2 3]   [1 4]  [0 5]</span>

<span class="sd">    The probability of each table is given by the hypergeometric distribution</span>
<span class="sd">    ``hypergeom.pmf(x, M, n, N)``.  For this example, these are (rounded to</span>
<span class="sd">    three significant digits)::</span>

<span class="sd">        x       2      3      4      5       6        7</span>
<span class="sd">        p  0.0163  0.163  0.408  0.326  0.0816  0.00466</span>

<span class="sd">    These can be computed with::</span>

<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import hypergeom</span>
<span class="sd">        &gt;&gt;&gt; table = np.array([[6, 2], [1, 4]])</span>
<span class="sd">        &gt;&gt;&gt; M = table.sum()</span>
<span class="sd">        &gt;&gt;&gt; n = table[0].sum()</span>
<span class="sd">        &gt;&gt;&gt; N = table[:, 0].sum()</span>
<span class="sd">        &gt;&gt;&gt; start, end = hypergeom.support(M, n, N)</span>
<span class="sd">        &gt;&gt;&gt; hypergeom.pmf(np.arange(start, end+1), M, n, N)</span>
<span class="sd">        array([0.01631702, 0.16317016, 0.40792541, 0.32634033, 0.08158508,</span>
<span class="sd">               0.004662  ])</span>

<span class="sd">    The two-sided p-value is the probability that, under the null hypothesis,</span>
<span class="sd">    a random table would have a probability equal to or less than the</span>
<span class="sd">    probability of the input table.  For our example, the probability of</span>
<span class="sd">    the input table (where ``x = 6``) is 0.0816.  The x values where the</span>
<span class="sd">    probability does not exceed this are 2, 6 and 7, so the two-sided p-value</span>
<span class="sd">    is ``0.0163 + 0.0816 + 0.00466 ~= 0.10256``::</span>

<span class="sd">        &gt;&gt;&gt; from scipy.stats import fisher_exact</span>
<span class="sd">        &gt;&gt;&gt; res = fisher_exact(table, alternative=&#39;two-sided&#39;)</span>
<span class="sd">        &gt;&gt;&gt; res.pvalue</span>
<span class="sd">        0.10256410256410257</span>

<span class="sd">    The one-sided p-value for ``alternative=&#39;greater&#39;`` is the probability</span>
<span class="sd">    that a random table has ``x &gt;= a``, which in our example is ``x &gt;= 6``,</span>
<span class="sd">    or ``0.0816 + 0.00466 ~= 0.08626``::</span>

<span class="sd">        &gt;&gt;&gt; res = fisher_exact(table, alternative=&#39;greater&#39;)</span>
<span class="sd">        &gt;&gt;&gt; res.pvalue</span>
<span class="sd">        0.08624708624708627</span>

<span class="sd">    This is equivalent to computing the survival function of the</span>
<span class="sd">    distribution at ``x = 5`` (one less than ``x`` from the input table,</span>
<span class="sd">    because we want to include the probability of ``x = 6`` in the sum)::</span>

<span class="sd">        &gt;&gt;&gt; hypergeom.sf(5, M, n, N)</span>
<span class="sd">        0.08624708624708627</span>

<span class="sd">    For ``alternative=&#39;less&#39;``, the one-sided p-value is the probability</span>
<span class="sd">    that a random table has ``x &lt;= a``, (i.e. ``x &lt;= 6`` in our example),</span>
<span class="sd">    or ``0.0163 + 0.163 + 0.408 + 0.326 + 0.0816 ~= 0.9949``::</span>

<span class="sd">        &gt;&gt;&gt; res = fisher_exact(table, alternative=&#39;less&#39;)</span>
<span class="sd">        &gt;&gt;&gt; res.pvalue</span>
<span class="sd">        0.9953379953379957</span>

<span class="sd">    This is equivalent to computing the cumulative distribution function</span>
<span class="sd">    of the distribution at ``x = 6``:</span>

<span class="sd">        &gt;&gt;&gt; hypergeom.cdf(6, M, n, N)</span>
<span class="sd">        0.9953379953379957</span>

<span class="sd">    *Odds ratio*</span>

<span class="sd">    The calculated odds ratio is different from the value computed by the</span>
<span class="sd">    R function ``fisher.test``.  This implementation returns the &quot;sample&quot;</span>
<span class="sd">    or &quot;unconditional&quot; maximum likelihood estimate, while ``fisher.test``</span>
<span class="sd">    in R uses the conditional maximum likelihood estimate.  To compute the</span>
<span class="sd">    conditional maximum likelihood estimate of the odds ratio, use</span>
<span class="sd">    `scipy.stats.contingency.odds_ratio`.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Fisher, Sir Ronald A, &quot;The Design of Experiments:</span>
<span class="sd">           Mathematics of a Lady Tasting Tea.&quot; ISBN 978-0-486-41151-4, 1935.</span>
<span class="sd">    .. [2] &quot;Fisher&#39;s exact test&quot;,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Fisher&#39;s_exact_test</span>
<span class="sd">    .. [3] Emma V. Low et al. &quot;Identifying the lowest effective dose of</span>
<span class="sd">           acetazolamide for the prophylaxis of acute mountain sickness:</span>
<span class="sd">           systematic review and meta-analysis.&quot;</span>
<span class="sd">           BMJ, 345, :doi:`10.1136/bmj.e6779`, 2012.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    In [3]_, the effective dose of acetazolamide for the prophylaxis of acute</span>
<span class="sd">    mountain sickness was investigated. The study notably concluded:</span>

<span class="sd">        Acetazolamide 250 mg, 500 mg, and 750 mg daily were all efficacious for</span>
<span class="sd">        preventing acute mountain sickness. Acetazolamide 250 mg was the lowest</span>
<span class="sd">        effective dose with available evidence for this indication.</span>

<span class="sd">    The following table summarizes the results of the experiment in which</span>
<span class="sd">    some participants took a daily dose of acetazolamide 250 mg while others</span>
<span class="sd">    took a placebo.</span>
<span class="sd">    Cases of acute mountain sickness were recorded::</span>

<span class="sd">                                    Acetazolamide   Control/Placebo</span>
<span class="sd">        Acute mountain sickness            7           17</span>
<span class="sd">        No                                15            5</span>


<span class="sd">    Is there evidence that the acetazolamide 250 mg reduces the risk of</span>
<span class="sd">    acute mountain sickness?</span>
<span class="sd">    We begin by formulating a null hypothesis :math:`H_0`:</span>

<span class="sd">        The odds of experiencing acute mountain sickness are the same with</span>
<span class="sd">        the acetazolamide treatment as they are with placebo.</span>

<span class="sd">    Let&#39;s assess the plausibility of this hypothesis with</span>
<span class="sd">    Fisher&#39;s test.</span>

<span class="sd">    &gt;&gt;&gt; from scipy.stats import fisher_exact</span>
<span class="sd">    &gt;&gt;&gt; res = fisher_exact([[7, 17], [15, 5]], alternative=&#39;less&#39;)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    0.13725490196078433</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.0028841933752349743</span>

<span class="sd">    Using a significance level of 5%, we would reject the null hypothesis in</span>
<span class="sd">    favor of the alternative hypothesis: &quot;The odds of experiencing acute</span>
<span class="sd">    mountain sickness with acetazolamide treatment are less than the odds of</span>
<span class="sd">    experiencing acute mountain sickness with placebo.&quot;</span>

<span class="sd">    .. note::</span>

<span class="sd">        Because the null distribution of Fisher&#39;s exact test is formed under</span>
<span class="sd">        the assumption that both row and column sums are fixed, the result of</span>
<span class="sd">        the test are conservative when applied to an experiment in which the</span>
<span class="sd">        row sums are not fixed.</span>

<span class="sd">        In this case, the column sums are fixed; there are 22 subjects in each</span>
<span class="sd">        group. But the number of cases of acute mountain sickness is not</span>
<span class="sd">        (and cannot be) fixed before conducting the experiment. It is a</span>
<span class="sd">        consequence.</span>

<span class="sd">        Boschloo&#39;s test does not depend on the assumption that the row sums</span>
<span class="sd">        are fixed, and consequently, it provides a more powerful test in this</span>
<span class="sd">        situation.</span>

<span class="sd">        &gt;&gt;&gt; from scipy.stats import boschloo_exact</span>
<span class="sd">        &gt;&gt;&gt; res = boschloo_exact([[7, 17], [15, 5]], alternative=&#39;less&#39;)</span>
<span class="sd">        &gt;&gt;&gt; res.statistic</span>
<span class="sd">        0.0028841933752349743</span>
<span class="sd">        &gt;&gt;&gt; res.pvalue</span>
<span class="sd">        0.0015141406667567101</span>

<span class="sd">        We verify that the p-value is less than with `fisher_exact`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">hypergeom</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">hypergeom</span>
    <span class="c1"># int32 is not enough for the algorithm</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">c</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The input `table` must be of shape (2, 2).&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">c</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;All values in `table` must be nonnegative.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="mi">0</span> <span class="ow">in</span> <span class="n">c</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="mi">0</span> <span class="ow">in</span> <span class="n">c</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># If both values in a row or column are zero, the p-value is 1 and</span>
        <span class="c1"># the odds ratio is NaN.</span>
        <span class="k">return</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">oddsratio</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">oddsratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

    <span class="n">n1</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">n2</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;less&#39;</span><span class="p">:</span>
        <span class="n">pvalue</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;greater&#39;</span><span class="p">:</span>
        <span class="c1"># Same formula as the &#39;less&#39; case, but with the second column.</span>
        <span class="n">pvalue</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;two-sided&#39;</span><span class="p">:</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span> <span class="o">+</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">pexact</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        <span class="n">pmode</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

        <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-14</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">epsilon</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pexact</span> <span class="o">-</span> <span class="n">pmode</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">pexact</span><span class="p">,</span> <span class="n">pmode</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">oddsratio</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">mode</span><span class="p">:</span>
            <span class="n">plower</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">pexact</span> <span class="o">*</span> <span class="n">gamma</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">oddsratio</span><span class="p">,</span> <span class="n">plower</span><span class="p">)</span>

            <span class="n">guess</span> <span class="o">=</span> <span class="n">_binary_search</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="o">-</span><span class="n">pexact</span> <span class="o">*</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="n">pvalue</span> <span class="o">=</span> <span class="n">plower</span> <span class="o">+</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">guess</span><span class="p">,</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pupper</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">pexact</span> <span class="o">*</span> <span class="n">gamma</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">oddsratio</span><span class="p">,</span> <span class="n">pupper</span><span class="p">)</span>

            <span class="n">guess</span> <span class="o">=</span> <span class="n">_binary_search</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span> <span class="n">pexact</span> <span class="o">*</span> <span class="n">gamma</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
            <span class="n">pvalue</span> <span class="o">=</span> <span class="n">pupper</span> <span class="o">+</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">guess</span><span class="p">,</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;`alternative` should be one of {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">pvalue</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">pvalue</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">oddsratio</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">spearmanr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span>
              <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculate a Spearman correlation coefficient with associated p-value.</span>

<span class="sd">    The Spearman rank-order correlation coefficient is a nonparametric measure</span>
<span class="sd">    of the monotonicity of the relationship between two datasets.</span>
<span class="sd">    Like other correlation coefficients,</span>
<span class="sd">    this one varies between -1 and +1 with 0 implying no correlation.</span>
<span class="sd">    Correlations of -1 or +1 imply an exact monotonic relationship. Positive</span>
<span class="sd">    correlations imply that as x increases, so does y. Negative correlations</span>
<span class="sd">    imply that as x increases, y decreases.</span>

<span class="sd">    The p-value roughly indicates the probability of an uncorrelated system</span>
<span class="sd">    producing datasets that have a Spearman correlation at least as extreme</span>
<span class="sd">    as the one computed from these datasets. Although calculation of the</span>
<span class="sd">    p-value does not make strong assumptions about the distributions underlying</span>
<span class="sd">    the samples, it is only accurate for very large samples (&gt;500</span>
<span class="sd">    observations). For smaller sample sizes, consider a permutation test (see</span>
<span class="sd">    Examples section below).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a, b : 1D or 2D array_like, b is optional</span>
<span class="sd">        One or two 1-D or 2-D arrays containing multiple variables and</span>
<span class="sd">        observations. When these are 1-D, each represents a vector of</span>
<span class="sd">        observations of a single variable. For the behavior in the 2-D case,</span>
<span class="sd">        see under ``axis``, below.</span>
<span class="sd">        Both arrays need to have the same length in the ``axis`` dimension.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        If axis=0 (default), then each column represents a variable, with</span>
<span class="sd">        observations in the rows. If axis=1, the relationship is transposed:</span>
<span class="sd">        each row represents a variable, while the columns contain observations.</span>
<span class="sd">        If axis=None, then both arrays will be raveled.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">        * &#39;propagate&#39;: returns nan</span>
<span class="sd">        * &#39;raise&#39;: throws an error</span>
<span class="sd">        * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis. Default is &#39;two-sided&#39;.</span>
<span class="sd">        The following options are available:</span>

<span class="sd">        * &#39;two-sided&#39;: the correlation is nonzero</span>
<span class="sd">        * &#39;less&#39;: the correlation is negative (less than zero)</span>
<span class="sd">        * &#39;greater&#39;:  the correlation is positive (greater than zero)</span>

<span class="sd">        .. versionadded:: 1.7.0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res : SignificanceResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float or ndarray (2-D square)</span>
<span class="sd">            Spearman correlation matrix or correlation coefficient (if only 2</span>
<span class="sd">            variables are given as parameters). Correlation matrix is square</span>
<span class="sd">            with length equal to total number of variables (columns or rows) in</span>
<span class="sd">            ``a`` and ``b`` combined.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            The p-value for a hypothesis test whose null hypothesis</span>
<span class="sd">            is that two samples have no ordinal correlation. See</span>
<span class="sd">            `alternative` above for alternative hypotheses. `pvalue` has the</span>
<span class="sd">            same shape as `statistic`.</span>

<span class="sd">    Warns</span>
<span class="sd">    -----</span>
<span class="sd">    `~scipy.stats.ConstantInputWarning`</span>
<span class="sd">        Raised if an input is a constant array.  The correlation coefficient</span>
<span class="sd">        is not defined in this case, so ``np.nan`` is returned.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard</span>
<span class="sd">       Probability and Statistics Tables and Formulae. Chapman &amp; Hall: New</span>
<span class="sd">       York. 2000.</span>
<span class="sd">       Section  14.7</span>
<span class="sd">    .. [2] Kendall, M. G. and Stuart, A. (1973).</span>
<span class="sd">       The Advanced Theory of Statistics, Volume 2: Inference and Relationship.</span>
<span class="sd">       Griffin. 1973.</span>
<span class="sd">       Section 31.18</span>
<span class="sd">    .. [3] Kershenobich, D., Fierro, F. J., &amp; Rojkind, M. (1970). The</span>
<span class="sd">       relationship between the free pool of proline and collagen content in</span>
<span class="sd">       human liver cirrhosis. The Journal of Clinical Investigation, 49(12),</span>
<span class="sd">       2246-2249.</span>
<span class="sd">    .. [4] Hollander, M., Wolfe, D. A., &amp; Chicken, E. (2013). Nonparametric</span>
<span class="sd">       statistical methods. John Wiley &amp; Sons.</span>
<span class="sd">    .. [5] B. Phipson and G. K. Smyth. &quot;Permutation P-values Should Never Be</span>
<span class="sd">       Zero: Calculating Exact P-values When Permutations Are Randomly Drawn.&quot;</span>
<span class="sd">       Statistical Applications in Genetics and Molecular Biology 9.1 (2010).</span>
<span class="sd">    .. [6] Ludbrook, J., &amp; Dudley, H. (1998). Why permutation tests are</span>
<span class="sd">       superior to t and F tests in biomedical research. The American</span>
<span class="sd">       Statistician, 52(2), 127-132.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Consider the following data from [3]_, which studied the relationship</span>
<span class="sd">    between free proline (an amino acid) and total collagen (a protein often</span>
<span class="sd">    found in connective tissue) in unhealthy human livers.</span>

<span class="sd">    The ``x`` and ``y`` arrays below record measurements of the two compounds.</span>
<span class="sd">    The observations are paired: each free proline measurement was taken from</span>
<span class="sd">    the same liver as the total collagen measurement at the same index.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; # total collagen (mg/g dry weight of liver)</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([7.1, 7.1, 7.2, 8.3, 9.4, 10.5, 11.4])</span>
<span class="sd">    &gt;&gt;&gt; # free proline ( mole/g dry weight of liver)</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([2.8, 2.9, 2.8, 2.6, 3.5, 4.6, 5.0])</span>

<span class="sd">    These data were analyzed in [4]_ using Spearman&#39;s correlation coefficient,</span>
<span class="sd">    a statistic sensitive to monotonic correlation between the samples.</span>

<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; res = stats.spearmanr(x, y)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    0.7000000000000001</span>

<span class="sd">    The value of this statistic tends to be high (close to 1) for samples with</span>
<span class="sd">    a strongly positive ordinal correlation, low (close to -1) for samples with</span>
<span class="sd">    a strongly negative ordinal correlation, and small in magnitude (close to</span>
<span class="sd">    zero) for samples with weak ordinal correlation.</span>

<span class="sd">    The test is performed by comparing the observed value of the</span>
<span class="sd">    statistic against the null distribution: the distribution of statistic</span>
<span class="sd">    values derived under the null hypothesis that total collagen and free</span>
<span class="sd">    proline measurements are independent.</span>

<span class="sd">    For this test, the statistic can be transformed such that the null</span>
<span class="sd">    distribution for large samples is Student&#39;s t distribution with</span>
<span class="sd">    ``len(x) - 2`` degrees of freedom.</span>

<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; dof = len(x)-2  # len(x) == len(y)</span>
<span class="sd">    &gt;&gt;&gt; dist = stats.t(df=dof)</span>
<span class="sd">    &gt;&gt;&gt; t_vals = np.linspace(-5, 5, 100)</span>
<span class="sd">    &gt;&gt;&gt; pdf = dist.pdf(t_vals)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; def plot(ax):  # we&#39;ll reuse this</span>
<span class="sd">    ...     ax.plot(t_vals, pdf)</span>
<span class="sd">    ...     ax.set_title(&quot;Spearman&#39;s Rho Test Null Distribution&quot;)</span>
<span class="sd">    ...     ax.set_xlabel(&quot;statistic&quot;)</span>
<span class="sd">    ...     ax.set_ylabel(&quot;probability density&quot;)</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    The comparison is quantified by the p-value: the proportion of values in</span>
<span class="sd">    the null distribution as extreme or more extreme than the observed</span>
<span class="sd">    value of the statistic. In a two-sided test in which the statistic is</span>
<span class="sd">    positive, elements of the null distribution greater than the transformed</span>
<span class="sd">    statistic and elements of the null distribution less than the negative of</span>
<span class="sd">    the observed statistic are both considered &quot;more extreme&quot;.</span>

<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; rs = res.statistic  # original statistic</span>
<span class="sd">    &gt;&gt;&gt; transformed = rs * np.sqrt(dof / ((rs+1.0)*(1.0-rs)))</span>
<span class="sd">    &gt;&gt;&gt; pvalue = dist.cdf(-transformed) + dist.sf(transformed)</span>
<span class="sd">    &gt;&gt;&gt; annotation = (f&#39;p-value={pvalue:.4f}\n(shaded area)&#39;)</span>
<span class="sd">    &gt;&gt;&gt; props = dict(facecolor=&#39;black&#39;, width=1, headwidth=5, headlength=8)</span>
<span class="sd">    &gt;&gt;&gt; _ = ax.annotate(annotation, (2.7, 0.025), (3, 0.03), arrowprops=props)</span>
<span class="sd">    &gt;&gt;&gt; i = t_vals &gt;= transformed</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(t_vals[i], y1=0, y2=pdf[i], color=&#39;C0&#39;)</span>
<span class="sd">    &gt;&gt;&gt; i = t_vals &lt;= -transformed</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(t_vals[i], y1=0, y2=pdf[i], color=&#39;C0&#39;)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_xlim(-5, 5)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_ylim(0, 0.1)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.07991669030889909  # two-sided p-value</span>

<span class="sd">    If the p-value is &quot;small&quot; - that is, if there is a low probability of</span>
<span class="sd">    sampling data from independent distributions that produces such an extreme</span>
<span class="sd">    value of the statistic - this may be taken as evidence against the null</span>
<span class="sd">    hypothesis in favor of the alternative: the distribution of total collagen</span>
<span class="sd">    and free proline are *not* independent. Note that:</span>

<span class="sd">    - The inverse is not true; that is, the test is not used to provide</span>
<span class="sd">      evidence for the null hypothesis.</span>
<span class="sd">    - The threshold for values that will be considered &quot;small&quot; is a choice that</span>
<span class="sd">      should be made before the data is analyzed [5]_ with consideration of the</span>
<span class="sd">      risks of both false positives (incorrectly rejecting the null hypothesis)</span>
<span class="sd">      and false negatives (failure to reject a false null hypothesis).</span>
<span class="sd">    - Small p-values are not evidence for a *large* effect; rather, they can</span>
<span class="sd">      only provide evidence for a &quot;significant&quot; effect, meaning that they are</span>
<span class="sd">      unlikely to have occurred under the null hypothesis.</span>

<span class="sd">    Suppose that before performing the experiment, the authors had reason</span>
<span class="sd">    to predict a positive correlation between the total collagen and free</span>
<span class="sd">    proline measurements, and that they had chosen to assess the plausibility</span>
<span class="sd">    of the null hypothesis against a one-sided alternative: free proline has a</span>
<span class="sd">    positive ordinal correlation with total collagen. In this case, only those</span>
<span class="sd">    values in the null distribution that are as great or greater than the</span>
<span class="sd">    observed statistic are considered to be more extreme.</span>

<span class="sd">    &gt;&gt;&gt; res = stats.spearmanr(x, y, alternative=&#39;greater&#39;)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    0.7000000000000001  # same statistic</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; pvalue = dist.sf(transformed)</span>
<span class="sd">    &gt;&gt;&gt; annotation = (f&#39;p-value={pvalue:.6f}\n(shaded area)&#39;)</span>
<span class="sd">    &gt;&gt;&gt; props = dict(facecolor=&#39;black&#39;, width=1, headwidth=5, headlength=8)</span>
<span class="sd">    &gt;&gt;&gt; _ = ax.annotate(annotation, (3, 0.018), (3.5, 0.03), arrowprops=props)</span>
<span class="sd">    &gt;&gt;&gt; i = t_vals &gt;= transformed</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(t_vals[i], y1=0, y2=pdf[i], color=&#39;C0&#39;)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_xlim(1, 5)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_ylim(0, 0.1)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.03995834515444954  # one-sided p-value; half of the two-sided p-value</span>

<span class="sd">    Note that the t-distribution provides an asymptotic approximation of the</span>
<span class="sd">    null distribution; it is only accurate for samples with many observations.</span>
<span class="sd">    For small samples, it may be more appropriate to perform a permutation</span>
<span class="sd">    test: Under the null hypothesis that total collagen and free proline are</span>
<span class="sd">    independent, each of the free proline measurements were equally likely to</span>
<span class="sd">    have been observed with any of the total collagen measurements. Therefore,</span>
<span class="sd">    we can form an *exact* null distribution by calculating the statistic under</span>
<span class="sd">    each possible pairing of elements between ``x`` and ``y``.</span>

<span class="sd">    &gt;&gt;&gt; def statistic(x):  # explore all possible pairings by permuting `x`</span>
<span class="sd">    ...     rs = stats.spearmanr(x, y).statistic  # ignore pvalue</span>
<span class="sd">    ...     transformed = rs * np.sqrt(dof / ((rs+1.0)*(1.0-rs)))</span>
<span class="sd">    ...     return transformed</span>
<span class="sd">    &gt;&gt;&gt; ref = stats.permutation_test((x,), statistic, alternative=&#39;greater&#39;,</span>
<span class="sd">    ...                              permutation_type=&#39;pairings&#39;)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; ax.hist(ref.null_distribution, np.linspace(-5, 5, 26),</span>
<span class="sd">    ...         density=True)</span>
<span class="sd">    &gt;&gt;&gt; ax.legend([&#39;aymptotic approximation\n(many observations)&#39;,</span>
<span class="sd">    ...            f&#39;exact \n({len(ref.null_distribution)} permutations)&#39;])</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; ref.pvalue</span>
<span class="sd">    0.04563492063492063  # exact one-sided p-value</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">axis</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;spearmanr only handles 1-D or 2-D arrays, &quot;</span>
                         <span class="sa">f</span><span class="s2">&quot;supplied axis argument </span><span class="si">{</span><span class="n">axis</span><span class="si">}</span><span class="s2">, please use only &quot;</span>
                         <span class="s2">&quot;values 0, 1 or None for axis&quot;</span><span class="p">)</span>

    <span class="n">a</span><span class="p">,</span> <span class="n">axisout</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;spearmanr only handles 1-D or 2-D arrays&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`spearmanr` needs at least 2 &quot;</span>
                             <span class="s2">&quot;variables to compare&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Concatenate a and b, so that we now only have to handle the case</span>
        <span class="c1"># of a 2-D `a`.</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">axisout</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>

    <span class="n">n_vars</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">axisout</span><span class="p">]</span>
    <span class="n">n_obs</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axisout</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">n_obs</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Handle empty arrays or single observations.</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="n">warn_msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;An input array is constant; the correlation coefficient &quot;</span>
                <span class="s2">&quot;is not defined.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axisout</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">a</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">a</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="ow">or</span> <span class="p">(</span><span class="n">a</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">a</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="c1"># If an input is constant, the correlation coefficient</span>
            <span class="c1"># is not defined.</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">ConstantInputWarning</span><span class="p">(</span><span class="n">warn_msg</span><span class="p">),</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">return</span> <span class="n">res</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># case when axisout == 1 b/c a is 2 dim only</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="ow">or</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="c1"># If an input is constant, the correlation coefficient</span>
            <span class="c1"># is not defined.</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">ConstantInputWarning</span><span class="p">(</span><span class="n">warn_msg</span><span class="p">),</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="k">return</span> <span class="n">res</span>

    <span class="n">a_contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>
    <span class="n">variable_has_nan</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">a_contains_nan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">,</span>
                                          <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;propagate&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">n_vars</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
                <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
                <span class="k">return</span> <span class="n">res</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Keep track of variables with NaNs, set the outputs to NaN</span>
                <span class="c1"># only for those variables</span>
                <span class="n">variable_has_nan</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axisout</span><span class="p">)</span>

    <span class="n">a_ranked</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">rankdata</span><span class="p">,</span> <span class="n">axisout</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">rs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">a_ranked</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="n">axisout</span><span class="p">)</span>
    <span class="n">dof</span> <span class="o">=</span> <span class="n">n_obs</span> <span class="o">-</span> <span class="mi">2</span>  <span class="c1"># degrees of freedom</span>

    <span class="c1"># rs can have elements equal to 1, so avoid zero division warnings</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
        <span class="c1"># clip the small negative values possibly caused by rounding</span>
        <span class="c1"># errors before taking the square root</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">rs</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">dof</span><span class="o">/</span><span class="p">((</span><span class="n">rs</span><span class="o">+</span><span class="mf">1.0</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">rs</span><span class="p">)))</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

    <span class="n">t</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">_ttest_finish</span><span class="p">(</span><span class="n">dof</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>

    <span class="c1"># For backwards compatibility, return scalars when comparing 2 columns</span>
    <span class="k">if</span> <span class="n">rs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">rs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">prob</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">rs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">res</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rs</span><span class="p">[</span><span class="n">variable_has_nan</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">rs</span><span class="p">[:,</span> <span class="n">variable_has_nan</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">rs</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span>
        <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">rs</span>
        <span class="k">return</span> <span class="n">res</span>


<span class="k">def</span><span class="w"> </span><span class="nf">pointbiserialr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculate a point biserial correlation coefficient and its p-value.</span>

<span class="sd">    The point biserial correlation is used to measure the relationship</span>
<span class="sd">    between a binary variable, x, and a continuous variable, y. Like other</span>
<span class="sd">    correlation coefficients, this one varies between -1 and +1 with 0</span>
<span class="sd">    implying no correlation. Correlations of -1 or +1 imply a determinative</span>
<span class="sd">    relationship.</span>

<span class="sd">    This function may be computed using a shortcut formula but produces the</span>
<span class="sd">    same result as `pearsonr`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : array_like of bools</span>
<span class="sd">        Input array.</span>
<span class="sd">    y : array_like</span>
<span class="sd">        Input array.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res: SignificanceResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            The R value.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            The two-sided p-value.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    `pointbiserialr` uses a t-test with ``n-1`` degrees of freedom.</span>
<span class="sd">    It is equivalent to `pearsonr`.</span>

<span class="sd">    The value of the point-biserial correlation can be calculated from:</span>

<span class="sd">    .. math::</span>

<span class="sd">        r_{pb} = \frac{\overline{Y_1} - \overline{Y_0}}</span>
<span class="sd">                      {s_y}</span>
<span class="sd">                 \sqrt{\frac{N_0 N_1}</span>
<span class="sd">                            {N (N - 1)}}</span>

<span class="sd">    Where :math:`\overline{Y_{0}}` and :math:`\overline{Y_{1}}` are means</span>
<span class="sd">    of the metric observations coded 0 and 1 respectively; :math:`N_{0}` and</span>
<span class="sd">    :math:`N_{1}` are number of observations coded 0 and 1 respectively;</span>
<span class="sd">    :math:`N` is the total number of observations and :math:`s_{y}` is the</span>
<span class="sd">    standard deviation of all the metric observations.</span>

<span class="sd">    A value of :math:`r_{pb}` that is significantly different from zero is</span>
<span class="sd">    completely equivalent to a significant difference in means between the two</span>
<span class="sd">    groups. Thus, an independent groups t Test with :math:`N-2` degrees of</span>
<span class="sd">    freedom may be used to test whether :math:`r_{pb}` is nonzero. The</span>
<span class="sd">    relation between the t-statistic for comparing two independent groups and</span>
<span class="sd">    :math:`r_{pb}` is given by:</span>

<span class="sd">    .. math::</span>

<span class="sd">        t = \sqrt{N - 2}\frac{r_{pb}}{\sqrt{1 - r^{2}_{pb}}}</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] J. Lev, &quot;The Point Biserial Coefficient of Correlation&quot;, Ann. Math.</span>
<span class="sd">           Statist., Vol. 20, no.1, pp. 125-126, 1949.</span>

<span class="sd">    .. [2] R.F. Tate, &quot;Correlation Between a Discrete and a Continuous</span>
<span class="sd">           Variable. Point-Biserial Correlation.&quot;, Ann. Math. Statist., Vol. 25,</span>
<span class="sd">           np. 3, pp. 603-607, 1954.</span>

<span class="sd">    .. [3] D. Kornbrot &quot;Point Biserial Correlation&quot;, In Wiley StatsRef:</span>
<span class="sd">           Statistics Reference Online (eds N. Balakrishnan, et al.), 2014.</span>
<span class="sd">           :doi:`10.1002/9781118445112.stat06227`</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; a = np.array([0, 0, 0, 1, 1, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; b = np.arange(7)</span>
<span class="sd">    &gt;&gt;&gt; stats.pointbiserialr(a, b)</span>
<span class="sd">    (0.8660254037844386, 0.011724811003954652)</span>
<span class="sd">    &gt;&gt;&gt; stats.pearsonr(a, b)</span>
<span class="sd">    (0.86602540378443871, 0.011724811003954626)</span>
<span class="sd">    &gt;&gt;&gt; np.corrcoef(a, b)</span>
<span class="sd">    array([[ 1.       ,  0.8660254],</span>
<span class="sd">           [ 0.8660254,  1.       ]])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rpb</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="c1"># create result object with alias for backward compatibility</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">rpb</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span>
    <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">rpb</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="nd">@_deprecate_positional_args</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s2">&quot;1.14&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kendalltau</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">initial_lexsort</span><span class="o">=</span><span class="n">_NoValue</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span>
               <span class="n">method</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">variant</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculate Kendall&#39;s tau, a correlation measure for ordinal data.</span>

<span class="sd">    Kendall&#39;s tau is a measure of the correspondence between two rankings.</span>
<span class="sd">    Values close to 1 indicate strong agreement, and values close to -1</span>
<span class="sd">    indicate strong disagreement. This implements two variants of Kendall&#39;s</span>
<span class="sd">    tau: tau-b (the default) and tau-c (also known as Stuart&#39;s tau-c). These</span>
<span class="sd">    differ only in how they are normalized to lie within the range -1 to 1;</span>
<span class="sd">    the hypothesis tests (their p-values) are identical. Kendall&#39;s original</span>
<span class="sd">    tau-a is not implemented separately because both tau-b and tau-c reduce</span>
<span class="sd">    to tau-a in the absence of ties.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x, y : array_like</span>
<span class="sd">        Arrays of rankings, of the same shape. If arrays are not 1-D, they</span>
<span class="sd">        will be flattened to 1-D.</span>
<span class="sd">    initial_lexsort : bool, optional, deprecated</span>
<span class="sd">        This argument is unused.</span>

<span class="sd">        .. deprecated:: 1.10.0</span>
<span class="sd">           `kendalltau` keyword argument `initial_lexsort` is deprecated as it</span>
<span class="sd">           is unused and will be removed in SciPy 1.14.0.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    method : {&#39;auto&#39;, &#39;asymptotic&#39;, &#39;exact&#39;}, optional</span>
<span class="sd">        Defines which method is used to calculate the p-value [5]_.</span>
<span class="sd">        The following options are available (default is &#39;auto&#39;):</span>

<span class="sd">          * &#39;auto&#39;: selects the appropriate method based on a trade-off</span>
<span class="sd">            between speed and accuracy</span>
<span class="sd">          * &#39;asymptotic&#39;: uses a normal approximation valid for large samples</span>
<span class="sd">          * &#39;exact&#39;: computes the exact p-value, but can only be used if no ties</span>
<span class="sd">            are present. As the sample size increases, the &#39;exact&#39; computation</span>
<span class="sd">            time may grow and the result may lose some precision.</span>
<span class="sd">    variant : {&#39;b&#39;, &#39;c&#39;}, optional</span>
<span class="sd">        Defines which variant of Kendall&#39;s tau is returned. Default is &#39;b&#39;.</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis. Default is &#39;two-sided&#39;.</span>
<span class="sd">        The following options are available:</span>

<span class="sd">        * &#39;two-sided&#39;: the rank correlation is nonzero</span>
<span class="sd">        * &#39;less&#39;: the rank correlation is negative (less than zero)</span>
<span class="sd">        * &#39;greater&#39;:  the rank correlation is positive (greater than zero)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res : SignificanceResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">           The tau statistic.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">           The p-value for a hypothesis test whose null hypothesis is</span>
<span class="sd">           an absence of association, tau = 0.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    spearmanr : Calculates a Spearman rank-order correlation coefficient.</span>
<span class="sd">    theilslopes : Computes the Theil-Sen estimator for a set of points (x, y).</span>
<span class="sd">    weightedtau : Computes a weighted version of Kendall&#39;s tau.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The definition of Kendall&#39;s tau that is used is [2]_::</span>

<span class="sd">      tau_b = (P - Q) / sqrt((P + Q + T) * (P + Q + U))</span>

<span class="sd">      tau_c = 2 (P - Q) / (n**2 * (m - 1) / m)</span>

<span class="sd">    where P is the number of concordant pairs, Q the number of discordant</span>
<span class="sd">    pairs, T the number of ties only in `x`, and U the number of ties only in</span>
<span class="sd">    `y`.  If a tie occurs for the same pair in both `x` and `y`, it is not</span>
<span class="sd">    added to either T or U. n is the total number of samples, and m is the</span>
<span class="sd">    number of unique values in either `x` or `y`, whichever is smaller.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Maurice G. Kendall, &quot;A New Measure of Rank Correlation&quot;, Biometrika</span>
<span class="sd">           Vol. 30, No. 1/2, pp. 81-93, 1938.</span>
<span class="sd">    .. [2] Maurice G. Kendall, &quot;The treatment of ties in ranking problems&quot;,</span>
<span class="sd">           Biometrika Vol. 33, No. 3, pp. 239-251. 1945.</span>
<span class="sd">    .. [3] Gottfried E. Noether, &quot;Elements of Nonparametric Statistics&quot;, John</span>
<span class="sd">           Wiley &amp; Sons, 1967.</span>
<span class="sd">    .. [4] Peter M. Fenwick, &quot;A new data structure for cumulative frequency</span>
<span class="sd">           tables&quot;, Software: Practice and Experience, Vol. 24, No. 3,</span>
<span class="sd">           pp. 327-336, 1994.</span>
<span class="sd">    .. [5] Maurice G. Kendall, &quot;Rank Correlation Methods&quot; (4th Edition),</span>
<span class="sd">           Charles Griffin &amp; Co., 1970.</span>
<span class="sd">    .. [6] Kershenobich, D., Fierro, F. J., &amp; Rojkind, M. (1970). The</span>
<span class="sd">           relationship between the free pool of proline and collagen content</span>
<span class="sd">           in human liver cirrhosis. The Journal of Clinical Investigation,</span>
<span class="sd">           49(12), 2246-2249.</span>
<span class="sd">    .. [7] Hollander, M., Wolfe, D. A., &amp; Chicken, E. (2013). Nonparametric</span>
<span class="sd">           statistical methods. John Wiley &amp; Sons.</span>
<span class="sd">    .. [8] B. Phipson and G. K. Smyth. &quot;Permutation P-values Should Never Be</span>
<span class="sd">           Zero: Calculating Exact P-values When Permutations Are Randomly</span>
<span class="sd">           Drawn.&quot; Statistical Applications in Genetics and Molecular Biology</span>
<span class="sd">           9.1 (2010).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Consider the following data from [6]_, which studied the relationship</span>
<span class="sd">    between free proline (an amino acid) and total collagen (a protein often</span>
<span class="sd">    found in connective tissue) in unhealthy human livers.</span>

<span class="sd">    The ``x`` and ``y`` arrays below record measurements of the two compounds.</span>
<span class="sd">    The observations are paired: each free proline measurement was taken from</span>
<span class="sd">    the same liver as the total collagen measurement at the same index.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; # total collagen (mg/g dry weight of liver)</span>
<span class="sd">    &gt;&gt;&gt; x = np.array([7.1, 7.1, 7.2, 8.3, 9.4, 10.5, 11.4])</span>
<span class="sd">    &gt;&gt;&gt; # free proline ( mole/g dry weight of liver)</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([2.8, 2.9, 2.8, 2.6, 3.5, 4.6, 5.0])</span>

<span class="sd">    These data were analyzed in [7]_ using Spearman&#39;s correlation coefficient,</span>
<span class="sd">    a statistic similar to to Kendall&#39;s tau in that it is also sensitive to</span>
<span class="sd">    ordinal correlation between the samples. Let&#39;s perform an analogous study</span>
<span class="sd">    using Kendall&#39;s tau.</span>

<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; res = stats.kendalltau(x, y)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    0.5499999999999999</span>

<span class="sd">    The value of this statistic tends to be high (close to 1) for samples with</span>
<span class="sd">    a strongly positive ordinal correlation, low (close to -1) for samples with</span>
<span class="sd">    a strongly negative ordinal correlation, and small in magnitude (close to</span>
<span class="sd">    zero) for samples with weak ordinal correlation.</span>

<span class="sd">    The test is performed by comparing the observed value of the</span>
<span class="sd">    statistic against the null distribution: the distribution of statistic</span>
<span class="sd">    values derived under the null hypothesis that total collagen and free</span>
<span class="sd">    proline measurements are independent.</span>

<span class="sd">    For this test, the null distribution for large samples without ties is</span>
<span class="sd">    approximated as the normal distribution with variance</span>
<span class="sd">    ``(2*(2*n + 5))/(9*n*(n - 1))``, where ``n = len(x)``.</span>

<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; n = len(x)  # len(x) == len(y)</span>
<span class="sd">    &gt;&gt;&gt; var = (2*(2*n + 5))/(9*n*(n - 1))</span>
<span class="sd">    &gt;&gt;&gt; dist = stats.norm(scale=np.sqrt(var))</span>
<span class="sd">    &gt;&gt;&gt; z_vals = np.linspace(-1.25, 1.25, 100)</span>
<span class="sd">    &gt;&gt;&gt; pdf = dist.pdf(z_vals)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; def plot(ax):  # we&#39;ll reuse this</span>
<span class="sd">    ...     ax.plot(z_vals, pdf)</span>
<span class="sd">    ...     ax.set_title(&quot;Kendall Tau Test Null Distribution&quot;)</span>
<span class="sd">    ...     ax.set_xlabel(&quot;statistic&quot;)</span>
<span class="sd">    ...     ax.set_ylabel(&quot;probability density&quot;)</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>

<span class="sd">    The comparison is quantified by the p-value: the proportion of values in</span>
<span class="sd">    the null distribution as extreme or more extreme than the observed</span>
<span class="sd">    value of the statistic. In a two-sided test in which the statistic is</span>
<span class="sd">    positive, elements of the null distribution greater than the transformed</span>
<span class="sd">    statistic and elements of the null distribution less than the negative of</span>
<span class="sd">    the observed statistic are both considered &quot;more extreme&quot;.</span>

<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; pvalue = dist.cdf(-res.statistic) + dist.sf(res.statistic)</span>
<span class="sd">    &gt;&gt;&gt; annotation = (f&#39;p-value={pvalue:.4f}\n(shaded area)&#39;)</span>
<span class="sd">    &gt;&gt;&gt; props = dict(facecolor=&#39;black&#39;, width=1, headwidth=5, headlength=8)</span>
<span class="sd">    &gt;&gt;&gt; _ = ax.annotate(annotation, (0.65, 0.15), (0.8, 0.3), arrowprops=props)</span>
<span class="sd">    &gt;&gt;&gt; i = z_vals &gt;= res.statistic</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(z_vals[i], y1=0, y2=pdf[i], color=&#39;C0&#39;)</span>
<span class="sd">    &gt;&gt;&gt; i = z_vals &lt;= -res.statistic</span>
<span class="sd">    &gt;&gt;&gt; ax.fill_between(z_vals[i], y1=0, y2=pdf[i], color=&#39;C0&#39;)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_xlim(-1.25, 1.25)</span>
<span class="sd">    &gt;&gt;&gt; ax.set_ylim(0, 0.5)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.09108705741631495  # approximate p-value</span>

<span class="sd">    Note that there is slight disagreement between the shaded area of the curve</span>
<span class="sd">    and the p-value returned by `kendalltau`. This is because our data has</span>
<span class="sd">    ties, and we have neglected a tie correction to the null distribution</span>
<span class="sd">    variance that `kendalltau` performs. For samples without ties, the shaded</span>
<span class="sd">    areas of our plot and p-value returned by `kendalltau` would match exactly.</span>

<span class="sd">    If the p-value is &quot;small&quot; - that is, if there is a low probability of</span>
<span class="sd">    sampling data from independent distributions that produces such an extreme</span>
<span class="sd">    value of the statistic - this may be taken as evidence against the null</span>
<span class="sd">    hypothesis in favor of the alternative: the distribution of total collagen</span>
<span class="sd">    and free proline are *not* independent. Note that:</span>

<span class="sd">    - The inverse is not true; that is, the test is not used to provide</span>
<span class="sd">      evidence for the null hypothesis.</span>
<span class="sd">    - The threshold for values that will be considered &quot;small&quot; is a choice that</span>
<span class="sd">      should be made before the data is analyzed [8]_ with consideration of the</span>
<span class="sd">      risks of both false positives (incorrectly rejecting the null hypothesis)</span>
<span class="sd">      and false negatives (failure to reject a false null hypothesis).</span>
<span class="sd">    - Small p-values are not evidence for a *large* effect; rather, they can</span>
<span class="sd">      only provide evidence for a &quot;significant&quot; effect, meaning that they are</span>
<span class="sd">      unlikely to have occurred under the null hypothesis.</span>

<span class="sd">    For samples without ties of moderate size, `kendalltau` can compute the</span>
<span class="sd">    p-value exactly. However, in the presence of ties, `kendalltau` resorts</span>
<span class="sd">    to an asymptotic approximation. Nonetheles, we can use a permutation test</span>
<span class="sd">    to compute the null distribution exactly: Under the null hypothesis that</span>
<span class="sd">    total collagen and free proline are independent, each of the free proline</span>
<span class="sd">    measurements were equally likely to have been observed with any of the</span>
<span class="sd">    total collagen measurements. Therefore, we can form an *exact* null</span>
<span class="sd">    distribution by calculating the statistic under each possible pairing of</span>
<span class="sd">    elements between ``x`` and ``y``.</span>

<span class="sd">    &gt;&gt;&gt; def statistic(x):  # explore all possible pairings by permuting `x`</span>
<span class="sd">    ...     return stats.kendalltau(x, y).statistic  # ignore pvalue</span>
<span class="sd">    &gt;&gt;&gt; ref = stats.permutation_test((x,), statistic,</span>
<span class="sd">    ...                              permutation_type=&#39;pairings&#39;)</span>
<span class="sd">    &gt;&gt;&gt; fig, ax = plt.subplots(figsize=(8, 5))</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; bins = np.linspace(-1.25, 1.25, 25)</span>
<span class="sd">    &gt;&gt;&gt; ax.hist(ref.null_distribution, bins=bins, density=True)</span>
<span class="sd">    &gt;&gt;&gt; ax.legend([&#39;aymptotic approximation\n(many observations)&#39;,</span>
<span class="sd">    ...            &#39;exact null distribution&#39;])</span>
<span class="sd">    &gt;&gt;&gt; plot(ax)</span>
<span class="sd">    &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &gt;&gt;&gt; ref.pvalue</span>
<span class="sd">    0.12222222222222222  # exact p-value</span>

<span class="sd">    Note that there is significant disagreement between the exact p-value</span>
<span class="sd">    calculated here and the approximation returned by `kendalltau` above. For</span>
<span class="sd">    small samples with ties, consider performing a permutation test for more</span>
<span class="sd">    accurate results.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">initial_lexsort</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_NoValue</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;&#39;kendalltau&#39; keyword argument &#39;initial_lexsort&#39; is deprecated&quot;</span>
               <span class="s2">&quot; as it is unused and will be removed in SciPy 1.12.0.&quot;</span><span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;All inputs to `kendalltau` must be of the same &quot;</span>
                         <span class="sa">f</span><span class="s2">&quot;size, found x-size </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2"> and y-size </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
        <span class="c1"># Return NaN if arrays are empty</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="c1"># check both x and y</span>
    <span class="n">cnx</span><span class="p">,</span> <span class="n">npx</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>
    <span class="n">cny</span><span class="p">,</span> <span class="n">npy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>
    <span class="n">contains_nan</span> <span class="o">=</span> <span class="n">cnx</span> <span class="ow">or</span> <span class="n">cny</span>
    <span class="k">if</span> <span class="n">npx</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span> <span class="ow">or</span> <span class="n">npy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="n">nan_policy</span> <span class="o">=</span> <span class="s1">&#39;omit&#39;</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;propagate&#39;</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">elif</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">variant</span> <span class="o">==</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">kendalltau</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">use_ties</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                           <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;nan_policy=&#39;omit&#39; is currently compatible only with &quot;</span>
                       <span class="s2">&quot;variant=&#39;b&#39;.&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">count_rank_tie</span><span class="p">(</span><span class="n">ranks</span><span class="p">):</span>
        <span class="n">cnt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int64&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">cnt</span> <span class="o">=</span> <span class="n">cnt</span><span class="p">[</span><span class="n">cnt</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Python ints to avoid overflow down the line</span>
        <span class="k">return</span> <span class="p">(</span><span class="nb">int</span><span class="p">((</span><span class="n">cnt</span> <span class="o">*</span> <span class="p">(</span><span class="n">cnt</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()),</span>
                <span class="nb">int</span><span class="p">((</span><span class="n">cnt</span> <span class="o">*</span> <span class="p">(</span><span class="n">cnt</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">cnt</span> <span class="o">-</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()),</span>
                <span class="nb">int</span><span class="p">((</span><span class="n">cnt</span> <span class="o">*</span> <span class="p">(</span><span class="n">cnt</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">cnt</span> <span class="o">+</span> <span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>

    <span class="n">size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># sort on y and convert y to dense ranks</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">perm</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">perm</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">y</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intp</span><span class="p">)</span>

    <span class="c1"># stable sort on x and convert x to dense ranks</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;mergesort&#39;</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">perm</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">perm</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intp</span><span class="p">)</span>

    <span class="n">dis</span> <span class="o">=</span> <span class="n">_kendall_dis</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># discordant pairs</span>

    <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">|</span> <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">y</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="kc">True</span><span class="p">]</span>
    <span class="n">cnt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">obs</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int64&#39;</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">ntie</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">cnt</span> <span class="o">*</span> <span class="p">(</span><span class="n">cnt</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>  <span class="c1"># joint ties</span>
    <span class="n">xtie</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">x1</span> <span class="o">=</span> <span class="n">count_rank_tie</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>     <span class="c1"># ties in x, stats</span>
    <span class="n">ytie</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">count_rank_tie</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>     <span class="c1"># ties in y, stats</span>

    <span class="n">tot</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span> <span class="o">*</span> <span class="p">(</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">2</span>

    <span class="k">if</span> <span class="n">xtie</span> <span class="o">==</span> <span class="n">tot</span> <span class="ow">or</span> <span class="n">ytie</span> <span class="o">==</span> <span class="n">tot</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="c1"># Note that tot = con + dis + (xtie - ntie) + (ytie - ntie) + ntie</span>
    <span class="c1">#               = con + dis + xtie + ytie - ntie</span>
    <span class="n">con_minus_dis</span> <span class="o">=</span> <span class="n">tot</span> <span class="o">-</span> <span class="n">xtie</span> <span class="o">-</span> <span class="n">ytie</span> <span class="o">+</span> <span class="n">ntie</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">dis</span>
    <span class="k">if</span> <span class="n">variant</span> <span class="o">==</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="n">con_minus_dis</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tot</span> <span class="o">-</span> <span class="n">xtie</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tot</span> <span class="o">-</span> <span class="n">ytie</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">variant</span> <span class="o">==</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span>
        <span class="n">minclasses</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">con_minus_dis</span> <span class="o">/</span> <span class="p">(</span><span class="n">size</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">minclasses</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">minclasses</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown variant of the method chosen: </span><span class="si">{</span><span class="n">variant</span><span class="si">}</span><span class="s2">. &quot;</span>
                         <span class="s2">&quot;variant must be &#39;b&#39; or &#39;c&#39;.&quot;</span><span class="p">)</span>

    <span class="c1"># Limit range to fix computational errors</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">tau</span><span class="p">))</span>

    <span class="c1"># The p-value calculation is the same for all variants since the p-value</span>
    <span class="c1"># depends only on con_minus_dis.</span>
    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;exact&#39;</span> <span class="ow">and</span> <span class="p">(</span><span class="n">xtie</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">ytie</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Ties found, exact method cannot be used.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">xtie</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">ytie</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">size</span> <span class="o">&lt;=</span> <span class="mi">33</span> <span class="ow">or</span>
                                          <span class="nb">min</span><span class="p">(</span><span class="n">dis</span><span class="p">,</span> <span class="n">tot</span><span class="o">-</span><span class="n">dis</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;exact&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;asymptotic&#39;</span>

    <span class="k">if</span> <span class="n">xtie</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">ytie</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;exact&#39;</span><span class="p">:</span>
        <span class="n">pvalue</span> <span class="o">=</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">_kendall_p_exact</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">tot</span><span class="o">-</span><span class="n">dis</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;asymptotic&#39;</span><span class="p">:</span>
        <span class="c1"># con_minus_dis is approx normally distributed with this variance [3]_</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">size</span> <span class="o">*</span> <span class="p">(</span><span class="n">size</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="p">((</span><span class="n">m</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">size</span> <span class="o">+</span> <span class="mi">5</span><span class="p">)</span> <span class="o">-</span> <span class="n">x1</span> <span class="o">-</span> <span class="n">y1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">18</span> <span class="o">+</span>
               <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">xtie</span> <span class="o">*</span> <span class="n">ytie</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span> <span class="o">+</span> <span class="n">x0</span> <span class="o">*</span> <span class="n">y0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">9</span> <span class="o">*</span> <span class="n">m</span> <span class="o">*</span> <span class="p">(</span><span class="n">size</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">con_minus_dis</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">_normtest_finish</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown method </span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2"> specified.  Use &#39;auto&#39;, &quot;</span>
                         <span class="s2">&quot;&#39;exact&#39; or &#39;asymptotic&#39;.&quot;</span><span class="p">)</span>

    <span class="c1"># create result object with alias for backward compatibility</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">)</span>
    <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">tau</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="k">def</span><span class="w"> </span><span class="nf">weightedtau</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">weigher</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">additive</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute a weighted version of Kendall&#39;s :math:`\tau`.</span>

<span class="sd">    The weighted :math:`\tau` is a weighted version of Kendall&#39;s</span>
<span class="sd">    :math:`\tau` in which exchanges of high weight are more influential than</span>
<span class="sd">    exchanges of low weight. The default parameters compute the additive</span>
<span class="sd">    hyperbolic version of the index, :math:`\tau_\mathrm h`, which has</span>
<span class="sd">    been shown to provide the best balance between important and</span>
<span class="sd">    unimportant elements [1]_.</span>

<span class="sd">    The weighting is defined by means of a rank array, which assigns a</span>
<span class="sd">    nonnegative rank to each element (higher importance ranks being</span>
<span class="sd">    associated with smaller values, e.g., 0 is the highest possible rank),</span>
<span class="sd">    and a weigher function, which assigns a weight based on the rank to</span>
<span class="sd">    each element. The weight of an exchange is then the sum or the product</span>
<span class="sd">    of the weights of the ranks of the exchanged elements. The default</span>
<span class="sd">    parameters compute :math:`\tau_\mathrm h`: an exchange between</span>
<span class="sd">    elements with rank :math:`r` and :math:`s` (starting from zero) has</span>
<span class="sd">    weight :math:`1/(r+1) + 1/(s+1)`.</span>

<span class="sd">    Specifying a rank array is meaningful only if you have in mind an</span>
<span class="sd">    external criterion of importance. If, as it usually happens, you do</span>
<span class="sd">    not have in mind a specific rank, the weighted :math:`\tau` is</span>
<span class="sd">    defined by averaging the values obtained using the decreasing</span>
<span class="sd">    lexicographical rank by (`x`, `y`) and by (`y`, `x`). This is the</span>
<span class="sd">    behavior with default parameters. Note that the convention used</span>
<span class="sd">    here for ranking (lower values imply higher importance) is opposite</span>
<span class="sd">    to that used by other SciPy statistical functions.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x, y : array_like</span>
<span class="sd">        Arrays of scores, of the same shape. If arrays are not 1-D, they will</span>
<span class="sd">        be flattened to 1-D.</span>
<span class="sd">    rank : array_like of ints or bool, optional</span>
<span class="sd">        A nonnegative rank assigned to each element. If it is None, the</span>
<span class="sd">        decreasing lexicographical rank by (`x`, `y`) will be used: elements of</span>
<span class="sd">        higher rank will be those with larger `x`-values, using `y`-values to</span>
<span class="sd">        break ties (in particular, swapping `x` and `y` will give a different</span>
<span class="sd">        result). If it is False, the element indices will be used</span>
<span class="sd">        directly as ranks. The default is True, in which case this</span>
<span class="sd">        function returns the average of the values obtained using the</span>
<span class="sd">        decreasing lexicographical rank by (`x`, `y`) and by (`y`, `x`).</span>
<span class="sd">    weigher : callable, optional</span>
<span class="sd">        The weigher function. Must map nonnegative integers (zero</span>
<span class="sd">        representing the most important element) to a nonnegative weight.</span>
<span class="sd">        The default, None, provides hyperbolic weighing, that is,</span>
<span class="sd">        rank :math:`r` is mapped to weight :math:`1/(r+1)`.</span>
<span class="sd">    additive : bool, optional</span>
<span class="sd">        If True, the weight of an exchange is computed by adding the</span>
<span class="sd">        weights of the ranks of the exchanged elements; otherwise, the weights</span>
<span class="sd">        are multiplied. The default is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res: SignificanceResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">           The weighted :math:`\tau` correlation index.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">           Presently ``np.nan``, as the null distribution of the statistic is</span>
<span class="sd">           unknown (even in the additive hyperbolic case).</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    kendalltau : Calculates Kendall&#39;s tau.</span>
<span class="sd">    spearmanr : Calculates a Spearman rank-order correlation coefficient.</span>
<span class="sd">    theilslopes : Computes the Theil-Sen estimator for a set of points (x, y).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function uses an :math:`O(n \log n)`, mergesort-based algorithm</span>
<span class="sd">    [1]_ that is a weighted extension of Knight&#39;s algorithm for Kendall&#39;s</span>
<span class="sd">    :math:`\tau` [2]_. It can compute Shieh&#39;s weighted :math:`\tau` [3]_</span>
<span class="sd">    between rankings without ties (i.e., permutations) by setting</span>
<span class="sd">    `additive` and `rank` to False, as the definition given in [1]_ is a</span>
<span class="sd">    generalization of Shieh&#39;s.</span>

<span class="sd">    NaNs are considered the smallest possible score.</span>

<span class="sd">    .. versionadded:: 0.19.0</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Sebastiano Vigna, &quot;A weighted correlation index for rankings with</span>
<span class="sd">           ties&quot;, Proceedings of the 24th international conference on World</span>
<span class="sd">           Wide Web, pp. 1166-1176, ACM, 2015.</span>
<span class="sd">    .. [2] W.R. Knight, &quot;A Computer Method for Calculating Kendall&#39;s Tau with</span>
<span class="sd">           Ungrouped Data&quot;, Journal of the American Statistical Association,</span>
<span class="sd">           Vol. 61, No. 314, Part 1, pp. 436-439, 1966.</span>
<span class="sd">    .. [3] Grace S. Shieh. &quot;A weighted Kendall&#39;s tau statistic&quot;, Statistics &amp;</span>
<span class="sd">           Probability Letters, Vol. 39, No. 1, pp. 17-24, 1998.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x = [12, 2, 1, 12, 2]</span>
<span class="sd">    &gt;&gt;&gt; y = [1, 4, 7, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; res = stats.weightedtau(x, y)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    -0.56694968153682723</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    nan</span>
<span class="sd">    &gt;&gt;&gt; res = stats.weightedtau(x, y, additive=False)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    -0.62205716951801038</span>

<span class="sd">    NaNs are considered the smallest possible score:</span>

<span class="sd">    &gt;&gt;&gt; x = [12, 2, 1, 12, 2]</span>
<span class="sd">    &gt;&gt;&gt; y = [1, 4, 7, 1, np.nan]</span>
<span class="sd">    &gt;&gt;&gt; res = stats.weightedtau(x, y)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    -0.56694968153682723</span>

<span class="sd">    This is exactly Kendall&#39;s tau:</span>

<span class="sd">    &gt;&gt;&gt; x = [12, 2, 1, 12, 2]</span>
<span class="sd">    &gt;&gt;&gt; y = [1, 4, 7, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; res = stats.weightedtau(x, y, weigher=lambda x: 1)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    -0.47140452079103173</span>

<span class="sd">    &gt;&gt;&gt; x = [12, 2, 1, 12, 2]</span>
<span class="sd">    &gt;&gt;&gt; y = [1, 4, 7, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; stats.weightedtau(x, y, rank=None)</span>
<span class="sd">    SignificanceResult(statistic=-0.4157652301037516, pvalue=nan)</span>
<span class="sd">    &gt;&gt;&gt; stats.weightedtau(y, x, rank=None)</span>
<span class="sd">    SignificanceResult(statistic=-0.7181341329699028, pvalue=nan)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;All inputs to `weightedtau` must be &quot;</span>
                         <span class="s2">&quot;of the same size, &quot;</span>
                         <span class="sa">f</span><span class="s2">&quot;found x-size </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2"> and y-size </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
        <span class="c1"># Return NaN if arrays are empty</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="c1"># If there are NaNs we apply _toint64()</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">_toint64</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">_toint64</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># Reduce to ranks unsupported types</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">_toint64</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">_toint64</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">_toint64</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">_toint64</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">_weightedrankedtau</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">weigher</span><span class="p">,</span> <span class="n">additive</span><span class="p">)</span> <span class="o">+</span>
            <span class="n">_weightedrankedtau</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">weigher</span><span class="p">,</span> <span class="n">additive</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">tau</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intp</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">rank</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;All inputs to `weightedtau` must be of the same size, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;found x-size </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2"> and rank-size </span><span class="si">{</span><span class="n">rank</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="n">tau</span> <span class="o">=</span> <span class="n">_weightedrankedtau</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">weigher</span><span class="p">,</span> <span class="n">additive</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
    <span class="n">res</span><span class="o">.</span><span class="n">correlation</span> <span class="o">=</span> <span class="n">tau</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="c1"># FROM MGCPY: https://github.com/neurodata/mgcpy</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_ParallelP</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper function to calculate parallel p-value.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_states</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_states</span> <span class="o">=</span> <span class="n">random_states</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_states</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">permy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">order</span><span class="p">][:,</span> <span class="n">order</span><span class="p">]</span>

        <span class="c1"># calculate permuted stats, store in null distribution</span>
        <span class="n">perm_stat</span> <span class="o">=</span> <span class="n">_mgc_stat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">permy</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">perm_stat</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_perm_test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">workers</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Helper function that calculates the p-value. See below for uses.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x, y : ndarray</span>
<span class="sd">        `x` and `y` have shapes `(n, p)` and `(n, q)`.</span>
<span class="sd">    stat : float</span>
<span class="sd">        The sample test statistic.</span>
<span class="sd">    reps : int, optional</span>
<span class="sd">        The number of replications used to estimate the null when using the</span>
<span class="sd">        permutation test. The default is 1000 replications.</span>
<span class="sd">    workers : int or map-like callable, optional</span>
<span class="sd">        If `workers` is an int the population is subdivided into `workers`</span>
<span class="sd">        sections and evaluated in parallel (uses</span>
<span class="sd">        `multiprocessing.Pool &lt;multiprocessing&gt;`). Supply `-1` to use all cores</span>
<span class="sd">        available to the Process. Alternatively supply a map-like callable,</span>
<span class="sd">        such as `multiprocessing.Pool.map` for evaluating the population in</span>
<span class="sd">        parallel. This evaluation is carried out as `workers(func, iterable)`.</span>
<span class="sd">        Requires that `func` be pickleable.</span>
<span class="sd">    random_state : {None, int, `numpy.random.Generator`,</span>
<span class="sd">                    `numpy.random.RandomState`}, optional</span>

<span class="sd">        If `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<span class="sd">        singleton is used.</span>
<span class="sd">        If `seed` is an int, a new ``RandomState`` instance is used,</span>
<span class="sd">        seeded with `seed`.</span>
<span class="sd">        If `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<span class="sd">        that instance is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pvalue : float</span>
<span class="sd">        The sample test p-value.</span>
<span class="sd">    null_dist : list</span>
<span class="sd">        The approximated null distribution.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># generate seeds for each rep (change to new parallel random number</span>
    <span class="c1"># capabilities in numpy &gt;= 1.17+)</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">random_states</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">rng_integers</span><span class="p">(</span><span class="n">random_state</span><span class="p">,</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">32</span><span class="p">,</span>
                     <span class="n">size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">)]</span>

    <span class="c1"># parallelizes with specified workers over number of reps and set seeds</span>
    <span class="n">parallelp</span> <span class="o">=</span> <span class="n">_ParallelP</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_states</span><span class="o">=</span><span class="n">random_states</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">MapWrapper</span><span class="p">(</span><span class="n">workers</span><span class="p">)</span> <span class="k">as</span> <span class="n">mapwrapper</span><span class="p">:</span>
        <span class="n">null_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">mapwrapper</span><span class="p">(</span><span class="n">parallelp</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">))))</span>

    <span class="c1"># calculate p-value and significant permutation map through list</span>
    <span class="n">pvalue</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">null_dist</span> <span class="o">&gt;=</span> <span class="n">stat</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">reps</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">null_dist</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_euclidean_dist</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>


<span class="n">MGCResult</span> <span class="o">=</span> <span class="n">_make_tuple_bunch</span><span class="p">(</span><span class="s1">&#39;MGCResult&#39;</span><span class="p">,</span>
                              <span class="p">[</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">,</span> <span class="s1">&#39;mgc_dict&#39;</span><span class="p">],</span> <span class="p">[])</span>


<span class="k">def</span><span class="w"> </span><span class="nf">multiscale_graphcorr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">compute_distance</span><span class="o">=</span><span class="n">_euclidean_dist</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                         <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">is_twosamp</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the Multiscale Graph Correlation (MGC) test statistic.</span>

<span class="sd">    Specifically, for each point, MGC finds the :math:`k`-nearest neighbors for</span>
<span class="sd">    one property (e.g. cloud density), and the :math:`l`-nearest neighbors for</span>
<span class="sd">    the other property (e.g. grass wetness) [1]_. This pair :math:`(k, l)` is</span>
<span class="sd">    called the &quot;scale&quot;. A priori, however, it is not know which scales will be</span>
<span class="sd">    most informative. So, MGC computes all distance pairs, and then efficiently</span>
<span class="sd">    computes the distance correlations for all scales. The local correlations</span>
<span class="sd">    illustrate which scales are relatively informative about the relationship.</span>
<span class="sd">    The key, therefore, to successfully discover and decipher relationships</span>
<span class="sd">    between disparate data modalities is to adaptively determine which scales</span>
<span class="sd">    are the most informative, and the geometric implication for the most</span>
<span class="sd">    informative scales. Doing so not only provides an estimate of whether the</span>
<span class="sd">    modalities are related, but also provides insight into how the</span>
<span class="sd">    determination was made. This is especially important in high-dimensional</span>
<span class="sd">    data, where simple visualizations do not reveal relationships to the</span>
<span class="sd">    unaided human eye. Characterizations of this implementation in particular</span>
<span class="sd">    have been derived from and benchmarked within in [2]_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x, y : ndarray</span>
<span class="sd">        If ``x`` and ``y`` have shapes ``(n, p)`` and ``(n, q)`` where `n` is</span>
<span class="sd">        the number of samples and `p` and `q` are the number of dimensions,</span>
<span class="sd">        then the MGC independence test will be run.  Alternatively, ``x`` and</span>
<span class="sd">        ``y`` can have shapes ``(n, n)`` if they are distance or similarity</span>
<span class="sd">        matrices, and ``compute_distance`` must be sent to ``None``. If ``x``</span>
<span class="sd">        and ``y`` have shapes ``(n, p)`` and ``(m, p)``, an unpaired</span>
<span class="sd">        two-sample MGC test will be run.</span>
<span class="sd">    compute_distance : callable, optional</span>
<span class="sd">        A function that computes the distance or similarity among the samples</span>
<span class="sd">        within each data matrix. Set to ``None`` if ``x`` and ``y`` are</span>
<span class="sd">        already distance matrices. The default uses the euclidean norm metric.</span>
<span class="sd">        If you are calling a custom function, either create the distance</span>
<span class="sd">        matrix before-hand or create a function of the form</span>
<span class="sd">        ``compute_distance(x)`` where `x` is the data matrix for which</span>
<span class="sd">        pairwise distances are calculated.</span>
<span class="sd">    reps : int, optional</span>
<span class="sd">        The number of replications used to estimate the null when using the</span>
<span class="sd">        permutation test. The default is ``1000``.</span>
<span class="sd">    workers : int or map-like callable, optional</span>
<span class="sd">        If ``workers`` is an int the population is subdivided into ``workers``</span>
<span class="sd">        sections and evaluated in parallel (uses ``multiprocessing.Pool</span>
<span class="sd">        &lt;multiprocessing&gt;``). Supply ``-1`` to use all cores available to the</span>
<span class="sd">        Process. Alternatively supply a map-like callable, such as</span>
<span class="sd">        ``multiprocessing.Pool.map`` for evaluating the p-value in parallel.</span>
<span class="sd">        This evaluation is carried out as ``workers(func, iterable)``.</span>
<span class="sd">        Requires that `func` be pickleable. The default is ``1``.</span>
<span class="sd">    is_twosamp : bool, optional</span>
<span class="sd">        If `True`, a two sample test will be run. If ``x`` and ``y`` have</span>
<span class="sd">        shapes ``(n, p)`` and ``(m, p)``, this optional will be overridden and</span>
<span class="sd">        set to ``True``. Set to ``True`` if ``x`` and ``y`` both have shapes</span>
<span class="sd">        ``(n, p)`` and a two sample test is desired. The default is ``False``.</span>
<span class="sd">        Note that this will not run if inputs are distance matrices.</span>
<span class="sd">    random_state : {None, int, `numpy.random.Generator`,</span>
<span class="sd">                    `numpy.random.RandomState`}, optional</span>

<span class="sd">        If `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<span class="sd">        singleton is used.</span>
<span class="sd">        If `seed` is an int, a new ``RandomState`` instance is used,</span>
<span class="sd">        seeded with `seed`.</span>
<span class="sd">        If `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<span class="sd">        that instance is used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res : MGCResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            The sample MGC test statistic within `[-1, 1]`.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            The p-value obtained via permutation.</span>
<span class="sd">        mgc_dict : dict</span>
<span class="sd">            Contains additional useful results:</span>

<span class="sd">                - mgc_map : ndarray</span>
<span class="sd">                    A 2D representation of the latent geometry of the</span>
<span class="sd">                    relationship.</span>
<span class="sd">                - opt_scale : (int, int)</span>
<span class="sd">                    The estimated optimal scale as a `(x, y)` pair.</span>
<span class="sd">                - null_dist : list</span>
<span class="sd">                    The null distribution derived from the permuted matrices.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    pearsonr : Pearson correlation coefficient and p-value for testing</span>
<span class="sd">               non-correlation.</span>
<span class="sd">    kendalltau : Calculates Kendall&#39;s tau.</span>
<span class="sd">    spearmanr : Calculates a Spearman rank-order correlation coefficient.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    A description of the process of MGC and applications on neuroscience data</span>
<span class="sd">    can be found in [1]_. It is performed using the following steps:</span>

<span class="sd">    #. Two distance matrices :math:`D^X` and :math:`D^Y` are computed and</span>
<span class="sd">       modified to be mean zero columnwise. This results in two</span>
<span class="sd">       :math:`n \times n` distance matrices :math:`A` and :math:`B` (the</span>
<span class="sd">       centering and unbiased modification) [3]_.</span>

<span class="sd">    #. For all values :math:`k` and :math:`l` from :math:`1, ..., n`,</span>

<span class="sd">       * The :math:`k`-nearest neighbor and :math:`l`-nearest neighbor graphs</span>
<span class="sd">         are calculated for each property. Here, :math:`G_k (i, j)` indicates</span>
<span class="sd">         the :math:`k`-smallest values of the :math:`i`-th row of :math:`A`</span>
<span class="sd">         and :math:`H_l (i, j)` indicates the :math:`l` smallested values of</span>
<span class="sd">         the :math:`i`-th row of :math:`B`</span>

<span class="sd">       * Let :math:`\circ` denotes the entry-wise matrix product, then local</span>
<span class="sd">         correlations are summed and normalized using the following statistic:</span>

<span class="sd">    .. math::</span>

<span class="sd">        c^{kl} = \frac{\sum_{ij} A G_k B H_l}</span>
<span class="sd">                      {\sqrt{\sum_{ij} A^2 G_k \times \sum_{ij} B^2 H_l}}</span>

<span class="sd">    #. The MGC test statistic is the smoothed optimal local correlation of</span>
<span class="sd">       :math:`\{ c^{kl} \}`. Denote the smoothing operation as :math:`R(\cdot)`</span>
<span class="sd">       (which essentially set all isolated large correlations) as 0 and</span>
<span class="sd">       connected large correlations the same as before, see [3]_.) MGC is,</span>

<span class="sd">    .. math::</span>

<span class="sd">        MGC_n (x, y) = \max_{(k, l)} R \left(c^{kl} \left( x_n, y_n \right)</span>
<span class="sd">                                                    \right)</span>

<span class="sd">    The test statistic returns a value between :math:`(-1, 1)` since it is</span>
<span class="sd">    normalized.</span>

<span class="sd">    The p-value returned is calculated using a permutation test. This process</span>
<span class="sd">    is completed by first randomly permuting :math:`y` to estimate the null</span>
<span class="sd">    distribution and then calculating the probability of observing a test</span>
<span class="sd">    statistic, under the null, at least as extreme as the observed test</span>
<span class="sd">    statistic.</span>

<span class="sd">    MGC requires at least 5 samples to run with reliable results. It can also</span>
<span class="sd">    handle high-dimensional data sets.</span>
<span class="sd">    In addition, by manipulating the input data matrices, the two-sample</span>
<span class="sd">    testing problem can be reduced to the independence testing problem [4]_.</span>
<span class="sd">    Given sample data :math:`U` and :math:`V` of sizes :math:`p \times n`</span>
<span class="sd">    :math:`p \times m`, data matrix :math:`X` and :math:`Y` can be created as</span>
<span class="sd">    follows:</span>

<span class="sd">    .. math::</span>

<span class="sd">        X = [U | V] \in \mathcal{R}^{p \times (n + m)}</span>
<span class="sd">        Y = [0_{1 \times n} | 1_{1 \times m}] \in \mathcal{R}^{(n + m)}</span>

<span class="sd">    Then, the MGC statistic can be calculated as normal. This methodology can</span>
<span class="sd">    be extended to similar tests such as distance correlation [4]_.</span>

<span class="sd">    .. versionadded:: 1.4.0</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Vogelstein, J. T., Bridgeford, E. W., Wang, Q., Priebe, C. E.,</span>
<span class="sd">           Maggioni, M., &amp; Shen, C. (2019). Discovering and deciphering</span>
<span class="sd">           relationships across disparate data modalities. ELife.</span>
<span class="sd">    .. [2] Panda, S., Palaniappan, S., Xiong, J., Swaminathan, A.,</span>
<span class="sd">           Ramachandran, S., Bridgeford, E. W., ... Vogelstein, J. T. (2019).</span>
<span class="sd">           mgcpy: A Comprehensive High Dimensional Independence Testing Python</span>
<span class="sd">           Package. :arXiv:`1907.02088`</span>
<span class="sd">    .. [3] Shen, C., Priebe, C.E., &amp; Vogelstein, J. T. (2019). From distance</span>
<span class="sd">           correlation to multiscale graph correlation. Journal of the American</span>
<span class="sd">           Statistical Association.</span>
<span class="sd">    .. [4] Shen, C. &amp; Vogelstein, J. T. (2018). The Exact Equivalence of</span>
<span class="sd">           Distance and Kernel Methods for Hypothesis Testing.</span>
<span class="sd">           :arXiv:`1806.05514`</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import multiscale_graphcorr</span>
<span class="sd">    &gt;&gt;&gt; x = np.arange(100)</span>
<span class="sd">    &gt;&gt;&gt; y = x</span>
<span class="sd">    &gt;&gt;&gt; res = multiscale_graphcorr(x, y)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic, res.pvalue</span>
<span class="sd">    (1.0, 0.001)</span>

<span class="sd">    To run an unpaired two-sample test,</span>

<span class="sd">    &gt;&gt;&gt; x = np.arange(100)</span>
<span class="sd">    &gt;&gt;&gt; y = np.arange(79)</span>
<span class="sd">    &gt;&gt;&gt; res = multiscale_graphcorr(x, y)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic, res.pvalue  # doctest: +SKIP</span>
<span class="sd">    (0.033258146255703246, 0.023)</span>

<span class="sd">    or, if shape of the inputs are the same,</span>

<span class="sd">    &gt;&gt;&gt; x = np.arange(100)</span>
<span class="sd">    &gt;&gt;&gt; y = x</span>
<span class="sd">    &gt;&gt;&gt; res = multiscale_graphcorr(x, y, is_twosamp=True)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic, res.pvalue  # doctest: +SKIP</span>
<span class="sd">    (-0.008021809890200488, 1.0)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;x and y must be ndarrays&quot;</span><span class="p">)</span>

    <span class="c1"># convert arrays of type (n,) to (n, 1)</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected a 2-D array `x`, found shape </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected a 2-D array `y`, found shape </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">nx</span><span class="p">,</span> <span class="n">px</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ny</span><span class="p">,</span> <span class="n">py</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># check for NaNs</span>
    <span class="n">_contains_nan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">)</span>
    <span class="n">_contains_nan</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">)</span>

    <span class="c1"># check for positive or negative infinity and raise error</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Inputs contain infinities&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">nx</span> <span class="o">!=</span> <span class="n">ny</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">px</span> <span class="o">==</span> <span class="n">py</span><span class="p">:</span>
            <span class="c1"># reshape x and y for two sample testing</span>
            <span class="n">is_twosamp</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Shape mismatch, x and y must have shape [n, p] &quot;</span>
                             <span class="s2">&quot;and [n, q] or have shape [n, p] and [m, p].&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">nx</span> <span class="o">&lt;</span> <span class="mi">5</span> <span class="ow">or</span> <span class="n">ny</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;MGC requires at least 5 samples to give reasonable &quot;</span>
                         <span class="s2">&quot;results.&quot;</span><span class="p">)</span>

    <span class="c1"># convert x and y to float</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="c1"># check if compute_distance_matrix if a callable()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">compute_distance</span><span class="p">)</span> <span class="ow">and</span> <span class="n">compute_distance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Compute_distance must be a function.&quot;</span><span class="p">)</span>

    <span class="c1"># check if number of reps exists, integer, or &gt; 0 (if under 1000 raises</span>
    <span class="c1"># warning)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reps</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">reps</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Number of reps must be an integer greater than 0.&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">reps</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;The number of replications is low (under 1000), and p-value &quot;</span>
               <span class="s2">&quot;calculations may be unreliable. Use the p-value result, with &quot;</span>
               <span class="s2">&quot;caution!&quot;</span><span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_twosamp</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">compute_distance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot run if inputs are distance matrices&quot;</span><span class="p">)</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">_two_sample_transform</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">compute_distance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># compute distance matrices for x and y</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">compute_distance</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">compute_distance</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># calculate MGC stat</span>
    <span class="n">stat</span><span class="p">,</span> <span class="n">stat_dict</span> <span class="o">=</span> <span class="n">_mgc_stat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">stat_mgc_map</span> <span class="o">=</span> <span class="n">stat_dict</span><span class="p">[</span><span class="s2">&quot;stat_mgc_map&quot;</span><span class="p">]</span>
    <span class="n">opt_scale</span> <span class="o">=</span> <span class="n">stat_dict</span><span class="p">[</span><span class="s2">&quot;opt_scale&quot;</span><span class="p">]</span>

    <span class="c1"># calculate permutation MGC p-value</span>
    <span class="n">pvalue</span><span class="p">,</span> <span class="n">null_dist</span> <span class="o">=</span> <span class="n">_perm_test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="n">reps</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>
                                   <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="c1"># save all stats (other than stat/p-value) in dictionary</span>
    <span class="n">mgc_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mgc_map&quot;</span><span class="p">:</span> <span class="n">stat_mgc_map</span><span class="p">,</span>
                <span class="s2">&quot;opt_scale&quot;</span><span class="p">:</span> <span class="n">opt_scale</span><span class="p">,</span>
                <span class="s2">&quot;null_dist&quot;</span><span class="p">:</span> <span class="n">null_dist</span><span class="p">}</span>

    <span class="c1"># create result object with alias for backward compatibility</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">MGCResult</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">mgc_dict</span><span class="p">)</span>
    <span class="n">res</span><span class="o">.</span><span class="n">stat</span> <span class="o">=</span> <span class="n">stat</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_mgc_stat</span><span class="p">(</span><span class="n">distx</span><span class="p">,</span> <span class="n">disty</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Helper function that calculates the MGC stat. See above for use.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    distx, disty : ndarray</span>
<span class="sd">        `distx` and `disty` have shapes `(n, p)` and `(n, q)` or</span>
<span class="sd">        `(n, n)` and `(n, n)`</span>
<span class="sd">        if distance matrices.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    stat : float</span>
<span class="sd">        The sample MGC test statistic within `[-1, 1]`.</span>
<span class="sd">    stat_dict : dict</span>
<span class="sd">        Contains additional useful additional returns containing the following</span>
<span class="sd">        keys:</span>

<span class="sd">            - stat_mgc_map : ndarray</span>
<span class="sd">                MGC-map of the statistics.</span>
<span class="sd">            - opt_scale : (float, float)</span>
<span class="sd">                The estimated optimal scale as a `(x, y)` pair.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># calculate MGC map and optimal scale</span>
    <span class="n">stat_mgc_map</span> <span class="o">=</span> <span class="n">_local_correlations</span><span class="p">(</span><span class="n">distx</span><span class="p">,</span> <span class="n">disty</span><span class="p">,</span> <span class="n">global_corr</span><span class="o">=</span><span class="s1">&#39;mgc&#39;</span><span class="p">)</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">stat_mgc_map</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">m</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># the global scale at is the statistic calculated at maximial nearest</span>
        <span class="c1"># neighbors. There is not enough local scale to search over, so</span>
        <span class="c1"># default to global scale</span>
        <span class="n">stat</span> <span class="o">=</span> <span class="n">stat_mgc_map</span><span class="p">[</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">opt_scale</span> <span class="o">=</span> <span class="n">m</span> <span class="o">*</span> <span class="n">n</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">samp_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">distx</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># threshold to find connected region of significant local correlations</span>
        <span class="n">sig_connect</span> <span class="o">=</span> <span class="n">_threshold_mgc_map</span><span class="p">(</span><span class="n">stat_mgc_map</span><span class="p">,</span> <span class="n">samp_size</span><span class="p">)</span>

        <span class="c1"># maximum within the significant region</span>
        <span class="n">stat</span><span class="p">,</span> <span class="n">opt_scale</span> <span class="o">=</span> <span class="n">_smooth_mgc_map</span><span class="p">(</span><span class="n">sig_connect</span><span class="p">,</span> <span class="n">stat_mgc_map</span><span class="p">)</span>

    <span class="n">stat_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;stat_mgc_map&quot;</span><span class="p">:</span> <span class="n">stat_mgc_map</span><span class="p">,</span>
                 <span class="s2">&quot;opt_scale&quot;</span><span class="p">:</span> <span class="n">opt_scale</span><span class="p">}</span>

    <span class="k">return</span> <span class="n">stat</span><span class="p">,</span> <span class="n">stat_dict</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_threshold_mgc_map</span><span class="p">(</span><span class="n">stat_mgc_map</span><span class="p">,</span> <span class="n">samp_size</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Finds a connected region of significance in the MGC-map by thresholding.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    stat_mgc_map : ndarray</span>
<span class="sd">        All local correlations within `[-1,1]`.</span>
<span class="sd">    samp_size : int</span>
<span class="sd">        The sample size of original data.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    sig_connect : ndarray</span>
<span class="sd">        A binary matrix with 1&#39;s indicating the significant region.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">stat_mgc_map</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># 0.02 is simply an empirical threshold, this can be set to 0.01 or 0.05</span>
    <span class="c1"># with varying levels of performance. Threshold is based on a beta</span>
    <span class="c1"># approximation.</span>
    <span class="n">per_sig</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.02</span> <span class="o">/</span> <span class="n">samp_size</span><span class="p">)</span>  <span class="c1"># Percentile to consider as significant</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">samp_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">samp_size</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span><span class="o">/</span><span class="mi">4</span> <span class="o">-</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span>  <span class="c1"># Beta approximation</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">per_sig</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># the global scale at is the statistic calculated at maximial nearest</span>
    <span class="c1"># neighbors. Threshold is the maximum on the global and local scales</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">stat_mgc_map</span><span class="p">[</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>

    <span class="c1"># find the largest connected component of significant correlations</span>
    <span class="n">sig_connect</span> <span class="o">=</span> <span class="n">stat_mgc_map</span> <span class="o">&gt;</span> <span class="n">threshold</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sig_connect</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">sig_connect</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_measurements</span><span class="o">.</span><span class="n">label</span><span class="p">(</span><span class="n">sig_connect</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">label_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">sig_connect</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># skip the first element in label_counts, as it is count(zeros)</span>
        <span class="n">max_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">label_counts</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">sig_connect</span> <span class="o">=</span> <span class="n">sig_connect</span> <span class="o">==</span> <span class="n">max_label</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">sig_connect</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="kc">False</span><span class="p">]])</span>

    <span class="k">return</span> <span class="n">sig_connect</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_smooth_mgc_map</span><span class="p">(</span><span class="n">sig_connect</span><span class="p">,</span> <span class="n">stat_mgc_map</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Finds the smoothed maximal within the significant region R.</span>

<span class="sd">    If area of R is too small it returns the last local correlation. Otherwise,</span>
<span class="sd">    returns the maximum within significant_connected_region.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sig_connect : ndarray</span>
<span class="sd">        A binary matrix with 1&#39;s indicating the significant region.</span>
<span class="sd">    stat_mgc_map : ndarray</span>
<span class="sd">        All local correlations within `[-1, 1]`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    stat : float</span>
<span class="sd">        The sample MGC statistic within `[-1, 1]`.</span>
<span class="sd">    opt_scale: (float, float)</span>
<span class="sd">        The estimated optimal scale as an `(x, y)` pair.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">stat_mgc_map</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># the global scale at is the statistic calculated at maximial nearest</span>
    <span class="c1"># neighbors. By default, statistic and optimal scale are global.</span>
    <span class="n">stat</span> <span class="o">=</span> <span class="n">stat_mgc_map</span><span class="p">[</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">opt_scale</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">sig_connect</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># proceed only when the connected region&#39;s area is sufficiently large</span>
        <span class="c1"># 0.02 is simply an empirical threshold, this can be set to 0.01 or 0.05</span>
        <span class="c1"># with varying levels of performance</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sig_connect</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="mf">0.02</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">max_corr</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">stat_mgc_map</span><span class="p">[</span><span class="n">sig_connect</span><span class="p">])</span>

            <span class="c1"># find all scales within significant_connected_region that maximize</span>
            <span class="c1"># the local correlation</span>
            <span class="n">max_corr_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">stat_mgc_map</span> <span class="o">&gt;=</span> <span class="n">max_corr</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">sig_connect</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">max_corr</span> <span class="o">&gt;=</span> <span class="n">stat</span><span class="p">:</span>
                <span class="n">stat</span> <span class="o">=</span> <span class="n">max_corr</span>

                <span class="n">k</span><span class="p">,</span> <span class="n">l</span> <span class="o">=</span> <span class="n">max_corr_index</span>
                <span class="n">one_d_indices</span> <span class="o">=</span> <span class="n">k</span> <span class="o">*</span> <span class="n">n</span> <span class="o">+</span> <span class="n">l</span>  <span class="c1"># 2D to 1D indexing</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">one_d_indices</span><span class="p">)</span> <span class="o">//</span> <span class="n">n</span>
                <span class="n">l</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">one_d_indices</span><span class="p">)</span> <span class="o">%</span> <span class="n">n</span>
                <span class="n">opt_scale</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># adding 1s to match R indexing</span>

    <span class="k">return</span> <span class="n">stat</span><span class="p">,</span> <span class="n">opt_scale</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_two_sample_transform</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper function that concatenates x and y for two sample MGC stat.</span>

<span class="sd">    See above for use.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    u, v : ndarray</span>
<span class="sd">        `u` and `v` have shapes `(n, p)` and `(m, p)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    x : ndarray</span>
<span class="sd">        Concatenate `u` and `v` along the `axis = 0`. `x` thus has shape</span>
<span class="sd">        `(2n, p)`.</span>
<span class="sd">    y : ndarray</span>
<span class="sd">        Label matrix for `x` where 0 refers to samples that comes from `u` and</span>
<span class="sd">        1 refers to samples that come from `v`. `y` thus has shape `(2n, 1)`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ny</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nx</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">ny</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>


<span class="c1">#####################################</span>
<span class="c1">#       INFERENTIAL STATISTICS      #</span>
<span class="c1">#####################################</span>

<span class="n">TtestResultBase</span> <span class="o">=</span> <span class="n">_make_tuple_bunch</span><span class="p">(</span><span class="s1">&#39;TtestResultBase&#39;</span><span class="p">,</span>
                                    <span class="p">[</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">])</span>


<span class="k">class</span><span class="w"> </span><span class="nc">TtestResult</span><span class="p">(</span><span class="n">TtestResultBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Result of a t-test.</span>

<span class="sd">    See the documentation of the particular t-test function for more</span>
<span class="sd">    information about the definition of the statistic and meaning of</span>
<span class="sd">    the confidence interval.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    statistic : float or array</span>
<span class="sd">        The t-statistic of the sample.</span>
<span class="sd">    pvalue : float or array</span>
<span class="sd">        The p-value associated with the given alternative.</span>
<span class="sd">    df : float or array</span>
<span class="sd">        The number of degrees of freedom used in calculation of the</span>
<span class="sd">        t-statistic; this is one less than the size of the sample</span>
<span class="sd">        (``a.shape[axis]-1`` if there are no masked elements or omitted NaNs).</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    confidence_interval</span>
<span class="sd">        Computes a confidence interval around the population statistic</span>
<span class="sd">        for the given confidence level.</span>
<span class="sd">        The confidence interval is returned in a ``namedtuple`` with</span>
<span class="sd">        fields `low` and `high`.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span>  <span class="c1"># public</span>
                 <span class="n">alternative</span><span class="p">,</span> <span class="n">standard_error</span><span class="p">,</span> <span class="n">estimate</span><span class="p">):</span>  <span class="c1"># private</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_alternative</span> <span class="o">=</span> <span class="n">alternative</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_standard_error</span> <span class="o">=</span> <span class="n">standard_error</span>  <span class="c1"># denominator of t-statistic</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_estimate</span> <span class="o">=</span> <span class="n">estimate</span>  <span class="c1"># point estimate of sample mean</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">confidence_interval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        confidence_level : float</span>
<span class="sd">            The confidence level for the calculation of the population mean</span>
<span class="sd">            confidence interval. Default is 0.95.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ci : namedtuple</span>
<span class="sd">            The confidence interval is returned in a ``namedtuple`` with</span>
<span class="sd">            fields `low` and `high`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="n">_t_confidence_interval</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span>
                                           <span class="n">confidence_level</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alternative</span><span class="p">)</span>
        <span class="n">low</span> <span class="o">=</span> <span class="n">low</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_standard_error</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimate</span>
        <span class="n">high</span> <span class="o">=</span> <span class="n">high</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_standard_error</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimate</span>
        <span class="k">return</span> <span class="n">ConfidenceInterval</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">pack_TtestResult</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">alternative</span><span class="p">,</span> <span class="n">standard_error</span><span class="p">,</span>
                     <span class="n">estimate</span><span class="p">):</span>
    <span class="c1"># this could be any number of dimensions (including 0d), but there is</span>
    <span class="c1"># at most one unique non-NaN value</span>
    <span class="n">alternative</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">alternative</span><span class="p">)</span>  <span class="c1"># can&#39;t index 0D object</span>
    <span class="n">alternative</span> <span class="o">=</span> <span class="n">alternative</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">alternative</span><span class="p">)]</span>
    <span class="n">alternative</span> <span class="o">=</span> <span class="n">alternative</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">alternative</span><span class="o">.</span><span class="n">size</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">return</span> <span class="n">TtestResult</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span>
                       <span class="n">standard_error</span><span class="o">=</span><span class="n">standard_error</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="n">estimate</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">unpack_TtestResult</span><span class="p">(</span><span class="n">res</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">df</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">_alternative</span><span class="p">,</span>
            <span class="n">res</span><span class="o">.</span><span class="n">_standard_error</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">_estimate</span><span class="p">)</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span><span class="n">pack_TtestResult</span><span class="p">,</span> <span class="n">default_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                          <span class="n">result_to_tuple</span><span class="o">=</span><span class="n">unpack_TtestResult</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ttest_1samp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">popmean</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span>
                <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;two-sided&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate the T-test for the mean of ONE group of scores.</span>

<span class="sd">    This is a test for the null hypothesis that the expected value</span>
<span class="sd">    (mean) of a sample of independent observations `a` is equal to the given</span>
<span class="sd">    population mean, `popmean`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Sample observation.</span>
<span class="sd">    popmean : float or array_like</span>
<span class="sd">        Expected value in null hypothesis. If array_like, then its length along</span>
<span class="sd">        `axis` must equal 1, and it must otherwise be broadcastable with `a`.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to compute test; default is 0. If None, compute over</span>
<span class="sd">        the whole array `a`.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis.</span>
<span class="sd">        The following options are available (default is &#39;two-sided&#39;):</span>

<span class="sd">        * &#39;two-sided&#39;: the mean of the underlying distribution of the sample</span>
<span class="sd">          is different than the given population mean (`popmean`)</span>
<span class="sd">        * &#39;less&#39;: the mean of the underlying distribution of the sample is</span>
<span class="sd">          less than the given population mean (`popmean`)</span>
<span class="sd">        * &#39;greater&#39;: the mean of the underlying distribution of the sample is</span>
<span class="sd">          greater than the given population mean (`popmean`)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : `~scipy.stats._result_classes.TtestResult`</span>
<span class="sd">        An object with the following attributes:</span>

<span class="sd">        statistic : float or array</span>
<span class="sd">            The t-statistic.</span>
<span class="sd">        pvalue : float or array</span>
<span class="sd">            The p-value associated with the given alternative.</span>
<span class="sd">        df : float or array</span>
<span class="sd">            The number of degrees of freedom used in calculation of the</span>
<span class="sd">            t-statistic; this is one less than the size of the sample</span>
<span class="sd">            (``a.shape[axis]``).</span>

<span class="sd">            .. versionadded:: 1.10.0</span>

<span class="sd">        The object also has the following method:</span>

<span class="sd">        confidence_interval(confidence_level=0.95)</span>
<span class="sd">            Computes a confidence interval around the population</span>
<span class="sd">            mean for the given confidence level.</span>
<span class="sd">            The confidence interval is returned in a ``namedtuple`` with</span>
<span class="sd">            fields `low` and `high`.</span>

<span class="sd">            .. versionadded:: 1.10.0</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The statistic is calculated as ``(np.mean(a) - popmean)/se``, where</span>
<span class="sd">    ``se`` is the standard error. Therefore, the statistic will be positive</span>
<span class="sd">    when the sample mean is greater than the population mean and negative when</span>
<span class="sd">    the sample mean is less than the population mean.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Suppose we wish to test the null hypothesis that the mean of a population</span>
<span class="sd">    is equal to 0.5. We choose a confidence level of 99%; that is, we will</span>
<span class="sd">    reject the null hypothesis in favor of the alternative if the p-value is</span>
<span class="sd">    less than 0.01.</span>

<span class="sd">    When testing random variates from the standard uniform distribution, which</span>
<span class="sd">    has a mean of 0.5, we expect the data to be consistent with the null</span>
<span class="sd">    hypothesis most of the time.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">    &gt;&gt;&gt; rvs = stats.uniform.rvs(size=50, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_1samp(rvs, popmean=0.5)</span>
<span class="sd">    TtestResult(statistic=2.456308468440, pvalue=0.017628209047638, df=49)</span>

<span class="sd">    As expected, the p-value of 0.017 is not below our threshold of 0.01, so</span>
<span class="sd">    we cannot reject the null hypothesis.</span>

<span class="sd">    When testing data from the standard *normal* distribution, which has a mean</span>
<span class="sd">    of 0, we would expect the null hypothesis to be rejected.</span>

<span class="sd">    &gt;&gt;&gt; rvs = stats.norm.rvs(size=50, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_1samp(rvs, popmean=0.5)</span>
<span class="sd">    TtestResult(statistic=-7.433605518875, pvalue=1.416760157221e-09, df=49)</span>

<span class="sd">    Indeed, the p-value is lower than our threshold of 0.01, so we reject the</span>
<span class="sd">    null hypothesis in favor of the default &quot;two-sided&quot; alternative: the mean</span>
<span class="sd">    of the population is *not* equal to 0.5.</span>

<span class="sd">    However, suppose we were to test the null hypothesis against the</span>
<span class="sd">    one-sided alternative that the mean of the population is *greater* than</span>
<span class="sd">    0.5. Since the mean of the standard normal is less than 0.5, we would not</span>
<span class="sd">    expect the null hypothesis to be rejected.</span>

<span class="sd">    &gt;&gt;&gt; stats.ttest_1samp(rvs, popmean=0.5, alternative=&#39;greater&#39;)</span>
<span class="sd">    TtestResult(statistic=-7.433605518875, pvalue=0.99999999929, df=49)</span>

<span class="sd">    Unsurprisingly, with a p-value greater than our threshold, we would not</span>
<span class="sd">    reject the null hypothesis.</span>

<span class="sd">    Note that when working with a confidence level of 99%, a true null</span>
<span class="sd">    hypothesis will be rejected approximately 1% of the time.</span>

<span class="sd">    &gt;&gt;&gt; rvs = stats.uniform.rvs(size=(100, 50), random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; res = stats.ttest_1samp(rvs, popmean=0.5, axis=1)</span>
<span class="sd">    &gt;&gt;&gt; np.sum(res.pvalue &lt; 0.01)</span>
<span class="sd">    1</span>

<span class="sd">    Indeed, even though all 100 samples above were drawn from the standard</span>
<span class="sd">    uniform distribution, which *does* have a population mean of 0.5, we would</span>
<span class="sd">    mistakenly reject the null hypothesis for one of them.</span>

<span class="sd">    `ttest_1samp` can also compute a confidence interval around the population</span>
<span class="sd">    mean.</span>

<span class="sd">    &gt;&gt;&gt; rvs = stats.norm.rvs(size=50, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; res = stats.ttest_1samp(rvs, popmean=0)</span>
<span class="sd">    &gt;&gt;&gt; ci = res.confidence_interval(confidence_level=0.95)</span>
<span class="sd">    &gt;&gt;&gt; ci</span>
<span class="sd">    ConfidenceInterval(low=-0.3193887540880017, high=0.2898583388980972)</span>

<span class="sd">    The bounds of the 95% confidence interval are the</span>
<span class="sd">    minimum and maximum values of the parameter `popmean` for which the</span>
<span class="sd">    p-value of the test would be 0.05.</span>

<span class="sd">    &gt;&gt;&gt; res = stats.ttest_1samp(rvs, popmean=ci.low)</span>
<span class="sd">    &gt;&gt;&gt; np.testing.assert_allclose(res.pvalue, 0.05)</span>
<span class="sd">    &gt;&gt;&gt; res = stats.ttest_1samp(rvs, popmean=ci.high)</span>
<span class="sd">    &gt;&gt;&gt; np.testing.assert_allclose(res.pvalue, 0.05)</span>

<span class="sd">    Under certain assumptions about the population from which a sample</span>
<span class="sd">    is drawn, the confidence interval with confidence level 95% is expected</span>
<span class="sd">    to contain the true population mean in 95% of sample replications.</span>

<span class="sd">    &gt;&gt;&gt; rvs = stats.norm.rvs(size=(50, 1000), loc=1, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; res = stats.ttest_1samp(rvs, popmean=0)</span>
<span class="sd">    &gt;&gt;&gt; ci = res.confidence_interval()</span>
<span class="sd">    &gt;&gt;&gt; contains_pop_mean = (ci.low &lt; 1) &amp; (ci.high &gt; 1)</span>
<span class="sd">    &gt;&gt;&gt; contains_pop_mean.sum()</span>
<span class="sd">    953</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">popmean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">popmean</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`popmean.shape[axis]` must equal 1.&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">-</span> <span class="n">popmean</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">_var</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">invalid</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">denom</span><span class="p">)</span>
    <span class="n">t</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">_ttest_finish</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>

    <span class="c1"># when nan_policy=&#39;omit&#39;, `df` can be different for different axis-slices</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)[()]</span>
    <span class="c1"># _axis_nan_policy decorator doesn&#39;t play well with strings</span>
    <span class="n">alternative_num</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;less&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;two-sided&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;greater&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}[</span><span class="n">alternative</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">TtestResult</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">alternative_num</span><span class="p">,</span>
                       <span class="n">standard_error</span><span class="o">=</span><span class="n">denom</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_t_confidence_interval</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">confidence_level</span><span class="p">,</span> <span class="n">alternative</span><span class="p">):</span>
    <span class="c1"># Input validation on `alternative` is already done</span>
    <span class="c1"># We just need IV on confidence_level</span>
    <span class="k">if</span> <span class="n">confidence_level</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">confidence_level</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;`confidence_level` must be a number between 0 and 1.&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">alternative</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># &#39;less&#39;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">confidence_level</span>
        <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_arrays</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">special</span><span class="o">.</span><span class="n">stdtrit</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># &#39;greater&#39;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">confidence_level</span>
        <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_arrays</span><span class="p">(</span><span class="n">special</span><span class="o">.</span><span class="n">stdtrit</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># &#39;two-sided&#39;</span>
        <span class="n">tail_probability</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">confidence_level</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">tail_probability</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">tail_probability</span>
        <span class="c1"># axis of p must be the zeroth and orthogonal to all the rest</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
        <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">stdtrit</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># alternative is NaN when input is empty (see _axis_nan_policy)</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">nans</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_arrays</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="n">nans</span><span class="p">,</span> <span class="n">nans</span>

    <span class="k">return</span> <span class="n">low</span><span class="p">[()],</span> <span class="n">high</span><span class="p">[()]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_ttest_finish</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alternative</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Common code between all 3 t-test functions.&quot;&quot;&quot;</span>
    <span class="c1"># We use ``stdtr`` directly here as it handles the case when ``nan``</span>
    <span class="c1"># values are present in the data and masked arrays are passed</span>
    <span class="c1"># while ``t.cdf`` emits runtime warnings. This way ``_ttest_finish``</span>
    <span class="c1"># can be shared between the ``stats`` and ``mstats`` versions.</span>

    <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;less&#39;</span><span class="p">:</span>
        <span class="n">pval</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">stdtr</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;greater&#39;</span><span class="p">:</span>
        <span class="n">pval</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">stdtr</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="o">-</span><span class="n">t</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;two-sided&#39;</span><span class="p">:</span>
        <span class="n">pval</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">stdtr</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t</span><span class="p">))</span><span class="o">*</span><span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;alternative must be &quot;</span>
                         <span class="s2">&quot;&#39;less&#39;, &#39;greater&#39; or &#39;two-sided&#39;&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[()]</span>
    <span class="k">if</span> <span class="n">pval</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">pval</span> <span class="o">=</span> <span class="n">pval</span><span class="p">[()]</span>

    <span class="k">return</span> <span class="n">t</span><span class="p">,</span> <span class="n">pval</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_ttest_ind_from_stats</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">denom</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">alternative</span><span class="p">):</span>

    <span class="n">d</span> <span class="o">=</span> <span class="n">mean1</span> <span class="o">-</span> <span class="n">mean2</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">invalid</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">denom</span><span class="p">)</span>
    <span class="n">t</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">_ttest_finish</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_unequal_var_ttest_denom</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="n">n2</span><span class="p">):</span>
    <span class="n">vn1</span> <span class="o">=</span> <span class="n">v1</span> <span class="o">/</span> <span class="n">n1</span>
    <span class="n">vn2</span> <span class="o">=</span> <span class="n">v2</span> <span class="o">/</span> <span class="n">n2</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">invalid</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="p">(</span><span class="n">vn1</span> <span class="o">+</span> <span class="n">vn2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">vn1</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">n1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">vn2</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">n2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># If df is undefined, variances are zero (assumes n1 &gt; 0 &amp; n2 &gt; 0).</span>
    <span class="c1"># Hence it doesn&#39;t matter what df is as long as it&#39;s not NaN.</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">df</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">vn1</span> <span class="o">+</span> <span class="n">vn2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">denom</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_equal_var_ttest_denom</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="n">n2</span><span class="p">):</span>
    <span class="c1"># If there is a single observation in one sample, this formula for pooled</span>
    <span class="c1"># variance breaks down because the variance of that sample is undefined.</span>
    <span class="c1"># The pooled variance is still defined, though, because the (n-1) in the</span>
    <span class="c1"># numerator should cancel with the (n-1) in the denominator, leaving only</span>
    <span class="c1"># the sum of squared differences from the mean: zero.</span>
    <span class="n">v1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">n1</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">v1</span><span class="p">)[()]</span>
    <span class="n">v2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">n2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">v2</span><span class="p">)[()]</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span> <span class="o">-</span> <span class="mf">2.0</span>
    <span class="n">svar</span> <span class="o">=</span> <span class="p">((</span><span class="n">n1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">v1</span> <span class="o">+</span> <span class="p">(</span><span class="n">n2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">v2</span><span class="p">)</span> <span class="o">/</span> <span class="n">df</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">svar</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">n1</span> <span class="o">+</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">n2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">denom</span>


<span class="n">Ttest_indResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Ttest_indResult&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">ttest_ind_from_stats</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">std1</span><span class="p">,</span> <span class="n">nobs1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">std2</span><span class="p">,</span> <span class="n">nobs2</span><span class="p">,</span>
                         <span class="n">equal_var</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;two-sided&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    T-test for means of two independent samples from descriptive statistics.</span>

<span class="sd">    This is a test for the null hypothesis that two independent</span>
<span class="sd">    samples have identical average (expected) values.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    mean1 : array_like</span>
<span class="sd">        The mean(s) of sample 1.</span>
<span class="sd">    std1 : array_like</span>
<span class="sd">        The corrected sample standard deviation of sample 1 (i.e. ``ddof=1``).</span>
<span class="sd">    nobs1 : array_like</span>
<span class="sd">        The number(s) of observations of sample 1.</span>
<span class="sd">    mean2 : array_like</span>
<span class="sd">        The mean(s) of sample 2.</span>
<span class="sd">    std2 : array_like</span>
<span class="sd">        The corrected sample standard deviation of sample 2 (i.e. ``ddof=1``).</span>
<span class="sd">    nobs2 : array_like</span>
<span class="sd">        The number(s) of observations of sample 2.</span>
<span class="sd">    equal_var : bool, optional</span>
<span class="sd">        If True (default), perform a standard independent 2 sample test</span>
<span class="sd">        that assumes equal population variances [1]_.</span>
<span class="sd">        If False, perform Welch&#39;s t-test, which does not assume equal</span>
<span class="sd">        population variance [2]_.</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis.</span>
<span class="sd">        The following options are available (default is &#39;two-sided&#39;):</span>

<span class="sd">        * &#39;two-sided&#39;: the means of the distributions are unequal.</span>
<span class="sd">        * &#39;less&#39;: the mean of the first distribution is less than the</span>
<span class="sd">          mean of the second distribution.</span>
<span class="sd">        * &#39;greater&#39;: the mean of the first distribution is greater than the</span>
<span class="sd">          mean of the second distribution.</span>

<span class="sd">        .. versionadded:: 1.6.0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float or array</span>
<span class="sd">        The calculated t-statistics.</span>
<span class="sd">    pvalue : float or array</span>
<span class="sd">        The two-tailed p-value.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    scipy.stats.ttest_ind</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The statistic is calculated as ``(mean1 - mean2)/se``, where ``se`` is the</span>
<span class="sd">    standard error. Therefore, the statistic will be positive when `mean1` is</span>
<span class="sd">    greater than `mean2` and negative when `mean1` is less than `mean2`.</span>

<span class="sd">    This method does not check whether any of the elements of `std1` or `std2`</span>
<span class="sd">    are negative. If any elements of the `std1` or `std2` parameters are</span>
<span class="sd">    negative in a call to this method, this method will return the same result</span>
<span class="sd">    as if it were passed ``numpy.abs(std1)`` and ``numpy.abs(std2)``,</span>
<span class="sd">    respectively, instead; no exceptions or warnings will be emitted.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test</span>

<span class="sd">    .. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Suppose we have the summary data for two samples, as follows (with the</span>
<span class="sd">    Sample Variance being the corrected sample variance)::</span>

<span class="sd">                         Sample   Sample</span>
<span class="sd">                   Size   Mean   Variance</span>
<span class="sd">        Sample 1    13    15.0     87.5</span>
<span class="sd">        Sample 2    11    12.0     39.0</span>

<span class="sd">    Apply the t-test to this data (with the assumption that the population</span>
<span class="sd">    variances are equal):</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import ttest_ind_from_stats</span>
<span class="sd">    &gt;&gt;&gt; ttest_ind_from_stats(mean1=15.0, std1=np.sqrt(87.5), nobs1=13,</span>
<span class="sd">    ...                      mean2=12.0, std2=np.sqrt(39.0), nobs2=11)</span>
<span class="sd">    Ttest_indResult(statistic=0.9051358093310269, pvalue=0.3751996797581487)</span>

<span class="sd">    For comparison, here is the data from which those summary statistics</span>
<span class="sd">    were taken.  With this data, we can compute the same result using</span>
<span class="sd">    `scipy.stats.ttest_ind`:</span>

<span class="sd">    &gt;&gt;&gt; a = np.array([1, 3, 4, 6, 11, 13, 15, 19, 22, 24, 25, 26, 26])</span>
<span class="sd">    &gt;&gt;&gt; b = np.array([2, 4, 6, 9, 11, 13, 14, 15, 18, 19, 21])</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import ttest_ind</span>
<span class="sd">    &gt;&gt;&gt; ttest_ind(a, b)</span>
<span class="sd">    Ttest_indResult(statistic=0.905135809331027, pvalue=0.3751996797581486)</span>

<span class="sd">    Suppose we instead have binary data and would like to apply a t-test to</span>
<span class="sd">    compare the proportion of 1s in two independent groups::</span>

<span class="sd">                          Number of    Sample     Sample</span>
<span class="sd">                    Size    ones        Mean     Variance</span>
<span class="sd">        Sample 1    150      30         0.2        0.161073</span>
<span class="sd">        Sample 2    200      45         0.225      0.175251</span>

<span class="sd">    The sample mean :math:`\hat{p}` is the proportion of ones in the sample</span>
<span class="sd">    and the variance for a binary observation is estimated by</span>
<span class="sd">    :math:`\hat{p}(1-\hat{p})`.</span>

<span class="sd">    &gt;&gt;&gt; ttest_ind_from_stats(mean1=0.2, std1=np.sqrt(0.161073), nobs1=150,</span>
<span class="sd">    ...                      mean2=0.225, std2=np.sqrt(0.175251), nobs2=200)</span>
<span class="sd">    Ttest_indResult(statistic=-0.5627187905196761, pvalue=0.5739887114209541)</span>

<span class="sd">    For comparison, we could compute the t statistic and p-value using</span>
<span class="sd">    arrays of 0s and 1s and `scipy.stat.ttest_ind`, as above.</span>

<span class="sd">    &gt;&gt;&gt; group1 = np.array([1]*30 + [0]*(150-30))</span>
<span class="sd">    &gt;&gt;&gt; group2 = np.array([1]*45 + [0]*(200-45))</span>
<span class="sd">    &gt;&gt;&gt; ttest_ind(group1, group2)</span>
<span class="sd">    Ttest_indResult(statistic=-0.5627179589855622, pvalue=0.573989277115258)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mean1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mean1</span><span class="p">)</span>
    <span class="n">std1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">std1</span><span class="p">)</span>
    <span class="n">mean2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mean2</span><span class="p">)</span>
    <span class="n">std2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">std2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">equal_var</span><span class="p">:</span>
        <span class="n">df</span><span class="p">,</span> <span class="n">denom</span> <span class="o">=</span> <span class="n">_equal_var_ttest_denom</span><span class="p">(</span><span class="n">std1</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">nobs1</span><span class="p">,</span> <span class="n">std2</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">nobs2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">df</span><span class="p">,</span> <span class="n">denom</span> <span class="o">=</span> <span class="n">_unequal_var_ttest_denom</span><span class="p">(</span><span class="n">std1</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">nobs1</span><span class="p">,</span>
                                             <span class="n">std2</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">nobs2</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">_ttest_ind_from_stats</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">denom</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Ttest_indResult</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="p">)</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span><span class="n">pack_TtestResult</span><span class="p">,</span> <span class="n">default_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                          <span class="n">result_to_tuple</span><span class="o">=</span><span class="n">unpack_TtestResult</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span>
              <span class="n">permutations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;two-sided&quot;</span><span class="p">,</span>
              <span class="n">trim</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the T-test for the means of *two independent* samples of scores.</span>

<span class="sd">    This is a test for the null hypothesis that 2 independent samples</span>
<span class="sd">    have identical average (expected) values. This test assumes that the</span>
<span class="sd">    populations have identical variances by default.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a, b : array_like</span>
<span class="sd">        The arrays must have the same shape, except in the dimension</span>
<span class="sd">        corresponding to `axis` (the first, by default).</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to compute test. If None, compute over the whole</span>
<span class="sd">        arrays, `a`, and `b`.</span>
<span class="sd">    equal_var : bool, optional</span>
<span class="sd">        If True (default), perform a standard independent 2 sample test</span>
<span class="sd">        that assumes equal population variances [1]_.</span>
<span class="sd">        If False, perform Welch&#39;s t-test, which does not assume equal</span>
<span class="sd">        population variance [2]_.</span>

<span class="sd">        .. versionadded:: 0.11.0</span>

<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">        The &#39;omit&#39; option is not currently available for permutation tests or</span>
<span class="sd">        one-sided asympyotic tests.</span>

<span class="sd">    permutations : non-negative int, np.inf, or None (default), optional</span>
<span class="sd">        If 0 or None (default), use the t-distribution to calculate p-values.</span>
<span class="sd">        Otherwise, `permutations` is  the number of random permutations that</span>
<span class="sd">        will be used to estimate p-values using a permutation test. If</span>
<span class="sd">        `permutations` equals or exceeds the number of distinct partitions of</span>
<span class="sd">        the pooled data, an exact test is performed instead (i.e. each</span>
<span class="sd">        distinct partition is used exactly once). See Notes for details.</span>

<span class="sd">        .. versionadded:: 1.7.0</span>

<span class="sd">    random_state : {None, int, `numpy.random.Generator`,</span>
<span class="sd">            `numpy.random.RandomState`}, optional</span>

<span class="sd">        If `seed` is None (or `np.random`), the `numpy.random.RandomState`</span>
<span class="sd">        singleton is used.</span>
<span class="sd">        If `seed` is an int, a new ``RandomState`` instance is used,</span>
<span class="sd">        seeded with `seed`.</span>
<span class="sd">        If `seed` is already a ``Generator`` or ``RandomState`` instance then</span>
<span class="sd">        that instance is used.</span>

<span class="sd">        Pseudorandom number generator state used to generate permutations</span>
<span class="sd">        (used only when `permutations` is not None).</span>

<span class="sd">        .. versionadded:: 1.7.0</span>

<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis.</span>
<span class="sd">        The following options are available (default is &#39;two-sided&#39;):</span>

<span class="sd">        * &#39;two-sided&#39;: the means of the distributions underlying the samples</span>
<span class="sd">          are unequal.</span>
<span class="sd">        * &#39;less&#39;: the mean of the distribution underlying the first sample</span>
<span class="sd">          is less than the mean of the distribution underlying the second</span>
<span class="sd">          sample.</span>
<span class="sd">        * &#39;greater&#39;: the mean of the distribution underlying the first</span>
<span class="sd">          sample is greater than the mean of the distribution underlying</span>
<span class="sd">          the second sample.</span>

<span class="sd">        .. versionadded:: 1.6.0</span>

<span class="sd">    trim : float, optional</span>
<span class="sd">        If nonzero, performs a trimmed (Yuen&#39;s) t-test.</span>
<span class="sd">        Defines the fraction of elements to be trimmed from each end of the</span>
<span class="sd">        input samples. If 0 (default), no elements will be trimmed from either</span>
<span class="sd">        side. The number of trimmed elements from each tail is the floor of the</span>
<span class="sd">        trim times the number of elements. Valid range is [0, .5).</span>

<span class="sd">        .. versionadded:: 1.7</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : `~scipy.stats._result_classes.TtestResult`</span>
<span class="sd">        An object with the following attributes:</span>

<span class="sd">        statistic : float or ndarray</span>
<span class="sd">            The t-statistic.</span>
<span class="sd">        pvalue : float or ndarray</span>
<span class="sd">            The p-value associated with the given alternative.</span>
<span class="sd">        df : float or ndarray</span>
<span class="sd">            The number of degrees of freedom used in calculation of the</span>
<span class="sd">            t-statistic. This is always NaN for a permutation t-test.</span>

<span class="sd">            .. versionadded:: 1.11.0</span>

<span class="sd">        The object also has the following method:</span>

<span class="sd">        confidence_interval(confidence_level=0.95)</span>
<span class="sd">            Computes a confidence interval around the difference in</span>
<span class="sd">            population means for the given confidence level.</span>
<span class="sd">            The confidence interval is returned in a ``namedtuple`` with</span>
<span class="sd">            fields ``low`` and ``high``.</span>
<span class="sd">            When a permutation t-test is performed, the confidence interval</span>
<span class="sd">            is not computed, and fields ``low`` and ``high`` contain NaN.</span>

<span class="sd">            .. versionadded:: 1.11.0</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Suppose we observe two independent samples, e.g. flower petal lengths, and</span>
<span class="sd">    we are considering whether the two samples were drawn from the same</span>
<span class="sd">    population (e.g. the same species of flower or two species with similar</span>
<span class="sd">    petal characteristics) or two different populations.</span>

<span class="sd">    The t-test quantifies the difference between the arithmetic means</span>
<span class="sd">    of the two samples. The p-value quantifies the probability of observing</span>
<span class="sd">    as or more extreme values assuming the null hypothesis, that the</span>
<span class="sd">    samples are drawn from populations with the same population means, is true.</span>
<span class="sd">    A p-value larger than a chosen threshold (e.g. 5% or 1%) indicates that</span>
<span class="sd">    our observation is not so unlikely to have occurred by chance. Therefore,</span>
<span class="sd">    we do not reject the null hypothesis of equal population means.</span>
<span class="sd">    If the p-value is smaller than our threshold, then we have evidence</span>
<span class="sd">    against the null hypothesis of equal population means.</span>

<span class="sd">    By default, the p-value is determined by comparing the t-statistic of the</span>
<span class="sd">    observed data against a theoretical t-distribution.</span>
<span class="sd">    When ``1 &lt; permutations &lt; binom(n, k)``, where</span>

<span class="sd">    * ``k`` is the number of observations in `a`,</span>
<span class="sd">    * ``n`` is the total number of observations in `a` and `b`, and</span>
<span class="sd">    * ``binom(n, k)`` is the binomial coefficient (``n`` choose ``k``),</span>

<span class="sd">    the data are pooled (concatenated), randomly assigned to either group `a`</span>
<span class="sd">    or `b`, and the t-statistic is calculated. This process is performed</span>
<span class="sd">    repeatedly (`permutation` times), generating a distribution of the</span>
<span class="sd">    t-statistic under the null hypothesis, and the t-statistic of the observed</span>
<span class="sd">    data is compared to this distribution to determine the p-value.</span>
<span class="sd">    Specifically, the p-value reported is the &quot;achieved significance level&quot;</span>
<span class="sd">    (ASL) as defined in 4.4 of [3]_. Note that there are other ways of</span>
<span class="sd">    estimating p-values using randomized permutation tests; for other</span>
<span class="sd">    options, see the more general `permutation_test`.</span>

<span class="sd">    When ``permutations &gt;= binom(n, k)``, an exact test is performed: the data</span>
<span class="sd">    are partitioned between the groups in each distinct way exactly once.</span>

<span class="sd">    The permutation test can be computationally expensive and not necessarily</span>
<span class="sd">    more accurate than the analytical test, but it does not make strong</span>
<span class="sd">    assumptions about the shape of the underlying distribution.</span>

<span class="sd">    Use of trimming is commonly referred to as the trimmed t-test. At times</span>
<span class="sd">    called Yuen&#39;s t-test, this is an extension of Welch&#39;s t-test, with the</span>
<span class="sd">    difference being the use of winsorized means in calculation of the variance</span>
<span class="sd">    and the trimmed sample size in calculation of the statistic. Trimming is</span>
<span class="sd">    recommended if the underlying distribution is long-tailed or contaminated</span>
<span class="sd">    with outliers [4]_.</span>

<span class="sd">    The statistic is calculated as ``(np.mean(a) - np.mean(b))/se``, where</span>
<span class="sd">    ``se`` is the standard error. Therefore, the statistic will be positive</span>
<span class="sd">    when the sample mean of `a` is greater than the sample mean of `b` and</span>
<span class="sd">    negative when the sample mean of `a` is less than the sample mean of</span>
<span class="sd">    `b`.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test</span>

<span class="sd">    .. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test</span>

<span class="sd">    .. [3] B. Efron and T. Hastie. Computer Age Statistical Inference. (2016).</span>

<span class="sd">    .. [4] Yuen, Karen K. &quot;The Two-Sample Trimmed t for Unequal Population</span>
<span class="sd">           Variances.&quot; Biometrika, vol. 61, no. 1, 1974, pp. 165-170. JSTOR,</span>
<span class="sd">           www.jstor.org/stable/2334299. Accessed 30 Mar. 2021.</span>

<span class="sd">    .. [5] Yuen, Karen K., and W. J. Dixon. &quot;The Approximate Behaviour and</span>
<span class="sd">           Performance of the Two-Sample Trimmed t.&quot; Biometrika, vol. 60,</span>
<span class="sd">           no. 2, 1973, pp. 369-374. JSTOR, www.jstor.org/stable/2334550.</span>
<span class="sd">           Accessed 30 Mar. 2021.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>

<span class="sd">    Test with sample with identical means:</span>

<span class="sd">    &gt;&gt;&gt; rvs1 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; rvs2 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_ind(rvs1, rvs2)</span>
<span class="sd">    Ttest_indResult(statistic=-0.4390847099199348, pvalue=0.6606952038870015)</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_ind(rvs1, rvs2, equal_var=False)</span>
<span class="sd">    Ttest_indResult(statistic=-0.4390847099199348, pvalue=0.6606952553131064)</span>

<span class="sd">    `ttest_ind` underestimates p for unequal variances:</span>

<span class="sd">    &gt;&gt;&gt; rvs3 = stats.norm.rvs(loc=5, scale=20, size=500, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_ind(rvs1, rvs3)</span>
<span class="sd">    Ttest_indResult(statistic=-1.6370984482905417, pvalue=0.1019251574705033)</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_ind(rvs1, rvs3, equal_var=False)</span>
<span class="sd">    Ttest_indResult(statistic=-1.637098448290542, pvalue=0.10202110497954867)</span>

<span class="sd">    When ``n1 != n2``, the equal variance t-statistic is no longer equal to the</span>
<span class="sd">    unequal variance t-statistic:</span>

<span class="sd">    &gt;&gt;&gt; rvs4 = stats.norm.rvs(loc=5, scale=20, size=100, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_ind(rvs1, rvs4)</span>
<span class="sd">    Ttest_indResult(statistic=-1.9481646859513422, pvalue=0.05186270935842703)</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_ind(rvs1, rvs4, equal_var=False)</span>
<span class="sd">    Ttest_indResult(statistic=-1.3146566100751664, pvalue=0.1913495266513811)</span>

<span class="sd">    T-test with different means, variance, and n:</span>

<span class="sd">    &gt;&gt;&gt; rvs5 = stats.norm.rvs(loc=8, scale=20, size=100, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_ind(rvs1, rvs5)</span>
<span class="sd">    Ttest_indResult(statistic=-2.8415950600298774, pvalue=0.0046418707568707885)</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_ind(rvs1, rvs5, equal_var=False)</span>
<span class="sd">    Ttest_indResult(statistic=-1.8686598649188084, pvalue=0.06434714193919686)</span>

<span class="sd">    When performing a permutation test, more permutations typically yields</span>
<span class="sd">    more accurate results. Use a ``np.random.Generator`` to ensure</span>
<span class="sd">    reproducibility:</span>

<span class="sd">    &gt;&gt;&gt; stats.ttest_ind(rvs1, rvs5, permutations=10000,</span>
<span class="sd">    ...                 random_state=rng)</span>
<span class="sd">    Ttest_indResult(statistic=-2.8415950600298774, pvalue=0.0052994700529947)</span>

<span class="sd">    Take these two samples, one of which has an extreme tail.</span>

<span class="sd">    &gt;&gt;&gt; a = (56, 128.6, 12, 123.8, 64.34, 78, 763.3)</span>
<span class="sd">    &gt;&gt;&gt; b = (1.1, 2.9, 4.2)</span>

<span class="sd">    Use the `trim` keyword to perform a trimmed (Yuen) t-test. For example,</span>
<span class="sd">    using 20% trimming, ``trim=.2``, the test will reduce the impact of one</span>
<span class="sd">    (``np.floor(trim*len(a))``) element from each tail of sample `a`. It will</span>
<span class="sd">    have no effect on sample `b` because ``np.floor(trim*len(b))`` is 0.</span>

<span class="sd">    &gt;&gt;&gt; stats.ttest_ind(a, b, trim=.2)</span>
<span class="sd">    Ttest_indResult(statistic=3.4463884028073513,</span>
<span class="sd">                    pvalue=0.01369338726499547)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">trim</span> <span class="o">&lt;</span> <span class="mf">.5</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Trimming percentage should be 0 &lt;= `trim` &lt; .5.&quot;</span><span class="p">)</span>

    <span class="n">NaN</span> <span class="o">=</span> <span class="n">_get_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">b</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># _axis_nan_policy decorator ensures this only happens with 1d input</span>
        <span class="k">return</span> <span class="n">TtestResult</span><span class="p">(</span><span class="n">NaN</span><span class="p">,</span> <span class="n">NaN</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">NaN</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">NaN</span><span class="p">,</span>
                           <span class="n">standard_error</span><span class="o">=</span><span class="n">NaN</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="n">NaN</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">permutations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">permutations</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">trim</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Permutations are currently not supported &quot;</span>
                             <span class="s2">&quot;with trimming.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">permutations</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">permutations</span><span class="p">)</span> <span class="ow">and</span>
                                <span class="nb">int</span><span class="p">(</span><span class="n">permutations</span><span class="p">)</span> <span class="o">!=</span> <span class="n">permutations</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Permutations must be a non-negative integer.&quot;</span><span class="p">)</span>

        <span class="n">t</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">_permutation_ttest</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">permutations</span><span class="o">=</span><span class="n">permutations</span><span class="p">,</span>
                                     <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="n">equal_var</span><span class="p">,</span>
                                     <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">,</span>
                                     <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                                     <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">)</span>
        <span class="n">df</span><span class="p">,</span> <span class="n">denom</span><span class="p">,</span> <span class="n">estimate</span> <span class="o">=</span> <span class="n">NaN</span><span class="p">,</span> <span class="n">NaN</span><span class="p">,</span> <span class="n">NaN</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">n1</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
        <span class="n">n2</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">trim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">equal_var</span><span class="p">:</span>
                <span class="n">old_errstate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">geterr</span><span class="p">()</span>
                <span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">invalid</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
            <span class="n">v1</span> <span class="o">=</span> <span class="n">_var</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">v2</span> <span class="o">=</span> <span class="n">_var</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">equal_var</span><span class="p">:</span>
                <span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="o">**</span><span class="n">old_errstate</span><span class="p">)</span>
            <span class="n">m1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
            <span class="n">m2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">v1</span><span class="p">,</span> <span class="n">m1</span><span class="p">,</span> <span class="n">n1</span> <span class="o">=</span> <span class="n">_ttest_trim_var_mean_len</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">trim</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
            <span class="n">v2</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">n2</span> <span class="o">=</span> <span class="n">_ttest_trim_var_mean_len</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">trim</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">equal_var</span><span class="p">:</span>
            <span class="n">df</span><span class="p">,</span> <span class="n">denom</span> <span class="o">=</span> <span class="n">_equal_var_ttest_denom</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">df</span><span class="p">,</span> <span class="n">denom</span> <span class="o">=</span> <span class="n">_unequal_var_ttest_denom</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span>
        <span class="n">t</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">_ttest_ind_from_stats</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">denom</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>

        <span class="c1"># when nan_policy=&#39;omit&#39;, `df` can be different for different axis-slices</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)[()]</span>
        <span class="n">estimate</span> <span class="o">=</span> <span class="n">m1</span><span class="o">-</span><span class="n">m2</span>

    <span class="c1"># _axis_nan_policy decorator doesn&#39;t play well with strings</span>
    <span class="n">alternative_num</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;less&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;two-sided&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;greater&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}[</span><span class="n">alternative</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">TtestResult</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">alternative_num</span><span class="p">,</span>
                       <span class="n">standard_error</span><span class="o">=</span><span class="n">denom</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="n">estimate</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_ttest_trim_var_mean_len</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">trim</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Variance, mean, and length of winsorized input along specified axis&quot;&quot;&quot;</span>
    <span class="c1"># for use with `ttest_ind` when trimming.</span>
    <span class="c1"># further calculations in this test assume that the inputs are sorted.</span>
    <span class="c1"># From [4] Section 1 &quot;Let x_1, ..., x_n be n ordered observations...&quot;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

    <span class="c1"># `g` is the number of elements to be replaced on each tail, converted</span>
    <span class="c1"># from a percentage amount of trimming</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">g</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">trim</span><span class="p">)</span>

    <span class="c1"># Calculate the Winsorized variance of the input samples according to</span>
    <span class="c1"># specified `g`</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">_calculate_winsorized_variance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="c1"># the total number of elements in the trimmed samples</span>
    <span class="n">n</span> <span class="o">-=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">g</span>

    <span class="c1"># calculate the g-times trimmed mean, as defined in [4] (1-1)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">trim_mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">trim</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">v</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_calculate_winsorized_variance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">axis</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculates g-times winsorized variance along specified axis&quot;&quot;&quot;</span>
    <span class="c1"># it is expected that the input `a` is sorted along the correct axis</span>
    <span class="k">if</span> <span class="n">g</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_var</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="c1"># move the intended axis to the end that way it is easier to manipulate</span>
    <span class="n">a_win</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># save where NaNs are for later use.</span>
    <span class="n">nans_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">a_win</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Winsorization and variance calculation are done in one step in [4]</span>
    <span class="c1"># (1-3), but here winsorization is done first; replace the left and</span>
    <span class="c1"># right sides with the repeating value. This can be see in effect in (</span>
    <span class="c1"># 1-3) in [4], where the leftmost and rightmost tails are replaced with</span>
    <span class="c1"># `(g + 1) * x_{g + 1}` on the left and `(g + 1) * x_{n - g}` on the</span>
    <span class="c1"># right. Zero-indexing turns `g + 1` to `g`, and `n - g` to `- g - 1` in</span>
    <span class="c1"># array indexing.</span>
    <span class="n">a_win</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">g</span><span class="p">]</span> <span class="o">=</span> <span class="n">a_win</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">[</span><span class="n">g</span><span class="p">]]</span>
    <span class="n">a_win</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">g</span><span class="p">:]</span> <span class="o">=</span> <span class="n">a_win</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="n">g</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span>

    <span class="c1"># Determine the variance. In [4], the degrees of freedom is expressed as</span>
    <span class="c1"># `h - 1`, where `h = n - 2g` (unnumbered equations in Section 1, end of</span>
    <span class="c1"># page 369, beginning of page 370). This is converted to NumPy&#39;s format,</span>
    <span class="c1"># `n - ddof` for use with `np.var`. The result is converted to an</span>
    <span class="c1"># array to accommodate indexing later.</span>
    <span class="n">var_win</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">_var</span><span class="p">(</span><span class="n">a_win</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">g</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>

    <span class="c1"># with `nan_policy=&#39;propagate&#39;`, NaNs may be completely trimmed out</span>
    <span class="c1"># because they were sorted into the tail of the array. In these cases,</span>
    <span class="c1"># replace computed variances with `np.nan`.</span>
    <span class="n">var_win</span><span class="p">[</span><span class="n">nans_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">return</span> <span class="n">var_win</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_permutation_distribution_t</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">permutations</span><span class="p">,</span> <span class="n">size_a</span><span class="p">,</span> <span class="n">equal_var</span><span class="p">,</span>
                                <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generation permutation distribution of t statistic&quot;&quot;&quot;</span>

    <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="c1"># prepare permutation indices</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># number of distinct combinations</span>
    <span class="n">n_max</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">comb</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">size_a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">permutations</span> <span class="o">&lt;</span> <span class="n">n_max</span><span class="p">:</span>
        <span class="n">perm_generator</span> <span class="o">=</span> <span class="p">(</span><span class="n">random_state</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
                          <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">permutations</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">permutations</span> <span class="o">=</span> <span class="n">n_max</span>
        <span class="n">perm_generator</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
                          <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">_all_partitions</span><span class="p">(</span><span class="n">size_a</span><span class="p">,</span> <span class="n">size</span><span class="o">-</span><span class="n">size_a</span><span class="p">))</span>

    <span class="n">t_stat</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">indices</span> <span class="ow">in</span> <span class="n">_batch_generator</span><span class="p">(</span><span class="n">perm_generator</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
        <span class="c1"># get one batch from perm_generator at a time as a list</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="c1"># generate permutations</span>
        <span class="n">data_perm</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">indices</span><span class="p">]</span>
        <span class="c1"># move axis indexing permutations to position 0 to broadcast</span>
        <span class="c1"># nicely with t_stat_observed, which doesn&#39;t have this dimension</span>
        <span class="n">data_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">data_perm</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="n">a</span> <span class="o">=</span> <span class="n">data_perm</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">size_a</span><span class="p">]</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">data_perm</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">size_a</span><span class="p">:]</span>
        <span class="n">t_stat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_calc_t_stat</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">equal_var</span><span class="p">))</span>

    <span class="n">t_stat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">t_stat</span><span class="p">,</span> <span class="n">permutations</span><span class="p">,</span> <span class="n">n_max</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_calc_t_stat</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">equal_var</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate the t statistic along the given dimension.&quot;&quot;&quot;</span>
    <span class="n">na</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">nb</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">avg_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">avg_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">var_a</span> <span class="o">=</span> <span class="n">_var</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">var_b</span> <span class="o">=</span> <span class="n">_var</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">equal_var</span><span class="p">:</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="n">_unequal_var_ttest_denom</span><span class="p">(</span><span class="n">var_a</span><span class="p">,</span> <span class="n">na</span><span class="p">,</span> <span class="n">var_b</span><span class="p">,</span> <span class="n">nb</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="n">_equal_var_ttest_denom</span><span class="p">(</span><span class="n">var_a</span><span class="p">,</span> <span class="n">na</span><span class="p">,</span> <span class="n">var_b</span><span class="p">,</span> <span class="n">nb</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">avg_a</span><span class="o">-</span><span class="n">avg_b</span><span class="p">)</span><span class="o">/</span><span class="n">denom</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_permutation_ttest</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">permutations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;two-sided&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the T-test for the means of TWO INDEPENDENT samples of scores</span>
<span class="sd">    using permutation methods.</span>

<span class="sd">    This test is similar to `stats.ttest_ind`, except it doesn&#39;t rely on an</span>
<span class="sd">    approximate normality assumption since it uses a permutation test.</span>
<span class="sd">    This function is only called from ttest_ind when permutations is not None.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a, b : array_like</span>
<span class="sd">        The arrays must be broadcastable, except along the dimension</span>
<span class="sd">        corresponding to `axis` (the zeroth, by default).</span>
<span class="sd">    axis : int, optional</span>
<span class="sd">        The axis over which to operate on a and b.</span>
<span class="sd">    permutations : int, optional</span>
<span class="sd">        Number of permutations used to calculate p-value. If greater than or</span>
<span class="sd">        equal to the number of distinct permutations, perform an exact test.</span>
<span class="sd">    equal_var : bool, optional</span>
<span class="sd">        If False, an equal variance (Welch&#39;s) t-test is conducted.  Otherwise,</span>
<span class="sd">        an ordinary t-test is conducted.</span>
<span class="sd">    random_state : {None, int, `numpy.random.Generator`}, optional</span>
<span class="sd">        If `seed` is None the `numpy.random.Generator` singleton is used.</span>
<span class="sd">        If `seed` is an int, a new ``Generator`` instance is used,</span>
<span class="sd">        seeded with `seed`.</span>
<span class="sd">        If `seed` is already a ``Generator`` instance then that instance is</span>
<span class="sd">        used.</span>
<span class="sd">        Pseudorandom number generator state used for generating random</span>
<span class="sd">        permutations.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float or array</span>
<span class="sd">        The calculated t-statistic.</span>
<span class="sd">    pvalue : float or array</span>
<span class="sd">        The p-value.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="n">t_stat_observed</span> <span class="o">=</span> <span class="n">_calc_t_stat</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">equal_var</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

    <span class="n">na</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">mat</span> <span class="o">=</span> <span class="n">_broadcast_concatenate</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">t_stat</span><span class="p">,</span> <span class="n">permutations</span><span class="p">,</span> <span class="n">n_max</span> <span class="o">=</span> <span class="n">_permutation_distribution_t</span><span class="p">(</span>
        <span class="n">mat</span><span class="p">,</span> <span class="n">permutations</span><span class="p">,</span> <span class="n">size_a</span><span class="o">=</span><span class="n">na</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="n">equal_var</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="n">compare</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;less&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">less_equal</span><span class="p">,</span>
               <span class="s2">&quot;greater&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">,</span>
               <span class="s2">&quot;two-sided&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">|</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">))}</span>

    <span class="c1"># Calculate the p-values</span>
    <span class="n">cmps</span> <span class="o">=</span> <span class="n">compare</span><span class="p">[</span><span class="n">alternative</span><span class="p">](</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">t_stat_observed</span><span class="p">)</span>
    <span class="c1"># Randomized test p-value calculation should use biased estimate; see e.g.</span>
    <span class="c1"># https://www.degruyter.com/document/doi/10.2202/1544-6115.1585/</span>
    <span class="n">adjustment</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">n_max</span> <span class="o">&gt;</span> <span class="n">permutations</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">pvalues</span> <span class="o">=</span> <span class="p">(</span><span class="n">cmps</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">adjustment</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">permutations</span> <span class="o">+</span> <span class="n">adjustment</span><span class="p">)</span>

    <span class="c1"># nans propagate naturally in statistic calculation, but need to be</span>
    <span class="c1"># propagated manually into pvalues</span>
    <span class="k">if</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;propagate&#39;</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">t_stat_observed</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">pvalues</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pvalues</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pvalues</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">t_stat_observed</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">t_stat_observed</span><span class="p">,</span> <span class="n">pvalues</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_get_len</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">msg</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">AxisError</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">msg</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="kc">None</span>
    <span class="k">return</span> <span class="n">n</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span><span class="n">pack_TtestResult</span><span class="p">,</span> <span class="n">default_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                          <span class="n">result_to_tuple</span><span class="o">=</span><span class="n">unpack_TtestResult</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                          <span class="n">paired</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ttest_rel</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;two-sided&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate the t-test on TWO RELATED samples of scores, a and b.</span>

<span class="sd">    This is a test for the null hypothesis that two related or</span>
<span class="sd">    repeated samples have identical average (expected) values.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a, b : array_like</span>
<span class="sd">        The arrays must have the same shape.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to compute test. If None, compute over the whole</span>
<span class="sd">        arrays, `a`, and `b`.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis.</span>
<span class="sd">        The following options are available (default is &#39;two-sided&#39;):</span>

<span class="sd">        * &#39;two-sided&#39;: the means of the distributions underlying the samples</span>
<span class="sd">          are unequal.</span>
<span class="sd">        * &#39;less&#39;: the mean of the distribution underlying the first sample</span>
<span class="sd">          is less than the mean of the distribution underlying the second</span>
<span class="sd">          sample.</span>
<span class="sd">        * &#39;greater&#39;: the mean of the distribution underlying the first</span>
<span class="sd">          sample is greater than the mean of the distribution underlying</span>
<span class="sd">          the second sample.</span>

<span class="sd">        .. versionadded:: 1.6.0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : `~scipy.stats._result_classes.TtestResult`</span>
<span class="sd">        An object with the following attributes:</span>

<span class="sd">        statistic : float or array</span>
<span class="sd">            The t-statistic.</span>
<span class="sd">        pvalue : float or array</span>
<span class="sd">            The p-value associated with the given alternative.</span>
<span class="sd">        df : float or array</span>
<span class="sd">            The number of degrees of freedom used in calculation of the</span>
<span class="sd">            t-statistic; this is one less than the size of the sample</span>
<span class="sd">            (``a.shape[axis]``).</span>

<span class="sd">            .. versionadded:: 1.10.0</span>

<span class="sd">        The object also has the following method:</span>

<span class="sd">        confidence_interval(confidence_level=0.95)</span>
<span class="sd">            Computes a confidence interval around the difference in</span>
<span class="sd">            population means for the given confidence level.</span>
<span class="sd">            The confidence interval is returned in a ``namedtuple`` with</span>
<span class="sd">            fields `low` and `high`.</span>

<span class="sd">            .. versionadded:: 1.10.0</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Examples for use are scores of the same set of student in</span>
<span class="sd">    different exams, or repeated sampling from the same units. The</span>
<span class="sd">    test measures whether the average score differs significantly</span>
<span class="sd">    across samples (e.g. exams). If we observe a large p-value, for</span>
<span class="sd">    example greater than 0.05 or 0.1 then we cannot reject the null</span>
<span class="sd">    hypothesis of identical average scores. If the p-value is smaller</span>
<span class="sd">    than the threshold, e.g. 1%, 5% or 10%, then we reject the null</span>
<span class="sd">    hypothesis of equal averages. Small p-values are associated with</span>
<span class="sd">    large t-statistics.</span>

<span class="sd">    The t-statistic is calculated as ``np.mean(a - b)/se``, where ``se`` is the</span>
<span class="sd">    standard error. Therefore, the t-statistic will be positive when the sample</span>
<span class="sd">    mean of ``a - b`` is greater than zero and negative when the sample mean of</span>
<span class="sd">    ``a - b`` is less than zero.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    https://en.wikipedia.org/wiki/T-test#Dependent_t-test_for_paired_samples</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>

<span class="sd">    &gt;&gt;&gt; rvs1 = stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; rvs2 = (stats.norm.rvs(loc=5, scale=10, size=500, random_state=rng)</span>
<span class="sd">    ...         + stats.norm.rvs(scale=0.2, size=500, random_state=rng))</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_rel(rvs1, rvs2)</span>
<span class="sd">    TtestResult(statistic=-0.4549717054410304, pvalue=0.6493274702088672, df=499)</span>
<span class="sd">    &gt;&gt;&gt; rvs3 = (stats.norm.rvs(loc=8, scale=10, size=500, random_state=rng)</span>
<span class="sd">    ...         + stats.norm.rvs(scale=0.2, size=500, random_state=rng))</span>
<span class="sd">    &gt;&gt;&gt; stats.ttest_rel(rvs1, rvs3)</span>
<span class="sd">    TtestResult(statistic=-5.879467544540889, pvalue=7.540777129099917e-09, df=499)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk2_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>

    <span class="n">na</span> <span class="o">=</span> <span class="n">_get_len</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;first argument&quot;</span><span class="p">)</span>
    <span class="n">nb</span> <span class="o">=</span> <span class="n">_get_len</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;second argument&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">na</span> <span class="o">!=</span> <span class="n">nb</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;unequal length arrays&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">na</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">nb</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># _axis_nan_policy decorator ensures this only happens with 1d input</span>
        <span class="n">NaN</span> <span class="o">=</span> <span class="n">_get_nan</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">TtestResult</span><span class="p">(</span><span class="n">NaN</span><span class="p">,</span> <span class="n">NaN</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">NaN</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">NaN</span><span class="p">,</span>
                           <span class="n">standard_error</span><span class="o">=</span><span class="n">NaN</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="n">NaN</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">_var</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">dm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">invalid</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">dm</span><span class="p">,</span> <span class="n">denom</span><span class="p">)</span>
    <span class="n">t</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">_ttest_finish</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>

    <span class="c1"># when nan_policy=&#39;omit&#39;, `df` can be different for different axis-slices</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)[()]</span>

    <span class="c1"># _axis_nan_policy decorator doesn&#39;t play well with strings</span>
    <span class="n">alternative_num</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;less&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;two-sided&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;greater&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}[</span><span class="n">alternative</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">TtestResult</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">alternative_num</span><span class="p">,</span>
                       <span class="n">standard_error</span><span class="o">=</span><span class="n">denom</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>


<span class="c1"># Map from names to lambda_ values used in power_divergence().</span>
<span class="n">_power_div_lambda_names</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;pearson&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;log-likelihood&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;freeman-tukey&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="s2">&quot;mod-log-likelihood&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;neyman&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span>
    <span class="s2">&quot;cressie-read&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_count</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Count the number of non-masked elements of an array.</span>

<span class="sd">    This function behaves like `np.ma.count`, but is much faster</span>
<span class="sd">    for ndarrays.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">):</span>
        <span class="n">num</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># In some cases, the `count` method returns a scalar array (e.g.</span>
            <span class="c1"># np.array(3)), but we want a plain integer.</span>
            <span class="n">num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">num</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_m_broadcast_to</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">isMaskedArray</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">masked_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">shape</span><span class="p">),</span>
                                  <span class="n">mask</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">subok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="n">Power_divergenceResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Power_divergenceResult&#39;</span><span class="p">,</span>
                                    <span class="p">(</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">power_divergence</span><span class="p">(</span><span class="n">f_obs</span><span class="p">,</span> <span class="n">f_exp</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cressie-Read power divergence statistic and goodness of fit test.</span>

<span class="sd">    This function tests the null hypothesis that the categorical data</span>
<span class="sd">    has the given frequencies, using the Cressie-Read power divergence</span>
<span class="sd">    statistic.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f_obs : array_like</span>
<span class="sd">        Observed frequencies in each category.</span>
<span class="sd">    f_exp : array_like, optional</span>
<span class="sd">        Expected frequencies in each category.  By default the categories are</span>
<span class="sd">        assumed to be equally likely.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        &quot;Delta degrees of freedom&quot;: adjustment to the degrees of freedom</span>
<span class="sd">        for the p-value.  The p-value is computed using a chi-squared</span>
<span class="sd">        distribution with ``k - 1 - ddof`` degrees of freedom, where `k`</span>
<span class="sd">        is the number of observed frequencies.  The default value of `ddof`</span>
<span class="sd">        is 0.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        The axis of the broadcast result of `f_obs` and `f_exp` along which to</span>
<span class="sd">        apply the test.  If axis is None, all values in `f_obs` are treated</span>
<span class="sd">        as a single data set.  Default is 0.</span>
<span class="sd">    lambda_ : float or str, optional</span>
<span class="sd">        The power in the Cressie-Read power divergence statistic.  The default</span>
<span class="sd">        is 1.  For convenience, `lambda_` may be assigned one of the following</span>
<span class="sd">        strings, in which case the corresponding numerical value is used:</span>

<span class="sd">        * ``&quot;pearson&quot;`` (value 1)</span>
<span class="sd">            Pearson&#39;s chi-squared statistic. In this case, the function is</span>
<span class="sd">            equivalent to `chisquare`.</span>
<span class="sd">        * ``&quot;log-likelihood&quot;`` (value 0)</span>
<span class="sd">            Log-likelihood ratio. Also known as the G-test [3]_.</span>
<span class="sd">        * ``&quot;freeman-tukey&quot;`` (value -1/2)</span>
<span class="sd">            Freeman-Tukey statistic.</span>
<span class="sd">        * ``&quot;mod-log-likelihood&quot;`` (value -1)</span>
<span class="sd">            Modified log-likelihood ratio.</span>
<span class="sd">        * ``&quot;neyman&quot;`` (value -2)</span>
<span class="sd">            Neyman&#39;s statistic.</span>
<span class="sd">        * ``&quot;cressie-read&quot;`` (value 2/3)</span>
<span class="sd">            The power recommended in [5]_.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res: Power_divergenceResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float or ndarray</span>
<span class="sd">            The Cressie-Read power divergence test statistic.  The value is</span>
<span class="sd">            a float if `axis` is None or if` `f_obs` and `f_exp` are 1-D.</span>
<span class="sd">        pvalue : float or ndarray</span>
<span class="sd">            The p-value of the test.  The value is a float if `ddof` and the</span>
<span class="sd">            return value `stat` are scalars.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    chisquare</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This test is invalid when the observed or expected frequencies in each</span>
<span class="sd">    category are too small.  A typical rule is that all of the observed</span>
<span class="sd">    and expected frequencies should be at least 5.</span>

<span class="sd">    Also, the sum of the observed and expected frequencies must be the same</span>
<span class="sd">    for the test to be valid; `power_divergence` raises an error if the sums</span>
<span class="sd">    do not agree within a relative tolerance of ``1e-8``.</span>

<span class="sd">    When `lambda_` is less than zero, the formula for the statistic involves</span>
<span class="sd">    dividing by `f_obs`, so a warning or error may be generated if any value</span>
<span class="sd">    in `f_obs` is 0.</span>

<span class="sd">    Similarly, a warning or error may be generated if any value in `f_exp` is</span>
<span class="sd">    zero when `lambda_` &gt;= 0.</span>

<span class="sd">    The default degrees of freedom, k-1, are for the case when no parameters</span>
<span class="sd">    of the distribution are estimated. If p parameters are estimated by</span>
<span class="sd">    efficient maximum likelihood then the correct degrees of freedom are</span>
<span class="sd">    k-1-p. If the parameters are estimated in a different way, then the</span>
<span class="sd">    dof can be between k-1-p and k-1. However, it is also possible that</span>
<span class="sd">    the asymptotic distribution is not a chisquare, in which case this</span>
<span class="sd">    test is not appropriate.</span>

<span class="sd">    This function handles masked arrays.  If an element of `f_obs` or `f_exp`</span>
<span class="sd">    is masked, then data at that position is ignored, and does not count</span>
<span class="sd">    towards the size of the data set.</span>

<span class="sd">    .. versionadded:: 0.13.0</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Lowry, Richard.  &quot;Concepts and Applications of Inferential</span>
<span class="sd">           Statistics&quot;. Chapter 8.</span>
<span class="sd">           https://web.archive.org/web/20171015035606/http://faculty.vassar.edu/lowry/ch8pt1.html</span>
<span class="sd">    .. [2] &quot;Chi-squared test&quot;, https://en.wikipedia.org/wiki/Chi-squared_test</span>
<span class="sd">    .. [3] &quot;G-test&quot;, https://en.wikipedia.org/wiki/G-test</span>
<span class="sd">    .. [4] Sokal, R. R. and Rohlf, F. J. &quot;Biometry: the principles and</span>
<span class="sd">           practice of statistics in biological research&quot;, New York: Freeman</span>
<span class="sd">           (1981)</span>
<span class="sd">    .. [5] Cressie, N. and Read, T. R. C., &quot;Multinomial Goodness-of-Fit</span>
<span class="sd">           Tests&quot;, J. Royal Stat. Soc. Series B, Vol. 46, No. 3 (1984),</span>
<span class="sd">           pp. 440-464.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    (See `chisquare` for more examples.)</span>

<span class="sd">    When just `f_obs` is given, it is assumed that the expected frequencies</span>
<span class="sd">    are uniform and given by the mean of the observed frequencies.  Here we</span>
<span class="sd">    perform a G-test (i.e. use the log-likelihood ratio statistic):</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import power_divergence</span>
<span class="sd">    &gt;&gt;&gt; power_divergence([16, 18, 16, 14, 12, 12], lambda_=&#39;log-likelihood&#39;)</span>
<span class="sd">    (2.006573162632538, 0.84823476779463769)</span>

<span class="sd">    The expected frequencies can be given with the `f_exp` argument:</span>

<span class="sd">    &gt;&gt;&gt; power_divergence([16, 18, 16, 14, 12, 12],</span>
<span class="sd">    ...                  f_exp=[16, 16, 16, 16, 16, 8],</span>
<span class="sd">    ...                  lambda_=&#39;log-likelihood&#39;)</span>
<span class="sd">    (3.3281031458963746, 0.6495419288047497)</span>

<span class="sd">    When `f_obs` is 2-D, by default the test is applied to each column.</span>

<span class="sd">    &gt;&gt;&gt; obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T</span>
<span class="sd">    &gt;&gt;&gt; obs.shape</span>
<span class="sd">    (6, 2)</span>
<span class="sd">    &gt;&gt;&gt; power_divergence(obs, lambda_=&quot;log-likelihood&quot;)</span>
<span class="sd">    (array([ 2.00657316,  6.77634498]), array([ 0.84823477,  0.23781225]))</span>

<span class="sd">    By setting ``axis=None``, the test is applied to all data in the array,</span>
<span class="sd">    which is equivalent to applying the test to the flattened array.</span>

<span class="sd">    &gt;&gt;&gt; power_divergence(obs, axis=None)</span>
<span class="sd">    (23.31034482758621, 0.015975692534127565)</span>
<span class="sd">    &gt;&gt;&gt; power_divergence(obs.ravel())</span>
<span class="sd">    (23.31034482758621, 0.015975692534127565)</span>

<span class="sd">    `ddof` is the change to make to the default degrees of freedom.</span>

<span class="sd">    &gt;&gt;&gt; power_divergence([16, 18, 16, 14, 12, 12], ddof=1)</span>
<span class="sd">    (2.0, 0.73575888234288467)</span>

<span class="sd">    The calculation of the p-values is done by broadcasting the</span>
<span class="sd">    test statistic with `ddof`.</span>

<span class="sd">    &gt;&gt;&gt; power_divergence([16, 18, 16, 14, 12, 12], ddof=[0,1,2])</span>
<span class="sd">    (2.0, array([ 0.84914504,  0.73575888,  0.5724067 ]))</span>

<span class="sd">    `f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has</span>
<span class="sd">    shape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting</span>
<span class="sd">    `f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared</span>
<span class="sd">    statistics, we must use ``axis=1``:</span>

<span class="sd">    &gt;&gt;&gt; power_divergence([16, 18, 16, 14, 12, 12],</span>
<span class="sd">    ...                  f_exp=[[16, 16, 16, 16, 16, 8],</span>
<span class="sd">    ...                         [8, 20, 20, 16, 12, 12]],</span>
<span class="sd">    ...                  axis=1)</span>
<span class="sd">    (array([ 3.5 ,  9.25]), array([ 0.62338763,  0.09949846]))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Convert the input argument `lambda_` to a numerical value.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lambda_</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">lambda_</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_power_div_lambda_names</span><span class="p">:</span>
            <span class="n">names</span> <span class="o">=</span> <span class="nb">repr</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">_power_div_lambda_names</span><span class="o">.</span><span class="n">keys</span><span class="p">()))[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;invalid string for lambda_: </span><span class="si">{</span><span class="n">lambda_</span><span class="si">!r}</span><span class="s2">. &quot;</span>
                             <span class="sa">f</span><span class="s2">&quot;Valid strings are </span><span class="si">{</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">lambda_</span> <span class="o">=</span> <span class="n">_power_div_lambda_names</span><span class="p">[</span><span class="n">lambda_</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">lambda_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lambda_</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">f_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">f_obs</span><span class="p">)</span>
    <span class="n">f_obs_float</span> <span class="o">=</span> <span class="n">f_obs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">f_exp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">f_exp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">f_exp</span><span class="p">)</span>
        <span class="n">bshape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span><span class="n">f_obs_float</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">f_exp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">f_obs_float</span> <span class="o">=</span> <span class="n">_m_broadcast_to</span><span class="p">(</span><span class="n">f_obs_float</span><span class="p">,</span> <span class="n">bshape</span><span class="p">)</span>
        <span class="n">f_exp</span> <span class="o">=</span> <span class="n">_m_broadcast_to</span><span class="p">(</span><span class="n">f_exp</span><span class="p">,</span> <span class="n">bshape</span><span class="p">)</span>
        <span class="n">rtol</span> <span class="o">=</span> <span class="mf">1e-8</span>  <span class="c1"># to pass existing tests</span>
        <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">invalid</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
            <span class="n">f_obs_sum</span> <span class="o">=</span> <span class="n">f_obs_float</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
            <span class="n">f_exp_sum</span> <span class="o">=</span> <span class="n">f_exp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
            <span class="n">relative_diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">f_obs_sum</span> <span class="o">-</span> <span class="n">f_exp_sum</span><span class="p">)</span> <span class="o">/</span>
                             <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">f_obs_sum</span><span class="p">,</span> <span class="n">f_exp_sum</span><span class="p">))</span>
            <span class="n">diff_gt_tol</span> <span class="o">=</span> <span class="p">(</span><span class="n">relative_diff</span> <span class="o">&gt;</span> <span class="n">rtol</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">diff_gt_tol</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;For each axis slice, the sum of the observed &quot;</span>
                   <span class="sa">f</span><span class="s2">&quot;frequencies must agree with the sum of the &quot;</span>
                   <span class="sa">f</span><span class="s2">&quot;expected frequencies to a relative tolerance &quot;</span>
                   <span class="sa">f</span><span class="s2">&quot;of </span><span class="si">{</span><span class="n">rtol</span><span class="si">}</span><span class="s2">, but the percent differences are:</span><span class="se">\n</span><span class="s2">&quot;</span>
                   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">relative_diff</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Ignore &#39;invalid&#39; errors so the edge case of a data set with length 0</span>
        <span class="c1"># is handled without spurious warnings.</span>
        <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">invalid</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">):</span>
            <span class="n">f_exp</span> <span class="o">=</span> <span class="n">f_obs</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># `terms` is the array of terms that are summed along `axis` to create</span>
    <span class="c1"># the test statistic.  We use some specialized code for a few special</span>
    <span class="c1"># cases of lambda_.</span>
    <span class="k">if</span> <span class="n">lambda_</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Pearson&#39;s chi-squared statistic</span>
        <span class="n">terms</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_obs_float</span> <span class="o">-</span> <span class="n">f_exp</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">f_exp</span>
    <span class="k">elif</span> <span class="n">lambda_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Log-likelihood ratio (i.e. G-test)</span>
        <span class="n">terms</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">f_obs</span><span class="p">,</span> <span class="n">f_obs</span> <span class="o">/</span> <span class="n">f_exp</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">lambda_</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Modified log-likelihood ratio</span>
        <span class="n">terms</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">f_exp</span><span class="p">,</span> <span class="n">f_exp</span> <span class="o">/</span> <span class="n">f_obs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># General Cressie-Read power divergence.</span>
        <span class="n">terms</span> <span class="o">=</span> <span class="n">f_obs</span> <span class="o">*</span> <span class="p">((</span><span class="n">f_obs</span> <span class="o">/</span> <span class="n">f_exp</span><span class="p">)</span><span class="o">**</span><span class="n">lambda_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">terms</span> <span class="o">/=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="p">(</span><span class="n">lambda_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">stat</span> <span class="o">=</span> <span class="n">terms</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

    <span class="n">num_obs</span> <span class="o">=</span> <span class="n">_count</span><span class="p">(</span><span class="n">terms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">ddof</span> <span class="o">=</span> <span class="n">asarray</span><span class="p">(</span><span class="n">ddof</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span> <span class="n">num_obs</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ddof</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Power_divergenceResult</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">chisquare</span><span class="p">(</span><span class="n">f_obs</span><span class="p">,</span> <span class="n">f_exp</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate a one-way chi-square test.</span>

<span class="sd">    The chi-square test tests the null hypothesis that the categorical data</span>
<span class="sd">    has the given frequencies.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    f_obs : array_like</span>
<span class="sd">        Observed frequencies in each category.</span>
<span class="sd">    f_exp : array_like, optional</span>
<span class="sd">        Expected frequencies in each category.  By default the categories are</span>
<span class="sd">        assumed to be equally likely.</span>
<span class="sd">    ddof : int, optional</span>
<span class="sd">        &quot;Delta degrees of freedom&quot;: adjustment to the degrees of freedom</span>
<span class="sd">        for the p-value.  The p-value is computed using a chi-squared</span>
<span class="sd">        distribution with ``k - 1 - ddof`` degrees of freedom, where `k`</span>
<span class="sd">        is the number of observed frequencies.  The default value of `ddof`</span>
<span class="sd">        is 0.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        The axis of the broadcast result of `f_obs` and `f_exp` along which to</span>
<span class="sd">        apply the test.  If axis is None, all values in `f_obs` are treated</span>
<span class="sd">        as a single data set.  Default is 0.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res: Power_divergenceResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float or ndarray</span>
<span class="sd">            The chi-squared test statistic.  The value is a float if `axis` is</span>
<span class="sd">            None or `f_obs` and `f_exp` are 1-D.</span>
<span class="sd">        pvalue : float or ndarray</span>
<span class="sd">            The p-value of the test.  The value is a float if `ddof` and the</span>
<span class="sd">            result attribute `statistic` are scalars.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    scipy.stats.power_divergence</span>
<span class="sd">    scipy.stats.fisher_exact : Fisher exact test on a 2x2 contingency table.</span>
<span class="sd">    scipy.stats.barnard_exact : An unconditional exact test. An alternative</span>
<span class="sd">        to chi-squared test for small sample sizes.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This test is invalid when the observed or expected frequencies in each</span>
<span class="sd">    category are too small.  A typical rule is that all of the observed</span>
<span class="sd">    and expected frequencies should be at least 5. According to [3]_, the</span>
<span class="sd">    total number of samples is recommended to be greater than 13,</span>
<span class="sd">    otherwise exact tests (such as Barnard&#39;s Exact test) should be used</span>
<span class="sd">    because they do not overreject.</span>

<span class="sd">    Also, the sum of the observed and expected frequencies must be the same</span>
<span class="sd">    for the test to be valid; `chisquare` raises an error if the sums do not</span>
<span class="sd">    agree within a relative tolerance of ``1e-8``.</span>

<span class="sd">    The default degrees of freedom, k-1, are for the case when no parameters</span>
<span class="sd">    of the distribution are estimated. If p parameters are estimated by</span>
<span class="sd">    efficient maximum likelihood then the correct degrees of freedom are</span>
<span class="sd">    k-1-p. If the parameters are estimated in a different way, then the</span>
<span class="sd">    dof can be between k-1-p and k-1. However, it is also possible that</span>
<span class="sd">    the asymptotic distribution is not chi-square, in which case this test</span>
<span class="sd">    is not appropriate.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Lowry, Richard.  &quot;Concepts and Applications of Inferential</span>
<span class="sd">           Statistics&quot;. Chapter 8.</span>
<span class="sd">           https://web.archive.org/web/20171022032306/http://vassarstats.net:80/textbook/ch8pt1.html</span>
<span class="sd">    .. [2] &quot;Chi-squared test&quot;, https://en.wikipedia.org/wiki/Chi-squared_test</span>
<span class="sd">    .. [3] Pearson, Karl. &quot;On the criterion that a given system of deviations from the probable</span>
<span class="sd">           in the case of a correlated system of variables is such that it can be reasonably</span>
<span class="sd">           supposed to have arisen from random sampling&quot;, Philosophical Magazine. Series 5. 50</span>
<span class="sd">           (1900), pp. 157-175.</span>
<span class="sd">    .. [4] Mannan, R. William and E. Charles. Meslow. &quot;Bird populations and</span>
<span class="sd">           vegetation characteristics in managed and old-growth forests,</span>
<span class="sd">           northeastern Oregon.&quot; Journal of Wildlife Management</span>
<span class="sd">           48, 1219-1238, :doi:`10.2307/3801783`, 1984.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    In [4]_, bird foraging behavior was investigated in an old-growth forest</span>
<span class="sd">    of Oregon.</span>
<span class="sd">    In the forest, 44% of the canopy volume was Douglas fir,</span>
<span class="sd">    24% was ponderosa pine, 29% was grand fir, and 3% was western larch.</span>
<span class="sd">    The authors observed the behavior of several species of birds, one of</span>
<span class="sd">    which was the red-breasted nuthatch. They made 189 observations of this</span>
<span class="sd">    species foraging, recording 43 (&quot;23%&quot;) of observations in Douglas fir,</span>
<span class="sd">    52 (&quot;28%&quot;) in ponderosa pine, 54 (&quot;29%&quot;) in grand fir, and 40 (&quot;21%&quot;) in</span>
<span class="sd">    western larch.</span>

<span class="sd">    Using a chi-square test, we can test the null hypothesis that the</span>
<span class="sd">    proportions of foraging events are equal to the proportions of canopy</span>
<span class="sd">    volume. The authors of the paper considered a p-value less than 1% to be</span>
<span class="sd">    significant.</span>

<span class="sd">    Using the above proportions of canopy volume and observed events, we can</span>
<span class="sd">    infer expected frequencies.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; f_exp = np.array([44, 24, 29, 3]) / 100 * 189</span>

<span class="sd">    The observed frequencies of foraging were:</span>

<span class="sd">    &gt;&gt;&gt; f_obs = np.array([43, 52, 54, 40])</span>

<span class="sd">    We can now compare the observed frequencies with the expected frequencies.</span>

<span class="sd">    &gt;&gt;&gt; from scipy.stats import chisquare</span>
<span class="sd">    &gt;&gt;&gt; chisquare(f_obs=f_obs, f_exp=f_exp)</span>
<span class="sd">    Power_divergenceResult(statistic=228.23515947653874, pvalue=3.3295585338846486e-49)</span>

<span class="sd">    The p-value is well below the chosen significance level. Hence, the</span>
<span class="sd">    authors considered the difference to be significant and concluded</span>
<span class="sd">    that the relative proportions of foraging events were not the same</span>
<span class="sd">    as the relative proportions of tree canopy volume.</span>

<span class="sd">    Following are other generic examples to demonstrate how the other</span>
<span class="sd">    parameters can be used.</span>

<span class="sd">    When just `f_obs` is given, it is assumed that the expected frequencies</span>
<span class="sd">    are uniform and given by the mean of the observed frequencies.</span>

<span class="sd">    &gt;&gt;&gt; chisquare([16, 18, 16, 14, 12, 12])</span>
<span class="sd">    Power_divergenceResult(statistic=2.0, pvalue=0.84914503608460956)</span>

<span class="sd">    With `f_exp` the expected frequencies can be given.</span>

<span class="sd">    &gt;&gt;&gt; chisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8])</span>
<span class="sd">    Power_divergenceResult(statistic=3.5, pvalue=0.62338762774958223)</span>

<span class="sd">    When `f_obs` is 2-D, by default the test is applied to each column.</span>

<span class="sd">    &gt;&gt;&gt; obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T</span>
<span class="sd">    &gt;&gt;&gt; obs.shape</span>
<span class="sd">    (6, 2)</span>
<span class="sd">    &gt;&gt;&gt; chisquare(obs)</span>
<span class="sd">    Power_divergenceResult(statistic=array([2.        , 6.66666667]), pvalue=array([0.84914504, 0.24663415]))</span>

<span class="sd">    By setting ``axis=None``, the test is applied to all data in the array,</span>
<span class="sd">    which is equivalent to applying the test to the flattened array.</span>

<span class="sd">    &gt;&gt;&gt; chisquare(obs, axis=None)</span>
<span class="sd">    Power_divergenceResult(statistic=23.31034482758621, pvalue=0.015975692534127565)</span>
<span class="sd">    &gt;&gt;&gt; chisquare(obs.ravel())</span>
<span class="sd">    Power_divergenceResult(statistic=23.310344827586206, pvalue=0.01597569253412758)</span>

<span class="sd">    `ddof` is the change to make to the default degrees of freedom.</span>

<span class="sd">    &gt;&gt;&gt; chisquare([16, 18, 16, 14, 12, 12], ddof=1)</span>
<span class="sd">    Power_divergenceResult(statistic=2.0, pvalue=0.7357588823428847)</span>

<span class="sd">    The calculation of the p-values is done by broadcasting the</span>
<span class="sd">    chi-squared statistic with `ddof`.</span>

<span class="sd">    &gt;&gt;&gt; chisquare([16, 18, 16, 14, 12, 12], ddof=[0,1,2])</span>
<span class="sd">    Power_divergenceResult(statistic=2.0, pvalue=array([0.84914504, 0.73575888, 0.5724067 ]))</span>

<span class="sd">    `f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has</span>
<span class="sd">    shape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting</span>
<span class="sd">    `f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared</span>
<span class="sd">    statistics, we use ``axis=1``:</span>

<span class="sd">    &gt;&gt;&gt; chisquare([16, 18, 16, 14, 12, 12],</span>
<span class="sd">    ...           f_exp=[[16, 16, 16, 16, 16, 8], [8, 20, 20, 16, 12, 12]],</span>
<span class="sd">    ...           axis=1)</span>
<span class="sd">    Power_divergenceResult(statistic=array([3.5 , 9.25]), pvalue=array([0.62338763, 0.09949846]))</span>

<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
    <span class="k">return</span> <span class="n">power_divergence</span><span class="p">(</span><span class="n">f_obs</span><span class="p">,</span> <span class="n">f_exp</span><span class="o">=</span><span class="n">f_exp</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                            <span class="n">lambda_</span><span class="o">=</span><span class="s2">&quot;pearson&quot;</span><span class="p">)</span>


<span class="n">KstestResult</span> <span class="o">=</span> <span class="n">_make_tuple_bunch</span><span class="p">(</span><span class="s1">&#39;KstestResult&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">],</span>
                                 <span class="p">[</span><span class="s1">&#39;statistic_location&#39;</span><span class="p">,</span> <span class="s1">&#39;statistic_sign&#39;</span><span class="p">])</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_compute_dplus</span><span class="p">(</span><span class="n">cdfvals</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes D+ as used in the Kolmogorov-Smirnov test.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cdfvals : array_like</span>
<span class="sd">        Sorted array of CDF values between 0 and 1</span>
<span class="sd">    x: array_like</span>
<span class="sd">        Sorted array of the stochastic variable itself</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res: Pair with the following elements:</span>
<span class="sd">        - The maximum distance of the CDF values below Uniform(0, 1).</span>
<span class="sd">        - The location at which the maximum is reached.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cdfvals</span><span class="p">)</span>
    <span class="n">dplus</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span> <span class="o">-</span> <span class="n">cdfvals</span><span class="p">)</span>
    <span class="n">amax</span> <span class="o">=</span> <span class="n">dplus</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
    <span class="n">loc_max</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">amax</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">dplus</span><span class="p">[</span><span class="n">amax</span><span class="p">],</span> <span class="n">loc_max</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_compute_dminus</span><span class="p">(</span><span class="n">cdfvals</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes D- as used in the Kolmogorov-Smirnov test.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cdfvals : array_like</span>
<span class="sd">        Sorted array of CDF values between 0 and 1</span>
<span class="sd">    x: array_like</span>
<span class="sd">        Sorted array of the stochastic variable itself</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res: Pair with the following elements:</span>
<span class="sd">        - Maximum distance of the CDF values above Uniform(0, 1)</span>
<span class="sd">        - The location at which the maximum is reached.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cdfvals</span><span class="p">)</span>
    <span class="n">dminus</span> <span class="o">=</span> <span class="p">(</span><span class="n">cdfvals</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">)</span>
    <span class="n">amax</span> <span class="o">=</span> <span class="n">dminus</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
    <span class="n">loc_max</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">amax</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">dminus</span><span class="p">[</span><span class="n">amax</span><span class="p">],</span> <span class="n">loc_max</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_tuple_to_KstestResult</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span>
                           <span class="n">statistic_location</span><span class="p">,</span> <span class="n">statistic_sign</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">KstestResult</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span>
                        <span class="n">statistic_location</span><span class="o">=</span><span class="n">statistic_location</span><span class="p">,</span>
                        <span class="n">statistic_sign</span><span class="o">=</span><span class="n">statistic_sign</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_KstestResult_to_tuple</span><span class="p">(</span><span class="n">res</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">*</span><span class="n">res</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">statistic_location</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">statistic_sign</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span><span class="n">_tuple_to_KstestResult</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                          <span class="n">result_to_tuple</span><span class="o">=</span><span class="n">_KstestResult_to_tuple</span><span class="p">)</span>
<span class="nd">@_rename_parameter</span><span class="p">(</span><span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="s2">&quot;method&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ks_1samp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">cdf</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(),</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs the one-sample Kolmogorov-Smirnov test for goodness of fit.</span>

<span class="sd">    This test compares the underlying distribution F(x) of a sample</span>
<span class="sd">    against a given continuous distribution G(x). See Notes for a description</span>
<span class="sd">    of the available null and alternative hypotheses.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : array_like</span>
<span class="sd">        a 1-D array of observations of iid random variables.</span>
<span class="sd">    cdf : callable</span>
<span class="sd">        callable used to calculate the cdf.</span>
<span class="sd">    args : tuple, sequence, optional</span>
<span class="sd">        Distribution parameters, used with `cdf`.</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the null and alternative hypotheses. Default is &#39;two-sided&#39;.</span>
<span class="sd">        Please see explanations in the Notes below.</span>
<span class="sd">    method : {&#39;auto&#39;, &#39;exact&#39;, &#39;approx&#39;, &#39;asymp&#39;}, optional</span>
<span class="sd">        Defines the distribution used for calculating the p-value.</span>
<span class="sd">        The following options are available (default is &#39;auto&#39;):</span>

<span class="sd">          * &#39;auto&#39; : selects one of the other options.</span>
<span class="sd">          * &#39;exact&#39; : uses the exact distribution of test statistic.</span>
<span class="sd">          * &#39;approx&#39; : approximates the two-sided probability with twice</span>
<span class="sd">            the one-sided probability</span>
<span class="sd">          * &#39;asymp&#39;: uses asymptotic distribution of test statistic</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res: KstestResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            KS test statistic, either D+, D-, or D (the maximum of the two)</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            One-tailed or two-tailed p-value.</span>
<span class="sd">        statistic_location : float</span>
<span class="sd">            Value of `x` corresponding with the KS statistic; i.e., the</span>
<span class="sd">            distance between the empirical distribution function and the</span>
<span class="sd">            hypothesized cumulative distribution function is measured at this</span>
<span class="sd">            observation.</span>
<span class="sd">        statistic_sign : int</span>
<span class="sd">            +1 if the KS statistic is the maximum positive difference between</span>
<span class="sd">            the empirical distribution function and the hypothesized cumulative</span>
<span class="sd">            distribution function (D+); -1 if the KS statistic is the maximum</span>
<span class="sd">            negative difference (D-).</span>


<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ks_2samp, kstest</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    There are three options for the null and corresponding alternative</span>
<span class="sd">    hypothesis that can be selected using the `alternative` parameter.</span>

<span class="sd">    - `two-sided`: The null hypothesis is that the two distributions are</span>
<span class="sd">      identical, F(x)=G(x) for all x; the alternative is that they are not</span>
<span class="sd">      identical.</span>

<span class="sd">    - `less`: The null hypothesis is that F(x) &gt;= G(x) for all x; the</span>
<span class="sd">      alternative is that F(x) &lt; G(x) for at least one x.</span>

<span class="sd">    - `greater`: The null hypothesis is that F(x) &lt;= G(x) for all x; the</span>
<span class="sd">      alternative is that F(x) &gt; G(x) for at least one x.</span>

<span class="sd">    Note that the alternative hypotheses describe the *CDFs* of the</span>
<span class="sd">    underlying distributions, not the observed values. For example,</span>
<span class="sd">    suppose x1 ~ F and x2 ~ G. If F(x) &gt; G(x) for all x, the values in</span>
<span class="sd">    x1 tend to be less than those in x2.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Suppose we wish to test the null hypothesis that a sample is distributed</span>
<span class="sd">    according to the standard normal.</span>
<span class="sd">    We choose a confidence level of 95%; that is, we will reject the null</span>
<span class="sd">    hypothesis in favor of the alternative if the p-value is less than 0.05.</span>

<span class="sd">    When testing uniformly distributed data, we would expect the</span>
<span class="sd">    null hypothesis to be rejected.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">    &gt;&gt;&gt; stats.ks_1samp(stats.uniform.rvs(size=100, random_state=rng),</span>
<span class="sd">    ...                stats.norm.cdf)</span>
<span class="sd">    KstestResult(statistic=0.5001899973268688, pvalue=1.1616392184763533e-23)</span>

<span class="sd">    Indeed, the p-value is lower than our threshold of 0.05, so we reject the</span>
<span class="sd">    null hypothesis in favor of the default &quot;two-sided&quot; alternative: the data</span>
<span class="sd">    are *not* distributed according to the standard normal.</span>

<span class="sd">    When testing random variates from the standard normal distribution, we</span>
<span class="sd">    expect the data to be consistent with the null hypothesis most of the time.</span>

<span class="sd">    &gt;&gt;&gt; x = stats.norm.rvs(size=100, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ks_1samp(x, stats.norm.cdf)</span>
<span class="sd">    KstestResult(statistic=0.05345882212970396, pvalue=0.9227159037744717)</span>

<span class="sd">    As expected, the p-value of 0.92 is not below our threshold of 0.05, so</span>
<span class="sd">    we cannot reject the null hypothesis.</span>

<span class="sd">    Suppose, however, that the random variates are distributed according to</span>
<span class="sd">    a normal distribution that is shifted toward greater values. In this case,</span>
<span class="sd">    the cumulative density function (CDF) of the underlying distribution tends</span>
<span class="sd">    to be *less* than the CDF of the standard normal. Therefore, we would</span>
<span class="sd">    expect the null hypothesis to be rejected with ``alternative=&#39;less&#39;``:</span>

<span class="sd">    &gt;&gt;&gt; x = stats.norm.rvs(size=100, loc=0.5, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ks_1samp(x, stats.norm.cdf, alternative=&#39;less&#39;)</span>
<span class="sd">    KstestResult(statistic=0.17482387821055168, pvalue=0.001913921057766743)</span>

<span class="sd">    and indeed, with p-value smaller than our threshold, we reject the null</span>
<span class="sd">    hypothesis in favor of the alternative.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">method</span>

    <span class="n">alternative</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;t&#39;</span><span class="p">:</span> <span class="s1">&#39;two-sided&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">:</span> <span class="s1">&#39;greater&#39;</span><span class="p">,</span> <span class="s1">&#39;l&#39;</span><span class="p">:</span> <span class="s1">&#39;less&#39;</span><span class="p">}</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
        <span class="n">alternative</span><span class="o">.</span><span class="n">lower</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alternative</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">alternative</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;two-sided&#39;</span><span class="p">,</span> <span class="s1">&#39;greater&#39;</span><span class="p">,</span> <span class="s1">&#39;less&#39;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unexpected alternative </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">alternative</span><span class="p">)</span>

    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">cdfvals</span> <span class="o">=</span> <span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
    <span class="n">np_one</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;greater&#39;</span><span class="p">:</span>
        <span class="n">Dplus</span><span class="p">,</span> <span class="n">d_location</span> <span class="o">=</span> <span class="n">_compute_dplus</span><span class="p">(</span><span class="n">cdfvals</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">KstestResult</span><span class="p">(</span><span class="n">Dplus</span><span class="p">,</span> <span class="n">distributions</span><span class="o">.</span><span class="n">ksone</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">Dplus</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span>
                            <span class="n">statistic_location</span><span class="o">=</span><span class="n">d_location</span><span class="p">,</span>
                            <span class="n">statistic_sign</span><span class="o">=</span><span class="n">np_one</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;less&#39;</span><span class="p">:</span>
        <span class="n">Dminus</span><span class="p">,</span> <span class="n">d_location</span> <span class="o">=</span> <span class="n">_compute_dminus</span><span class="p">(</span><span class="n">cdfvals</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">KstestResult</span><span class="p">(</span><span class="n">Dminus</span><span class="p">,</span> <span class="n">distributions</span><span class="o">.</span><span class="n">ksone</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">Dminus</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span>
                            <span class="n">statistic_location</span><span class="o">=</span><span class="n">d_location</span><span class="p">,</span>
                            <span class="n">statistic_sign</span><span class="o">=-</span><span class="n">np_one</span><span class="p">)</span>

    <span class="c1"># alternative == &#39;two-sided&#39;:</span>
    <span class="n">Dplus</span><span class="p">,</span> <span class="n">dplus_location</span> <span class="o">=</span> <span class="n">_compute_dplus</span><span class="p">(</span><span class="n">cdfvals</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">Dminus</span><span class="p">,</span> <span class="n">dminus_location</span> <span class="o">=</span> <span class="n">_compute_dminus</span><span class="p">(</span><span class="n">cdfvals</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">Dplus</span> <span class="o">&gt;</span> <span class="n">Dminus</span><span class="p">:</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">Dplus</span>
        <span class="n">d_location</span> <span class="o">=</span> <span class="n">dplus_location</span>
        <span class="n">d_sign</span> <span class="o">=</span> <span class="n">np_one</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">Dminus</span>
        <span class="n">d_location</span> <span class="o">=</span> <span class="n">dminus_location</span>
        <span class="n">d_sign</span> <span class="o">=</span> <span class="o">-</span><span class="n">np_one</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>  <span class="c1"># Always select exact</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;exact&#39;</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;exact&#39;</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">kstwo</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;asymp&#39;</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">kstwobign</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">D</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># mode == &#39;approx&#39;</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">distributions</span><span class="o">.</span><span class="n">ksone</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">KstestResult</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span>
                        <span class="n">statistic_location</span><span class="o">=</span><span class="n">d_location</span><span class="p">,</span>
                        <span class="n">statistic_sign</span><span class="o">=</span><span class="n">d_sign</span><span class="p">)</span>


<span class="n">Ks_2sampResult</span> <span class="o">=</span> <span class="n">KstestResult</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_compute_prob_outside_square</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the proportion of paths that pass outside the two diagonal lines.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : integer</span>
<span class="sd">        n &gt; 0</span>
<span class="sd">    h : integer</span>
<span class="sd">        0 &lt;= h &lt;= n</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    p : float</span>
<span class="sd">        The proportion of paths that pass outside the lines x-y = +/-h.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Compute Pr(D_{n,n} &gt;= h/n)</span>
    <span class="c1"># Prob = 2 * ( binom(2n, n-h) - binom(2n, n-2a) + binom(2n, n-3a) - ... )</span>
    <span class="c1"># / binom(2n, n)</span>
    <span class="c1"># This formulation exhibits subtractive cancellation.</span>
    <span class="c1"># Instead divide each term by binom(2n, n), then factor common terms</span>
    <span class="c1"># and use a Horner-like algorithm</span>
    <span class="c1"># P = 2 * A0 * (1 - A1*(1 - A2*(1 - A3*(1 - A4*(...)))))</span>

    <span class="n">P</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">k</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="n">h</span><span class="p">))</span>
    <span class="k">while</span> <span class="n">k</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">p1</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="c1"># Each of the Ai terms has numerator and denominator with</span>
        <span class="c1"># h simple terms.</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">h</span><span class="p">):</span>
            <span class="n">p1</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">k</span> <span class="o">*</span> <span class="n">h</span> <span class="o">-</span> <span class="n">j</span><span class="p">)</span> <span class="o">*</span> <span class="n">p1</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="n">k</span> <span class="o">*</span> <span class="n">h</span> <span class="o">+</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">P</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">P</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_count_paths_outside_method</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Count the number of paths that pass outside the specified diagonal.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    m : integer</span>
<span class="sd">        m &gt; 0</span>
<span class="sd">    n : integer</span>
<span class="sd">        n &gt; 0</span>
<span class="sd">    g : integer</span>
<span class="sd">        g is greatest common divisor of m and n</span>
<span class="sd">    h : integer</span>
<span class="sd">        0 &lt;= h &lt;= lcm(m,n)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    p : float</span>
<span class="sd">        The number of paths that go low.</span>
<span class="sd">        The calculation may overflow - check for a finite answer.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Count the integer lattice paths from (0, 0) to (m, n), which at some</span>
<span class="sd">    point (x, y) along the path, satisfy:</span>
<span class="sd">      m*y &lt;= n*x - h*g</span>
<span class="sd">    The paths make steps of size +1 in either positive x or positive y</span>
<span class="sd">    directions.</span>

<span class="sd">    We generally follow Hodges&#39; treatment of Drion/Gnedenko/Korolyuk.</span>
<span class="sd">    Hodges, J.L. Jr.,</span>
<span class="sd">    &quot;The Significance Probability of the Smirnov Two-Sample Test,&quot;</span>
<span class="sd">    Arkiv fiur Matematik, 3, No. 43 (1958), 469-86.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Compute #paths which stay lower than x/m-y/n = h/lcm(m,n)</span>
    <span class="c1"># B(x, y) = #{paths from (0,0) to (x,y) without</span>
    <span class="c1">#             previously crossing the boundary}</span>
    <span class="c1">#         = binom(x, y) - #{paths which already reached the boundary}</span>
    <span class="c1"># Multiply by the number of path extensions going from (x, y) to (m, n)</span>
    <span class="c1"># Sum.</span>

    <span class="c1"># Probability is symmetrical in m, n.  Computation below assumes m &gt;= n.</span>
    <span class="k">if</span> <span class="n">m</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span>
    <span class="n">mg</span> <span class="o">=</span> <span class="n">m</span> <span class="o">//</span> <span class="n">g</span>
    <span class="n">ng</span> <span class="o">=</span> <span class="n">n</span> <span class="o">//</span> <span class="n">g</span>

    <span class="c1"># Not every x needs to be considered.</span>
    <span class="c1"># xj holds the list of x values to be checked.</span>
    <span class="c1"># Wherever n*x/m + ng*h crosses an integer</span>
    <span class="n">lxj</span> <span class="o">=</span> <span class="n">n</span> <span class="o">+</span> <span class="p">(</span><span class="n">mg</span><span class="o">-</span><span class="n">h</span><span class="p">)</span><span class="o">//</span><span class="n">mg</span>
    <span class="n">xj</span> <span class="o">=</span> <span class="p">[(</span><span class="n">h</span> <span class="o">+</span> <span class="n">mg</span> <span class="o">*</span> <span class="n">j</span> <span class="o">+</span> <span class="n">ng</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="n">ng</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">lxj</span><span class="p">)]</span>
    <span class="c1"># B is an array just holding a few values of B(x,y), the ones needed.</span>
    <span class="c1"># B[j] == B(x_j, j)</span>
    <span class="k">if</span> <span class="n">lxj</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">lxj</span><span class="p">)</span>
    <span class="n">B</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1"># Compute the B(x, y) terms</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lxj</span><span class="p">):</span>
        <span class="n">Bj</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="n">xj</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>
            <span class="nb">bin</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="n">xj</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">xj</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">j</span> <span class="o">-</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="n">i</span><span class="p">)</span>
            <span class="n">Bj</span> <span class="o">-=</span> <span class="nb">bin</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">B</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">Bj</span>
    <span class="c1"># Compute the number of path extensions...</span>
    <span class="n">num_paths</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">lxj</span><span class="p">):</span>
        <span class="nb">bin</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">((</span><span class="n">m</span><span class="o">-</span><span class="n">xj</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">j</span><span class="p">),</span> <span class="n">n</span><span class="o">-</span><span class="n">j</span><span class="p">)</span>
        <span class="n">term</span> <span class="o">=</span> <span class="n">B</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="nb">bin</span>
        <span class="n">num_paths</span> <span class="o">+=</span> <span class="n">term</span>
    <span class="k">return</span> <span class="n">num_paths</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_attempt_exact_2kssamp</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">alternative</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Attempts to compute the exact 2sample probability.</span>

<span class="sd">    n1, n2 are the sample sizes</span>
<span class="sd">    g is the gcd(n1, n2)</span>
<span class="sd">    d is the computed max difference in ECDFs</span>

<span class="sd">    Returns (success, d, probability)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lcm</span> <span class="o">=</span> <span class="p">(</span><span class="n">n1</span> <span class="o">//</span> <span class="n">g</span><span class="p">)</span> <span class="o">*</span> <span class="n">n2</span>
    <span class="n">h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">d</span> <span class="o">*</span> <span class="n">lcm</span><span class="p">))</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">lcm</span>
    <span class="k">if</span> <span class="n">h</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="mf">1.0</span>
    <span class="n">saw_fp_error</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">invalid</span><span class="o">=</span><span class="s2">&quot;raise&quot;</span><span class="p">,</span> <span class="n">over</span><span class="o">=</span><span class="s2">&quot;raise&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;two-sided&#39;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">n1</span> <span class="o">==</span> <span class="n">n2</span><span class="p">:</span>
                    <span class="n">prob</span> <span class="o">=</span> <span class="n">_compute_prob_outside_square</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">prob</span> <span class="o">=</span> <span class="n">_compute_outer_prob_inside_method</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">n1</span> <span class="o">==</span> <span class="n">n2</span><span class="p">:</span>
                    <span class="c1"># prob = binom(2n, n-h) / binom(2n, n)</span>
                    <span class="c1"># Evaluating in that form incurs roundoff errors</span>
                    <span class="c1"># from special.binom. Instead calculate directly</span>
                    <span class="n">jrange</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
                    <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">((</span><span class="n">n1</span> <span class="o">-</span> <span class="n">jrange</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="n">jrange</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">over</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">):</span>
                        <span class="n">num_paths</span> <span class="o">=</span> <span class="n">_count_paths_outside_method</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
                    <span class="nb">bin</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">,</span> <span class="n">n1</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">num_paths</span> <span class="o">&gt;</span> <span class="nb">bin</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="nb">bin</span><span class="p">):</span>
                        <span class="n">saw_fp_error</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">prob</span> <span class="o">=</span> <span class="n">num_paths</span> <span class="o">/</span> <span class="nb">bin</span>

    <span class="k">except</span> <span class="p">(</span><span class="ne">FloatingPointError</span><span class="p">,</span> <span class="ne">OverflowError</span><span class="p">):</span>
        <span class="n">saw_fp_error</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="n">saw_fp_error</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">prob</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">prob</span>
    <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">prob</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span><span class="n">_tuple_to_KstestResult</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_outputs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                          <span class="n">result_to_tuple</span><span class="o">=</span><span class="n">_KstestResult_to_tuple</span><span class="p">)</span>
<span class="nd">@_rename_parameter</span><span class="p">(</span><span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="s2">&quot;method&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ks_2samp</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs the two-sample Kolmogorov-Smirnov test for goodness of fit.</span>

<span class="sd">    This test compares the underlying continuous distributions F(x) and G(x)</span>
<span class="sd">    of two independent samples.  See Notes for a description of the available</span>
<span class="sd">    null and alternative hypotheses.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data1, data2 : array_like, 1-Dimensional</span>
<span class="sd">        Two arrays of sample observations assumed to be drawn from a continuous</span>
<span class="sd">        distribution, sample sizes can be different.</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the null and alternative hypotheses. Default is &#39;two-sided&#39;.</span>
<span class="sd">        Please see explanations in the Notes below.</span>
<span class="sd">    method : {&#39;auto&#39;, &#39;exact&#39;, &#39;asymp&#39;}, optional</span>
<span class="sd">        Defines the method used for calculating the p-value.</span>
<span class="sd">        The following options are available (default is &#39;auto&#39;):</span>

<span class="sd">          * &#39;auto&#39; : use &#39;exact&#39; for small size arrays, &#39;asymp&#39; for large</span>
<span class="sd">          * &#39;exact&#39; : use exact distribution of test statistic</span>
<span class="sd">          * &#39;asymp&#39; : use asymptotic distribution of test statistic</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res: KstestResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            KS test statistic.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            One-tailed or two-tailed p-value.</span>
<span class="sd">        statistic_location : float</span>
<span class="sd">            Value from `data1` or `data2` corresponding with the KS statistic;</span>
<span class="sd">            i.e., the distance between the empirical distribution functions is</span>
<span class="sd">            measured at this observation.</span>
<span class="sd">        statistic_sign : int</span>
<span class="sd">            +1 if the empirical distribution function of `data1` exceeds</span>
<span class="sd">            the empirical distribution function of `data2` at</span>
<span class="sd">            `statistic_location`, otherwise -1.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    kstest, ks_1samp, epps_singleton_2samp, anderson_ksamp</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    There are three options for the null and corresponding alternative</span>
<span class="sd">    hypothesis that can be selected using the `alternative` parameter.</span>

<span class="sd">    - `less`: The null hypothesis is that F(x) &gt;= G(x) for all x; the</span>
<span class="sd">      alternative is that F(x) &lt; G(x) for at least one x. The statistic</span>
<span class="sd">      is the magnitude of the minimum (most negative) difference between the</span>
<span class="sd">      empirical distribution functions of the samples.</span>

<span class="sd">    - `greater`: The null hypothesis is that F(x) &lt;= G(x) for all x; the</span>
<span class="sd">      alternative is that F(x) &gt; G(x) for at least one x. The statistic</span>
<span class="sd">      is the maximum (most positive) difference between the empirical</span>
<span class="sd">      distribution functions of the samples.</span>

<span class="sd">    - `two-sided`: The null hypothesis is that the two distributions are</span>
<span class="sd">      identical, F(x)=G(x) for all x; the alternative is that they are not</span>
<span class="sd">      identical. The statistic is the maximum absolute difference between the</span>
<span class="sd">      empirical distribution functions of the samples.</span>

<span class="sd">    Note that the alternative hypotheses describe the *CDFs* of the</span>
<span class="sd">    underlying distributions, not the observed values of the data. For example,</span>
<span class="sd">    suppose x1 ~ F and x2 ~ G. If F(x) &gt; G(x) for all x, the values in</span>
<span class="sd">    x1 tend to be less than those in x2.</span>

<span class="sd">    If the KS statistic is large, then the p-value will be small, and this may</span>
<span class="sd">    be taken as evidence against the null hypothesis in favor of the</span>
<span class="sd">    alternative.</span>

<span class="sd">    If ``method=&#39;exact&#39;``, `ks_2samp` attempts to compute an exact p-value,</span>
<span class="sd">    that is, the probability under the null hypothesis of obtaining a test</span>
<span class="sd">    statistic value as extreme as the value computed from the data.</span>
<span class="sd">    If ``method=&#39;asymp&#39;``, the asymptotic Kolmogorov-Smirnov distribution is</span>
<span class="sd">    used to compute an approximate p-value.</span>
<span class="sd">    If ``method=&#39;auto&#39;``, an exact p-value computation is attempted if both</span>
<span class="sd">    sample sizes are less than 10000; otherwise, the asymptotic method is used.</span>
<span class="sd">    In any case, if an exact p-value calculation is attempted and fails, a</span>
<span class="sd">    warning will be emitted, and the asymptotic p-value will be returned.</span>

<span class="sd">    The &#39;two-sided&#39; &#39;exact&#39; computation computes the complementary probability</span>
<span class="sd">    and then subtracts from 1.  As such, the minimum probability it can return</span>
<span class="sd">    is about 1e-16.  While the algorithm itself is exact, numerical</span>
<span class="sd">    errors may accumulate for large sample sizes.   It is most suited to</span>
<span class="sd">    situations in which one of the sample sizes is only a few thousand.</span>

<span class="sd">    We generally follow Hodges&#39; treatment of Drion/Gnedenko/Korolyuk [1]_.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Hodges, J.L. Jr.,  &quot;The Significance Probability of the Smirnov</span>
<span class="sd">           Two-Sample Test,&quot; Arkiv fiur Matematik, 3, No. 43 (1958), 469-486.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Suppose we wish to test the null hypothesis that two samples were drawn</span>
<span class="sd">    from the same distribution.</span>
<span class="sd">    We choose a confidence level of 95%; that is, we will reject the null</span>
<span class="sd">    hypothesis in favor of the alternative if the p-value is less than 0.05.</span>

<span class="sd">    If the first sample were drawn from a uniform distribution and the second</span>
<span class="sd">    were drawn from the standard normal, we would expect the null hypothesis</span>
<span class="sd">    to be rejected.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">    &gt;&gt;&gt; sample1 = stats.uniform.rvs(size=100, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; sample2 = stats.norm.rvs(size=110, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ks_2samp(sample1, sample2)</span>
<span class="sd">    KstestResult(statistic=0.5454545454545454, pvalue=7.37417839555191e-15)</span>

<span class="sd">    Indeed, the p-value is lower than our threshold of 0.05, so we reject the</span>
<span class="sd">    null hypothesis in favor of the default &quot;two-sided&quot; alternative: the data</span>
<span class="sd">    were *not* drawn from the same distribution.</span>

<span class="sd">    When both samples are drawn from the same distribution, we expect the data</span>
<span class="sd">    to be consistent with the null hypothesis most of the time.</span>

<span class="sd">    &gt;&gt;&gt; sample1 = stats.norm.rvs(size=105, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; sample2 = stats.norm.rvs(size=95, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ks_2samp(sample1, sample2)</span>
<span class="sd">    KstestResult(statistic=0.10927318295739348, pvalue=0.5438289009927495)</span>

<span class="sd">    As expected, the p-value of 0.54 is not below our threshold of 0.05, so</span>
<span class="sd">    we cannot reject the null hypothesis.</span>

<span class="sd">    Suppose, however, that the first sample were drawn from</span>
<span class="sd">    a normal distribution shifted toward greater values. In this case,</span>
<span class="sd">    the cumulative density function (CDF) of the underlying distribution tends</span>
<span class="sd">    to be *less* than the CDF underlying the second sample. Therefore, we would</span>
<span class="sd">    expect the null hypothesis to be rejected with ``alternative=&#39;less&#39;``:</span>

<span class="sd">    &gt;&gt;&gt; sample1 = stats.norm.rvs(size=105, loc=0.5, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.ks_2samp(sample1, sample2, alternative=&#39;less&#39;)</span>
<span class="sd">    KstestResult(statistic=0.4055137844611529, pvalue=3.5474563068855554e-08)</span>

<span class="sd">    and indeed, with p-value smaller than our threshold, we reject the null</span>
<span class="sd">    hypothesis in favor of the alternative.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">method</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;exact&#39;</span><span class="p">,</span> <span class="s1">&#39;asymp&#39;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid value for mode: </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">alternative</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;t&#39;</span><span class="p">:</span> <span class="s1">&#39;two-sided&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">:</span> <span class="s1">&#39;greater&#39;</span><span class="p">,</span> <span class="s1">&#39;l&#39;</span><span class="p">:</span> <span class="s1">&#39;less&#39;</span><span class="p">}</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
        <span class="n">alternative</span><span class="o">.</span><span class="n">lower</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alternative</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">alternative</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;two-sided&#39;</span><span class="p">,</span> <span class="s1">&#39;less&#39;</span><span class="p">,</span> <span class="s1">&#39;greater&#39;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Invalid value for alternative: </span><span class="si">{</span><span class="n">alternative</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">MAX_AUTO_N</span> <span class="o">=</span> <span class="mi">10000</span>  <span class="c1"># &#39;auto&#39; will attempt to be exact if n1,n2 &lt;= MAX_AUTO_N</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">is_masked</span><span class="p">(</span><span class="n">data1</span><span class="p">):</span>
        <span class="n">data1</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">compressed</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">is_masked</span><span class="p">(</span><span class="n">data2</span><span class="p">):</span>
        <span class="n">data2</span> <span class="o">=</span> <span class="n">data2</span><span class="o">.</span><span class="n">compressed</span><span class="p">()</span>
    <span class="n">data1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">data1</span><span class="p">)</span>
    <span class="n">data2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">data2</span><span class="p">)</span>
    <span class="n">n1</span> <span class="o">=</span> <span class="n">data1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n2</span> <span class="o">=</span> <span class="n">data2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">min</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Data passed to ks_2samp must not be empty&#39;</span><span class="p">)</span>

    <span class="n">data_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">])</span>
    <span class="c1"># using searchsorted solves equal data problem</span>
    <span class="n">cdf1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data_all</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="n">n1</span>
    <span class="n">cdf2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span> <span class="n">data_all</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="n">n2</span>
    <span class="n">cddiffs</span> <span class="o">=</span> <span class="n">cdf1</span> <span class="o">-</span> <span class="n">cdf2</span>

    <span class="c1"># Identify the location of the statistic</span>
    <span class="n">argminS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">cddiffs</span><span class="p">)</span>
    <span class="n">argmaxS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cddiffs</span><span class="p">)</span>
    <span class="n">loc_minS</span> <span class="o">=</span> <span class="n">data_all</span><span class="p">[</span><span class="n">argminS</span><span class="p">]</span>
    <span class="n">loc_maxS</span> <span class="o">=</span> <span class="n">data_all</span><span class="p">[</span><span class="n">argmaxS</span><span class="p">]</span>

    <span class="c1"># Ensure sign of minS is not negative.</span>
    <span class="n">minS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="o">-</span><span class="n">cddiffs</span><span class="p">[</span><span class="n">argminS</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">maxS</span> <span class="o">=</span> <span class="n">cddiffs</span><span class="p">[</span><span class="n">argmaxS</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;less&#39;</span> <span class="ow">or</span> <span class="p">(</span><span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;two-sided&#39;</span> <span class="ow">and</span> <span class="n">minS</span> <span class="o">&gt;</span> <span class="n">maxS</span><span class="p">):</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">minS</span>
        <span class="n">d_location</span> <span class="o">=</span> <span class="n">loc_minS</span>
        <span class="n">d_sign</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">maxS</span>
        <span class="n">d_location</span> <span class="o">=</span> <span class="n">loc_maxS</span>
        <span class="n">d_sign</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">gcd</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span>
    <span class="n">n1g</span> <span class="o">=</span> <span class="n">n1</span> <span class="o">//</span> <span class="n">g</span>
    <span class="n">n2g</span> <span class="o">=</span> <span class="n">n2</span> <span class="o">//</span> <span class="n">g</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;exact&#39;</span> <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">MAX_AUTO_N</span> <span class="k">else</span> <span class="s1">&#39;asymp&#39;</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;exact&#39;</span><span class="p">:</span>
        <span class="c1"># If lcm(n1, n2) is too big, switch from exact to asymp</span>
        <span class="k">if</span> <span class="n">n1g</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">max</span> <span class="o">/</span> <span class="n">n2g</span><span class="p">:</span>
            <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;asymp&#39;</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Exact ks_2samp calculation not possible with samples sizes &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">n1</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">n2</span><span class="si">}</span><span class="s2">. Switching to &#39;asymp&#39;.&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;exact&#39;</span><span class="p">:</span>
        <span class="n">success</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">_attempt_exact_2kssamp</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">success</span><span class="p">:</span>
            <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;asymp&#39;</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ks_2samp: Exact calculation unsuccessful. &quot;</span>
                          <span class="sa">f</span><span class="s2">&quot;Switching to method=</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">,</span>
                          <span class="n">stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;asymp&#39;</span><span class="p">:</span>
        <span class="c1"># The product n1*n2 is large.  Use Smirnov&#39;s asymptoptic formula.</span>
        <span class="c1"># Ensure float to avoid overflow in multiplication</span>
        <span class="c1"># sorted because the one-sided formula is not symmetric in n1, n2</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">n1</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="n">n2</span><span class="p">)],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">en</span> <span class="o">=</span> <span class="n">m</span> <span class="o">*</span> <span class="n">n</span> <span class="o">/</span> <span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;two-sided&#39;</span><span class="p">:</span>
            <span class="n">prob</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">kstwo</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">en</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">en</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span>
            <span class="c1"># Use Hodges&#39; suggested approximation Eqn 5.3</span>
            <span class="c1"># Requires m to be the larger of (n1, n2)</span>
            <span class="n">expt</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">z</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">z</span> <span class="o">*</span> <span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">m</span><span class="o">*</span><span class="n">n</span><span class="o">*</span><span class="p">(</span><span class="n">m</span><span class="o">+</span><span class="n">n</span><span class="p">))</span><span class="o">/</span><span class="mf">3.0</span>
            <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">expt</span><span class="p">)</span>

    <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Currently, `d` is a Python float. We want it to be a NumPy type, so</span>
    <span class="c1"># float64 is appropriate. An enhancement would be for `d` to respect the</span>
    <span class="c1"># dtype of the input.</span>
    <span class="k">return</span> <span class="n">KstestResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">d</span><span class="p">),</span> <span class="n">prob</span><span class="p">,</span> <span class="n">statistic_location</span><span class="o">=</span><span class="n">d_location</span><span class="p">,</span>
                        <span class="n">statistic_sign</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">(</span><span class="n">d_sign</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_parse_kstest_args</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="c1"># kstest allows many different variations of arguments.</span>
    <span class="c1"># Pull out the parsing into a separate function</span>
    <span class="c1"># (xvals, yvals, )  # 2sample</span>
    <span class="c1"># (xvals, cdf function,..)</span>
    <span class="c1"># (xvals, name of distribution, ...)</span>
    <span class="c1"># (name of distribution, name of distribution, ...)</span>

    <span class="c1"># Returns xvals, yvals, cdf</span>
    <span class="c1"># where cdf is a cdf function, or None</span>
    <span class="c1"># and yvals is either an array_like of values, or None</span>
    <span class="c1"># and xvals is array_like.</span>
    <span class="n">rvsfunc</span><span class="p">,</span> <span class="n">cdf</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">rvsfunc</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">distributions</span><span class="p">,</span> <span class="n">data1</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span>
    <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">data1</span><span class="p">):</span>
        <span class="n">rvsfunc</span> <span class="o">=</span> <span class="n">data1</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data2</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">cdf</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">distributions</span><span class="p">,</span> <span class="n">data2</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span>
        <span class="n">data2</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">data2</span><span class="p">):</span>
        <span class="n">cdf</span> <span class="o">=</span> <span class="n">data2</span>
        <span class="n">data2</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">data1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">rvsfunc</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span> <span class="k">if</span> <span class="n">rvsfunc</span> <span class="k">else</span> <span class="n">data1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">,</span> <span class="n">cdf</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_kstest_n_samples</span><span class="p">(</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">cdf</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;cdf&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">cdf</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">callable</span><span class="p">(</span><span class="n">cdf</span><span class="p">))</span> <span class="k">else</span> <span class="mi">2</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span><span class="n">_tuple_to_KstestResult</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="n">_kstest_n_samples</span><span class="p">,</span>
                          <span class="n">n_outputs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">result_to_tuple</span><span class="o">=</span><span class="n">_KstestResult_to_tuple</span><span class="p">)</span>
<span class="nd">@_rename_parameter</span><span class="p">(</span><span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="s2">&quot;method&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kstest</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">cdf</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(),</span> <span class="n">N</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs the (one-sample or two-sample) Kolmogorov-Smirnov test for</span>
<span class="sd">    goodness of fit.</span>

<span class="sd">    The one-sample test compares the underlying distribution F(x) of a sample</span>
<span class="sd">    against a given distribution G(x). The two-sample test compares the</span>
<span class="sd">    underlying distributions of two independent samples. Both tests are valid</span>
<span class="sd">    only for continuous distributions.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    rvs : str, array_like, or callable</span>
<span class="sd">        If an array, it should be a 1-D array of observations of random</span>
<span class="sd">        variables.</span>
<span class="sd">        If a callable, it should be a function to generate random variables;</span>
<span class="sd">        it is required to have a keyword argument `size`.</span>
<span class="sd">        If a string, it should be the name of a distribution in `scipy.stats`,</span>
<span class="sd">        which will be used to generate random variables.</span>
<span class="sd">    cdf : str, array_like or callable</span>
<span class="sd">        If array_like, it should be a 1-D array of observations of random</span>
<span class="sd">        variables, and the two-sample test is performed</span>
<span class="sd">        (and rvs must be array_like).</span>
<span class="sd">        If a callable, that callable is used to calculate the cdf.</span>
<span class="sd">        If a string, it should be the name of a distribution in `scipy.stats`,</span>
<span class="sd">        which will be used as the cdf function.</span>
<span class="sd">    args : tuple, sequence, optional</span>
<span class="sd">        Distribution parameters, used if `rvs` or `cdf` are strings or</span>
<span class="sd">        callables.</span>
<span class="sd">    N : int, optional</span>
<span class="sd">        Sample size if `rvs` is string or callable.  Default is 20.</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the null and alternative hypotheses. Default is &#39;two-sided&#39;.</span>
<span class="sd">        Please see explanations in the Notes below.</span>
<span class="sd">    method : {&#39;auto&#39;, &#39;exact&#39;, &#39;approx&#39;, &#39;asymp&#39;}, optional</span>
<span class="sd">        Defines the distribution used for calculating the p-value.</span>
<span class="sd">        The following options are available (default is &#39;auto&#39;):</span>

<span class="sd">          * &#39;auto&#39; : selects one of the other options.</span>
<span class="sd">          * &#39;exact&#39; : uses the exact distribution of test statistic.</span>
<span class="sd">          * &#39;approx&#39; : approximates the two-sided probability with twice the</span>
<span class="sd">            one-sided probability</span>
<span class="sd">          * &#39;asymp&#39;: uses asymptotic distribution of test statistic</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res: KstestResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            KS test statistic, either D+, D-, or D (the maximum of the two)</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            One-tailed or two-tailed p-value.</span>
<span class="sd">        statistic_location : float</span>
<span class="sd">            In a one-sample test, this is the value of `rvs`</span>
<span class="sd">            corresponding with the KS statistic; i.e., the distance between</span>
<span class="sd">            the empirical distribution function and the hypothesized cumulative</span>
<span class="sd">            distribution function is measured at this observation.</span>

<span class="sd">            In a two-sample test, this is the value from `rvs` or `cdf`</span>
<span class="sd">            corresponding with the KS statistic; i.e., the distance between</span>
<span class="sd">            the empirical distribution functions is measured at this</span>
<span class="sd">            observation.</span>
<span class="sd">        statistic_sign : int</span>
<span class="sd">            In a one-sample test, this is +1 if the KS statistic is the</span>
<span class="sd">            maximum positive difference between the empirical distribution</span>
<span class="sd">            function and the hypothesized cumulative distribution function</span>
<span class="sd">            (D+); it is -1 if the KS statistic is the maximum negative</span>
<span class="sd">            difference (D-).</span>

<span class="sd">            In a two-sample test, this is +1 if the empirical distribution</span>
<span class="sd">            function of `rvs` exceeds the empirical distribution</span>
<span class="sd">            function of `cdf` at `statistic_location`, otherwise -1.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    ks_1samp, ks_2samp</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    There are three options for the null and corresponding alternative</span>
<span class="sd">    hypothesis that can be selected using the `alternative` parameter.</span>

<span class="sd">    - `two-sided`: The null hypothesis is that the two distributions are</span>
<span class="sd">      identical, F(x)=G(x) for all x; the alternative is that they are not</span>
<span class="sd">      identical.</span>

<span class="sd">    - `less`: The null hypothesis is that F(x) &gt;= G(x) for all x; the</span>
<span class="sd">      alternative is that F(x) &lt; G(x) for at least one x.</span>

<span class="sd">    - `greater`: The null hypothesis is that F(x) &lt;= G(x) for all x; the</span>
<span class="sd">      alternative is that F(x) &gt; G(x) for at least one x.</span>

<span class="sd">    Note that the alternative hypotheses describe the *CDFs* of the</span>
<span class="sd">    underlying distributions, not the observed values. For example,</span>
<span class="sd">    suppose x1 ~ F and x2 ~ G. If F(x) &gt; G(x) for all x, the values in</span>
<span class="sd">    x1 tend to be less than those in x2.</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Suppose we wish to test the null hypothesis that a sample is distributed</span>
<span class="sd">    according to the standard normal.</span>
<span class="sd">    We choose a confidence level of 95%; that is, we will reject the null</span>
<span class="sd">    hypothesis in favor of the alternative if the p-value is less than 0.05.</span>

<span class="sd">    When testing uniformly distributed data, we would expect the</span>
<span class="sd">    null hypothesis to be rejected.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">    &gt;&gt;&gt; stats.kstest(stats.uniform.rvs(size=100, random_state=rng),</span>
<span class="sd">    ...              stats.norm.cdf)</span>
<span class="sd">    KstestResult(statistic=0.5001899973268688, pvalue=1.1616392184763533e-23)</span>

<span class="sd">    Indeed, the p-value is lower than our threshold of 0.05, so we reject the</span>
<span class="sd">    null hypothesis in favor of the default &quot;two-sided&quot; alternative: the data</span>
<span class="sd">    are *not* distributed according to the standard normal.</span>

<span class="sd">    When testing random variates from the standard normal distribution, we</span>
<span class="sd">    expect the data to be consistent with the null hypothesis most of the time.</span>

<span class="sd">    &gt;&gt;&gt; x = stats.norm.rvs(size=100, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.kstest(x, stats.norm.cdf)</span>
<span class="sd">    KstestResult(statistic=0.05345882212970396, pvalue=0.9227159037744717)</span>

<span class="sd">    As expected, the p-value of 0.92 is not below our threshold of 0.05, so</span>
<span class="sd">    we cannot reject the null hypothesis.</span>

<span class="sd">    Suppose, however, that the random variates are distributed according to</span>
<span class="sd">    a normal distribution that is shifted toward greater values. In this case,</span>
<span class="sd">    the cumulative density function (CDF) of the underlying distribution tends</span>
<span class="sd">    to be *less* than the CDF of the standard normal. Therefore, we would</span>
<span class="sd">    expect the null hypothesis to be rejected with ``alternative=&#39;less&#39;``:</span>

<span class="sd">    &gt;&gt;&gt; x = stats.norm.rvs(size=100, loc=0.5, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.kstest(x, stats.norm.cdf, alternative=&#39;less&#39;)</span>
<span class="sd">    KstestResult(statistic=0.17482387821055168, pvalue=0.001913921057766743)</span>

<span class="sd">    and indeed, with p-value smaller than our threshold, we reject the null</span>
<span class="sd">    hypothesis in favor of the alternative.</span>

<span class="sd">    For convenience, the previous test can be performed using the name of the</span>
<span class="sd">    distribution as the second argument.</span>

<span class="sd">    &gt;&gt;&gt; stats.kstest(x, &quot;norm&quot;, alternative=&#39;less&#39;)</span>
<span class="sd">    KstestResult(statistic=0.17482387821055168, pvalue=0.001913921057766743)</span>

<span class="sd">    The examples above have all been one-sample tests identical to those</span>
<span class="sd">    performed by `ks_1samp`. Note that `kstest` can also perform two-sample</span>
<span class="sd">    tests identical to those performed by `ks_2samp`. For example, when two</span>
<span class="sd">    samples are drawn from the same distribution, we expect the data to be</span>
<span class="sd">    consistent with the null hypothesis most of the time.</span>

<span class="sd">    &gt;&gt;&gt; sample1 = stats.laplace.rvs(size=105, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; sample2 = stats.laplace.rvs(size=95, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.kstest(sample1, sample2)</span>
<span class="sd">    KstestResult(statistic=0.11779448621553884, pvalue=0.4494256912629795)</span>

<span class="sd">    As expected, the p-value of 0.45 is not below our threshold of 0.05, so</span>
<span class="sd">    we cannot reject the null hypothesis.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># to not break compatibility with existing code</span>
    <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;two_sided&#39;</span><span class="p">:</span>
        <span class="n">alternative</span> <span class="o">=</span> <span class="s1">&#39;two-sided&#39;</span>
    <span class="k">if</span> <span class="n">alternative</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;two-sided&#39;</span><span class="p">,</span> <span class="s1">&#39;greater&#39;</span><span class="p">,</span> <span class="s1">&#39;less&#39;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unexpected alternative </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">alternative</span><span class="p">)</span>
    <span class="n">xvals</span><span class="p">,</span> <span class="n">yvals</span><span class="p">,</span> <span class="n">cdf</span> <span class="o">=</span> <span class="n">_parse_kstest_args</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">cdf</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cdf</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ks_1samp</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">cdf</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span>
                        <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">_no_deco</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ks_2samp</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">yvals</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="n">alternative</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                    <span class="n">_no_deco</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">tiecorrect</span><span class="p">(</span><span class="n">rankvals</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tie correction factor for Mann-Whitney U and Kruskal-Wallis H tests.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    rankvals : array_like</span>
<span class="sd">        A 1-D sequence of ranks.  Typically this will be the array</span>
<span class="sd">        returned by `~scipy.stats.rankdata`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    factor : float</span>
<span class="sd">        Correction factor for U or H.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    rankdata : Assign ranks to the data</span>
<span class="sd">    mannwhitneyu : Mann-Whitney rank test</span>
<span class="sd">    kruskal : Kruskal-Wallis H test</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Siegel, S. (1956) Nonparametric Statistics for the Behavioral</span>
<span class="sd">           Sciences.  New York: McGraw-Hill.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import tiecorrect, rankdata</span>
<span class="sd">    &gt;&gt;&gt; tiecorrect([1, 2.5, 2.5, 4])</span>
<span class="sd">    0.9</span>
<span class="sd">    &gt;&gt;&gt; ranks = rankdata([1, 3, 2, 4, 5, 7, 2, 8, 4])</span>
<span class="sd">    &gt;&gt;&gt; ranks</span>
<span class="sd">    array([ 1. ,  4. ,  2.5,  5.5,  7. ,  8. ,  2.5,  9. ,  5.5])</span>
<span class="sd">    &gt;&gt;&gt; tiecorrect(ranks)</span>
<span class="sd">    0.9833333333333333</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">rankvals</span><span class="p">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="n">arr</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">arr</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="kc">True</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">cnt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="n">size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">size</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">cnt</span><span class="o">**</span><span class="mi">3</span> <span class="o">-</span> <span class="n">cnt</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">size</span><span class="o">**</span><span class="mi">3</span> <span class="o">-</span> <span class="n">size</span><span class="p">)</span>


<span class="n">RanksumsResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;RanksumsResult&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">))</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span><span class="n">RanksumsResult</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ranksums</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the Wilcoxon rank-sum statistic for two samples.</span>

<span class="sd">    The Wilcoxon rank-sum test tests the null hypothesis that two sets</span>
<span class="sd">    of measurements are drawn from the same distribution.  The alternative</span>
<span class="sd">    hypothesis is that values in one sample are more likely to be</span>
<span class="sd">    larger than the values in the other sample.</span>

<span class="sd">    This test should be used to compare two samples from continuous</span>
<span class="sd">    distributions.  It does not handle ties between measurements</span>
<span class="sd">    in x and y.  For tie-handling and an optional continuity correction</span>
<span class="sd">    see `scipy.stats.mannwhitneyu`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x,y : array_like</span>
<span class="sd">        The data from the two samples.</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis. Default is &#39;two-sided&#39;.</span>
<span class="sd">        The following options are available:</span>

<span class="sd">        * &#39;two-sided&#39;: one of the distributions (underlying `x` or `y`) is</span>
<span class="sd">          stochastically greater than the other.</span>
<span class="sd">        * &#39;less&#39;: the distribution underlying `x` is stochastically less</span>
<span class="sd">          than the distribution underlying `y`.</span>
<span class="sd">        * &#39;greater&#39;: the distribution underlying `x` is stochastically greater</span>
<span class="sd">          than the distribution underlying `y`.</span>

<span class="sd">        .. versionadded:: 1.7.0</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float</span>
<span class="sd">        The test statistic under the large-sample approximation that the</span>
<span class="sd">        rank sum statistic is normally distributed.</span>
<span class="sd">    pvalue : float</span>
<span class="sd">        The p-value of the test.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] https://en.wikipedia.org/wiki/Wilcoxon_rank-sum_test</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    We can test the hypothesis that two independent unequal-sized samples are</span>
<span class="sd">    drawn from the same distribution with computing the Wilcoxon rank-sum</span>
<span class="sd">    statistic.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import ranksums</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">    &gt;&gt;&gt; sample1 = rng.uniform(-1, 1, 200)</span>
<span class="sd">    &gt;&gt;&gt; sample2 = rng.uniform(-0.5, 1.5, 300) # a shifted distribution</span>
<span class="sd">    &gt;&gt;&gt; ranksums(sample1, sample2)</span>
<span class="sd">    RanksumsResult(statistic=-7.887059,</span>
<span class="sd">                   pvalue=3.09390448e-15) # may vary</span>
<span class="sd">    &gt;&gt;&gt; ranksums(sample1, sample2, alternative=&#39;less&#39;)</span>
<span class="sd">    RanksumsResult(statistic=-7.750585297581713,</span>
<span class="sd">                   pvalue=4.573497606342543e-15) # may vary</span>
<span class="sd">    &gt;&gt;&gt; ranksums(sample1, sample2, alternative=&#39;greater&#39;)</span>
<span class="sd">    RanksumsResult(statistic=-7.750585297581713,</span>
<span class="sd">                   pvalue=0.9999999999999954) # may vary</span>

<span class="sd">    The p-value of less than ``0.05`` indicates that this test rejects the</span>
<span class="sd">    hypothesis at the 5% significance level.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
    <span class="n">n1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">n2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">alldata</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
    <span class="n">ranked</span> <span class="o">=</span> <span class="n">rankdata</span><span class="p">(</span><span class="n">alldata</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ranked</span><span class="p">[:</span><span class="n">n1</span><span class="p">]</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="n">n1</span> <span class="o">*</span> <span class="p">(</span><span class="n">n1</span><span class="o">+</span><span class="n">n2</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span> <span class="o">-</span> <span class="n">expected</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n1</span><span class="o">*</span><span class="n">n2</span><span class="o">*</span><span class="p">(</span><span class="n">n1</span><span class="o">+</span><span class="n">n2</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mf">12.0</span><span class="p">)</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="n">_normtest_finish</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">RanksumsResult</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span>


<span class="n">KruskalResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;KruskalResult&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">))</span>


<span class="nd">@_axis_nan_policy_factory</span><span class="p">(</span><span class="n">KruskalResult</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kruskal</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the Kruskal-Wallis H-test for independent samples.</span>

<span class="sd">    The Kruskal-Wallis H-test tests the null hypothesis that the population</span>
<span class="sd">    median of all of the groups are equal.  It is a non-parametric version of</span>
<span class="sd">    ANOVA.  The test works on 2 or more independent samples, which may have</span>
<span class="sd">    different sizes.  Note that rejecting the null hypothesis does not</span>
<span class="sd">    indicate which of the groups differs.  Post hoc comparisons between</span>
<span class="sd">    groups are required to determine which groups are different.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sample1, sample2, ... : array_like</span>
<span class="sd">       Two or more arrays with the sample measurements can be given as</span>
<span class="sd">       arguments. Samples must be one-dimensional.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float</span>
<span class="sd">       The Kruskal-Wallis H statistic, corrected for ties.</span>
<span class="sd">    pvalue : float</span>
<span class="sd">       The p-value for the test using the assumption that H has a chi</span>
<span class="sd">       square distribution. The p-value returned is the survival function of</span>
<span class="sd">       the chi square distribution evaluated at H.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    f_oneway : 1-way ANOVA.</span>
<span class="sd">    mannwhitneyu : Mann-Whitney rank test on two samples.</span>
<span class="sd">    friedmanchisquare : Friedman test for repeated measurements.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Due to the assumption that H has a chi square distribution, the number</span>
<span class="sd">    of samples in each group must not be too small.  A typical rule is</span>
<span class="sd">    that each sample must have at least 5 measurements.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] W. H. Kruskal &amp; W. W. Wallis, &quot;Use of Ranks in</span>
<span class="sd">       One-Criterion Variance Analysis&quot;, Journal of the American Statistical</span>
<span class="sd">       Association, Vol. 47, Issue 260, pp. 583-621, 1952.</span>
<span class="sd">    .. [2] https://en.wikipedia.org/wiki/Kruskal-Wallis_one-way_analysis_of_variance</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x = [1, 3, 5, 7, 9]</span>
<span class="sd">    &gt;&gt;&gt; y = [2, 4, 6, 8, 10]</span>
<span class="sd">    &gt;&gt;&gt; stats.kruskal(x, y)</span>
<span class="sd">    KruskalResult(statistic=0.2727272727272734, pvalue=0.6015081344405895)</span>

<span class="sd">    &gt;&gt;&gt; x = [1, 1, 1]</span>
<span class="sd">    &gt;&gt;&gt; y = [2, 2, 2]</span>
<span class="sd">    &gt;&gt;&gt; z = [2, 2]</span>
<span class="sd">    &gt;&gt;&gt; stats.kruskal(x, y, z)</span>
<span class="sd">    KruskalResult(statistic=7.0, pvalue=0.0301973834223185)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">,</span> <span class="n">samples</span><span class="p">))</span>

    <span class="n">num_groups</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_groups</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Need at least two groups in stats.kruskal()&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">sample</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">NaN</span> <span class="o">=</span> <span class="n">_get_nan</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">KruskalResult</span><span class="p">(</span><span class="n">NaN</span><span class="p">,</span> <span class="n">NaN</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">sample</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Samples must be one-dimensional.&quot;</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">samples</span><span class="p">)))</span>

    <span class="k">if</span> <span class="n">nan_policy</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;propagate&#39;</span><span class="p">,</span> <span class="s1">&#39;raise&#39;</span><span class="p">,</span> <span class="s1">&#39;omit&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;nan_policy must be &#39;propagate&#39;, &#39;raise&#39; or &#39;omit&#39;&quot;</span><span class="p">)</span>

    <span class="n">contains_nan</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
        <span class="n">cn</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cn</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">contains_nan</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">break</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">kruskal</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;propagate&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">KruskalResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

    <span class="n">alldata</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">ranked</span> <span class="o">=</span> <span class="n">rankdata</span><span class="p">(</span><span class="n">alldata</span><span class="p">)</span>
    <span class="n">ties</span> <span class="o">=</span> <span class="n">tiecorrect</span><span class="p">(</span><span class="n">ranked</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ties</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;All numbers are identical in kruskal&#39;</span><span class="p">)</span>

    <span class="c1"># Compute sum^2/n for each group and sum</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">ssbn</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_groups</span><span class="p">):</span>
        <span class="n">ssbn</span> <span class="o">+=</span> <span class="n">_square_of_sums</span><span class="p">(</span><span class="n">ranked</span><span class="p">[</span><span class="n">j</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span><span class="n">j</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]])</span> <span class="o">/</span> <span class="n">n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">totaln</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">12.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">totaln</span> <span class="o">*</span> <span class="p">(</span><span class="n">totaln</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">ssbn</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">*</span> <span class="p">(</span><span class="n">totaln</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">num_groups</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">h</span> <span class="o">/=</span> <span class="n">ties</span>

    <span class="k">return</span> <span class="n">KruskalResult</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">distributions</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">df</span><span class="p">))</span>


<span class="n">FriedmanchisquareResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;FriedmanchisquareResult&#39;</span><span class="p">,</span>
                                     <span class="p">(</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">friedmanchisquare</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the Friedman test for repeated samples.</span>

<span class="sd">    The Friedman test tests the null hypothesis that repeated samples of</span>
<span class="sd">    the same individuals have the same distribution.  It is often used</span>
<span class="sd">    to test for consistency among samples obtained in different ways.</span>
<span class="sd">    For example, if two sampling techniques are used on the same set of</span>
<span class="sd">    individuals, the Friedman test can be used to determine if the two</span>
<span class="sd">    sampling techniques are consistent.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sample1, sample2, sample3... : array_like</span>
<span class="sd">        Arrays of observations.  All of the arrays must have the same number</span>
<span class="sd">        of elements.  At least three samples must be given.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float</span>
<span class="sd">        The test statistic, correcting for ties.</span>
<span class="sd">    pvalue : float</span>
<span class="sd">        The associated p-value assuming that the test statistic has a chi</span>
<span class="sd">        squared distribution.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Due to the assumption that the test statistic has a chi squared</span>
<span class="sd">    distribution, the p-value is only reliable for n &gt; 10 and more than</span>
<span class="sd">    6 repeated samples.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] https://en.wikipedia.org/wiki/Friedman_test</span>
<span class="sd">    .. [2] P. Sprent and N.C. Smeeton, &quot;Applied Nonparametric Statistical</span>
<span class="sd">           Methods, Third Edition&quot;. Chapter 6, Section 6.3.2.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    In [2]_, the pulse rate (per minute) of a group of seven students was</span>
<span class="sd">    measured before exercise, immediately after exercise and 5 minutes</span>
<span class="sd">    after exercise. Is there evidence to suggest that the pulse rates on</span>
<span class="sd">    these three occasions are similar?</span>

<span class="sd">    We begin by formulating a null hypothesis :math:`H_0`:</span>

<span class="sd">        The pulse rates are identical on these three occasions.</span>

<span class="sd">    Let&#39;s assess the plausibility of this hypothesis with a Friedman test.</span>

<span class="sd">    &gt;&gt;&gt; from scipy.stats import friedmanchisquare</span>
<span class="sd">    &gt;&gt;&gt; before = [72, 96, 88, 92, 74, 76, 82]</span>
<span class="sd">    &gt;&gt;&gt; immediately_after = [120, 120, 132, 120, 101, 96, 112]</span>
<span class="sd">    &gt;&gt;&gt; five_min_after = [76, 95, 104, 96, 84, 72, 76]</span>
<span class="sd">    &gt;&gt;&gt; res = friedmanchisquare(before, immediately_after, five_min_after)</span>
<span class="sd">    &gt;&gt;&gt; res.statistic</span>
<span class="sd">    10.57142857142857</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.005063414171757498</span>

<span class="sd">    Using a significance level of 5%, we would reject the null hypothesis in</span>
<span class="sd">    favor of the alternative hypothesis: &quot;the pulse rates are different on</span>
<span class="sd">    these three occasions&quot;.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">k</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;At least 3 sets of samples must be given &#39;</span>
                         <span class="sa">f</span><span class="s1">&#39;for Friedman test, got </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">!=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unequal N in friedmanchisquare.  Aborting.&#39;</span><span class="p">)</span>

    <span class="c1"># Rank data</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
        <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rankdata</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="c1"># Handle ties</span>
    <span class="n">ties</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="n">replist</span><span class="p">,</span> <span class="n">repnum</span> <span class="o">=</span> <span class="n">find_repeats</span><span class="p">(</span><span class="n">array</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">repnum</span><span class="p">:</span>
            <span class="n">ties</span> <span class="o">+=</span> <span class="n">t</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span><span class="o">*</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ties</span> <span class="o">/</span> <span class="p">(</span><span class="n">k</span><span class="o">*</span><span class="p">(</span><span class="n">k</span><span class="o">*</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">n</span><span class="p">)</span>

    <span class="n">ssbn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">chisq</span> <span class="o">=</span> <span class="p">(</span><span class="mf">12.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">k</span><span class="o">*</span><span class="n">n</span><span class="o">*</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">ssbn</span> <span class="o">-</span> <span class="mi">3</span><span class="o">*</span><span class="n">n</span><span class="o">*</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">c</span>

    <span class="k">return</span> <span class="n">FriedmanchisquareResult</span><span class="p">(</span><span class="n">chisq</span><span class="p">,</span> <span class="n">distributions</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">chisq</span><span class="p">,</span> <span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>


<span class="n">BrunnerMunzelResult</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;BrunnerMunzelResult&#39;</span><span class="p">,</span>
                                 <span class="p">(</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;pvalue&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">brunnermunzel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;two-sided&quot;</span><span class="p">,</span> <span class="n">distribution</span><span class="o">=</span><span class="s2">&quot;t&quot;</span><span class="p">,</span>
                  <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the Brunner-Munzel test on samples x and y.</span>

<span class="sd">    The Brunner-Munzel test is a nonparametric test of the null hypothesis that</span>
<span class="sd">    when values are taken one by one from each group, the probabilities of</span>
<span class="sd">    getting large values in both groups are equal.</span>
<span class="sd">    Unlike the Wilcoxon-Mann-Whitney&#39;s U test, this does not require the</span>
<span class="sd">    assumption of equivariance of two groups. Note that this does not assume</span>
<span class="sd">    the distributions are same. This test works on two independent samples,</span>
<span class="sd">    which may have different sizes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x, y : array_like</span>
<span class="sd">        Array of samples, should be one-dimensional.</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis.</span>
<span class="sd">        The following options are available (default is &#39;two-sided&#39;):</span>

<span class="sd">          * &#39;two-sided&#39;</span>
<span class="sd">          * &#39;less&#39;: one-sided</span>
<span class="sd">          * &#39;greater&#39;: one-sided</span>
<span class="sd">    distribution : {&#39;t&#39;, &#39;normal&#39;}, optional</span>
<span class="sd">        Defines how to get the p-value.</span>
<span class="sd">        The following options are available (default is &#39;t&#39;):</span>

<span class="sd">          * &#39;t&#39;: get the p-value by t-distribution</span>
<span class="sd">          * &#39;normal&#39;: get the p-value by standard normal distribution.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;raise&#39;, &#39;omit&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: returns nan</span>
<span class="sd">          * &#39;raise&#39;: throws an error</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float</span>
<span class="sd">        The Brunner-Munzer W statistic.</span>
<span class="sd">    pvalue : float</span>
<span class="sd">        p-value assuming an t distribution. One-sided or</span>
<span class="sd">        two-sided, depending on the choice of `alternative` and `distribution`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    mannwhitneyu : Mann-Whitney rank test on two samples.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Brunner and Munzel recommended to estimate the p-value by t-distribution</span>
<span class="sd">    when the size of data is 50 or less. If the size is lower than 10, it would</span>
<span class="sd">    be better to use permuted Brunner Munzel test (see [2]_).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Brunner, E. and Munzel, U. &quot;The nonparametric Benhrens-Fisher</span>
<span class="sd">           problem: Asymptotic theory and a small-sample approximation&quot;.</span>
<span class="sd">           Biometrical Journal. Vol. 42(2000): 17-25.</span>
<span class="sd">    .. [2] Neubert, K. and Brunner, E. &quot;A studentized permutation test for the</span>
<span class="sd">           non-parametric Behrens-Fisher problem&quot;. Computational Statistics and</span>
<span class="sd">           Data Analysis. Vol. 51(2007): 5192-5204.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; x1 = [1,2,1,1,1,1,1,1,1,1,2,4,1,1]</span>
<span class="sd">    &gt;&gt;&gt; x2 = [3,3,4,3,1,2,3,1,1,5,4]</span>
<span class="sd">    &gt;&gt;&gt; w, p_value = stats.brunnermunzel(x1, x2)</span>
<span class="sd">    &gt;&gt;&gt; w</span>
<span class="sd">    3.1374674823029505</span>
<span class="sd">    &gt;&gt;&gt; p_value</span>
<span class="sd">    0.0057862086661515377</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># check both x and y</span>
    <span class="n">cnx</span><span class="p">,</span> <span class="n">npx</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>
    <span class="n">cny</span><span class="p">,</span> <span class="n">npy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>
    <span class="n">contains_nan</span> <span class="o">=</span> <span class="n">cnx</span> <span class="ow">or</span> <span class="n">cny</span>
    <span class="k">if</span> <span class="n">npx</span> <span class="o">==</span> <span class="s2">&quot;omit&quot;</span> <span class="ow">or</span> <span class="n">npy</span> <span class="o">==</span> <span class="s2">&quot;omit&quot;</span><span class="p">:</span>
        <span class="n">nan_policy</span> <span class="o">=</span> <span class="s2">&quot;omit&quot;</span>

    <span class="k">if</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s2">&quot;propagate&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">BrunnerMunzelResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">contains_nan</span> <span class="ow">and</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s2">&quot;omit&quot;</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">ma</span><span class="o">.</span><span class="n">masked_invalid</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mstats_basic</span><span class="o">.</span><span class="n">brunnermunzel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alternative</span><span class="p">,</span> <span class="n">distribution</span><span class="p">)</span>

    <span class="n">nx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ny</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">nx</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">ny</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">BrunnerMunzelResult</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
    <span class="n">rankc</span> <span class="o">=</span> <span class="n">rankdata</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)))</span>
    <span class="n">rankcx</span> <span class="o">=</span> <span class="n">rankc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">nx</span><span class="p">]</span>
    <span class="n">rankcy</span> <span class="o">=</span> <span class="n">rankc</span><span class="p">[</span><span class="n">nx</span><span class="p">:</span><span class="n">nx</span><span class="o">+</span><span class="n">ny</span><span class="p">]</span>
    <span class="n">rankcx_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rankcx</span><span class="p">)</span>
    <span class="n">rankcy_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rankcy</span><span class="p">)</span>
    <span class="n">rankx</span> <span class="o">=</span> <span class="n">rankdata</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ranky</span> <span class="o">=</span> <span class="n">rankdata</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">rankx_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rankx</span><span class="p">)</span>
    <span class="n">ranky_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ranky</span><span class="p">)</span>

    <span class="n">Sx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">rankcx</span> <span class="o">-</span> <span class="n">rankx</span> <span class="o">-</span> <span class="n">rankcx_mean</span> <span class="o">+</span> <span class="n">rankx_mean</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span>
    <span class="n">Sx</span> <span class="o">/=</span> <span class="n">nx</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">Sy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">rankcy</span> <span class="o">-</span> <span class="n">ranky</span> <span class="o">-</span> <span class="n">rankcy_mean</span> <span class="o">+</span> <span class="n">ranky_mean</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span>
    <span class="n">Sy</span> <span class="o">/=</span> <span class="n">ny</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">wbfn</span> <span class="o">=</span> <span class="n">nx</span> <span class="o">*</span> <span class="n">ny</span> <span class="o">*</span> <span class="p">(</span><span class="n">rankcy_mean</span> <span class="o">-</span> <span class="n">rankcx_mean</span><span class="p">)</span>
    <span class="n">wbfn</span> <span class="o">/=</span> <span class="p">(</span><span class="n">nx</span> <span class="o">+</span> <span class="n">ny</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">nx</span> <span class="o">*</span> <span class="n">Sx</span> <span class="o">+</span> <span class="n">ny</span> <span class="o">*</span> <span class="n">Sy</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">distribution</span> <span class="o">==</span> <span class="s2">&quot;t&quot;</span><span class="p">:</span>
        <span class="n">df_numer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">nx</span> <span class="o">*</span> <span class="n">Sx</span> <span class="o">+</span> <span class="n">ny</span> <span class="o">*</span> <span class="n">Sy</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span>
        <span class="n">df_denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">nx</span> <span class="o">*</span> <span class="n">Sx</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">nx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">df_denom</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">ny</span> <span class="o">*</span> <span class="n">Sy</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">ny</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df_numer</span> <span class="o">/</span> <span class="n">df_denom</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">df_numer</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">df_denom</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">message</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;p-value cannot be estimated with `distribution=&#39;t&#39; &quot;</span>
                       <span class="s2">&quot;because degrees of freedom parameter is undefined &quot;</span>
                       <span class="s2">&quot;(0/0). Try using `distribution=&#39;normal&#39;&quot;</span><span class="p">)</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">p</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">wbfn</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">distribution</span> <span class="o">==</span> <span class="s2">&quot;normal&quot;</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">wbfn</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;distribution should be &#39;t&#39; or &#39;normal&#39;&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s2">&quot;greater&quot;</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s2">&quot;less&quot;</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p</span>
    <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s2">&quot;two-sided&quot;</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;alternative should be &#39;less&#39;, &#39;greater&#39; or &#39;two-sided&#39;&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">BrunnerMunzelResult</span><span class="p">(</span><span class="n">wbfn</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">combine_pvalues</span><span class="p">(</span><span class="n">pvalues</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;fisher&#39;</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Combine p-values from independent tests that bear upon the same hypothesis.</span>

<span class="sd">    These methods are intended only for combining p-values from hypothesis</span>
<span class="sd">    tests based upon continuous distributions.</span>

<span class="sd">    Each method assumes that under the null hypothesis, the p-values are</span>
<span class="sd">    sampled independently and uniformly from the interval [0, 1]. A test</span>
<span class="sd">    statistic (different for each method) is computed and a combined</span>
<span class="sd">    p-value is calculated based upon the distribution of this test statistic</span>
<span class="sd">    under the null hypothesis.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pvalues : array_like, 1-D</span>
<span class="sd">        Array of p-values assumed to come from independent tests based on</span>
<span class="sd">        continuous distributions.</span>
<span class="sd">    method : {&#39;fisher&#39;, &#39;pearson&#39;, &#39;tippett&#39;, &#39;stouffer&#39;, &#39;mudholkar_george&#39;}</span>

<span class="sd">        Name of method to use to combine p-values.</span>

<span class="sd">        The available methods are (see Notes for details):</span>

<span class="sd">        * &#39;fisher&#39;: Fisher&#39;s method (Fisher&#39;s combined probability test)</span>
<span class="sd">        * &#39;pearson&#39;: Pearson&#39;s method</span>
<span class="sd">        * &#39;mudholkar_george&#39;: Mudholkar&#39;s and George&#39;s method</span>
<span class="sd">        * &#39;tippett&#39;: Tippett&#39;s method</span>
<span class="sd">        * &#39;stouffer&#39;: Stouffer&#39;s Z-score method</span>
<span class="sd">    weights : array_like, 1-D, optional</span>
<span class="sd">        Optional array of weights used only for Stouffer&#39;s Z-score method.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    res : SignificanceResult</span>
<span class="sd">        An object containing attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            The statistic calculated by the specified method.</span>
<span class="sd">        pvalue : float</span>
<span class="sd">            The combined p-value.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Suppose we wish to combine p-values from four independent tests</span>
<span class="sd">    of the same null hypothesis using Fisher&#39;s method (default).</span>

<span class="sd">    &gt;&gt;&gt; from scipy.stats import combine_pvalues</span>
<span class="sd">    &gt;&gt;&gt; pvalues = [0.1, 0.05, 0.02, 0.3]</span>
<span class="sd">    &gt;&gt;&gt; combine_pvalues(pvalues)</span>
<span class="sd">    SignificanceResult(statistic=20.828626352604235, pvalue=0.007616871850449092)</span>

<span class="sd">    When the individual p-values carry different weights, consider Stouffer&#39;s</span>
<span class="sd">    method.</span>

<span class="sd">    &gt;&gt;&gt; weights = [1, 2, 3, 4]</span>
<span class="sd">    &gt;&gt;&gt; res = combine_pvalues(pvalues, method=&#39;stouffer&#39;, weights=weights)</span>
<span class="sd">    &gt;&gt;&gt; res.pvalue</span>
<span class="sd">    0.009578891494533616</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If this function is applied to tests with a discrete statistics such as</span>
<span class="sd">    any rank test or contingency-table test, it will yield systematically</span>
<span class="sd">    wrong results, e.g. Fisher&#39;s method will systematically overestimate the</span>
<span class="sd">    p-value [1]_. This problem becomes less severe for large sample sizes</span>
<span class="sd">    when the discrete distributions become approximately continuous.</span>

<span class="sd">    The differences between the methods can be best illustrated by their</span>
<span class="sd">    statistics and what aspects of a combination of p-values they emphasise</span>
<span class="sd">    when considering significance [2]_. For example, methods emphasising large</span>
<span class="sd">    p-values are more sensitive to strong false and true negatives; conversely</span>
<span class="sd">    methods focussing on small p-values are sensitive to positives.</span>

<span class="sd">    * The statistics of Fisher&#39;s method (also known as Fisher&#39;s combined</span>
<span class="sd">      probability test) [3]_ is :math:`-2\\sum_i \\log(p_i)`, which is</span>
<span class="sd">      equivalent (as a test statistics) to the product of individual p-values:</span>
<span class="sd">      :math:`\\prod_i p_i`. Under the null hypothesis, this statistics follows</span>
<span class="sd">      a :math:`\\chi^2` distribution. This method emphasises small p-values.</span>
<span class="sd">    * Pearson&#39;s method uses :math:`-2\\sum_i\\log(1-p_i)`, which is equivalent</span>
<span class="sd">      to :math:`\\prod_i \\frac{1}{1-p_i}` [2]_.</span>
<span class="sd">      It thus emphasises large p-values.</span>
<span class="sd">    * Mudholkar and George compromise between Fisher&#39;s and Pearson&#39;s method by</span>
<span class="sd">      averaging their statistics [4]_. Their method emphasises extreme</span>
<span class="sd">      p-values, both close to 1 and 0.</span>
<span class="sd">    * Stouffer&#39;s method [5]_ uses Z-scores and the statistic:</span>
<span class="sd">      :math:`\\sum_i \\Phi^{-1} (p_i)`, where :math:`\\Phi` is the CDF of the</span>
<span class="sd">      standard normal distribution. The advantage of this method is that it is</span>
<span class="sd">      straightforward to introduce weights, which can make Stouffer&#39;s method</span>
<span class="sd">      more powerful than Fisher&#39;s method when the p-values are from studies</span>
<span class="sd">      of different size [6]_ [7]_.</span>
<span class="sd">    * Tippett&#39;s method uses the smallest p-value as a statistic.</span>
<span class="sd">      (Mind that this minimum is not the combined p-value.)</span>

<span class="sd">    Fisher&#39;s method may be extended to combine p-values from dependent tests</span>
<span class="sd">    [8]_. Extensions such as Brown&#39;s method and Kost&#39;s method are not currently</span>
<span class="sd">    implemented.</span>

<span class="sd">    .. versionadded:: 0.15.0</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Kincaid, W. M., &quot;The Combination of Tests Based on Discrete</span>
<span class="sd">           Distributions.&quot; Journal of the American Statistical Association 57,</span>
<span class="sd">           no. 297 (1962), 10-19.</span>
<span class="sd">    .. [2] Heard, N. and Rubin-Delanchey, P. &quot;Choosing between methods of</span>
<span class="sd">           combining p-values.&quot;  Biometrika 105.1 (2018): 239-246.</span>
<span class="sd">    .. [3] https://en.wikipedia.org/wiki/Fisher%27s_method</span>
<span class="sd">    .. [4] George, E. O., and G. S. Mudholkar. &quot;On the convolution of logistic</span>
<span class="sd">           random variables.&quot; Metrika 30.1 (1983): 1-13.</span>
<span class="sd">    .. [5] https://en.wikipedia.org/wiki/Fisher%27s_method#Relation_to_Stouffer.27s_Z-score_method</span>
<span class="sd">    .. [6] Whitlock, M. C. &quot;Combining probability from independent tests: the</span>
<span class="sd">           weighted Z-method is superior to Fisher&#39;s approach.&quot; Journal of</span>
<span class="sd">           Evolutionary Biology 18, no. 5 (2005): 1368-1373.</span>
<span class="sd">    .. [7] Zaykin, Dmitri V. &quot;Optimally weighted Z-test is a powerful method</span>
<span class="sd">           for combining probabilities in meta-analysis.&quot; Journal of</span>
<span class="sd">           Evolutionary Biology 24, no. 8 (2011): 1836-1841.</span>
<span class="sd">    .. [8] https://en.wikipedia.org/wiki/Extensions_of_Fisher%27s_method</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pvalues</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">pvalues</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pvalues</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pvalues is not 1-D&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;fisher&#39;</span><span class="p">:</span>
        <span class="n">statistic</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pvalues</span><span class="p">))</span>
        <span class="n">pval</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">pvalues</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;pearson&#39;</span><span class="p">:</span>
        <span class="n">statistic</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="o">-</span><span class="n">pvalues</span><span class="p">))</span>
        <span class="n">pval</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="n">statistic</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">pvalues</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;mudholkar_george&#39;</span><span class="p">:</span>
        <span class="n">normalizing_factor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">pvalues</span><span class="p">))</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span>
        <span class="n">statistic</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pvalues</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="o">-</span><span class="n">pvalues</span><span class="p">))</span>
        <span class="n">nu</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">pvalues</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span>
        <span class="n">approx_factor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">nu</span> <span class="o">/</span> <span class="p">(</span><span class="n">nu</span> <span class="o">-</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">pval</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">statistic</span> <span class="o">*</span> <span class="n">normalizing_factor</span>
                                  <span class="o">*</span> <span class="n">approx_factor</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;tippett&#39;</span><span class="p">:</span>
        <span class="n">statistic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">pvalues</span><span class="p">)</span>
        <span class="n">pval</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pvalues</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;stouffer&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">pvalues</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pvalues</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pvalues and weights must be of the same size.&quot;</span><span class="p">)</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weights</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;weights is not 1-D&quot;</span><span class="p">)</span>

        <span class="n">Zi</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">isf</span><span class="p">(</span><span class="n">pvalues</span><span class="p">)</span>
        <span class="n">statistic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">Zi</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">pval</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">statistic</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Invalid method </span><span class="si">{</span><span class="n">method</span><span class="si">!r}</span><span class="s2">. Valid methods are &#39;fisher&#39;, &quot;</span>
            <span class="s2">&quot;&#39;pearson&#39;, &#39;mudholkar_george&#39;, &#39;tippett&#39;, and &#39;stouffer&#39;&quot;</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">SignificanceResult</span><span class="p">(</span><span class="n">statistic</span><span class="p">,</span> <span class="n">pval</span><span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">QuantileTestResult</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Result of `scipy.stats.quantile_test`.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    statistic: float</span>
<span class="sd">        The statistic used to calculate the p-value; either ``T1``, the</span>
<span class="sd">        number of observations less than or equal to the hypothesized quantile,</span>
<span class="sd">        or ``T2``, the number of observations strictly less than the</span>
<span class="sd">        hypothesized quantile. Two test statistics are required to handle the</span>
<span class="sd">        possibility the data was generated from a discrete or mixed</span>
<span class="sd">        distribution.</span>

<span class="sd">    statistic_type : int</span>
<span class="sd">        ``1`` or ``2`` depending on which of ``T1`` or ``T2`` was used to</span>
<span class="sd">        calculate the p-value respectively. ``T1`` corresponds to the</span>
<span class="sd">        ``&quot;greater&quot;`` alternative hypothesis and ``T2`` to the ``&quot;less&quot;``.  For</span>
<span class="sd">        the ``&quot;two-sided&quot;`` case, the statistic type that leads to smallest</span>
<span class="sd">        p-value is used.  For significant tests, ``statistic_type = 1`` means</span>
<span class="sd">        there is evidence that the population quantile is significantly greater</span>
<span class="sd">        than the hypothesized value and ``statistic_type = 2`` means there is</span>
<span class="sd">        evidence that it is significantly less than the hypothesized value.</span>

<span class="sd">    pvalue : float</span>
<span class="sd">        The p-value of the hypothesis test.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">statistic</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">statistic_type</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">pvalue</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">_alternative</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="nb">repr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">_x</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="nb">repr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">_p</span> <span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="nb">repr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">confidence_interval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the confidence interval of the quantile.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        confidence_level : float, default: 0.95</span>
<span class="sd">            Confidence level for the computed confidence interval</span>
<span class="sd">            of the quantile. Default is 0.95.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ci : ``ConfidenceInterval`` object</span>
<span class="sd">            The object has attributes ``low`` and ``high`` that hold the</span>
<span class="sd">            lower and upper bounds of the confidence interval.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import scipy.stats as stats</span>
<span class="sd">        &gt;&gt;&gt; p = 0.75  # quantile of interest</span>
<span class="sd">        &gt;&gt;&gt; q = 0  # hypothesized value of the quantile</span>
<span class="sd">        &gt;&gt;&gt; x = np.exp(np.arange(0, 1.01, 0.01))</span>
<span class="sd">        &gt;&gt;&gt; res = stats.quantile_test(x, q=q, p=p, alternative=&#39;less&#39;)</span>
<span class="sd">        &gt;&gt;&gt; lb, ub = res.confidence_interval()</span>
<span class="sd">        &gt;&gt;&gt; lb, ub</span>
<span class="sd">        (-inf, 2.293318740264183)</span>
<span class="sd">        &gt;&gt;&gt; res = stats.quantile_test(x, q=q, p=p, alternative=&#39;two-sided&#39;)</span>
<span class="sd">        &gt;&gt;&gt; lb, ub = res.confidence_interval(0.9)</span>
<span class="sd">        &gt;&gt;&gt; lb, ub</span>
<span class="sd">        (1.9542373206359396, 2.293318740264183)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">alternative</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alternative</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_p</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_x</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">bd</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">confidence_level</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">confidence_level</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;`confidence_level` must be a number between 0 and 1.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

        <span class="n">low_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">high_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

        <span class="k">if</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;less&#39;</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">confidence_level</span>
            <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="n">high_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">bd</span><span class="o">.</span><span class="n">isf</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
            <span class="n">high</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">high_index</span><span class="p">]</span> <span class="k">if</span> <span class="n">high_index</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;greater&#39;</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">confidence_level</span>
            <span class="n">low_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">bd</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">low</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">low_index</span><span class="p">]</span> <span class="k">if</span> <span class="n">low_index</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">elif</span> <span class="n">alternative</span> <span class="o">==</span> <span class="s1">&#39;two-sided&#39;</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">confidence_level</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">low_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">bd</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">low</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">low_index</span><span class="p">]</span> <span class="k">if</span> <span class="n">low_index</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="n">high_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">bd</span><span class="o">.</span><span class="n">isf</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
            <span class="n">high</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">high_index</span><span class="p">]</span> <span class="k">if</span> <span class="n">high_index</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

        <span class="k">return</span> <span class="n">ConfidenceInterval</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">quantile_test_iv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">alternative</span><span class="p">):</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;`x` must be a one-dimensional array of numbers.&#39;</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">q</span><span class="p">)[()]</span>
    <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;`q` must be a scalar.&quot;</span>
    <span class="k">if</span> <span class="n">q</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">p</span><span class="p">)[()]</span>
    <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;`p` must be a float strictly between 0 and 1.&quot;</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">p</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">p</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="n">alternatives</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;two-sided&#39;</span><span class="p">,</span> <span class="s1">&#39;less&#39;</span><span class="p">,</span> <span class="s1">&#39;greater&#39;</span><span class="p">}</span>
    <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;`alternative` must be one of </span><span class="si">{</span><span class="n">alternatives</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">if</span> <span class="n">alternative</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">alternatives</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">alternative</span>


<span class="k">def</span><span class="w"> </span><span class="nf">quantile_test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform a quantile test and compute a confidence interval of the quantile.</span>

<span class="sd">    This function tests the null hypothesis that `q` is the value of the</span>
<span class="sd">    quantile associated with probability `p` of the population underlying</span>
<span class="sd">    sample `x`. For example, with default parameters, it tests that the</span>
<span class="sd">    median of the population underlying `x` is zero. The function returns an</span>
<span class="sd">    object including the test statistic, a p-value, and a method for computing</span>
<span class="sd">    the confidence interval around the quantile.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : array_like</span>
<span class="sd">        A one-dimensional sample.</span>
<span class="sd">    q : float, default: 0</span>
<span class="sd">        The hypothesized value of the quantile.</span>
<span class="sd">    p : float, default: 0.5</span>
<span class="sd">        The probability associated with the quantile; i.e. the proportion of</span>
<span class="sd">        the population less than `q` is `p`. Must be strictly between 0 and</span>
<span class="sd">        1.</span>
<span class="sd">    alternative : {&#39;two-sided&#39;, &#39;less&#39;, &#39;greater&#39;}, optional</span>
<span class="sd">        Defines the alternative hypothesis.</span>
<span class="sd">        The following options are available (default is &#39;two-sided&#39;):</span>

<span class="sd">        * &#39;two-sided&#39;: the quantile associated with the probability `p`</span>
<span class="sd">          is not `q`.</span>
<span class="sd">        * &#39;less&#39;: the quantile associated with the probability `p` is less</span>
<span class="sd">          than `q`.</span>
<span class="sd">        * &#39;greater&#39;: the quantile associated with the probability `p` is</span>
<span class="sd">          greater than `q`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : QuantileTestResult</span>
<span class="sd">        An object with the following attributes:</span>

<span class="sd">        statistic : float</span>
<span class="sd">            One of two test statistics that may be used in the quantile test.</span>
<span class="sd">            The first test statistic, ``T1``, is the proportion of samples in</span>
<span class="sd">            `x` that are less than or equal to the hypothesized quantile</span>
<span class="sd">            `q`. The second test statistic, ``T2``, is the proportion of</span>
<span class="sd">            samples in `x` that are strictly less than the hypothesized</span>
<span class="sd">            quantile `q`.</span>

<span class="sd">            When ``alternative = &#39;greater&#39;``, ``T1`` is used to calculate the</span>
<span class="sd">            p-value and ``statistic`` is set to ``T1``.</span>

<span class="sd">            When ``alternative = &#39;less&#39;``, ``T2`` is used to calculate the</span>
<span class="sd">            p-value and ``statistic`` is set to ``T2``.</span>

<span class="sd">            When ``alternative = &#39;two-sided&#39;``, both ``T1`` and ``T2`` are</span>
<span class="sd">            considered, and the one that leads to the smallest p-value is used.</span>

<span class="sd">        statistic_type : int</span>
<span class="sd">            Either `1` or `2` depending on which of ``T1`` or ``T2`` was</span>
<span class="sd">            used to calculate the p-value.</span>

<span class="sd">        pvalue : float</span>
<span class="sd">            The p-value associated with the given alternative.</span>

<span class="sd">        The object also has the following method:</span>

<span class="sd">        confidence_interval(confidence_level=0.95)</span>
<span class="sd">            Computes a confidence interval around the the</span>
<span class="sd">            population quantile associated with the probability `p`. The</span>
<span class="sd">            confidence interval is returned in a ``namedtuple`` with</span>
<span class="sd">            fields `low` and `high`.  Values are `nan` when there are</span>
<span class="sd">            not enough observations to compute the confidence interval at</span>
<span class="sd">            the desired confidence.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This test and its method for computing confidence intervals are</span>
<span class="sd">    non-parametric. They are valid if and only if the observations are i.i.d.</span>

<span class="sd">    The implementation of the test follows Conover [1]_. Two test statistics</span>
<span class="sd">    are considered.</span>

<span class="sd">    ``T1``: The number of observations in `x` less than or equal to `q`.</span>

<span class="sd">        ``T1 = (x &lt;= q).sum()``</span>

<span class="sd">    ``T2``: The number of observations in `x` strictly less than `q`.</span>

<span class="sd">        ``T2 = (x &lt; q).sum()``</span>

<span class="sd">    The use of two test statistics is necessary to handle the possibility that</span>
<span class="sd">    `x` was generated from a discrete or mixed distribution.</span>

<span class="sd">    The null hypothesis for the test is:</span>

<span class="sd">        H0: The :math:`p^{\mathrm{th}}` population quantile is `q`.</span>

<span class="sd">    and the null distribution for each test statistic is</span>
<span class="sd">    :math:`\mathrm{binom}\left(n, p\right)`. When ``alternative=&#39;less&#39;``,</span>
<span class="sd">    the alternative hypothesis is:</span>

<span class="sd">        H1: The :math:`p^{\mathrm{th}}` population quantile is less than `q`.</span>

<span class="sd">    and the p-value is the probability that the binomial random variable</span>

<span class="sd">    .. math::</span>
<span class="sd">        Y \sim \mathrm{binom}\left(n, p\right)</span>

<span class="sd">    is greater than or equal to the observed value ``T2``.</span>

<span class="sd">    When ``alternative=&#39;greater&#39;``, the alternative hypothesis is:</span>

<span class="sd">        H1: The :math:`p^{\mathrm{th}}` population quantile is greater than `q`</span>

<span class="sd">    and the p-value is the probability that the binomial random variable Y</span>
<span class="sd">    is less than or equal to the observed value ``T1``.</span>

<span class="sd">    When ``alternative=&#39;two-sided&#39;``, the alternative hypothesis is</span>

<span class="sd">        H1: `q` is not the :math:`p^{\mathrm{th}}` population quantile.</span>

<span class="sd">    and the p-value is twice the smaller of the p-values for the ``&#39;less&#39;``</span>
<span class="sd">    and ``&#39;greater&#39;`` cases. Both of these p-values can exceed 0.5 for the same</span>
<span class="sd">    data, so the value is clipped into the interval :math:`[0, 1]`.</span>

<span class="sd">    The approach for confidence intervals is attributed to Thompson [2]_ and</span>
<span class="sd">    later proven to be applicable to any set of i.i.d. samples [3]_. The</span>
<span class="sd">    computation is based on the observation that the probability of a quantile</span>
<span class="sd">    :math:`q` to be larger than any observations :math:`x_m (1\leq m \leq N)`</span>
<span class="sd">    can be computed as</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathbb{P}(x_m \leq q) = 1 - \sum_{k=0}^{m-1} \binom{N}{k}</span>
<span class="sd">        q^k(1-q)^{N-k}</span>

<span class="sd">    By default, confidence intervals are computed for a 95% confidence level.</span>
<span class="sd">    A common interpretation of a 95% confidence intervals is that if i.i.d.</span>
<span class="sd">    samples are drawn repeatedly from the same population and confidence</span>
<span class="sd">    intervals are formed each time, the confidence interval will contain the</span>
<span class="sd">    true value of the specified quantile in approximately 95% of trials.</span>

<span class="sd">    A similar function is available in the QuantileNPCI R package [4]_. The</span>
<span class="sd">    foundation is the same, but it computes the confidence interval bounds by</span>
<span class="sd">    doing interpolations between the sample values, whereas this function uses</span>
<span class="sd">    only sample values as bounds. Thus, ``quantile_test.confidence_interval``</span>
<span class="sd">    returns more conservative intervals (i.e., larger).</span>

<span class="sd">    The same computation of confidence intervals for quantiles is included in</span>
<span class="sd">    the confintr package [5]_.</span>

<span class="sd">    Two-sided confidence intervals are not guaranteed to be optimal; i.e.,</span>
<span class="sd">    there may exist a tighter interval that may contain the quantile of</span>
<span class="sd">    interest with probability larger than the confidence level.</span>
<span class="sd">    Without further assumption on the samples (e.g., the nature of the</span>
<span class="sd">    underlying distribution), the one-sided intervals are optimally tight.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] W. J. Conover. Practical Nonparametric Statistics, 3rd Ed. 1999.</span>
<span class="sd">    .. [2] W. R. Thompson, &quot;On Confidence Ranges for the Median and Other</span>
<span class="sd">       Expectation Distributions for Populations of Unknown Distribution</span>
<span class="sd">       Form,&quot; The Annals of Mathematical Statistics, vol. 7, no. 3,</span>
<span class="sd">       pp. 122-128, 1936, Accessed: Sep. 18, 2019. [Online]. Available:</span>
<span class="sd">       https://www.jstor.org/stable/2957563.</span>
<span class="sd">    .. [3] H. A. David and H. N. Nagaraja, &quot;Order Statistics in Nonparametric</span>
<span class="sd">       Inference&quot; in Order Statistics, John Wiley &amp; Sons, Ltd, 2005, pp.</span>
<span class="sd">       159-170. Available:</span>
<span class="sd">       https://onlinelibrary.wiley.com/doi/10.1002/0471722162.ch7.</span>
<span class="sd">    .. [4] N. Hutson, A. Hutson, L. Yan, &quot;QuantileNPCI: Nonparametric</span>
<span class="sd">       Confidence Intervals for Quantiles,&quot; R package,</span>
<span class="sd">       https://cran.r-project.org/package=QuantileNPCI</span>
<span class="sd">    .. [5] M. Mayer, &quot;confintr: Confidence Intervals,&quot; R package,</span>
<span class="sd">       https://cran.r-project.org/package=confintr</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    Suppose we wish to test the null hypothesis that the median of a population</span>
<span class="sd">    is equal to 0.5. We choose a confidence level of 99%; that is, we will</span>
<span class="sd">    reject the null hypothesis in favor of the alternative if the p-value is</span>
<span class="sd">    less than 0.01.</span>

<span class="sd">    When testing random variates from the standard uniform distribution, which</span>
<span class="sd">    has a median of 0.5, we expect the data to be consistent with the null</span>
<span class="sd">    hypothesis most of the time.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; rng = np.random.default_rng(6981396440634228121)</span>
<span class="sd">    &gt;&gt;&gt; rvs = stats.uniform.rvs(size=100, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.quantile_test(rvs, q=0.5, p=0.5)</span>
<span class="sd">    QuantileTestResult(statistic=45, statistic_type=1, pvalue=0.36820161732669576)</span>

<span class="sd">    As expected, the p-value is not below our threshold of 0.01, so</span>
<span class="sd">    we cannot reject the null hypothesis.</span>

<span class="sd">    When testing data from the standard *normal* distribution, which has a</span>
<span class="sd">    median of 0, we would expect the null hypothesis to be rejected.</span>

<span class="sd">    &gt;&gt;&gt; rvs = stats.norm.rvs(size=100, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.quantile_test(rvs, q=0.5, p=0.5)</span>
<span class="sd">    QuantileTestResult(statistic=67, statistic_type=2, pvalue=0.0008737198369123724)</span>

<span class="sd">    Indeed, the p-value is lower than our threshold of 0.01, so we reject the</span>
<span class="sd">    null hypothesis in favor of the default &quot;two-sided&quot; alternative: the median</span>
<span class="sd">    of the population is *not* equal to 0.5.</span>

<span class="sd">    However, suppose we were to test the null hypothesis against the</span>
<span class="sd">    one-sided alternative that the median of the population is *greater* than</span>
<span class="sd">    0.5. Since the median of the standard normal is less than 0.5, we would not</span>
<span class="sd">    expect the null hypothesis to be rejected.</span>

<span class="sd">    &gt;&gt;&gt; stats.quantile_test(rvs, q=0.5, p=0.5, alternative=&#39;greater&#39;)</span>
<span class="sd">    QuantileTestResult(statistic=67, statistic_type=1, pvalue=0.9997956114162866)</span>

<span class="sd">    Unsurprisingly, with a p-value greater than our threshold, we would not</span>
<span class="sd">    reject the null hypothesis in favor of the chosen alternative.</span>

<span class="sd">    The quantile test can be used for any quantile, not only the median. For</span>
<span class="sd">    example, we can test whether the third quartile of the distribution</span>
<span class="sd">    underlying the sample is greater than 0.6.</span>

<span class="sd">    &gt;&gt;&gt; rvs = stats.uniform.rvs(size=100, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; stats.quantile_test(rvs, q=0.6, p=0.75, alternative=&#39;greater&#39;)</span>
<span class="sd">    QuantileTestResult(statistic=64, statistic_type=1, pvalue=0.00940696592998271)</span>

<span class="sd">    The p-value is lower than the threshold. We reject the null hypothesis in</span>
<span class="sd">    favor of the alternative: the third quartile of the distribution underlying</span>
<span class="sd">    our sample is greater than 0.6.</span>

<span class="sd">    `quantile_test` can also compute confidence intervals for any quantile.</span>

<span class="sd">    &gt;&gt;&gt; rvs = stats.norm.rvs(size=100, random_state=rng)</span>
<span class="sd">    &gt;&gt;&gt; res = stats.quantile_test(rvs, q=0.6, p=0.75)</span>
<span class="sd">    &gt;&gt;&gt; ci = res.confidence_interval(confidence_level=0.95)</span>
<span class="sd">    &gt;&gt;&gt; ci</span>
<span class="sd">    ConfidenceInterval(low=0.284491604437432, high=0.8912531024914844)</span>

<span class="sd">    When testing a one-sided alternative, the confidence interval contains</span>
<span class="sd">    all observations such that if passed as `q`, the p-value of the</span>
<span class="sd">    test would be greater than 0.05, and therefore the null hypothesis</span>
<span class="sd">    would not be rejected. For example:</span>

<span class="sd">    &gt;&gt;&gt; rvs.sort()</span>
<span class="sd">    &gt;&gt;&gt; q, p, alpha = 0.6, 0.75, 0.95</span>
<span class="sd">    &gt;&gt;&gt; res = stats.quantile_test(rvs, q=q, p=p, alternative=&#39;less&#39;)</span>
<span class="sd">    &gt;&gt;&gt; ci = res.confidence_interval(confidence_level=alpha)</span>
<span class="sd">    &gt;&gt;&gt; for x in rvs[rvs &lt;= ci.high]:</span>
<span class="sd">    ...     res = stats.quantile_test(rvs, q=x, p=p, alternative=&#39;less&#39;)</span>
<span class="sd">    ...     assert res.pvalue &gt; 1-alpha</span>
<span class="sd">    &gt;&gt;&gt; for x in rvs[rvs &gt; ci.high]:</span>
<span class="sd">    ...     res = stats.quantile_test(rvs, q=x, p=p, alternative=&#39;less&#39;)</span>
<span class="sd">    ...     assert res.pvalue &lt; 1-alpha</span>

<span class="sd">    Also, if a 95% confidence interval is repeatedly generated for random</span>
<span class="sd">    samples, the confidence interval will contain the true quantile value in</span>
<span class="sd">    approximately 95% of replications.</span>

<span class="sd">    &gt;&gt;&gt; dist = stats.rayleigh() # our &quot;unknown&quot; distribution</span>
<span class="sd">    &gt;&gt;&gt; p = 0.2</span>
<span class="sd">    &gt;&gt;&gt; true_stat = dist.ppf(p) # the true value of the statistic</span>
<span class="sd">    &gt;&gt;&gt; n_trials = 1000</span>
<span class="sd">    &gt;&gt;&gt; quantile_ci_contains_true_stat = 0</span>
<span class="sd">    &gt;&gt;&gt; for i in range(n_trials):</span>
<span class="sd">    ...     data = dist.rvs(size=100, random_state=rng)</span>
<span class="sd">    ...     res = stats.quantile_test(data, p=p)</span>
<span class="sd">    ...     ci = res.confidence_interval(0.95)</span>
<span class="sd">    ...     if ci[0] &lt; true_stat &lt; ci[1]:</span>
<span class="sd">    ...         quantile_ci_contains_true_stat += 1</span>
<span class="sd">    &gt;&gt;&gt; quantile_ci_contains_true_stat &gt;= 950</span>
<span class="sd">    True</span>

<span class="sd">    This works with any distribution and any quantile, as long as the samples</span>
<span class="sd">    are i.i.d.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Implementation carefully follows [1] 3.2</span>
    <span class="c1"># &quot;H0: the p*th quantile of X is x*&quot;</span>
    <span class="c1"># To facilitate comparison with [1], we&#39;ll use variable names that</span>
    <span class="c1"># best match Conover&#39;s notation</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">x_star</span><span class="p">,</span> <span class="n">p_star</span><span class="p">,</span> <span class="n">H1</span> <span class="o">=</span> <span class="n">quantile_test_iv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">alternative</span><span class="p">)</span>

    <span class="c1"># &quot;We will use two test statistics in this test. Let T1 equal &quot;</span>
    <span class="c1"># &quot;the number of observations less than or equal to x*, and &quot;</span>
    <span class="c1"># &quot;let T2 equal the number of observations less than x*.&quot;</span>
    <span class="n">T1</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">&lt;=</span> <span class="n">x_star</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">T2</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">&lt;</span> <span class="n">x_star</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># &quot;The null distribution of the test statistics T1 and T2 is &quot;</span>
    <span class="c1"># &quot;the binomial distribution, with parameters n = sample size, and &quot;</span>
    <span class="c1"># &quot;p = p* as given in the null hypothesis.... Y has the binomial &quot;</span>
    <span class="c1"># &quot;distribution with parameters n and p*.&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p_star</span><span class="p">)</span>

    <span class="c1"># &quot;H1: the p* population quantile is less than x*&quot;</span>
    <span class="k">if</span> <span class="n">H1</span> <span class="o">==</span> <span class="s1">&#39;less&#39;</span><span class="p">:</span>
        <span class="c1"># &quot;The p-value is the probability that a binomial random variable Y &quot;</span>
        <span class="c1"># &quot;is greater than *or equal to* the observed value of T2...using p=p*&quot;</span>
        <span class="n">pvalue</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">T2</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Y.pmf(T2) + Y.sf(T2)</span>
        <span class="n">statistic</span> <span class="o">=</span> <span class="n">T2</span>
        <span class="n">statistic_type</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="c1"># &quot;H1: the p* population quantile is greater than x*&quot;</span>
    <span class="k">elif</span> <span class="n">H1</span> <span class="o">==</span> <span class="s1">&#39;greater&#39;</span><span class="p">:</span>
        <span class="c1"># &quot;The p-value is the probability that a binomial random variable Y &quot;</span>
        <span class="c1"># &quot;is less than or equal to the observed value of T1... using p = p*&quot;</span>
        <span class="n">pvalue</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">)</span>
        <span class="n">statistic</span> <span class="o">=</span> <span class="n">T1</span>
        <span class="n">statistic_type</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1"># &quot;H1: x* is not the p*th population quantile&quot;</span>
    <span class="k">elif</span> <span class="n">H1</span> <span class="o">==</span> <span class="s1">&#39;two-sided&#39;</span><span class="p">:</span>
        <span class="c1"># &quot;The p-value is twice the smaller of the probabilities that a</span>
        <span class="c1"># binomial random variable Y is less than or equal to the observed</span>
        <span class="c1"># value of T1 or greater than or equal to the observed value of T2</span>
        <span class="c1"># using p=p*.&quot;</span>
        <span class="c1"># Note: both one-sided p-values can exceed 0.5 for the same data, so</span>
        <span class="c1"># `clip`</span>
        <span class="n">pvalues</span> <span class="o">=</span> <span class="p">[</span><span class="n">Y</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">T1</span><span class="p">),</span> <span class="n">Y</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">T2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>  <span class="c1"># [greater, less]</span>
        <span class="n">sorted_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">pvalues</span><span class="p">)</span>
        <span class="n">pvalue</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">pvalues</span><span class="p">[</span><span class="n">sorted_idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sorted_idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">statistic</span><span class="p">,</span> <span class="n">statistic_type</span> <span class="o">=</span> <span class="n">T2</span><span class="p">,</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">statistic</span><span class="p">,</span> <span class="n">statistic_type</span> <span class="o">=</span> <span class="n">T1</span><span class="p">,</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">QuantileTestResult</span><span class="p">(</span>
        <span class="n">statistic</span><span class="o">=</span><span class="n">statistic</span><span class="p">,</span>
        <span class="n">statistic_type</span><span class="o">=</span><span class="n">statistic_type</span><span class="p">,</span>
        <span class="n">pvalue</span><span class="o">=</span><span class="n">pvalue</span><span class="p">,</span>
        <span class="n">_alternative</span><span class="o">=</span><span class="n">H1</span><span class="p">,</span>
        <span class="n">_x</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
        <span class="n">_p</span><span class="o">=</span><span class="n">p_star</span>
    <span class="p">)</span>


<span class="c1">#####################################</span>
<span class="c1">#       STATISTICAL DISTANCES       #</span>
<span class="c1">#####################################</span>


<span class="k">def</span><span class="w"> </span><span class="nf">wasserstein_distance</span><span class="p">(</span><span class="n">u_values</span><span class="p">,</span> <span class="n">v_values</span><span class="p">,</span> <span class="n">u_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">v_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the first Wasserstein distance between two 1D distributions.</span>

<span class="sd">    This distance is also known as the earth mover&#39;s distance, since it can be</span>
<span class="sd">    seen as the minimum amount of &quot;work&quot; required to transform :math:`u` into</span>
<span class="sd">    :math:`v`, where &quot;work&quot; is measured as the amount of distribution weight</span>
<span class="sd">    that must be moved, multiplied by the distance it has to be moved.</span>

<span class="sd">    .. versionadded:: 1.0.0</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    u_values, v_values : array_like</span>
<span class="sd">        Values observed in the (empirical) distribution.</span>
<span class="sd">    u_weights, v_weights : array_like, optional</span>
<span class="sd">        Weight for each value. If unspecified, each value is assigned the same</span>
<span class="sd">        weight.</span>
<span class="sd">        `u_weights` (resp. `v_weights`) must have the same length as</span>
<span class="sd">        `u_values` (resp. `v_values`). If the weight sum differs from 1, it</span>
<span class="sd">        must still be positive and finite so that the weights can be normalized</span>
<span class="sd">        to sum to 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    distance : float</span>
<span class="sd">        The computed distance between the distributions.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The first Wasserstein distance between the distributions :math:`u` and</span>
<span class="sd">    :math:`v` is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        l_1 (u, v) = \inf_{\pi \in \Gamma (u, v)} \int_{\mathbb{R} \times</span>
<span class="sd">        \mathbb{R}} |x-y| \mathrm{d} \pi (x, y)</span>

<span class="sd">    where :math:`\Gamma (u, v)` is the set of (probability) distributions on</span>
<span class="sd">    :math:`\mathbb{R} \times \mathbb{R}` whose marginals are :math:`u` and</span>
<span class="sd">    :math:`v` on the first and second factors respectively.</span>

<span class="sd">    If :math:`U` and :math:`V` are the respective CDFs of :math:`u` and</span>
<span class="sd">    :math:`v`, this distance also equals to:</span>

<span class="sd">    .. math::</span>

<span class="sd">        l_1(u, v) = \int_{-\infty}^{+\infty} |U-V|</span>

<span class="sd">    See [2]_ for a proof of the equivalence of both definitions.</span>

<span class="sd">    The input distributions can be empirical, therefore coming from samples</span>
<span class="sd">    whose values are effectively inputs of the function, or they can be seen as</span>
<span class="sd">    generalized functions, in which case they are weighted sums of Dirac delta</span>
<span class="sd">    functions located at the specified values.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Wasserstein metric&quot;, https://en.wikipedia.org/wiki/Wasserstein_metric</span>
<span class="sd">    .. [2] Ramdas, Garcia, Cuturi &quot;On Wasserstein Two Sample Testing and Related</span>
<span class="sd">           Families of Nonparametric Tests&quot; (2015). :arXiv:`1509.02237`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import wasserstein_distance</span>
<span class="sd">    &gt;&gt;&gt; wasserstein_distance([0, 1, 3], [5, 6, 8])</span>
<span class="sd">    5.0</span>
<span class="sd">    &gt;&gt;&gt; wasserstein_distance([0, 1], [0, 1], [3, 1], [2, 2])</span>
<span class="sd">    0.25</span>
<span class="sd">    &gt;&gt;&gt; wasserstein_distance([3.4, 3.9, 7.5, 7.8], [4.5, 1.4],</span>
<span class="sd">    ...                      [1.4, 0.9, 3.1, 7.2], [3.2, 3.5])</span>
<span class="sd">    4.0781331438047861</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_cdf_distance</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">u_values</span><span class="p">,</span> <span class="n">v_values</span><span class="p">,</span> <span class="n">u_weights</span><span class="p">,</span> <span class="n">v_weights</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">energy_distance</span><span class="p">(</span><span class="n">u_values</span><span class="p">,</span> <span class="n">v_values</span><span class="p">,</span> <span class="n">u_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">v_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the energy distance between two 1D distributions.</span>

<span class="sd">    .. versionadded:: 1.0.0</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    u_values, v_values : array_like</span>
<span class="sd">        Values observed in the (empirical) distribution.</span>
<span class="sd">    u_weights, v_weights : array_like, optional</span>
<span class="sd">        Weight for each value. If unspecified, each value is assigned the same</span>
<span class="sd">        weight.</span>
<span class="sd">        `u_weights` (resp. `v_weights`) must have the same length as</span>
<span class="sd">        `u_values` (resp. `v_values`). If the weight sum differs from 1, it</span>
<span class="sd">        must still be positive and finite so that the weights can be normalized</span>
<span class="sd">        to sum to 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    distance : float</span>
<span class="sd">        The computed distance between the distributions.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The energy distance between two distributions :math:`u` and :math:`v`, whose</span>
<span class="sd">    respective CDFs are :math:`U` and :math:`V`, equals to:</span>

<span class="sd">    .. math::</span>

<span class="sd">        D(u, v) = \left( 2\mathbb E|X - Y| - \mathbb E|X - X&#39;| -</span>
<span class="sd">        \mathbb E|Y - Y&#39;| \right)^{1/2}</span>

<span class="sd">    where :math:`X` and :math:`X&#39;` (resp. :math:`Y` and :math:`Y&#39;`) are</span>
<span class="sd">    independent random variables whose probability distribution is :math:`u`</span>
<span class="sd">    (resp. :math:`v`).</span>

<span class="sd">    Sometimes the square of this quantity is referred to as the &quot;energy</span>
<span class="sd">    distance&quot; (e.g. in [2]_, [4]_), but as noted in [1]_ and [3]_, only the</span>
<span class="sd">    definition above satisfies the axioms of a distance function (metric).</span>

<span class="sd">    As shown in [2]_, for one-dimensional real-valued variables, the energy</span>
<span class="sd">    distance is linked to the non-distribution-free version of the Cramr-von</span>
<span class="sd">    Mises distance:</span>

<span class="sd">    .. math::</span>

<span class="sd">        D(u, v) = \sqrt{2} l_2(u, v) = \left( 2 \int_{-\infty}^{+\infty} (U-V)^2</span>
<span class="sd">        \right)^{1/2}</span>

<span class="sd">    Note that the common Cramr-von Mises criterion uses the distribution-free</span>
<span class="sd">    version of the distance. See [2]_ (section 2), for more details about both</span>
<span class="sd">    versions of the distance.</span>

<span class="sd">    The input distributions can be empirical, therefore coming from samples</span>
<span class="sd">    whose values are effectively inputs of the function, or they can be seen as</span>
<span class="sd">    generalized functions, in which case they are weighted sums of Dirac delta</span>
<span class="sd">    functions located at the specified values.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Rizzo, Szekely &quot;Energy distance.&quot; Wiley Interdisciplinary Reviews:</span>
<span class="sd">           Computational Statistics, 8(1):27-38 (2015).</span>
<span class="sd">    .. [2] Szekely &quot;E-statistics: The energy of statistical samples.&quot; Bowling</span>
<span class="sd">           Green State University, Department of Mathematics and Statistics,</span>
<span class="sd">           Technical Report 02-16 (2002).</span>
<span class="sd">    .. [3] &quot;Energy distance&quot;, https://en.wikipedia.org/wiki/Energy_distance</span>
<span class="sd">    .. [4] Bellemare, Danihelka, Dabney, Mohamed, Lakshminarayanan, Hoyer,</span>
<span class="sd">           Munos &quot;The Cramer Distance as a Solution to Biased Wasserstein</span>
<span class="sd">           Gradients&quot; (2017). :arXiv:`1705.10743`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import energy_distance</span>
<span class="sd">    &gt;&gt;&gt; energy_distance([0], [2])</span>
<span class="sd">    2.0000000000000004</span>
<span class="sd">    &gt;&gt;&gt; energy_distance([0, 8], [0, 8], [3, 1], [2, 2])</span>
<span class="sd">    1.0000000000000002</span>
<span class="sd">    &gt;&gt;&gt; energy_distance([0.7, 7.4, 2.4, 6.8], [1.4, 8. ],</span>
<span class="sd">    ...                 [2.1, 4.2, 7.4, 8. ], [7.6, 8.8])</span>
<span class="sd">    0.88003340976158217</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">_cdf_distance</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">u_values</span><span class="p">,</span> <span class="n">v_values</span><span class="p">,</span>
                                      <span class="n">u_weights</span><span class="p">,</span> <span class="n">v_weights</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_cdf_distance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">u_values</span><span class="p">,</span> <span class="n">v_values</span><span class="p">,</span> <span class="n">u_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">v_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute, between two one-dimensional distributions :math:`u` and</span>
<span class="sd">    :math:`v`, whose respective CDFs are :math:`U` and :math:`V`, the</span>
<span class="sd">    statistical distance that is defined as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        l_p(u, v) = \left( \int_{-\infty}^{+\infty} |U-V|^p \right)^{1/p}</span>

<span class="sd">    p is a positive parameter; p = 1 gives the Wasserstein distance, p = 2</span>
<span class="sd">    gives the energy distance.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    u_values, v_values : array_like</span>
<span class="sd">        Values observed in the (empirical) distribution.</span>
<span class="sd">    u_weights, v_weights : array_like, optional</span>
<span class="sd">        Weight for each value. If unspecified, each value is assigned the same</span>
<span class="sd">        weight.</span>
<span class="sd">        `u_weights` (resp. `v_weights`) must have the same length as</span>
<span class="sd">        `u_values` (resp. `v_values`). If the weight sum differs from 1, it</span>
<span class="sd">        must still be positive and finite so that the weights can be normalized</span>
<span class="sd">        to sum to 1.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    distance : float</span>
<span class="sd">        The computed distance between the distributions.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The input distributions can be empirical, therefore coming from samples</span>
<span class="sd">    whose values are effectively inputs of the function, or they can be seen as</span>
<span class="sd">    generalized functions, in which case they are weighted sums of Dirac delta</span>
<span class="sd">    functions located at the specified values.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Bellemare, Danihelka, Dabney, Mohamed, Lakshminarayanan, Hoyer,</span>
<span class="sd">           Munos &quot;The Cramer Distance as a Solution to Biased Wasserstein</span>
<span class="sd">           Gradients&quot; (2017). :arXiv:`1705.10743`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">u_values</span><span class="p">,</span> <span class="n">u_weights</span> <span class="o">=</span> <span class="n">_validate_distribution</span><span class="p">(</span><span class="n">u_values</span><span class="p">,</span> <span class="n">u_weights</span><span class="p">)</span>
    <span class="n">v_values</span><span class="p">,</span> <span class="n">v_weights</span> <span class="o">=</span> <span class="n">_validate_distribution</span><span class="p">(</span><span class="n">v_values</span><span class="p">,</span> <span class="n">v_weights</span><span class="p">)</span>

    <span class="n">u_sorter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">u_values</span><span class="p">)</span>
    <span class="n">v_sorter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">v_values</span><span class="p">)</span>

    <span class="n">all_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">u_values</span><span class="p">,</span> <span class="n">v_values</span><span class="p">))</span>
    <span class="n">all_values</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;mergesort&#39;</span><span class="p">)</span>

    <span class="c1"># Compute the differences between pairs of successive values of u and v.</span>
    <span class="n">deltas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">all_values</span><span class="p">)</span>

    <span class="c1"># Get the respective positions of the values of u and v among the values of</span>
    <span class="c1"># both distributions.</span>
    <span class="n">u_cdf_indices</span> <span class="o">=</span> <span class="n">u_values</span><span class="p">[</span><span class="n">u_sorter</span><span class="p">]</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">all_values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;right&#39;</span><span class="p">)</span>
    <span class="n">v_cdf_indices</span> <span class="o">=</span> <span class="n">v_values</span><span class="p">[</span><span class="n">v_sorter</span><span class="p">]</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">all_values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;right&#39;</span><span class="p">)</span>

    <span class="c1"># Calculate the CDFs of u and v using their weights, if specified.</span>
    <span class="k">if</span> <span class="n">u_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">u_cdf</span> <span class="o">=</span> <span class="n">u_cdf_indices</span> <span class="o">/</span> <span class="n">u_values</span><span class="o">.</span><span class="n">size</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">u_sorted_cumweights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="mi">0</span><span class="p">],</span>
                                              <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">u_weights</span><span class="p">[</span><span class="n">u_sorter</span><span class="p">])))</span>
        <span class="n">u_cdf</span> <span class="o">=</span> <span class="n">u_sorted_cumweights</span><span class="p">[</span><span class="n">u_cdf_indices</span><span class="p">]</span> <span class="o">/</span> <span class="n">u_sorted_cumweights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">v_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">v_cdf</span> <span class="o">=</span> <span class="n">v_cdf_indices</span> <span class="o">/</span> <span class="n">v_values</span><span class="o">.</span><span class="n">size</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">v_sorted_cumweights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="mi">0</span><span class="p">],</span>
                                              <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">v_weights</span><span class="p">[</span><span class="n">v_sorter</span><span class="p">])))</span>
        <span class="n">v_cdf</span> <span class="o">=</span> <span class="n">v_sorted_cumweights</span><span class="p">[</span><span class="n">v_cdf_indices</span><span class="p">]</span> <span class="o">/</span> <span class="n">v_sorted_cumweights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Compute the value of the integral based on the CDFs.</span>
    <span class="c1"># If p = 1 or p = 2, we avoid using np.power, which introduces an overhead</span>
    <span class="c1"># of about 15%.</span>
    <span class="k">if</span> <span class="n">p</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">u_cdf</span> <span class="o">-</span> <span class="n">v_cdf</span><span class="p">),</span> <span class="n">deltas</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">p</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">u_cdf</span> <span class="o">-</span> <span class="n">v_cdf</span><span class="p">),</span> <span class="n">deltas</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">u_cdf</span> <span class="o">-</span> <span class="n">v_cdf</span><span class="p">),</span> <span class="n">p</span><span class="p">),</span>
                                       <span class="n">deltas</span><span class="p">)),</span> <span class="mi">1</span><span class="o">/</span><span class="n">p</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_validate_distribution</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validate the values and weights from a distribution input of `cdf_distance`</span>
<span class="sd">    and return them as ndarray objects.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    values : array_like</span>
<span class="sd">        Values observed in the (empirical) distribution.</span>
<span class="sd">    weights : array_like</span>
<span class="sd">        Weight for each value.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    values : ndarray</span>
<span class="sd">        Values as ndarray.</span>
<span class="sd">    weights : ndarray</span>
<span class="sd">        Weights as ndarray.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Validate the value array.</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Distribution can&#39;t be empty.&quot;</span><span class="p">)</span>

    <span class="c1"># Validate the weight array, if specified.</span>
    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Value and weight array-likes for the same &#39;</span>
                             <span class="s1">&#39;empirical distribution must be of the same size.&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">weights</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;All weights must be non-negative.&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Weight array-like sum must be positive and &#39;</span>
                             <span class="s1">&#39;finite. Set as None for an equal distribution of &#39;</span>
                             <span class="s1">&#39;weight.&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">values</span><span class="p">,</span> <span class="n">weights</span>

    <span class="k">return</span> <span class="n">values</span><span class="p">,</span> <span class="kc">None</span>


<span class="c1">#####################################</span>
<span class="c1">#         SUPPORT FUNCTIONS         #</span>
<span class="c1">#####################################</span>

<span class="n">RepeatedResults</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;RepeatedResults&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;values&#39;</span><span class="p">,</span> <span class="s1">&#39;counts&#39;</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">find_repeats</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Find repeats and repeat counts.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    arr : array_like</span>
<span class="sd">        Input array. This is cast to float64.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    values : ndarray</span>
<span class="sd">        The unique values from the (flattened) input that are repeated.</span>

<span class="sd">    counts : ndarray</span>
<span class="sd">        Number of times the corresponding &#39;value&#39; is repeated.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    In numpy &gt;= 1.9 `numpy.unique` provides similar functionality. The main</span>
<span class="sd">    difference is that `find_repeats` only returns repeated values.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">    &gt;&gt;&gt; stats.find_repeats([2, 1, 2, 3, 2, 2, 5])</span>
<span class="sd">    RepeatedResults(values=array([2.]), counts=array([4]))</span>

<span class="sd">    &gt;&gt;&gt; stats.find_repeats([[10, 20, 1, 2], [5, 5, 4, 4]])</span>
<span class="sd">    RepeatedResults(values=array([4.,  5.]), counts=array([2, 2]))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Note: always copies.</span>
    <span class="k">return</span> <span class="n">RepeatedResults</span><span class="p">(</span><span class="o">*</span><span class="n">_find_repeats</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_sum_of_squares</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Square each element of the input array, and return the sum(s) of that.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Input array.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to calculate. Default is 0. If None, compute over</span>
<span class="sd">        the whole array `a`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    sum_of_squares : ndarray</span>
<span class="sd">        The sum along the given axis for (a**2).</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    _square_of_sums : The square(s) of the sum(s) (the opposite of</span>
<span class="sd">        `_sum_of_squares`).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_square_of_sums</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sum elements of the input array, and return the square(s) of that sum.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Input array.</span>
<span class="sd">    axis : int or None, optional</span>
<span class="sd">        Axis along which to calculate. Default is 0. If None, compute over</span>
<span class="sd">        the whole array `a`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    square_of_sums : float or ndarray</span>
<span class="sd">        The square of the sum over `axis`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    _sum_of_squares : The sum of squares (the opposite of `square_of_sums`).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">_chk_asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">*</span> <span class="n">s</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">*</span> <span class="n">s</span>


<span class="k">def</span><span class="w"> </span><span class="nf">rankdata</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;average&#39;</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;propagate&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Assign ranks to data, dealing with ties appropriately.</span>

<span class="sd">    By default (``axis=None``), the data array is first flattened, and a flat</span>
<span class="sd">    array of ranks is returned. Separately reshape the rank array to the</span>
<span class="sd">    shape of the data array if desired (see Examples).</span>

<span class="sd">    Ranks begin at 1.  The `method` argument controls how ranks are assigned</span>
<span class="sd">    to equal values.  See [1]_ for further discussion of ranking methods.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        The array of values to be ranked.</span>
<span class="sd">    method : {&#39;average&#39;, &#39;min&#39;, &#39;max&#39;, &#39;dense&#39;, &#39;ordinal&#39;}, optional</span>
<span class="sd">        The method used to assign ranks to tied elements.</span>
<span class="sd">        The following methods are available (default is &#39;average&#39;):</span>

<span class="sd">          * &#39;average&#39;: The average of the ranks that would have been assigned to</span>
<span class="sd">            all the tied values is assigned to each value.</span>
<span class="sd">          * &#39;min&#39;: The minimum of the ranks that would have been assigned to all</span>
<span class="sd">            the tied values is assigned to each value.  (This is also</span>
<span class="sd">            referred to as &quot;competition&quot; ranking.)</span>
<span class="sd">          * &#39;max&#39;: The maximum of the ranks that would have been assigned to all</span>
<span class="sd">            the tied values is assigned to each value.</span>
<span class="sd">          * &#39;dense&#39;: Like &#39;min&#39;, but the rank of the next highest element is</span>
<span class="sd">            assigned the rank immediately after those assigned to the tied</span>
<span class="sd">            elements.</span>
<span class="sd">          * &#39;ordinal&#39;: All values are given a distinct rank, corresponding to</span>
<span class="sd">            the order that the values occur in `a`.</span>
<span class="sd">    axis : {None, int}, optional</span>
<span class="sd">        Axis along which to perform the ranking. If ``None``, the data array</span>
<span class="sd">        is first flattened.</span>
<span class="sd">    nan_policy : {&#39;propagate&#39;, &#39;omit&#39;, &#39;raise&#39;}, optional</span>
<span class="sd">        Defines how to handle when input contains nan.</span>
<span class="sd">        The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">          * &#39;propagate&#39;: propagates nans through the rank calculation</span>
<span class="sd">          * &#39;omit&#39;: performs the calculations ignoring nan values</span>
<span class="sd">          * &#39;raise&#39;: raises an error</span>

<span class="sd">        .. note::</span>

<span class="sd">            When `nan_policy` is &#39;propagate&#39;, the output is an array of *all*</span>
<span class="sd">            nans because ranks relative to nans in the input are undefined.</span>
<span class="sd">            When `nan_policy` is &#39;omit&#39;, nans in `a` are ignored when ranking</span>
<span class="sd">            the other values, and the corresponding locations of the output</span>
<span class="sd">            are nan.</span>

<span class="sd">        .. versionadded:: 1.10</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ranks : ndarray</span>
<span class="sd">         An array of size equal to the size of `a`, containing rank</span>
<span class="sd">         scores.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Ranking&quot;, https://en.wikipedia.org/wiki/Ranking</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import rankdata</span>
<span class="sd">    &gt;&gt;&gt; rankdata([0, 2, 3, 2])</span>
<span class="sd">    array([ 1. ,  2.5,  4. ,  2.5])</span>
<span class="sd">    &gt;&gt;&gt; rankdata([0, 2, 3, 2], method=&#39;min&#39;)</span>
<span class="sd">    array([ 1,  2,  4,  2])</span>
<span class="sd">    &gt;&gt;&gt; rankdata([0, 2, 3, 2], method=&#39;max&#39;)</span>
<span class="sd">    array([ 1,  3,  4,  3])</span>
<span class="sd">    &gt;&gt;&gt; rankdata([0, 2, 3, 2], method=&#39;dense&#39;)</span>
<span class="sd">    array([ 1,  2,  3,  2])</span>
<span class="sd">    &gt;&gt;&gt; rankdata([0, 2, 3, 2], method=&#39;ordinal&#39;)</span>
<span class="sd">    array([ 1,  2,  4,  3])</span>
<span class="sd">    &gt;&gt;&gt; rankdata([[0, 2], [3, 2]]).reshape(2,2)</span>
<span class="sd">    array([[1. , 2.5],</span>
<span class="sd">          [4. , 2.5]])</span>
<span class="sd">    &gt;&gt;&gt; rankdata([[0, 2, 2], [3, 2, 5]], axis=1)</span>
<span class="sd">    array([[1. , 2.5, 2.5],</span>
<span class="sd">           [2. , 1. , 3. ]])</span>
<span class="sd">    &gt;&gt;&gt; rankdata([0, 2, 3, np.nan, -2, np.nan], nan_policy=&quot;propagate&quot;)</span>
<span class="sd">    array([nan, nan, nan, nan, nan, nan])</span>
<span class="sd">    &gt;&gt;&gt; rankdata([0, 2, 3, np.nan, -2, np.nan], nan_policy=&quot;omit&quot;)</span>
<span class="sd">    array([ 2.,  3.,  4., nan,  1., nan])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;average&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="s1">&#39;dense&#39;</span><span class="p">,</span> <span class="s1">&#39;ordinal&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;unknown method &quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">)</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># The return values of `normalize_axis_index` are ignored.  The</span>
            <span class="c1"># call validates `axis`, even though we won&#39;t use it.</span>
            <span class="n">normalize_axis_index</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;average&#39;</span><span class="p">:</span>
                <span class="n">dt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">rankdata</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span>
                                   <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">)</span>

    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">contains_nan</span><span class="p">,</span> <span class="n">nan_policy</span> <span class="o">=</span> <span class="n">_contains_nan</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">nan_policy</span><span class="p">)</span>
    <span class="n">nan_indexes</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">contains_nan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;omit&#39;</span><span class="p">:</span>
            <span class="n">nan_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nan_policy</span> <span class="o">==</span> <span class="s1">&#39;propagate&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

    <span class="n">algo</span> <span class="o">=</span> <span class="s1">&#39;mergesort&#39;</span> <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;ordinal&#39;</span> <span class="k">else</span> <span class="s1">&#39;quicksort&#39;</span>
    <span class="n">sorter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="n">algo</span><span class="p">)</span>

    <span class="n">inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">sorter</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intp</span><span class="p">)</span>
    <span class="n">inv</span><span class="p">[</span><span class="n">sorter</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">sorter</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intp</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;ordinal&#39;</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">inv</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="p">[</span><span class="n">sorter</span><span class="p">]</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="n">arr</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">arr</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">dense</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()[</span><span class="n">inv</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;dense&#39;</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">dense</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># cumulative counts of each unique value</span>
            <span class="n">count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">obs</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">obs</span><span class="p">)]</span>

            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">count</span><span class="p">[</span><span class="n">dense</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">count</span><span class="p">[</span><span class="n">dense</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;average&#39;</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="mf">.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">count</span><span class="p">[</span><span class="n">dense</span><span class="p">]</span> <span class="o">+</span> <span class="n">count</span><span class="p">[</span><span class="n">dense</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">nan_indexes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
        <span class="n">result</span><span class="p">[</span><span class="n">nan_indexes</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span><span class="w"> </span><span class="nf">expectile</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the expectile at the specified level.</span>

<span class="sd">    Expectiles are a generalization of the expectation in the same way as</span>
<span class="sd">    quantiles are a generalization of the median. The expectile at level</span>
<span class="sd">    `alpha = 0.5` is the mean (average). See Notes for more details.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array containing numbers whose expectile is desired.</span>
<span class="sd">    alpha : float, default: 0.5</span>
<span class="sd">        The level of the expectile; e.g., `alpha=0.5` gives the mean.</span>
<span class="sd">    weights : array_like, optional</span>
<span class="sd">        An array of weights associated with the values in `a`.</span>
<span class="sd">        The `weights` must be broadcastable to the same shape as `a`.</span>
<span class="sd">        Default is None, which gives each value a weight of 1.0.</span>
<span class="sd">        An integer valued weight element acts like repeating the corresponding</span>
<span class="sd">        observation in `a` that many times. See Notes for more details.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    expectile : ndarray</span>
<span class="sd">        The empirical expectile at level `alpha`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.mean : Arithmetic average</span>
<span class="sd">    numpy.quantile : Quantile</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    In general, the expectile at level :math:`\alpha` of a random variable</span>
<span class="sd">    :math:`X` with cumulative distribution function (CDF) :math:`F` is given</span>
<span class="sd">    by the unique solution :math:`t` of:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \alpha E((X - t)_+) = (1 - \alpha) E((t - X)_+) \,.</span>

<span class="sd">    Here, :math:`(x)_+ = \max(0, x)` is the positive part of :math:`x`.</span>
<span class="sd">    This equation can be equivalently written as:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \alpha \int_t^\infty (x - t)\mathrm{d}F(x)</span>
<span class="sd">        = (1 - \alpha) \int_{-\infty}^t (t - x)\mathrm{d}F(x) \,.</span>

<span class="sd">    The empirical expectile at level :math:`\alpha` (`alpha`) of a sample</span>
<span class="sd">    :math:`a_i` (the array `a`) is defined by plugging in the empirical CDF of</span>
<span class="sd">    `a`. Given sample or case weights :math:`w` (the array `weights`), it</span>
<span class="sd">    reads :math:`F_a(x) = \frac{1}{\sum_i w_i} \sum_i w_i 1_{a_i \leq x}`</span>
<span class="sd">    with indicator function :math:`1_{A}`. This leads to the definition of the</span>
<span class="sd">    empirical expectile at level `alpha` as the unique solution :math:`t` of:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \alpha \sum_{i=1}^n w_i (a_i - t)_+ =</span>
<span class="sd">            (1 - \alpha) \sum_{i=1}^n w_i (t - a_i)_+ \,.</span>

<span class="sd">    For :math:`\alpha=0.5`, this simplifies to the weighted average.</span>
<span class="sd">    Furthermore, the larger :math:`\alpha`, the larger the value of the</span>
<span class="sd">    expectile.</span>

<span class="sd">    As a final remark, the expectile at level :math:`\alpha` can also be</span>
<span class="sd">    written as a minimization problem. One often used choice is</span>

<span class="sd">    .. math::</span>

<span class="sd">        \operatorname{argmin}_t</span>
<span class="sd">        E(\lvert 1_{t\geq X} - \alpha\rvert(t - X)^2) \,.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] W. K. Newey and J. L. Powell (1987), &quot;Asymmetric Least Squares</span>
<span class="sd">           Estimation and Testing,&quot; Econometrica, 55, 819-847.</span>
<span class="sd">    .. [2] T. Gneiting (2009). &quot;Making and Evaluating Point Forecasts,&quot;</span>
<span class="sd">           Journal of the American Statistical Association, 106, 746 - 762.</span>
<span class="sd">           :doi:`10.48550/arXiv.0912.0902`</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats import expectile</span>
<span class="sd">    &gt;&gt;&gt; a = [1, 4, 2, -1]</span>
<span class="sd">    &gt;&gt;&gt; expectile(a, alpha=0.5) == np.mean(a)</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; expectile(a, alpha=0.2)</span>
<span class="sd">    0.42857142857142855</span>
<span class="sd">    &gt;&gt;&gt; expectile(a, alpha=0.8)</span>
<span class="sd">    2.5714285714285716</span>
<span class="sd">    &gt;&gt;&gt; weights = [1, 3, 1, 1]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">alpha</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">alpha</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The expectile level alpha must be in the range [0, 1].&quot;</span>
        <span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># This is the empirical equivalent of Eq. (13) with identification</span>
    <span class="c1"># function from Table 9 (omitting a factor of 2) in [2] (their y is our</span>
    <span class="c1"># data a, their x is our t)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">first_order</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">a</span> <span class="o">&lt;=</span> <span class="n">t</span><span class="p">)</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">-</span> <span class="n">a</span><span class="p">),</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">alpha</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">x0</span> <span class="o">==</span> <span class="n">x1</span><span class="p">:</span>
        <span class="c1"># a has a single unique element</span>
        <span class="k">return</span> <span class="n">x0</span>

    <span class="c1"># Note that the expectile is the unique solution, so no worries about</span>
    <span class="c1"># finding a wrong root.</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">root_scalar</span><span class="p">(</span><span class="n">first_order</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="o">=</span><span class="n">x1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">root</span>
</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The BayesFlow authors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2023-2025, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>