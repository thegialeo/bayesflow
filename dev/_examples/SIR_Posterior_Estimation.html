
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>3. Posterior Estimation for SIR-like Models &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=8fec244e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_examples/SIR_Posterior_Estimation';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = '/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'dev';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="canonical" href="https://www.bayesflow.org/_examples/SIR_Posterior_Estimation.html" />
    <link rel="icon" href="../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4. Hyperparameter Optimization Using Optuna" href="Hyperparameter_Optimization.html" />
    <link rel="prev" title="2. Two Moons: Tackling Bimodal Posteriors" href="Two_Moons_Starter.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/bayesflow_hor.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <img src="../_static/bayesflow_hor_dark.png" class="logo__image only-dark pst-js-only" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/bayesflow.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    About us
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Developer docs
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/bayesflow.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    About us
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Developer docs
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Linear_Regression_Starter.html">1. Amortized Posterior Estimation for Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="Two_Moons_Starter.html">2. Two Moons: Tackling Bimodal Posteriors</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">3. Posterior Estimation for SIR-like Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="Hyperparameter_Optimization.html">4. Hyperparameter Optimization Using Optuna</a></li>
<li class="toctree-l1"><a class="reference internal" href="Bayesian_Experimental_Design.html">5. Bayesian Experimental Design (BED) with BayesFlow and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="From_ABC_to_BayesFlow.html">6. From pyABC to BayesFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="One_Sample_TTest.html">7. Simple Model Comparison - One Sample T-Test</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../examples.html" class="nav-link">Examples</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis"><span class="section-number">3. </span>Posterior Estimation for SIR-like Models</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="posterior-estimation-for-sir-like-models">
<h1><span class="section-number">3. </span>Posterior Estimation for SIR-like Models<a class="headerlink" href="#posterior-estimation-for-sir-like-models" title="Link to this heading">#</a></h1>
<p><em>Author: Stefan T. Radev</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">datetime</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># ensure the backend is set</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="k">if</span> <span class="s2">&quot;KERAS_BACKEND&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="c1"># set this to &quot;torch&quot;, &quot;tensorflow&quot;, or &quot;jax&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;KERAS_BACKEND&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;tensorflow&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">keras</span>

<span class="c1"># For BayesFlow devs: this ensures that the latest dev version can be found</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;../&#39;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">bayesflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">bf</span>
</pre></div>
</div>
</div>
</div>
<section id="introduction">
<h2><span class="section-number">3.1. </span>Introduction <a class="anchor" id="introduction"></a><a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>In this tutorial, we will illustrate how to perform posterior inference on simple, stationary SIR-like models (complex models will be tackled in a further notebook). SIR-like models comprise suitable illustrative examples, since they generate time-series and their outputs represent the results of solving a system of ordinary differential equations (ODEs).</p>
<p>The details for tackling stochastic epidemiological models with neural networks are described in our corresponding paper, which you can consult for a more formal exposition and a more comprehensive treatment of neural architectures:</p>
<p><em>OutbreakFlow: Model-based Bayesian inference of disease outbreak dynamics with invertible neural networks and its application to the COVID-19 pandemics in Germany</em> https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009472</p>
</section>
<section id="defining-the-simulator">
<h2><span class="section-number">3.2. </span>Defining the Simulator <a class="anchor" id="defining_the_generative"></a><a class="headerlink" href="#defining-the-simulator" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">RNG</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">2024</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As described in our <a class="reference internal" href="#Quickstart_Amortized_Posterior_Estimation.ipynb"><span class="xref myst">very first notebook</span></a>, a generative model consists of a prior (encoding suitable parameter ranges) and a simulator (generating data given simulations). Our underlying model distinguishes between susceptible, <span class="math notranslate nohighlight">\(S\)</span>, infected, <span class="math notranslate nohighlight">\(I\)</span>, and recovered, <span class="math notranslate nohighlight">\(R\)</span>, individuals with infection and recovery occurring at a constant transmission rate <span class="math notranslate nohighlight">\(\lambda\)</span> and constant recovery rate <span class="math notranslate nohighlight">\(\mu\)</span>, respectively. The model dynamics are governed by the following system of ODEs:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
    \frac{dS}{dt} &amp;= -\lambda\,\left(\frac{S\,I}{N}\right) \\
    \frac{dI}{dt} &amp;= \lambda\,\left(\frac{S\,I}{N}\right) - \mu\,I \\
    \frac{dR}{dt} &amp;= \mu\,I,
\end{align}
\end{split}\]</div>
<p>with <span class="math notranslate nohighlight">\(N = S + I + R\)</span> denoting the total population size. For the purpose of forward inference (simulation), we will use a time step of <span class="math notranslate nohighlight">\(dt = 1\)</span>, corresponding to daily case reports. In addition to the ODE parameters <span class="math notranslate nohighlight">\(\lambda\)</span> and <span class="math notranslate nohighlight">\(\mu\)</span>, we consider a reporting delay parameter <span class="math notranslate nohighlight">\(L\)</span> and a dispersion parameter <span class="math notranslate nohighlight">\(\psi\)</span>, which affect the number of reported infected individuals via a negative binomial disttribution (https://en.wikipedia.org/wiki/Negative_binomial_distribution):</p>
<div class="math notranslate nohighlight">
\[
\begin{equation}
    I_t^{(obs)} \sim \textrm{NegBinomial}(I^{(new)}_{t-L}, \psi),
\end{equation}
\]</div>
<p>In this way, we connect the latent disease model to an observation model, which renders the relationship between parameters and data a stochastic one. Note, that the observation model induces a further parameter <span class="math notranslate nohighlight">\(\psi\)</span>, responsible for the dispersion of the noise.
Finally, we will also treat the number of initially infected individuals, <span class="math notranslate nohighlight">\(I_0\)</span> as an unknown parameter (having its own prior distribution).</p>
<section id="prior">
<h3><span class="section-number">3.2.1. </span>Prior <a class="anchor" id="prior"></a><a class="headerlink" href="#prior" title="Link to this heading">#</a></h3>
<p>We will place the following prior distributions over the five model parameters, summarized in the table below:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp; \text {Table 1. Description of model parameters and corresponding prior distributions}\\
&amp;\begin{array}{lcl}
\hline \hline \text { Description} &amp; \text { Symbol } &amp; \text { Prior Distribution } \\
\hline \hline \text{Initial transmission rate} &amp; \text{$\lambda$} &amp; \text{$\textrm{LogNormal}(\log(0.4), 0.5)$} \\
\text{Recovery rate of infected individuals} &amp; \text{$\mu$} &amp; \text{$\textrm{LogNormal}(\log(1/8), 0.2)$} \\
\text{Reporting delay (lag)} &amp; \text{$L$} &amp; \text{$\textrm{LogNormal}(\log(8), 0.2)$} \\
\text{Number of initially infected individuals} &amp; \text{$I_0$} &amp; \text{$\textrm{Gamma}(2, 20)$} \\
\text{Dispersion of the negative binomial distribution} &amp; \text{$\psi$} &amp; \text{$\textrm{Exponential}(5)$} \\
\hline
\end{array}
\end{aligned}
\end{split}\]</div>
<p>How did we come up with these priors? In this case, we rely on the domain expertise and previous research  (https://www.science.org/doi/10.1126/science.abb9789). In addition, the new parameter <span class="math notranslate nohighlight">\(\psi\)</span> follows an exponential distribution, which restricts it to positive numbers. Below is the implementation of these priors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prior</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates a random draw from the joint prior.&quot;&quot;&quot;</span>

    <span class="n">lambd</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">lognormal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.4</span><span class="p">),</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">lognormal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">8</span><span class="p">),</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">lognormal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">8</span><span class="p">),</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">I0</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;lambd&quot;</span><span class="p">:</span> <span class="n">lambd</span><span class="p">,</span> <span class="s2">&quot;mu&quot;</span><span class="p">:</span> <span class="n">mu</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">:</span> <span class="n">D</span><span class="p">,</span> <span class="s2">&quot;I0&quot;</span><span class="p">:</span> <span class="n">I0</span><span class="p">,</span> <span class="s2">&quot;psi&quot;</span><span class="p">:</span> <span class="n">psi</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="observation-model-implicit-likelihood-function">
<h3><span class="section-number">3.2.2. </span>Observation Model (Implicit Likelihood Function) <a class="anchor" id="simulator__implicit_likelihood"></a><a class="headerlink" href="#observation-model-implicit-likelihood-function" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">nbinom</span>


<span class="k">def</span><span class="w"> </span><span class="nf">convert_params</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">phi</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper function to convert mean/dispersion parameterization of a negative binomial to N and p,</span>
<span class="sd">    as expected by numpy&#39;s negative_binomial.</span>

<span class="sd">    See https://en.wikipedia.org/wiki/Negative_binomial_distribution#Alternative_formulations</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">r</span> <span class="o">=</span> <span class="n">phi</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">r</span> <span class="o">*</span> <span class="n">mu</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">p</span> <span class="o">=</span> <span class="p">(</span><span class="n">var</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">var</span>
    <span class="k">return</span> <span class="n">r</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p</span>


<span class="k">def</span><span class="w"> </span><span class="nf">stationary_SIR</span><span class="p">(</span><span class="n">lambd</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">I0</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mf">83e6</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Performs a forward simulation from the stationary SIR model given a random draw from the prior.&quot;&quot;&quot;</span>

    <span class="c1"># Extract parameters and round I0 and D</span>
    <span class="n">I0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">I0</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">D</span><span class="p">))</span>

    <span class="c1"># Initial conditions</span>
    <span class="n">S</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="p">[</span><span class="n">N</span> <span class="o">-</span> <span class="n">I0</span><span class="p">],</span> <span class="p">[</span><span class="n">I0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Reported new cases</span>
    <span class="n">C</span> <span class="o">=</span> <span class="p">[</span><span class="n">I0</span><span class="p">]</span>

    <span class="c1"># Simulate T-1 timesteps</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">T</span> <span class="o">+</span> <span class="n">D</span><span class="p">):</span>
        <span class="c1"># Calculate new cases</span>
        <span class="n">I_new</span> <span class="o">=</span> <span class="n">lambd</span> <span class="o">*</span> <span class="p">(</span><span class="n">I</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">S</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span>

        <span class="c1"># SIR equations</span>
        <span class="n">S_t</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">I_new</span>
        <span class="n">I_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">I</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">I_new</span> <span class="o">-</span> <span class="n">mu</span> <span class="o">*</span> <span class="n">I</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
        <span class="n">R_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">R</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">mu</span> <span class="o">*</span> <span class="n">I</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

        <span class="c1"># Track</span>
        <span class="n">S</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">S_t</span><span class="p">)</span>
        <span class="n">I</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">I_t</span><span class="p">)</span>
        <span class="n">R</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">R_t</span><span class="p">)</span>
        <span class="n">C</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">I_new</span><span class="p">)</span>

    <span class="n">reparam</span> <span class="o">=</span> <span class="n">convert_params</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="n">D</span><span class="p">:]),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span>
    <span class="n">C_obs</span> <span class="o">=</span> <span class="n">RNG</span><span class="o">.</span><span class="n">negative_binomial</span><span class="p">(</span><span class="n">reparam</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reparam</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">cases</span><span class="o">=</span><span class="n">C_obs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As you can see, in addition to the parameters, our simulator requires two further arguments: the total population size <span class="math notranslate nohighlight">\(N\)</span> and the time horizon <span class="math notranslate nohighlight">\(T\)</span>. These are quantities over which we can amortize (i.e., context variables), but for this example, we will just use the population of Germany and the first two weeks of the pandemics (i.e., <span class="math notranslate nohighlight">\(T=14\)</span>), in the same vein as https://www.science.org/doi/10.1126/science.abb9789.</p>
</section>
<section id="loading-real-data">
<h3><span class="section-number">3.2.3. </span>Loading Real Data <a class="anchor" id="loading_real_data"></a><a class="headerlink" href="#loading-real-data" title="Link to this heading">#</a></h3>
<p>We will define a simple helper function to load the actually reported cases in 2020 for the first two weeks of the Covid-19 pandemic in Germany.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">load_data</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper function to load cumulative cases and transform them to new cases.&quot;&quot;&quot;</span>

    <span class="n">confirmed_cases_url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&quot;</span>
    <span class="n">confirmed_cases</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">confirmed_cases_url</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>

    <span class="n">date_data_begin</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">date_data_end</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
    <span class="n">format_date</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">date_py</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">date_py</span><span class="o">.</span><span class="n">month</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">date_py</span><span class="o">.</span><span class="n">day</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">date_py</span><span class="o">.</span><span class="n">year</span><span class="p">)[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">date_formatted_begin</span> <span class="o">=</span> <span class="n">format_date</span><span class="p">(</span><span class="n">date_data_begin</span><span class="p">)</span>
    <span class="n">date_formatted_end</span> <span class="o">=</span> <span class="n">format_date</span><span class="p">(</span><span class="n">date_data_end</span><span class="p">)</span>

    <span class="n">cases_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
        <span class="n">confirmed_cases</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">confirmed_cases</span><span class="p">[</span><span class="s2">&quot;Country/Region&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Germany&quot;</span><span class="p">,</span> <span class="n">date_formatted_begin</span><span class="p">:</span><span class="n">date_formatted_end</span><span class="p">]</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">new_cases_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">cases_obs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_cases_obs</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="stitiching-things-together">
<h3><span class="section-number">3.2.4. </span>Stitiching Things Together <a class="anchor" id="generative_model"></a><a class="headerlink" href="#stitiching-things-together" title="Link to this heading">#</a></h3>
<p>We can combine the prior <span class="math notranslate nohighlight">\(p(\theta)\)</span> and the observation model <span class="math notranslate nohighlight">\(p(x_{1:T}\mid\theta)\)</span> into a joint model <span class="math notranslate nohighlight">\(p(\theta, x_{1:T}) = p(\theta) \; p(x_{1:T}\mid\theta)\)</span> using the <code class="docutils literal notranslate"><span class="pre">make_simulator</span></code> builder.
The resulting object can now generate <em>batches</em> of simulations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">simulator</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">make_simulator</span><span class="p">([</span><span class="n">prior</span><span class="p">,</span> <span class="n">stationary_SIR</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">test_sims</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;lambd&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;D&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;cases&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2, 1)
(2, 1)
(2, 14)
CPU times: user 1.01 ms, sys: 182 Î¼s, total: 1.19 ms
Wall time: 1.13 ms
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="prior-checking">
<h2><span class="section-number">3.3. </span>Prior Checking <a class="anchor" id="prior_checking"></a><a class="headerlink" href="#prior-checking" title="Link to this heading">#</a></h2>
<p>Any principled Bayesian workflow requires some prior predictive or prior pushforward checks to ensure that the prior specification is consistent with domain expertise (see https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html). The BayesFlow library provides some rudimentary visual tools for performing prior checking. For instance, we can visually inspect the joint prior in the form of bivariate plots. We can focus on particular parameter combinations, such as <span class="math notranslate nohighlight">\(\lambda\)</span>, <span class="math notranslate nohighlight">\(\mu\)</span>, and <span class="math notranslate nohighlight">\(D\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">prior_samples</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">simulators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">grid</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">pairs_samples</span><span class="p">(</span>
    <span class="n">prior_samples</span><span class="p">,</span> <span class="n">variable_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lambd&quot;</span><span class="p">,</span> <span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/b3de7431f5edf30689464bb22c355672c3d5795bb943ede91c585f05cca39afe.png" src="../_images/b3de7431f5edf30689464bb22c355672c3d5795bb943ede91c585f05cca39afe.png" />
</div>
</div>
</section>
<section id="defining-the-adapter">
<h2><span class="section-number">3.4. </span>Defining the Adapter<a class="headerlink" href="#defining-the-adapter" title="Link to this heading">#</a></h2>
<p>We need to ensure that the outputs of the forward model are suitable for processing with neural networks. Currently, they are not, since our data <span class="math notranslate nohighlight">\(x_{1:T}\)</span> consists of large integer (count) values. However, neural networks like scaled data. Furthermore, our parameters <span class="math notranslate nohighlight">\(\theta\)</span> exhibit widely different scales due to their prior specification and role in the simulator. Finally, BayesFlow needs to know which variables are to be inferred and which ones are to be processed by the summary network before being passed to the inference network. We handle all of these steps using an <code class="docutils literal notranslate"><span class="pre">Adapter</span></code>.</p>
<p>Since all of our parameters and observables can only take on positive values, we will apply a log plus one transform to all quantities. Note, that <code class="docutils literal notranslate"><span class="pre">BayesFlow</span></code> expects the following keys to be present in the final outputs of your configured simulations:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inference_variables</span></code>: These are the variables we are inferring.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">summary_variables</span></code>: These are the variables that are compressed throgh a summary network and used for inferring the inference variables.</p></li>
</ul>
<p>Thus, what our approximators are learning is <span class="math notranslate nohighlight">\(p(\text{inference variables} \mid t(\text{summary variables}))\)</span>, where <span class="math notranslate nohighlight">\(t\)</span> is the summary network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">adapter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">bf</span><span class="o">.</span><span class="n">adapters</span><span class="o">.</span><span class="n">Adapter</span><span class="p">()</span>
    <span class="o">.</span><span class="n">convert_dtype</span><span class="p">(</span><span class="s2">&quot;float64&quot;</span><span class="p">,</span> <span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">as_time_series</span><span class="p">(</span><span class="s2">&quot;cases&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="s2">&quot;lambd&quot;</span><span class="p">,</span> <span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">,</span> <span class="s2">&quot;I0&quot;</span><span class="p">,</span> <span class="s2">&quot;psi&quot;</span><span class="p">],</span> <span class="n">into</span><span class="o">=</span><span class="s2">&quot;inference_variables&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;cases&quot;</span><span class="p">,</span> <span class="s2">&quot;summary_variables&quot;</span><span class="p">)</span>
    <span class="c1"># since all our variables are non-negative (zero or larger)</span>
    <span class="c1"># this .apply call ensures that the variables are transformed</span>
    <span class="c1"># to the unconstrained real space and can be back-transformed under the hood</span>
    <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">forward</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">inverse</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s check out the new shapes</span>
<span class="n">adapted_sims</span> <span class="o">=</span> <span class="n">adapter</span><span class="p">(</span><span class="n">simulator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">adapted_sims</span><span class="p">[</span><span class="s2">&quot;summary_variables&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">adapted_sims</span><span class="p">[</span><span class="s2">&quot;inference_variables&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2, 14, 1)
(2, 5)
</pre></div>
</div>
</div>
</div>
</section>
<section id="defining-the-neural-approximator">
<h2><span class="section-number">3.5. </span>Defining the Neural Approximator <a class="anchor" id="defining_the_neural"></a><a class="headerlink" href="#defining-the-neural-approximator" title="Link to this heading">#</a></h2>
<p>We can now proceed to define our <code class="docutils literal notranslate"><span class="pre">BayesFlow</span></code> neural architecture, that is, combine a summary network with an inference network.</p>
<section id="summary-network">
<h3><span class="section-number">3.5.1. </span>Summary Network <a class="anchor" id="summary_network"></a><a class="headerlink" href="#summary-network" title="Link to this heading">#</a></h3>
<p>Since our simulator outputs 3D tensors of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">T</span> <span class="pre">=</span> <span class="pre">14,</span> <span class="pre">1)</span></code>, we need to reduce this three-dimensional tensor into a two-dimensional tensor of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">summary_dim)</span></code>. Our model outputs are actually so simple that we could have just removed the trailing dimension of the raw outputs and simply fed the data directly to the inference network.</p>
<p>However, we demonstrate the use of a simple Gated Recurrent Unit (GRU) summary network. Any <code class="docutils literal notranslate"><span class="pre">keras</span></code> model can interact with <code class="docutils literal notranslate"><span class="pre">BayesFlow</span></code> by inherting from <code class="docutils literal notranslate"><span class="pre">SummaryNetwork</span></code> which accepts an addition <code class="docutils literal notranslate"><span class="pre">stage</span></code> argument indicating the mode the network is currently operating in (i.e., <code class="docutils literal notranslate"><span class="pre">training</span></code> vs. <code class="docutils literal notranslate"><span class="pre">inference</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">GRU</span><span class="p">(</span><span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">SummaryNetwork</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_stats</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">time_series</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compresses time_series of shape (batch_size, T, 1) into summaries of shape (batch_size, 8).&quot;&quot;&quot;</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">time_series</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;stage&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;training&quot;</span><span class="p">)</span>
        <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_stats</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">summary</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">summary_net</span> <span class="o">=</span> <span class="n">GRU</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="inference-network">
<h3><span class="section-number">3.5.2. </span>Inference Network<a class="headerlink" href="#inference-network" title="Link to this heading">#</a></h3>
<p>As inference network we choose a flow matching architecture with some dropout to robustify the inference. Dropout is primarily important when learning from a (small) offline dataset. See below for details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inference_net</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">CouplingFlow</span><span class="p">(</span>
    <span class="n">subnet_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;residual&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s2">&quot;widths&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">workflow</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">BasicWorkflow</span><span class="p">(</span>
    <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
    <span class="n">adapter</span><span class="o">=</span><span class="n">adapter</span><span class="p">,</span>
    <span class="n">inference_network</span><span class="o">=</span><span class="n">inference_net</span><span class="p">,</span>
    <span class="n">summary_network</span><span class="o">=</span><span class="n">summary_net</span><span class="p">,</span>
    <span class="n">inference_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lambd&quot;</span><span class="p">,</span> <span class="s2">&quot;mu&quot;</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">,</span> <span class="s2">&quot;I0&quot;</span><span class="p">,</span> <span class="s2">&quot;psi&quot;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="training">
<h2><span class="section-number">3.6. </span>Training <a class="anchor" id="training"></a><a class="headerlink" href="#training" title="Link to this heading">#</a></h2>
<p>Ready to train! Since our simulator is pretty fast, we can safely go with online training. Letâs glean the time taken for a batch of <span class="math notranslate nohighlight">\(32\)</span> simulations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 4.82 ms, sys: 733 Î¼s, total: 5.55 ms
Wall time: 5.06 ms
</pre></div>
</div>
</div>
</div>
<p>Not too bad! However, for the purpose of illustration, we will go with offline training using a fixed data set of simulations.</p>
<section id="generating-offline-data">
<h3><span class="section-number">3.6.1. </span>Generating Offline Data <a class="anchor" id="generating_offline_data"></a><a class="headerlink" href="#generating-offline-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">training_data</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">validation_data</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We are now ready to train. If not provided, the default settings use <span class="math notranslate nohighlight">\(100\)</span> epochs with a batch size of <span class="math notranslate nohighlight">\(32\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">fit_offline</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">5s</span> 38ms/step - loss: 2.5759 - loss/inference_loss: 2.5759 - val_loss: -1.5397 - val_loss/inference_loss: -1.5397
Epoch 2/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -1.8226 - loss/inference_loss: -1.8226 - val_loss: -2.0951 - val_loss/inference_loss: -2.0951
Epoch 3/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 7ms/step - loss: -2.4630 - loss/inference_loss: -2.4630 - val_loss: -2.9181 - val_loss/inference_loss: -2.9181
Epoch 4/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -2.4353 - loss/inference_loss: -2.4353 - val_loss: -2.1468 - val_loss/inference_loss: -2.1468
Epoch 5/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -2.8392 - loss/inference_loss: -2.8392 - val_loss: -2.4448 - val_loss/inference_loss: -2.4448
Epoch 6/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -2.7054 - loss/inference_loss: -2.7054 - val_loss: -2.9647 - val_loss/inference_loss: -2.9647
Epoch 7/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -2.7452 - loss/inference_loss: -2.7452 - val_loss: -2.9191 - val_loss/inference_loss: -2.9191
Epoch 8/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -2.7901 - loss/inference_loss: -2.7901 - val_loss: -2.3278 - val_loss/inference_loss: -2.3278
Epoch 9/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 7ms/step - loss: -2.8969 - loss/inference_loss: -2.8969 - val_loss: -3.1457 - val_loss/inference_loss: -3.1457
Epoch 10/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -2.9737 - loss/inference_loss: -2.9737 - val_loss: -2.6719 - val_loss/inference_loss: -2.6719
Epoch 11/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -2.8779 - loss/inference_loss: -2.8779 - val_loss: -3.2797 - val_loss/inference_loss: -3.2797
Epoch 12/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -2.9281 - loss/inference_loss: -2.9281 - val_loss: -3.1939 - val_loss/inference_loss: -3.1939
Epoch 13/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -2.9576 - loss/inference_loss: -2.9576 - val_loss: -2.1279 - val_loss/inference_loss: -2.1279
Epoch 14/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.0696 - loss/inference_loss: -3.0696 - val_loss: -3.3281 - val_loss/inference_loss: -3.3281
Epoch 15/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -2.9692 - loss/inference_loss: -2.9692 - val_loss: -3.3059 - val_loss/inference_loss: -3.3059
Epoch 16/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 7ms/step - loss: -2.8937 - loss/inference_loss: -2.8937 - val_loss: -3.3683 - val_loss/inference_loss: -3.3683
Epoch 17/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.0199 - loss/inference_loss: -3.0199 - val_loss: -3.0553 - val_loss/inference_loss: -3.0553
Epoch 18/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -3.0720 - loss/inference_loss: -3.0720 - val_loss: -2.4741 - val_loss/inference_loss: -2.4741
Epoch 19/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -2.8367 - loss/inference_loss: -2.8367 - val_loss: -3.4404 - val_loss/inference_loss: -3.4404
Epoch 20/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.0862 - loss/inference_loss: -3.0862 - val_loss: -3.2909 - val_loss/inference_loss: -3.2909
Epoch 21/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.2712 - loss/inference_loss: -3.2712 - val_loss: -3.3955 - val_loss/inference_loss: -3.3955
Epoch 22/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.1948 - loss/inference_loss: -3.1948 - val_loss: -2.5209 - val_loss/inference_loss: -2.5209
Epoch 23/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.2677 - loss/inference_loss: -3.2677 - val_loss: -3.0838 - val_loss/inference_loss: -3.0838
Epoch 24/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.4376 - loss/inference_loss: -3.4376 - val_loss: -3.6139 - val_loss/inference_loss: -3.6139
Epoch 25/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.3568 - loss/inference_loss: -3.3568 - val_loss: -2.9090 - val_loss/inference_loss: -2.9090
Epoch 26/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.3278 - loss/inference_loss: -3.3278 - val_loss: -3.2694 - val_loss/inference_loss: -3.2694
Epoch 27/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.4394 - loss/inference_loss: -3.4394 - val_loss: -3.9272 - val_loss/inference_loss: -3.9272
Epoch 28/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.5104 - loss/inference_loss: -3.5104 - val_loss: -3.4261 - val_loss/inference_loss: -3.4261
Epoch 29/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.5621 - loss/inference_loss: -3.5621 - val_loss: -3.8807 - val_loss/inference_loss: -3.8807
Epoch 30/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.5536 - loss/inference_loss: -3.5536 - val_loss: -4.0935 - val_loss/inference_loss: -4.0935
Epoch 31/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.6206 - loss/inference_loss: -3.6206 - val_loss: -3.2150 - val_loss/inference_loss: -3.2150
Epoch 32/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.7108 - loss/inference_loss: -3.7108 - val_loss: -3.3350 - val_loss/inference_loss: -3.3350
Epoch 33/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -3.7629 - loss/inference_loss: -3.7629 - val_loss: -3.7399 - val_loss/inference_loss: -3.7399
Epoch 34/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.8004 - loss/inference_loss: -3.8004 - val_loss: -4.0267 - val_loss/inference_loss: -4.0267
Epoch 35/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.7546 - loss/inference_loss: -3.7546 - val_loss: -3.5888 - val_loss/inference_loss: -3.5888
Epoch 36/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -3.8229 - loss/inference_loss: -3.8229 - val_loss: -3.8725 - val_loss/inference_loss: -3.8725
Epoch 37/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.6206 - loss/inference_loss: -3.6206 - val_loss: -4.1656 - val_loss/inference_loss: -4.1656
Epoch 38/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.9574 - loss/inference_loss: -3.9574 - val_loss: -3.5146 - val_loss/inference_loss: -3.5146
Epoch 39/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -3.6467 - loss/inference_loss: -3.6467 - val_loss: -4.1144 - val_loss/inference_loss: -4.1144
Epoch 40/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.8612 - loss/inference_loss: -3.8612 - val_loss: -3.7952 - val_loss/inference_loss: -3.7952
Epoch 41/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -3.8482 - loss/inference_loss: -3.8482 - val_loss: -3.6063 - val_loss/inference_loss: -3.6063
Epoch 42/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.9601 - loss/inference_loss: -3.9601 - val_loss: -4.2152 - val_loss/inference_loss: -4.2152
Epoch 43/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.8636 - loss/inference_loss: -3.8636 - val_loss: -3.4729 - val_loss/inference_loss: -3.4729
Epoch 44/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.9076 - loss/inference_loss: -3.9076 - val_loss: -2.6703 - val_loss/inference_loss: -2.6703
Epoch 45/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.9190 - loss/inference_loss: -3.9190 - val_loss: -3.6787 - val_loss/inference_loss: -3.6787
Epoch 46/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.9781 - loss/inference_loss: -3.9781 - val_loss: -3.8450 - val_loss/inference_loss: -3.8450
Epoch 47/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.9696 - loss/inference_loss: -3.9696 - val_loss: -3.0915 - val_loss/inference_loss: -3.0915
Epoch 48/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.0038 - loss/inference_loss: -4.0038 - val_loss: -3.5089 - val_loss/inference_loss: -3.5089
Epoch 49/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.8984 - loss/inference_loss: -3.8984 - val_loss: -4.2436 - val_loss/inference_loss: -4.2436
Epoch 50/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.0717 - loss/inference_loss: -4.0717 - val_loss: -3.8192 - val_loss/inference_loss: -3.8192
Epoch 51/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.2213 - loss/inference_loss: -4.2213 - val_loss: -4.3196 - val_loss/inference_loss: -4.3196
Epoch 52/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.0240 - loss/inference_loss: -4.0240 - val_loss: -3.5607 - val_loss/inference_loss: -3.5607
Epoch 53/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.1124 - loss/inference_loss: -4.1124 - val_loss: -4.0867 - val_loss/inference_loss: -4.0867
Epoch 54/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -3.9183 - loss/inference_loss: -3.9183 - val_loss: -3.5536 - val_loss/inference_loss: -3.5536
Epoch 55/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.1445 - loss/inference_loss: -4.1445 - val_loss: -3.8083 - val_loss/inference_loss: -3.8083
Epoch 56/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.2292 - loss/inference_loss: -4.2292 - val_loss: -4.0900 - val_loss/inference_loss: -4.0900
Epoch 57/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.2470 - loss/inference_loss: -4.2470 - val_loss: -4.2393 - val_loss/inference_loss: -4.2393
Epoch 58/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.2115 - loss/inference_loss: -4.2115 - val_loss: -4.5119 - val_loss/inference_loss: -4.5119
Epoch 59/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.2984 - loss/inference_loss: -4.2984 - val_loss: -4.2654 - val_loss/inference_loss: -4.2654
Epoch 60/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.3837 - loss/inference_loss: -4.3837 - val_loss: -3.5729 - val_loss/inference_loss: -3.5729
Epoch 61/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.4160 - loss/inference_loss: -4.4160 - val_loss: -4.6158 - val_loss/inference_loss: -4.6158
Epoch 62/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.4260 - loss/inference_loss: -4.4260 - val_loss: -4.6498 - val_loss/inference_loss: -4.6498
Epoch 63/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5024 - loss/inference_loss: -4.5024 - val_loss: -4.4340 - val_loss/inference_loss: -4.4340
Epoch 64/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5113 - loss/inference_loss: -4.5113 - val_loss: -4.4258 - val_loss/inference_loss: -4.4258
Epoch 65/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.3942 - loss/inference_loss: -4.3942 - val_loss: -4.1430 - val_loss/inference_loss: -4.1430
Epoch 66/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.4874 - loss/inference_loss: -4.4874 - val_loss: -4.1138 - val_loss/inference_loss: -4.1138
Epoch 67/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5030 - loss/inference_loss: -4.5030 - val_loss: -4.5718 - val_loss/inference_loss: -4.5718
Epoch 68/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.4269 - loss/inference_loss: -4.4269 - val_loss: -3.9706 - val_loss/inference_loss: -3.9706
Epoch 69/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.3311 - loss/inference_loss: -4.3311 - val_loss: -4.6668 - val_loss/inference_loss: -4.6668
Epoch 70/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5304 - loss/inference_loss: -4.5304 - val_loss: -4.4964 - val_loss/inference_loss: -4.4964
Epoch 71/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.6015 - loss/inference_loss: -4.6015 - val_loss: -4.4840 - val_loss/inference_loss: -4.4840
Epoch 72/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.4524 - loss/inference_loss: -4.4524 - val_loss: -4.1247 - val_loss/inference_loss: -4.1247
Epoch 73/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.4926 - loss/inference_loss: -4.4926 - val_loss: -4.1591 - val_loss/inference_loss: -4.1591
Epoch 74/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.3867 - loss/inference_loss: -4.3867 - val_loss: -4.8677 - val_loss/inference_loss: -4.8677
Epoch 75/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5482 - loss/inference_loss: -4.5482 - val_loss: -4.0794 - val_loss/inference_loss: -4.0794
Epoch 76/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5016 - loss/inference_loss: -4.5016 - val_loss: -4.0062 - val_loss/inference_loss: -4.0062
Epoch 77/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5690 - loss/inference_loss: -4.5690 - val_loss: -4.3880 - val_loss/inference_loss: -4.3880
Epoch 78/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.6479 - loss/inference_loss: -4.6479 - val_loss: -4.8755 - val_loss/inference_loss: -4.8755
Epoch 79/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.6034 - loss/inference_loss: -4.6034 - val_loss: -4.4100 - val_loss/inference_loss: -4.4100
Epoch 80/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.6603 - loss/inference_loss: -4.6603 - val_loss: -4.1391 - val_loss/inference_loss: -4.1391
Epoch 81/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5726 - loss/inference_loss: -4.5726 - val_loss: -4.7057 - val_loss/inference_loss: -4.7057
Epoch 82/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7409 - loss/inference_loss: -4.7409 - val_loss: -4.6320 - val_loss/inference_loss: -4.6320
Epoch 83/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5362 - loss/inference_loss: -4.5362 - val_loss: -4.2294 - val_loss/inference_loss: -4.2294
Epoch 84/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.6675 - loss/inference_loss: -4.6675 - val_loss: -4.3661 - val_loss/inference_loss: -4.3661
Epoch 85/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.6606 - loss/inference_loss: -4.6606 - val_loss: -4.7008 - val_loss/inference_loss: -4.7008
Epoch 86/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7181 - loss/inference_loss: -4.7181 - val_loss: -4.4110 - val_loss/inference_loss: -4.4110
Epoch 87/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.6335 - loss/inference_loss: -4.6335 - val_loss: -4.2426 - val_loss/inference_loss: -4.2426
Epoch 88/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5772 - loss/inference_loss: -4.5772 - val_loss: -4.1760 - val_loss/inference_loss: -4.1760
Epoch 89/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.5882 - loss/inference_loss: -4.5882 - val_loss: -4.5908 - val_loss/inference_loss: -4.5908
Epoch 90/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7031 - loss/inference_loss: -4.7031 - val_loss: -4.7127 - val_loss/inference_loss: -4.7127
Epoch 91/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.6948 - loss/inference_loss: -4.6948 - val_loss: -4.9292 - val_loss/inference_loss: -4.9292
Epoch 92/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7277 - loss/inference_loss: -4.7277 - val_loss: -4.3392 - val_loss/inference_loss: -4.3392
Epoch 93/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.6701 - loss/inference_loss: -4.6701 - val_loss: -4.9827 - val_loss/inference_loss: -4.9827
Epoch 94/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7204 - loss/inference_loss: -4.7204 - val_loss: -4.7546 - val_loss/inference_loss: -4.7546
Epoch 95/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7103 - loss/inference_loss: -4.7103 - val_loss: -4.7964 - val_loss/inference_loss: -4.7964
Epoch 96/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7233 - loss/inference_loss: -4.7233 - val_loss: -4.7185 - val_loss/inference_loss: -4.7185
Epoch 97/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7438 - loss/inference_loss: -4.7438 - val_loss: -4.8384 - val_loss/inference_loss: -4.8384
Epoch 98/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8466 - loss/inference_loss: -4.8466 - val_loss: -5.2245 - val_loss/inference_loss: -5.2245
Epoch 99/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7852 - loss/inference_loss: -4.7852 - val_loss: -5.0661 - val_loss/inference_loss: -5.0661
Epoch 100/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8479 - loss/inference_loss: -4.8479 - val_loss: -4.4572 - val_loss/inference_loss: -4.4572
Epoch 101/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7231 - loss/inference_loss: -4.7231 - val_loss: -4.8050 - val_loss/inference_loss: -4.8050
Epoch 102/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7751 - loss/inference_loss: -4.7751 - val_loss: -4.4844 - val_loss/inference_loss: -4.4844
Epoch 103/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7523 - loss/inference_loss: -4.7523 - val_loss: -4.9006 - val_loss/inference_loss: -4.9006
Epoch 104/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7033 - loss/inference_loss: -4.7033 - val_loss: -4.6990 - val_loss/inference_loss: -4.6990
Epoch 105/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7926 - loss/inference_loss: -4.7926 - val_loss: -4.7092 - val_loss/inference_loss: -4.7092
Epoch 106/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7627 - loss/inference_loss: -4.7627 - val_loss: -4.7843 - val_loss/inference_loss: -4.7843
Epoch 107/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7980 - loss/inference_loss: -4.7980 - val_loss: -4.6400 - val_loss/inference_loss: -4.6400
Epoch 108/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8174 - loss/inference_loss: -4.8174 - val_loss: -4.6199 - val_loss/inference_loss: -4.6199
Epoch 109/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8923 - loss/inference_loss: -4.8923 - val_loss: -4.7405 - val_loss/inference_loss: -4.7405
Epoch 110/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7881 - loss/inference_loss: -4.7881 - val_loss: -4.7952 - val_loss/inference_loss: -4.7952
Epoch 111/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8111 - loss/inference_loss: -4.8111 - val_loss: -4.7270 - val_loss/inference_loss: -4.7270
Epoch 112/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8073 - loss/inference_loss: -4.8073 - val_loss: -4.7758 - val_loss/inference_loss: -4.7758
Epoch 113/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8272 - loss/inference_loss: -4.8272 - val_loss: -4.4083 - val_loss/inference_loss: -4.4083
Epoch 114/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.6858 - loss/inference_loss: -4.6858 - val_loss: -5.1794 - val_loss/inference_loss: -5.1794
Epoch 115/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7966 - loss/inference_loss: -4.7966 - val_loss: -4.6483 - val_loss/inference_loss: -4.6483
Epoch 116/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7098 - loss/inference_loss: -4.7098 - val_loss: -4.2666 - val_loss/inference_loss: -4.2666
Epoch 117/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8022 - loss/inference_loss: -4.8022 - val_loss: -4.6585 - val_loss/inference_loss: -4.6585
Epoch 118/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7420 - loss/inference_loss: -4.7420 - val_loss: -5.1754 - val_loss/inference_loss: -5.1754
Epoch 119/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8117 - loss/inference_loss: -4.8117 - val_loss: -4.3136 - val_loss/inference_loss: -4.3136
Epoch 120/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.7576 - loss/inference_loss: -4.7576 - val_loss: -4.8899 - val_loss/inference_loss: -4.8899
Epoch 121/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8446 - loss/inference_loss: -4.8446 - val_loss: -4.7951 - val_loss/inference_loss: -4.7951
Epoch 122/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8060 - loss/inference_loss: -4.8060 - val_loss: -4.6095 - val_loss/inference_loss: -4.6095
Epoch 123/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8055 - loss/inference_loss: -4.8055 - val_loss: -4.6514 - val_loss/inference_loss: -4.6514
Epoch 124/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8456 - loss/inference_loss: -4.8456 - val_loss: -4.9848 - val_loss/inference_loss: -4.9848
Epoch 125/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8467 - loss/inference_loss: -4.8467 - val_loss: -4.7969 - val_loss/inference_loss: -4.7969
Epoch 126/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8731 - loss/inference_loss: -4.8731 - val_loss: -4.7916 - val_loss/inference_loss: -4.7916
Epoch 127/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8011 - loss/inference_loss: -4.8011 - val_loss: -4.7630 - val_loss/inference_loss: -4.7630
Epoch 128/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8441 - loss/inference_loss: -4.8441 - val_loss: -4.4663 - val_loss/inference_loss: -4.4663
Epoch 129/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8726 - loss/inference_loss: -4.8726 - val_loss: -4.8503 - val_loss/inference_loss: -4.8503
Epoch 130/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8168 - loss/inference_loss: -4.8168 - val_loss: -4.3244 - val_loss/inference_loss: -4.3244
Epoch 131/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8885 - loss/inference_loss: -4.8885 - val_loss: -4.6628 - val_loss/inference_loss: -4.6628
Epoch 132/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9099 - loss/inference_loss: -4.9099 - val_loss: -4.5226 - val_loss/inference_loss: -4.5226
Epoch 133/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8987 - loss/inference_loss: -4.8987 - val_loss: -4.3938 - val_loss/inference_loss: -4.3938
Epoch 134/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8768 - loss/inference_loss: -4.8768 - val_loss: -4.5117 - val_loss/inference_loss: -4.5117
Epoch 135/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8756 - loss/inference_loss: -4.8756 - val_loss: -4.0552 - val_loss/inference_loss: -4.0552
Epoch 136/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9152 - loss/inference_loss: -4.9152 - val_loss: -4.7676 - val_loss/inference_loss: -4.7676
Epoch 137/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9292 - loss/inference_loss: -4.9292 - val_loss: -4.9010 - val_loss/inference_loss: -4.9010
Epoch 138/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9391 - loss/inference_loss: -4.9391 - val_loss: -4.4246 - val_loss/inference_loss: -4.4246
Epoch 139/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9360 - loss/inference_loss: -4.9360 - val_loss: -4.9845 - val_loss/inference_loss: -4.9845
Epoch 140/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9609 - loss/inference_loss: -4.9609 - val_loss: -4.7373 - val_loss/inference_loss: -4.7373
Epoch 141/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9594 - loss/inference_loss: -4.9594 - val_loss: -4.4457 - val_loss/inference_loss: -4.4457
Epoch 142/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.8992 - loss/inference_loss: -4.8992 - val_loss: -4.3389 - val_loss/inference_loss: -4.3389
Epoch 143/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9599 - loss/inference_loss: -4.9599 - val_loss: -4.9655 - val_loss/inference_loss: -4.9655
Epoch 144/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9364 - loss/inference_loss: -4.9364 - val_loss: -5.0779 - val_loss/inference_loss: -5.0779
Epoch 145/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9665 - loss/inference_loss: -4.9665 - val_loss: -4.7489 - val_loss/inference_loss: -4.7489
Epoch 146/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9137 - loss/inference_loss: -4.9137 - val_loss: -4.6059 - val_loss/inference_loss: -4.6059
Epoch 147/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9384 - loss/inference_loss: -4.9384 - val_loss: -4.7446 - val_loss/inference_loss: -4.7446
Epoch 148/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9788 - loss/inference_loss: -4.9788 - val_loss: -4.7581 - val_loss/inference_loss: -4.7581
Epoch 149/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9440 - loss/inference_loss: -4.9440 - val_loss: -4.7092 - val_loss/inference_loss: -4.7092
Epoch 150/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9026 - loss/inference_loss: -4.9026 - val_loss: -4.8947 - val_loss/inference_loss: -4.8947
Epoch 151/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9095 - loss/inference_loss: -4.9095 - val_loss: -4.8753 - val_loss/inference_loss: -4.8753
Epoch 152/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9849 - loss/inference_loss: -4.9849 - val_loss: -4.9397 - val_loss/inference_loss: -4.9397
Epoch 153/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9486 - loss/inference_loss: -4.9486 - val_loss: -4.5034 - val_loss/inference_loss: -4.5034
Epoch 154/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0167 - loss/inference_loss: -5.0167 - val_loss: -5.0282 - val_loss/inference_loss: -5.0282
Epoch 155/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0143 - loss/inference_loss: -5.0143 - val_loss: -4.7885 - val_loss/inference_loss: -4.7885
Epoch 156/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0044 - loss/inference_loss: -5.0044 - val_loss: -4.6482 - val_loss/inference_loss: -4.6482
Epoch 157/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0092 - loss/inference_loss: -5.0092 - val_loss: -4.5912 - val_loss/inference_loss: -4.5912
Epoch 158/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9626 - loss/inference_loss: -4.9626 - val_loss: -4.6790 - val_loss/inference_loss: -4.6790
Epoch 159/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9329 - loss/inference_loss: -4.9329 - val_loss: -4.0731 - val_loss/inference_loss: -4.0731
Epoch 160/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9800 - loss/inference_loss: -4.9800 - val_loss: -5.0796 - val_loss/inference_loss: -5.0796
Epoch 161/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9898 - loss/inference_loss: -4.9898 - val_loss: -5.0705 - val_loss/inference_loss: -5.0705
Epoch 162/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0186 - loss/inference_loss: -5.0186 - val_loss: -4.7744 - val_loss/inference_loss: -4.7744
Epoch 163/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9956 - loss/inference_loss: -4.9956 - val_loss: -5.1583 - val_loss/inference_loss: -5.1583
Epoch 164/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0345 - loss/inference_loss: -5.0345 - val_loss: -4.8315 - val_loss/inference_loss: -4.8315
Epoch 165/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0031 - loss/inference_loss: -5.0031 - val_loss: -4.7934 - val_loss/inference_loss: -4.7934
Epoch 166/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0411 - loss/inference_loss: -5.0411 - val_loss: -5.0811 - val_loss/inference_loss: -5.0811
Epoch 167/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0383 - loss/inference_loss: -5.0383 - val_loss: -4.8525 - val_loss/inference_loss: -4.8525
Epoch 168/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.0453 - loss/inference_loss: -5.0453 - val_loss: -4.2973 - val_loss/inference_loss: -4.2973
Epoch 169/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0497 - loss/inference_loss: -5.0497 - val_loss: -5.0105 - val_loss/inference_loss: -5.0105
Epoch 170/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0254 - loss/inference_loss: -5.0254 - val_loss: -5.0074 - val_loss/inference_loss: -5.0074
Epoch 171/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9798 - loss/inference_loss: -4.9798 - val_loss: -4.6884 - val_loss/inference_loss: -4.6884
Epoch 172/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0384 - loss/inference_loss: -5.0384 - val_loss: -4.6030 - val_loss/inference_loss: -4.6030
Epoch 173/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0385 - loss/inference_loss: -5.0385 - val_loss: -4.9788 - val_loss/inference_loss: -4.9788
Epoch 174/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0739 - loss/inference_loss: -5.0739 - val_loss: -4.7837 - val_loss/inference_loss: -4.7837
Epoch 175/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0846 - loss/inference_loss: -5.0846 - val_loss: -4.9393 - val_loss/inference_loss: -4.9393
Epoch 176/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0697 - loss/inference_loss: -5.0697 - val_loss: -4.8081 - val_loss/inference_loss: -4.8081
Epoch 177/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0151 - loss/inference_loss: -5.0151 - val_loss: -5.2398 - val_loss/inference_loss: -5.2398
Epoch 178/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0568 - loss/inference_loss: -5.0568 - val_loss: -5.0189 - val_loss/inference_loss: -5.0189
Epoch 179/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0650 - loss/inference_loss: -5.0650 - val_loss: -4.8031 - val_loss/inference_loss: -4.8031
Epoch 180/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0647 - loss/inference_loss: -5.0647 - val_loss: -4.2003 - val_loss/inference_loss: -4.2003
Epoch 181/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0207 - loss/inference_loss: -5.0207 - val_loss: -4.5383 - val_loss/inference_loss: -4.5383
Epoch 182/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1012 - loss/inference_loss: -5.1012 - val_loss: -5.1531 - val_loss/inference_loss: -5.1531
Epoch 183/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -4.9985 - loss/inference_loss: -4.9985 - val_loss: -4.4025 - val_loss/inference_loss: -4.4025
Epoch 184/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0874 - loss/inference_loss: -5.0874 - val_loss: -4.4460 - val_loss/inference_loss: -4.4460
Epoch 185/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0888 - loss/inference_loss: -5.0888 - val_loss: -4.7571 - val_loss/inference_loss: -4.7571
Epoch 186/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0859 - loss/inference_loss: -5.0859 - val_loss: -4.9933 - val_loss/inference_loss: -4.9933
Epoch 187/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0997 - loss/inference_loss: -5.0997 - val_loss: -4.9750 - val_loss/inference_loss: -4.9750
Epoch 188/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0469 - loss/inference_loss: -5.0469 - val_loss: -5.1889 - val_loss/inference_loss: -5.1889
Epoch 189/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1106 - loss/inference_loss: -5.1106 - val_loss: -4.5627 - val_loss/inference_loss: -4.5627
Epoch 190/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1199 - loss/inference_loss: -5.1199 - val_loss: -5.3866 - val_loss/inference_loss: -5.3866
Epoch 191/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0844 - loss/inference_loss: -5.0844 - val_loss: -5.3815 - val_loss/inference_loss: -5.3815
Epoch 192/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0841 - loss/inference_loss: -5.0841 - val_loss: -4.6929 - val_loss/inference_loss: -4.6929
Epoch 193/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1101 - loss/inference_loss: -5.1101 - val_loss: -5.0214 - val_loss/inference_loss: -5.0214
Epoch 194/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1321 - loss/inference_loss: -5.1321 - val_loss: -4.9826 - val_loss/inference_loss: -4.9826
Epoch 195/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1199 - loss/inference_loss: -5.1199 - val_loss: -5.0892 - val_loss/inference_loss: -5.0892
Epoch 196/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.0896 - loss/inference_loss: -5.0896 - val_loss: -4.8210 - val_loss/inference_loss: -4.8210
Epoch 197/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1220 - loss/inference_loss: -5.1220 - val_loss: -4.9720 - val_loss/inference_loss: -4.9720
Epoch 198/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1010 - loss/inference_loss: -5.1010 - val_loss: -5.2234 - val_loss/inference_loss: -5.2234
Epoch 199/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1187 - loss/inference_loss: -5.1187 - val_loss: -4.4078 - val_loss/inference_loss: -4.4078
Epoch 200/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1073 - loss/inference_loss: -5.1073 - val_loss: -5.2212 - val_loss/inference_loss: -5.2212
Epoch 201/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1493 - loss/inference_loss: -5.1493 - val_loss: -4.6900 - val_loss/inference_loss: -4.6900
Epoch 202/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1132 - loss/inference_loss: -5.1132 - val_loss: -4.5256 - val_loss/inference_loss: -4.5256
Epoch 203/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1115 - loss/inference_loss: -5.1115 - val_loss: -4.9009 - val_loss/inference_loss: -4.9009
Epoch 204/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1265 - loss/inference_loss: -5.1265 - val_loss: -5.1998 - val_loss/inference_loss: -5.1998
Epoch 205/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1508 - loss/inference_loss: -5.1508 - val_loss: -5.2862 - val_loss/inference_loss: -5.2862
Epoch 206/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1619 - loss/inference_loss: -5.1619 - val_loss: -4.9146 - val_loss/inference_loss: -4.9146
Epoch 207/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1485 - loss/inference_loss: -5.1485 - val_loss: -5.1593 - val_loss/inference_loss: -5.1593
Epoch 208/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1569 - loss/inference_loss: -5.1569 - val_loss: -4.4365 - val_loss/inference_loss: -4.4365
Epoch 209/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1646 - loss/inference_loss: -5.1646 - val_loss: -4.8914 - val_loss/inference_loss: -4.8914
Epoch 210/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1388 - loss/inference_loss: -5.1388 - val_loss: -4.3652 - val_loss/inference_loss: -4.3652
Epoch 211/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1660 - loss/inference_loss: -5.1660 - val_loss: -4.8763 - val_loss/inference_loss: -4.8763
Epoch 212/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1384 - loss/inference_loss: -5.1384 - val_loss: -4.5972 - val_loss/inference_loss: -4.5972
Epoch 213/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1523 - loss/inference_loss: -5.1523 - val_loss: -3.8672 - val_loss/inference_loss: -3.8672
Epoch 214/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1485 - loss/inference_loss: -5.1485 - val_loss: -4.8373 - val_loss/inference_loss: -4.8373
Epoch 215/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1575 - loss/inference_loss: -5.1575 - val_loss: -5.0225 - val_loss/inference_loss: -5.0225
Epoch 216/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1622 - loss/inference_loss: -5.1622 - val_loss: -4.9540 - val_loss/inference_loss: -4.9540
Epoch 217/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1636 - loss/inference_loss: -5.1636 - val_loss: -4.4958 - val_loss/inference_loss: -4.4958
Epoch 218/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1138 - loss/inference_loss: -5.1138 - val_loss: -5.0124 - val_loss/inference_loss: -5.0124
Epoch 219/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1753 - loss/inference_loss: -5.1753 - val_loss: -4.0152 - val_loss/inference_loss: -4.0152
Epoch 220/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1846 - loss/inference_loss: -5.1846 - val_loss: -5.0675 - val_loss/inference_loss: -5.0675
Epoch 221/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1987 - loss/inference_loss: -5.1987 - val_loss: -4.9107 - val_loss/inference_loss: -4.9107
Epoch 222/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2020 - loss/inference_loss: -5.2020 - val_loss: -4.9793 - val_loss/inference_loss: -4.9793
Epoch 223/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1998 - loss/inference_loss: -5.1998 - val_loss: -4.7262 - val_loss/inference_loss: -4.7262
Epoch 224/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1867 - loss/inference_loss: -5.1867 - val_loss: -5.0550 - val_loss/inference_loss: -5.0550
Epoch 225/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1779 - loss/inference_loss: -5.1779 - val_loss: -5.1747 - val_loss/inference_loss: -5.1747
Epoch 226/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1880 - loss/inference_loss: -5.1880 - val_loss: -4.9970 - val_loss/inference_loss: -4.9970
Epoch 227/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1704 - loss/inference_loss: -5.1704 - val_loss: -4.1797 - val_loss/inference_loss: -4.1797
Epoch 228/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1711 - loss/inference_loss: -5.1711 - val_loss: -5.1624 - val_loss/inference_loss: -5.1624
Epoch 229/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2137 - loss/inference_loss: -5.2137 - val_loss: -4.4952 - val_loss/inference_loss: -4.4952
Epoch 230/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.1894 - loss/inference_loss: -5.1894 - val_loss: -4.9429 - val_loss/inference_loss: -4.9429
Epoch 231/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2019 - loss/inference_loss: -5.2019 - val_loss: -4.9421 - val_loss/inference_loss: -4.9421
Epoch 232/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2075 - loss/inference_loss: -5.2075 - val_loss: -4.4526 - val_loss/inference_loss: -4.4526
Epoch 233/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2245 - loss/inference_loss: -5.2245 - val_loss: -5.2263 - val_loss/inference_loss: -5.2263
Epoch 234/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2098 - loss/inference_loss: -5.2098 - val_loss: -4.9435 - val_loss/inference_loss: -4.9435
Epoch 235/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2072 - loss/inference_loss: -5.2072 - val_loss: -4.7753 - val_loss/inference_loss: -4.7753
Epoch 236/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2007 - loss/inference_loss: -5.2007 - val_loss: -5.0158 - val_loss/inference_loss: -5.0158
Epoch 237/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2205 - loss/inference_loss: -5.2205 - val_loss: -4.6009 - val_loss/inference_loss: -4.6009
Epoch 238/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2184 - loss/inference_loss: -5.2184 - val_loss: -4.8733 - val_loss/inference_loss: -4.8733
Epoch 239/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2007 - loss/inference_loss: -5.2007 - val_loss: -5.3199 - val_loss/inference_loss: -5.3199
Epoch 240/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2139 - loss/inference_loss: -5.2139 - val_loss: -5.0239 - val_loss/inference_loss: -5.0239
Epoch 241/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2170 - loss/inference_loss: -5.2170 - val_loss: -4.6476 - val_loss/inference_loss: -4.6476
Epoch 242/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2158 - loss/inference_loss: -5.2158 - val_loss: -4.9325 - val_loss/inference_loss: -4.9325
Epoch 243/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2041 - loss/inference_loss: -5.2041 - val_loss: -4.5048 - val_loss/inference_loss: -4.5048
Epoch 244/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 7ms/step - loss: -5.2235 - loss/inference_loss: -5.2235 - val_loss: -4.6053 - val_loss/inference_loss: -4.6053
Epoch 245/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 7ms/step - loss: -5.2080 - loss/inference_loss: -5.2080 - val_loss: -4.2855 - val_loss/inference_loss: -4.2855
Epoch 246/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2231 - loss/inference_loss: -5.2231 - val_loss: -4.4008 - val_loss/inference_loss: -4.4008
Epoch 247/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2323 - loss/inference_loss: -5.2323 - val_loss: -4.2850 - val_loss/inference_loss: -4.2850
Epoch 248/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 7ms/step - loss: -5.2099 - loss/inference_loss: -5.2099 - val_loss: -4.7779 - val_loss/inference_loss: -4.7779
Epoch 249/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2454 - loss/inference_loss: -5.2454 - val_loss: -4.6392 - val_loss/inference_loss: -4.6392
Epoch 250/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2350 - loss/inference_loss: -5.2350 - val_loss: -4.2019 - val_loss/inference_loss: -4.2019
Epoch 251/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 7ms/step - loss: -5.2407 - loss/inference_loss: -5.2407 - val_loss: -4.9557 - val_loss/inference_loss: -4.9557
Epoch 252/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2248 - loss/inference_loss: -5.2248 - val_loss: -5.2701 - val_loss/inference_loss: -5.2701
Epoch 253/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2426 - loss/inference_loss: -5.2426 - val_loss: -4.9074 - val_loss/inference_loss: -4.9074
Epoch 254/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2481 - loss/inference_loss: -5.2481 - val_loss: -5.1268 - val_loss/inference_loss: -5.1268
Epoch 255/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 7ms/step - loss: -5.2427 - loss/inference_loss: -5.2427 - val_loss: -4.8440 - val_loss/inference_loss: -4.8440
Epoch 256/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2350 - loss/inference_loss: -5.2350 - val_loss: -4.1364 - val_loss/inference_loss: -4.1364
Epoch 257/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2633 - loss/inference_loss: -5.2633 - val_loss: -4.8091 - val_loss/inference_loss: -4.8091
Epoch 258/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 7ms/step - loss: -5.2535 - loss/inference_loss: -5.2535 - val_loss: -5.3434 - val_loss/inference_loss: -5.3434
Epoch 259/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2594 - loss/inference_loss: -5.2594 - val_loss: -3.9829 - val_loss/inference_loss: -3.9829
Epoch 260/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2658 - loss/inference_loss: -5.2658 - val_loss: -4.9126 - val_loss/inference_loss: -4.9126
Epoch 261/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2540 - loss/inference_loss: -5.2540 - val_loss: -5.1829 - val_loss/inference_loss: -5.1829
Epoch 262/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2659 - loss/inference_loss: -5.2659 - val_loss: -4.9568 - val_loss/inference_loss: -4.9568
Epoch 263/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2619 - loss/inference_loss: -5.2619 - val_loss: -4.9157 - val_loss/inference_loss: -4.9157
Epoch 264/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 7ms/step - loss: -5.2559 - loss/inference_loss: -5.2559 - val_loss: -5.0228 - val_loss/inference_loss: -5.0228
Epoch 265/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2561 - loss/inference_loss: -5.2561 - val_loss: -3.7003 - val_loss/inference_loss: -3.7003
Epoch 266/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2555 - loss/inference_loss: -5.2555 - val_loss: -3.9305 - val_loss/inference_loss: -3.9305
Epoch 267/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2587 - loss/inference_loss: -5.2587 - val_loss: -5.1861 - val_loss/inference_loss: -5.1861
Epoch 268/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2672 - loss/inference_loss: -5.2672 - val_loss: -5.2098 - val_loss/inference_loss: -5.2098
Epoch 269/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2680 - loss/inference_loss: -5.2680 - val_loss: -5.0293 - val_loss/inference_loss: -5.0293
Epoch 270/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2653 - loss/inference_loss: -5.2653 - val_loss: -4.9944 - val_loss/inference_loss: -4.9944
Epoch 271/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2662 - loss/inference_loss: -5.2662 - val_loss: -4.9195 - val_loss/inference_loss: -4.9195
Epoch 272/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2759 - loss/inference_loss: -5.2759 - val_loss: -4.7815 - val_loss/inference_loss: -4.7815
Epoch 273/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2681 - loss/inference_loss: -5.2681 - val_loss: -4.8184 - val_loss/inference_loss: -4.8184
Epoch 274/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2746 - loss/inference_loss: -5.2746 - val_loss: -4.9573 - val_loss/inference_loss: -4.9573
Epoch 275/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2654 - loss/inference_loss: -5.2654 - val_loss: -5.0802 - val_loss/inference_loss: -5.0802
Epoch 276/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2725 - loss/inference_loss: -5.2725 - val_loss: -5.3104 - val_loss/inference_loss: -5.3104
Epoch 277/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2666 - loss/inference_loss: -5.2666 - val_loss: -5.1854 - val_loss/inference_loss: -5.1854
Epoch 278/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2645 - loss/inference_loss: -5.2645 - val_loss: -4.7666 - val_loss/inference_loss: -4.7666
Epoch 279/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2737 - loss/inference_loss: -5.2737 - val_loss: -5.2036 - val_loss/inference_loss: -5.2036
Epoch 280/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2775 - loss/inference_loss: -5.2775 - val_loss: -4.7902 - val_loss/inference_loss: -4.7902
Epoch 281/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2636 - loss/inference_loss: -5.2636 - val_loss: -4.9190 - val_loss/inference_loss: -4.9190
Epoch 282/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2854 - loss/inference_loss: -5.2854 - val_loss: -4.6584 - val_loss/inference_loss: -4.6584
Epoch 283/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2753 - loss/inference_loss: -5.2753 - val_loss: -4.9887 - val_loss/inference_loss: -4.9887
Epoch 284/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2742 - loss/inference_loss: -5.2742 - val_loss: -5.1311 - val_loss/inference_loss: -5.1311
Epoch 285/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2823 - loss/inference_loss: -5.2823 - val_loss: -5.5849 - val_loss/inference_loss: -5.5849
Epoch 286/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2805 - loss/inference_loss: -5.2805 - val_loss: -4.8407 - val_loss/inference_loss: -4.8407
Epoch 287/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2869 - loss/inference_loss: -5.2869 - val_loss: -4.9081 - val_loss/inference_loss: -4.9081
Epoch 288/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2902 - loss/inference_loss: -5.2902 - val_loss: -4.6613 - val_loss/inference_loss: -4.6613
Epoch 289/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2798 - loss/inference_loss: -5.2798 - val_loss: -5.0978 - val_loss/inference_loss: -5.0978
Epoch 290/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2747 - loss/inference_loss: -5.2747 - val_loss: -4.8248 - val_loss/inference_loss: -4.8248
Epoch 291/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2930 - loss/inference_loss: -5.2930 - val_loss: -5.0412 - val_loss/inference_loss: -5.0412
Epoch 292/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2747 - loss/inference_loss: -5.2747 - val_loss: -4.4734 - val_loss/inference_loss: -4.4734
Epoch 293/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2810 - loss/inference_loss: -5.2810 - val_loss: -4.9051 - val_loss/inference_loss: -4.9051
Epoch 294/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2799 - loss/inference_loss: -5.2799 - val_loss: -4.8535 - val_loss/inference_loss: -4.8535
Epoch 295/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2866 - loss/inference_loss: -5.2866 - val_loss: -4.7359 - val_loss/inference_loss: -4.7359
Epoch 296/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2920 - loss/inference_loss: -5.2920 - val_loss: -5.4105 - val_loss/inference_loss: -5.4105
Epoch 297/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2967 - loss/inference_loss: -5.2967 - val_loss: -4.9626 - val_loss/inference_loss: -4.9626
Epoch 298/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2894 - loss/inference_loss: -5.2894 - val_loss: -5.1888 - val_loss/inference_loss: -5.1888
Epoch 299/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">0s</span> 6ms/step - loss: -5.2883 - loss/inference_loss: -5.2883 - val_loss: -4.1353 - val_loss/inference_loss: -4.1353
Epoch 300/300
<span class=" -Color -Color-Bold">79/79</span> <span class=" -Color -Color-Green">ââââââââââââââââââââ</span> <span class=" -Color -Color-Bold">1s</span> 6ms/step - loss: -5.2805 - loss/inference_loss: -5.2805 - val_loss: -5.1944 - val_loss/inference_loss: -5.1944
</pre></div>
</div>
</div>
</div>
</section>
<section id="inspecting-the-loss">
<h3><span class="section-number">3.6.2. </span>Inspecting the Loss <a class="anchor" id="inspecting_the_loss"></a><a class="headerlink" href="#inspecting-the-loss" title="Link to this heading">#</a></h3>
<p>Following our online simulation-based training, we can quickly visualize the loss trajectory using the <code class="docutils literal notranslate"><span class="pre">plots.loss</span></code> function from the <code class="docutils literal notranslate"><span class="pre">diagnostics</span></code> module.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/44fc5ae0ca3f6c77c5e64e19d08e44ac56f15713561fe9296182ce494e9acee9.png" src="../_images/44fc5ae0ca3f6c77c5e64e19d08e44ac56f15713561fe9296182ce494e9acee9.png" />
</div>
</div>
<p>Great, it seems that our approximator has converged! Before we get too excited and throw our networks at real data, we need to make sure that they meet our expectations <em>in silico</em>, that is, given the small world of simulations the networks have seen during training.</p>
</section>
</section>
<section id="validation-phase">
<h2><span class="section-number">3.7. </span>Validation Phase<a class="headerlink" href="#validation-phase" title="Link to this heading">#</a></h2>
<p>When it comes to validating posterior inference, we can either deploy manual diagnostics from the <code class="docutils literal notranslate"><span class="pre">diagnostics</span></code> module, or use the automated functions from the <code class="docutils literal notranslate"><span class="pre">BasicWorkflow</span></code> object. First, we demonstrate manual validation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the number of posterior draws you want to get</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Simulate 300 scenarios and extract time series from dict</span>
<span class="n">test_sims</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>
<span class="n">time_series</span> <span class="o">=</span> <span class="n">test_sims</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cases&quot;</span><span class="p">)</span>

<span class="c1"># Obtain num_samples posterior samples per scenario</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">conditions</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;cases&quot;</span><span class="p">:</span> <span class="n">time_series</span><span class="p">},</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="simulation-based-calibration-rank-histograms">
<h3><span class="section-number">3.7.1. </span>Simulation-Based Calibration - Rank Histograms<a class="headerlink" href="#simulation-based-calibration-rank-histograms" title="Link to this heading">#</a></h3>
<p>As a further <strong>small world</strong> (i.e., before real data) sanity check, we can also test the calibration of the amortizer through simulation-based calibration (SBC). See the corresponding paper for more details (https://arxiv.org/pdf/1804.06788.pdf). Accordingly, we expect to observe approximately uniform rank statistic histograms. In the present case, this is indeed what we get:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">calibration_histogram</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">test_sims</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/63877d43b3910f657546c0d0d5f78d5ea095d5e98dea0ebac12770ebc4da0460.png" src="../_images/63877d43b3910f657546c0d0d5f78d5ea095d5e98dea0ebac12770ebc4da0460.png" />
</div>
</div>
</section>
<section id="simulation-based-calibration-rank-ecdf">
<h3><span class="section-number">3.7.2. </span>Simulation-Based Calibration - Rank ECDF<a class="headerlink" href="#simulation-based-calibration-rank-ecdf" title="Link to this heading">#</a></h3>
<p>For models with many parameters, inspecting many histograms can become unwieldly. Moreover, the <code class="docutils literal notranslate"><span class="pre">num_bins</span></code> hyperparameter for the construction of SBC rank histograms can be hard to choose. An alternative diagnostic approach for calibration is through empirical cumulative distribution functions (ECDF) of rank statistics. You can read more about this approach in the corresponding paper (https://arxiv.org/abs/2103.10522).</p>
<p>In order to inspect the ECDFs of marginal distributions, we will simulate <span class="math notranslate nohighlight">\(300\)</span> new pairs of simulated data and generating parameters <span class="math notranslate nohighlight">\((\boldsymbol{x}, \boldsymbol{\theta})\)</span> and use the function <code class="docutils literal notranslate"><span class="pre">plots.calibration_ecdf</span></code> from the <code class="docutils literal notranslate"><span class="pre">diagnostics</span></code> module:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">calibration_ecdf</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">test_sims</span><span class="p">,</span> <span class="n">difference</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9671396d8687cb03e8c2bec25f2e2ba3f27a3f9f9eef6f8605335dd3be0040cb.png" src="../_images/9671396d8687cb03e8c2bec25f2e2ba3f27a3f9f9eef6f8605335dd3be0040cb.png" />
</div>
</div>
</section>
<section id="inferential-adequacy-global">
<h3><span class="section-number">3.7.3. </span>Inferential Adequacy (Global)<a class="headerlink" href="#inferential-adequacy-global" title="Link to this heading">#</a></h3>
<p>Depending on the application, it might be interesting to see how well summaries of the full posterior (e.g., means, medians) recover the assumed true parameter values. We can test this <em>in silico</em> via the <code class="docutils literal notranslate"><span class="pre">plots.recovery</span></code> function in the <code class="docutils literal notranslate"><span class="pre">diagnostics</span></code> module. For instance, we can compare how well posterior means recover the true parameter (i.e., posterior z-score, https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">recovery</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">test_sims</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/910d4536932e8e6f0b47896a6ae53d20ba3ca92686e44365cb6add0f31b12792.png" src="../_images/910d4536932e8e6f0b47896a6ae53d20ba3ca92686e44365cb6add0f31b12792.png" />
</div>
</div>
<p>Interestingly, it seems that the parameters <span class="math notranslate nohighlight">\(\theta_1 = \mu\)</span> and <span class="math notranslate nohighlight">\(\theta_2 = D\)</span> have not been learned properly as they are estimated roughly the same for every simulated datset used during testing. For some models, this might indicate that the the network training had partially failed; and we would have to train longer or adjust the network architecture. For this specific model, however, the reason is different: From the provided observables, these parameters are actually not identified so cannot be learned consistently, no matter the kind of approximator we would use.</p>
</section>
<section id="automatic-diagnostics">
<h3><span class="section-number">3.7.4. </span>Automatic Diagnostics<a class="headerlink" href="#automatic-diagnostics" title="Link to this heading">#</a></h3>
<p>The basic workflow object wraps together a bunch of useful functions that can be called automatically. For instance, we can easily obtain numerical error estimates for the big three: normalized roor mean square error (NRMSE), posterior contraction, and calibration, for <span class="math notranslate nohighlight">\(300\)</span> new data sets:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metrics</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">compute_diagnostics</span><span class="p">(</span><span class="n">test_data</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">metrics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lambd</th>
      <th>mu</th>
      <th>D</th>
      <th>I0</th>
      <th>psi</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>NRMSE</th>
      <td>0.067225</td>
      <td>0.234122</td>
      <td>0.245685</td>
      <td>0.168430</td>
      <td>0.168900</td>
    </tr>
    <tr>
      <th>Posterior Contraction</th>
      <td>0.946775</td>
      <td>0.211903</td>
      <td>0.087245</td>
      <td>0.418774</td>
      <td>0.899313</td>
    </tr>
    <tr>
      <th>Calibration Error</th>
      <td>0.024298</td>
      <td>0.037544</td>
      <td>0.022632</td>
      <td>0.016316</td>
      <td>0.011404</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can also obtain the full set of graphical diagnostics:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">figures</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">plot_diagnostics</span><span class="p">(</span>
    <span class="n">test_data</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">loss_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;label_fontsize&quot;</span><span class="p">:</span> <span class="mi">12</span><span class="p">},</span>
    <span class="n">recovery_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;label_fontsize&quot;</span><span class="p">:</span> <span class="mi">12</span><span class="p">},</span>
    <span class="n">calibration_ecdf_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;legend_fontsize&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s2">&quot;difference&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;label_fontsize&quot;</span><span class="p">:</span> <span class="mi">12</span><span class="p">},</span>
    <span class="n">z_score_contraction_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;label_fontsize&quot;</span><span class="p">:</span> <span class="mi">12</span><span class="p">}</span>    
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;positron-console-cell-24&gt;:10: RuntimeWarning: overflow encountered in expm1
/opt/miniconda3/envs/bayesflow/lib/python3.11/site-packages/numpy/core/_methods.py:173: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)
</pre></div>
</div>
<img alt="../_images/3eb430aa2455fd5fd4c4678c0ad6ebb1b5348b80e564aca0372e3fb428b89df8.png" src="../_images/3eb430aa2455fd5fd4c4678c0ad6ebb1b5348b80e564aca0372e3fb428b89df8.png" />
<img alt="../_images/423274f5a86f50c7b65267b29bd719bacca8be25f96e67aa1f8aafb3a6c099d6.png" src="../_images/423274f5a86f50c7b65267b29bd719bacca8be25f96e67aa1f8aafb3a6c099d6.png" />
<img alt="../_images/3ce5f62c81f85bbfa28eb39e6823e7614344f4272edcbd6391e8ed2acb1a6e40.png" src="../_images/3ce5f62c81f85bbfa28eb39e6823e7614344f4272edcbd6391e8ed2acb1a6e40.png" />
<img alt="../_images/155beff21b95dde1449a248212e76c0195b12d86f10f470aa148a4c97ce8784e.png" src="../_images/155beff21b95dde1449a248212e76c0195b12d86f10f470aa148a4c97ce8784e.png" />
</div>
</div>
</section>
</section>
<section id="inference-phase">
<h2><span class="section-number">3.8. </span>Inference Phase <a class="anchor" id="inference_phase"></a><a class="headerlink" href="#inference-phase" title="Link to this heading">#</a></h2>
<p>We can now move on to using real data. This is easy, and since we are using an adapter, the same transformations applied during training will be applied during the inference phase.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Our real-data loader returns the time series as a 1D array</span>
<span class="n">obs_cases</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Note that we transform the 1D array into shape (1, T), indicating one time series</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">conditions</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;cases&quot;</span><span class="p">:</span> <span class="n">obs_cases</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]},</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>

<span class="c1"># Convert into a nice format 2D data frame</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">samples_to_data_frame</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

<span class="n">samples</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lambd</th>
      <th>mu</th>
      <th>D</th>
      <th>I0</th>
      <th>psi</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.389977</td>
      <td>0.099344</td>
      <td>6.423841</td>
      <td>22.259497</td>
      <td>4.388555</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.333174</td>
      <td>0.096319</td>
      <td>7.382321</td>
      <td>43.247791</td>
      <td>13.968859</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.374435</td>
      <td>0.108260</td>
      <td>8.571528</td>
      <td>21.924253</td>
      <td>4.500786</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.414256</td>
      <td>0.164638</td>
      <td>8.253544</td>
      <td>25.943682</td>
      <td>9.791203</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.408597</td>
      <td>0.128407</td>
      <td>6.193287</td>
      <td>33.744724</td>
      <td>5.930839</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>995</th>
      <td>0.426901</td>
      <td>0.137356</td>
      <td>7.524636</td>
      <td>19.449280</td>
      <td>5.443706</td>
    </tr>
    <tr>
      <th>996</th>
      <td>0.388506</td>
      <td>0.145415</td>
      <td>8.965568</td>
      <td>25.825762</td>
      <td>11.506467</td>
    </tr>
    <tr>
      <th>997</th>
      <td>0.458162</td>
      <td>0.147817</td>
      <td>9.568476</td>
      <td>9.221110</td>
      <td>12.137198</td>
    </tr>
    <tr>
      <th>998</th>
      <td>0.359414</td>
      <td>0.141969</td>
      <td>9.411676</td>
      <td>39.595699</td>
      <td>2.017844</td>
    </tr>
    <tr>
      <th>999</th>
      <td>0.392589</td>
      <td>0.161338</td>
      <td>7.945607</td>
      <td>30.871384</td>
      <td>1.356222</td>
    </tr>
  </tbody>
</table>
<p>1000 rows Ã 5 columns</p>
</div></div></div>
</div>
<section id="posterior-retrodictive-checks">
<h3><span class="section-number">3.8.1. </span>Posterior Retrodictive Checks <a class="anchor" id="posterior_retrodictive_checks"></a><a class="headerlink" href="#posterior-retrodictive-checks" title="Link to this heading">#</a></h3>
<p>These are also called <em>posterior predictive checks</em>, but here we want to explicitly highlight the fact that we are not predicting future data but testing the <strong>generative performance</strong> or <strong>re-simulation performance</strong> of the model. In other words, we want to test how well the simulator can reproduce the actually observed data given the parameter posterior <span class="math notranslate nohighlight">\(p(\theta \mid x_{1:T})\)</span>.</p>
<p>Here, we will create a custom function which plots the observed data and then overlays draws from the posterior predictive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_ppc</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">obs_cases</span><span class="p">,</span> <span class="n">logscale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#132a70&quot;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">18</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to perform some plotting of the posterior predictive.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Plot settings</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;font.size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">font_size</span>
    <span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="n">T</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">obs_cases</span><span class="p">)</span>

    <span class="c1"># Re-simulations</span>
    <span class="n">sims</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="c1"># Note - simulator returns 2D arrays of shape (T, 1), so we remove trailing dim</span>
        <span class="n">sim_cases</span> <span class="o">=</span> <span class="n">stationary_SIR</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">sims</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sim_cases</span><span class="p">[</span><span class="s2">&quot;cases&quot;</span><span class="p">])</span>
    <span class="n">sims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sims</span><span class="p">)</span>

    <span class="c1"># Compute quantiles for each t = 1,...,T</span>
    <span class="n">qs_50</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">sims</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">qs_90</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">sims</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">qs_95</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">sims</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="p">[</span><span class="mf">0.025</span><span class="p">,</span> <span class="mf">0.975</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Plot median predictions and observed data</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">sims</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Median predicted cases&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">obs_cases</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Reported cases&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

    <span class="c1"># Add compatibility intervals (also called credible intervals)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">qs_50</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">qs_50</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;50% CI&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">qs_90</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">qs_90</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;90% CI&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">qs_95</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">qs_95</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;95% CI&quot;</span><span class="p">)</span>

    <span class="c1"># Grid and schmuck</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">&quot;top&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Days since pandemic onset&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of cases&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">minorticks_off</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">logscale</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f</span>
</pre></div>
</div>
</div>
</div>
<p>We can now go on and plot the re-simulations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">plot_ppc</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">obs_cases</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7f419bdf6352e7b5f75b7f6af35e441689d23eb45fffc299c50c42393d64e5eb.png" src="../_images/7f419bdf6352e7b5f75b7f6af35e441689d23eb45fffc299c50c42393d64e5eb.png" />
</div>
</div>
<p>Thatâs it for this tutorial! You now know how to use the basic building blocks of <code class="docutils literal notranslate"><span class="pre">BayesFlow</span></code> to create amortized neural approximators. :)</p>
<!-- In the [next tutorial](./PriorSensitivity_Covid19_Initial.ipynb), we will go through a <strong>prior sensitivity analysis</strong> with `BayesFlow`, which is as easy to perform as it is important for ascertaining the robustness of our inferences. --></section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Two_Moons_Starter.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Two Moons: Tackling Bimodal Posteriors</p>
      </div>
    </a>
    <a class="right-next"
       href="Hyperparameter_Optimization.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Hyperparameter Optimization Using Optuna</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">3.1. Introduction <a class="anchor" id="introduction"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-simulator">3.2. Defining the Simulator <a class="anchor" id="defining_the_generative"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior">3.2.1. Prior <a class="anchor" id="prior"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#observation-model-implicit-likelihood-function">3.2.2. Observation Model (Implicit Likelihood Function) <a class="anchor" id="simulator__implicit_likelihood"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-real-data">3.2.3. Loading Real Data <a class="anchor" id="loading_real_data"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stitiching-things-together">3.2.4. Stitiching Things Together <a class="anchor" id="generative_model"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-checking">3.3. Prior Checking <a class="anchor" id="prior_checking"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-adapter">3.4. Defining the Adapter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-neural-approximator">3.5. Defining the Neural Approximator <a class="anchor" id="defining_the_neural"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-network">3.5.1. Summary Network <a class="anchor" id="summary_network"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-network">3.5.2. Inference Network</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training">3.6. Training <a class="anchor" id="training"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-offline-data">3.6.1. Generating Offline Data <a class="anchor" id="generating_offline_data"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inspecting-the-loss">3.6.2. Inspecting the Loss <a class="anchor" id="inspecting_the_loss"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#validation-phase">3.7. Validation Phase</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-based-calibration-rank-histograms">3.7.1. Simulation-Based Calibration - Rank Histograms</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-based-calibration-rank-ecdf">3.7.2. Simulation-Based Calibration - Rank ECDF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inferential-adequacy-global">3.7.3. Inferential Adequacy (Global)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-diagnostics">3.7.4. Automatic Diagnostics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-phase">3.8. Inference Phase <a class="anchor" id="inference_phase"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-retrodictive-checks">3.8.1. Posterior Retrodictive Checks <a class="anchor" id="posterior_retrodictive_checks"></a></a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/bayesflow-org/bayesflow/edit/dev/docsrc/_examples/SIR_Posterior_Estimation.ipynb">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      Â© Copyright 2023-2025, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>