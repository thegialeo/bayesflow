
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Hyperparameter Optimization Using Optuna &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=8fec244e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_examples/experimental/Hyperparameter_Optimization';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = '/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'dev';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="canonical" href="https://www.bayesflow.org/_examples/experimental/Hyperparameter_Optimization.html" />
    <link rel="icon" href="../../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/bayesflow_hor.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <img src="../../_static/bayesflow_hor_dark.png" class="logo__image only-dark pst-js-only" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/bayesflow.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../about.html">
    About us
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../development/index.html">
    Developer docs
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/bayesflow.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../about.html">
    About us
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../development/index.html">
    Developer docs
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Hyperparameter Optimization Using Optuna</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="hyperparameter-optimization-using-optuna">
<h1>Hyperparameter Optimization Using Optuna<a class="headerlink" href="#hyperparameter-optimization-using-optuna" title="Link to this heading">#</a></h1>
<p><em>Author: Stefan T. Radev</em></p>
<p>This is a quick tutorial demonstrating how to combine automatic hyperparameter optimization using the awesome <code class="docutils literal notranslate"><span class="pre">optuna</span></code> package with <code class="docutils literal notranslate"><span class="pre">BayesFlow</span></code>.</p>
<p>Optuna is a powerful and easy-to-use framework for automatic hyperparameter optimization. It provides efficient search algorithms, such as Tree-structured Parzen Estimator (TPE) and Bayesian optimization, to find the best hyperparameters for machine learning models. Optuna is particularly useful for deep learning applications, as it allows users to define search spaces, implement pruning strategies, and parallelize optimization runs.</p>
<p>For more details, check out the official Optuna documentation: https://optuna.org.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install if not already installed</span>
<span class="o">%</span><span class="k">pip</span> install optuna -q
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="c1"># Ensure the backend is set</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="k">if</span> <span class="s2">&quot;KERAS_BACKEND&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="c1"># set this to &quot;torch&quot;, &quot;tensorflow&quot;, or &quot;jax&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;KERAS_BACKEND&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;jax&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">keras</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">optuna</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">bayesflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">bf</span>
</pre></div>
</div>
</div>
</div>
<section id="simulator-and-data">
<h2>Simulator and Data<a class="headerlink" href="#simulator-and-data" title="Link to this heading">#</a></h2>
<p>First, we simulate mini training and validation data sets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prepare simulator - using our favorite two moons</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">simulator</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">benchmarks</span><span class="o">.</span><span class="n">simulators</span><span class="o">.</span><span class="n">TwoMoons</span><span class="p">()</span>

<span class="c1"># Prepare data dictionaries</span>
<span class="n">train_samples</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="n">val_samples</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

<span class="c1"># Prepare data adapter to connect data with networks</span>
<span class="n">adapter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">bf</span><span class="o">.</span><span class="n">adapters</span><span class="o">.</span><span class="n">Adapter</span><span class="p">()</span>
    <span class="o">.</span><span class="n">convert_dtype</span><span class="p">(</span><span class="s2">&quot;float64&quot;</span><span class="p">,</span> <span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;parameters&quot;</span><span class="p">,</span> <span class="s2">&quot;inference_variables&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;observables&quot;</span><span class="p">,</span> <span class="s2">&quot;inference_conditions&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Prepare data sets</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">OfflineDataset</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">train_samples</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
    <span class="n">adapter</span><span class="o">=</span><span class="n">adapter</span>
<span class="p">)</span>

<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">OfflineDataset</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">val_samples</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
    <span class="n">adapter</span><span class="o">=</span><span class="n">adapter</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="test-objective">
<h2>Test Objective<a class="headerlink" href="#test-objective" title="Link to this heading">#</a></h2>
<p>We then define an “objective function” that will carry out the entire training and return the average validation loss over the last 5 epochs. This objective function will play the role of our “black box” function that we are going to minimize.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dummy objective function without adaptive parameters.&quot;&quot;&quot;</span>

    <span class="c1"># Hardcode hyperparameters</span>
    <span class="n">max_time</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">width</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">depth</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.05</span>
    <span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="mf">5e-4</span>
    
    <span class="c1"># Create inference net</span>
    <span class="n">sigma2</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">train_samples</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">inference_network</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">ConsistencyModel</span><span class="p">(</span>
        <span class="n">subnet_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;widths&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">width</span><span class="p">,)</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout</span><span class="p">},</span>
        <span class="n">total_steps</span><span class="o">=</span><span class="n">epochs</span><span class="o">*</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">num_batches</span><span class="p">,</span>
        <span class="n">max_time</span><span class="o">=</span><span class="n">max_time</span><span class="p">,</span>
        <span class="n">sigma2</span><span class="o">=</span><span class="n">sigma2</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Create optimizer</span>
    <span class="n">scheduled_lr</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">CosineDecay</span><span class="p">(</span>
        <span class="n">initial_learning_rate</span><span class="o">=</span><span class="n">initial_learning_rate</span><span class="p">,</span>
        <span class="n">decay_steps</span><span class="o">=</span><span class="n">epochs</span><span class="o">*</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">num_batches</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-8</span>
    <span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">scheduled_lr</span><span class="p">)</span>
    
    
    <span class="c1"># Create approximator</span>
    <span class="n">approximator</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">ContinuousApproximator</span><span class="p">(</span>
        <span class="n">inference_network</span><span class="o">=</span><span class="n">inference_network</span><span class="p">,</span>
        <span class="n">adapter</span><span class="o">=</span><span class="n">adapter</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">approximator</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
    
    <span class="c1"># Train and compute the average of last 5 validation losses</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">approximator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
        <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">validation_data</span><span class="o">=</span><span class="n">val_dataset</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">5</span><span class="p">:])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation loss: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">objective</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validation loss: 0.31451714038848877
</pre></div>
</div>
</div>
</div>
</section>
<section id="optuna-objective">
<h2>Optuna Objective<a class="headerlink" href="#optuna-objective" title="Link to this heading">#</a></h2>
<p>Nextm we will create an optuna objective that will optimize some of the parameters. The objective is the same as before, but we will train for more epochs and take the average of the last 10 validation losses</p>
<p>You can read more about <code class="docutils literal notranslate"><span class="pre">optuna</span></code>’s trial and study objects here:
https://optuna.readthedocs.io/en/stable/tutorial/index.html</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optuna-friendly objective functions with adaptive parameters.&quot;&quot;&quot;</span>
    
    <span class="c1"># Optimize hyperparameters</span>
    <span class="n">max_time</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;max_time&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
    <span class="n">width</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;width&quot;</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
    <span class="n">depth</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;depth&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">)</span> 
    
    <span class="c1"># Create inference net</span>
    <span class="n">sigma2</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">train_samples</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">inference_network</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">ConsistencyModel</span><span class="p">(</span>
        <span class="n">subnet_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;widths&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">width</span><span class="p">,)</span><span class="o">*</span><span class="n">depth</span><span class="p">,</span> <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout</span><span class="p">},</span>
        <span class="n">total_steps</span><span class="o">=</span><span class="n">epochs</span><span class="o">*</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">num_batches</span><span class="p">,</span>
        <span class="n">max_time</span><span class="o">=</span><span class="n">max_time</span><span class="p">,</span>
        <span class="n">sigma2</span><span class="o">=</span><span class="n">sigma2</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Create optimizer</span>
    <span class="n">scheduled_lr</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">CosineDecay</span><span class="p">(</span>
        <span class="n">initial_learning_rate</span><span class="o">=</span><span class="n">initial_learning_rate</span><span class="p">,</span>
        <span class="n">decay_steps</span><span class="o">=</span><span class="n">epochs</span><span class="o">*</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">num_batches</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-8</span>
    <span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">scheduled_lr</span><span class="p">)</span>
    
    
    <span class="c1"># Create approximator</span>
    <span class="n">approximator</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">ContinuousApproximator</span><span class="p">(</span>
        <span class="n">inference_network</span><span class="o">=</span><span class="n">inference_network</span><span class="p">,</span>
        <span class="n">adapter</span><span class="o">=</span><span class="n">adapter</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">approximator</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
    
    <span class="c1"># Train and compute the average of last 5 validation losses</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">approximator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
        <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">validation_data</span><span class="o">=</span><span class="n">val_dataset</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">10</span><span class="p">:])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="optimization">
<h2>Optimization<a class="headerlink" href="#optimization" title="Link to this heading">#</a></h2>
<p>This will take some time…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s2">&quot;minimize&quot;</span><span class="p">)</span>

<span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[I 2024-10-23 20:29:50,984] A new study created in memory with name: no-name-8fedce79-d631-428a-99f0-21b2fd7091bb
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:30:10,936] Trial 0 finished with value: 0.2781076431274414 and parameters: {&#39;max_time&#39;: 16, &#39;width&#39;: 487, &#39;depth&#39;: 8, &#39;dropout&#39;: 0.08407618206861452, &#39;lr&#39;: 0.000996043558997382}. Best is trial 0 with value: 0.2781076431274414.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:30:30,105] Trial 1 finished with value: 0.30119574069976807 and parameters: {&#39;max_time&#39;: 10, &#39;width&#39;: 397, &#39;depth&#39;: 8, &#39;dropout&#39;: 0.08842429740420331, &#39;lr&#39;: 0.0002496152860809169}. Best is trial 0 with value: 0.2781076431274414.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:30:40,460] Trial 2 finished with value: 0.3316212296485901 and parameters: {&#39;max_time&#39;: 21, &#39;width&#39;: 476, &#39;depth&#39;: 3, &#39;dropout&#39;: 0.3094303276114094, &#39;lr&#39;: 0.0004744518984923979}. Best is trial 0 with value: 0.2781076431274414.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:30:48,740] Trial 3 finished with value: 0.4399487376213074 and parameters: {&#39;max_time&#39;: 13, &#39;width&#39;: 131, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.4535853588990584, &#39;lr&#39;: 0.00027249948607552173}. Best is trial 0 with value: 0.2781076431274414.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:31:00,970] Trial 4 finished with value: 0.28782323002815247 and parameters: {&#39;max_time&#39;: 7, &#39;width&#39;: 487, &#39;depth&#39;: 4, &#39;dropout&#39;: 0.13565935172617397, &#39;lr&#39;: 0.0003622044158515283}. Best is trial 0 with value: 0.2781076431274414.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:31:12,235] Trial 5 finished with value: 0.4406112730503082 and parameters: {&#39;max_time&#39;: 8, &#39;width&#39;: 292, &#39;depth&#39;: 5, &#39;dropout&#39;: 0.4596952563387505, &#39;lr&#39;: 0.000375937763213568}. Best is trial 0 with value: 0.2781076431274414.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:31:21,357] Trial 6 finished with value: 0.31373152136802673 and parameters: {&#39;max_time&#39;: 23, &#39;width&#39;: 276, &#39;depth&#39;: 4, &#39;dropout&#39;: 0.1641997731426553, &#39;lr&#39;: 0.0005601232470638673}. Best is trial 0 with value: 0.2781076431274414.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:31:29,318] Trial 7 finished with value: 0.3127148747444153 and parameters: {&#39;max_time&#39;: 29, &#39;width&#39;: 345, &#39;depth&#39;: 2, &#39;dropout&#39;: 0.3023139236781793, &#39;lr&#39;: 0.0008747884710466424}. Best is trial 0 with value: 0.2781076431274414.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:31:44,167] Trial 8 finished with value: 0.27121502161026 and parameters: {&#39;max_time&#39;: 29, &#39;width&#39;: 420, &#39;depth&#39;: 5, &#39;dropout&#39;: 0.0647419223980172, &#39;lr&#39;: 0.00017727938067634182}. Best is trial 8 with value: 0.27121502161026.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:31:56,209] Trial 9 finished with value: 0.31134939193725586 and parameters: {&#39;max_time&#39;: 12, &#39;width&#39;: 386, &#39;depth&#39;: 4, &#39;dropout&#39;: 0.05736439345407353, &#39;lr&#39;: 0.00013618500286639618}. Best is trial 8 with value: 0.27121502161026.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:32:06,678] Trial 10 finished with value: 0.35270339250564575 and parameters: {&#39;max_time&#39;: 28, &#39;width&#39;: 213, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.23743630668200222, &#39;lr&#39;: 0.000670992032723469}. Best is trial 8 with value: 0.27121502161026.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:32:23,652] Trial 11 finished with value: 0.28634124994277954 and parameters: {&#39;max_time&#39;: 2, &#39;width&#39;: 436, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.018166710442146898, &#39;lr&#39;: 0.0009489201368517872}. Best is trial 8 with value: 0.27121502161026.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:32:42,675] Trial 12 finished with value: 0.28297972679138184 and parameters: {&#39;max_time&#39;: 19, &#39;width&#39;: 497, &#39;depth&#39;: 8, &#39;dropout&#39;: 0.19260064948667557, &#39;lr&#39;: 0.0007364024416144082}. Best is trial 8 with value: 0.27121502161026.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:33:00,019] Trial 13 finished with value: 0.2630299925804138 and parameters: {&#39;max_time&#39;: 17, &#39;width&#39;: 436, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.10082047489123368, &#39;lr&#39;: 0.0007689133072032641}. Best is trial 13 with value: 0.2630299925804138.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:33:16,021] Trial 14 finished with value: 0.2374543845653534 and parameters: {&#39;max_time&#39;: 25, &#39;width&#39;: 407, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.019483517614186013, &#39;lr&#39;: 0.0007809645019547853}. Best is trial 14 with value: 0.2374543845653534.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:33:30,326] Trial 15 finished with value: 0.23585954308509827 and parameters: {&#39;max_time&#39;: 24, &#39;width&#39;: 358, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.011485157806539359, &#39;lr&#39;: 0.0007856429313897751}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:33:46,207] Trial 16 finished with value: 0.25637853145599365 and parameters: {&#39;max_time&#39;: 24, &#39;width&#39;: 362, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.019357166478202768, &#39;lr&#39;: 0.0008269829614057555}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:34:00,131] Trial 17 finished with value: 0.4107109606266022 and parameters: {&#39;max_time&#39;: 25, &#39;width&#39;: 311, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.38833937398420926, &#39;lr&#39;: 0.000605510873986127}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:34:10,531] Trial 18 finished with value: 0.31555992364883423 and parameters: {&#39;max_time&#39;: 26, &#39;width&#39;: 238, &#39;depth&#39;: 5, &#39;dropout&#39;: 0.22749946828320425, &#39;lr&#39;: 0.0006771971929378476}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:34:24,773] Trial 19 finished with value: 0.27185505628585815 and parameters: {&#39;max_time&#39;: 22, &#39;width&#39;: 348, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.14135531690505235, &#39;lr&#39;: 0.0009005874662489604}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:34:36,451] Trial 20 finished with value: 0.2486293613910675 and parameters: {&#39;max_time&#39;: 20, &#39;width&#39;: 256, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.011514739768607767, &#39;lr&#39;: 0.0008016106620789684}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:34:47,750] Trial 21 finished with value: 0.2578854560852051 and parameters: {&#39;max_time&#39;: 19, &#39;width&#39;: 248, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.013527312920168132, &#39;lr&#39;: 0.0007959606936233601}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:34:56,676] Trial 22 finished with value: 0.25158369541168213 and parameters: {&#39;max_time&#39;: 20, &#39;width&#39;: 153, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.011637856002160264, &#39;lr&#39;: 0.0006951360770033031}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:35:06,581] Trial 23 finished with value: 0.2482193261384964 and parameters: {&#39;max_time&#39;: 26, &#39;width&#39;: 176, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.057785640956793546, &#39;lr&#39;: 0.0008353358157159328}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:35:15,523] Trial 24 finished with value: 0.30703312158584595 and parameters: {&#39;max_time&#39;: 27, &#39;width&#39;: 176, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.10898778860482289, &#39;lr&#39;: 0.0008875112382879753}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:35:28,892] Trial 25 finished with value: 0.25223618745803833 and parameters: {&#39;max_time&#39;: 25, &#39;width&#39;: 375, &#39;depth&#39;: 5, &#39;dropout&#39;: 0.06143755723772134, &#39;lr&#39;: 0.0005893963771896564}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:35:42,967] Trial 26 finished with value: 0.3183043599128723 and parameters: {&#39;max_time&#39;: 23, &#39;width&#39;: 328, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.17269343361499223, &#39;lr&#39;: 0.0005113259742472198}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:35:53,822] Trial 27 finished with value: 0.2664421498775482 and parameters: {&#39;max_time&#39;: 30, &#39;width&#39;: 199, &#39;depth&#39;: 8, &#39;dropout&#39;: 0.05774561326504818, &#39;lr&#39;: 0.000994233730869293}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:36:10,074] Trial 28 finished with value: 0.27608925104141235 and parameters: {&#39;max_time&#39;: 27, &#39;width&#39;: 408, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.12378190472454766, &#39;lr&#39;: 0.0008536859132849431}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:36:32,743] Trial 29 finished with value: 0.34573644399642944 and parameters: {&#39;max_time&#39;: 16, &#39;width&#39;: 459, &#39;depth&#39;: 8, &#39;dropout&#39;: 0.28668991179079406, &#39;lr&#39;: 0.0009393776402383928}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:36:45,931] Trial 30 finished with value: 0.3940160870552063 and parameters: {&#39;max_time&#39;: 17, &#39;width&#39;: 307, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.37623620958457404, &#39;lr&#39;: 0.0007302812284694401}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:36:57,591] Trial 31 finished with value: 0.24941691756248474 and parameters: {&#39;max_time&#39;: 21, &#39;width&#39;: 262, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.04406785794209124, &#39;lr&#39;: 0.0006358787426657725}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:37:10,521] Trial 32 finished with value: 0.29204675555229187 and parameters: {&#39;max_time&#39;: 24, &#39;width&#39;: 223, &#39;depth&#39;: 8, &#39;dropout&#39;: 0.09607961794475522, &#39;lr&#39;: 0.0007992923237756109}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:37:19,424] Trial 33 finished with value: 0.28238824009895325 and parameters: {&#39;max_time&#39;: 22, &#39;width&#39;: 187, &#39;depth&#39;: 5, &#39;dropout&#39;: 0.04394434504811212, &#39;lr&#39;: 0.0007519610278709087}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:37:28,822] Trial 34 finished with value: 0.27748358249664307 and parameters: {&#39;max_time&#39;: 19, &#39;width&#39;: 164, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.08575903851214398, &#39;lr&#39;: 0.0008291660043419292}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:37:42,249] Trial 35 finished with value: 0.2443634569644928 and parameters: {&#39;max_time&#39;: 26, &#39;width&#39;: 281, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.03393856736959856, &#39;lr&#39;: 0.0009429219041053773}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:37:58,407] Trial 36 finished with value: 0.25684645771980286 and parameters: {&#39;max_time&#39;: 26, &#39;width&#39;: 336, &#39;depth&#39;: 8, &#39;dropout&#39;: 0.07337639305827656, &#39;lr&#39;: 0.0009981276939963497}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:38:10,025] Trial 37 finished with value: 0.2512300908565521 and parameters: {&#39;max_time&#39;: 30, &#39;width&#39;: 284, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.042278259935898926, &#39;lr&#39;: 0.0009428233215986037}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:38:18,628] Trial 38 finished with value: 0.286550372838974 and parameters: {&#39;max_time&#39;: 28, &#39;width&#39;: 463, &#39;depth&#39;: 2, &#39;dropout&#39;: 0.13020915284607743, &#39;lr&#39;: 0.0009168690665284549}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:38:27,715] Trial 39 finished with value: 0.33955931663513184 and parameters: {&#39;max_time&#39;: 14, &#39;width&#39;: 135, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.08887121425947395, &#39;lr&#39;: 0.0004727285141874531}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:38:40,080] Trial 40 finished with value: 0.3291551470756531 and parameters: {&#39;max_time&#39;: 24, &#39;width&#39;: 381, &#39;depth&#39;: 4, &#39;dropout&#39;: 0.3504728461888442, &#39;lr&#39;: 0.0008610260457886173}. Best is trial 15 with value: 0.23585954308509827.
INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
[I 2024-10-23 20:38:52,194] Trial 41 finished with value: 0.258425235748291 and parameters: {&#39;max_time&#39;: 21, &#39;width&#39;: 267, &#39;depth&#39;: 7, &#39;dropout&#39;: 0.03398980985626532, &#39;lr&#39;: 0.0008063069035018496}. Best is trial 15 with value: 0.23585954308509827.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trial</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trial</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation loss: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best hyperparameters: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validation loss: 0.23585954308509827
Best hyperparameters: {&#39;max_time&#39;: 24, &#39;width&#39;: 358, &#39;depth&#39;: 6, &#39;dropout&#39;: 0.011485157806539359, &#39;lr&#39;: 0.0007856429313897751}
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-with-best-parameters">
<h2>Training With Best Parameters<a class="headerlink" href="#training-with-best-parameters" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create inference net</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sigma2</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">train_samples</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">inference_network</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">ConsistencyModel</span><span class="p">(</span>
    <span class="n">subnet_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;widths&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;width&quot;</span><span class="p">],)</span><span class="o">*</span><span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;depth&quot;</span><span class="p">],</span> <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]},</span>
    <span class="n">total_steps</span><span class="o">=</span><span class="n">epochs</span><span class="o">*</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">num_batches</span><span class="p">,</span>
    <span class="n">max_time</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;max_time&quot;</span><span class="p">],</span>
    <span class="n">sigma2</span><span class="o">=</span><span class="n">sigma2</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Create optimizer</span>
<span class="n">scheduled_lr</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">CosineDecay</span><span class="p">(</span>
    <span class="n">initial_learning_rate</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span>
    <span class="n">decay_steps</span><span class="o">=</span><span class="n">epochs</span><span class="o">*</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">num_batches</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-8</span>
<span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">scheduled_lr</span><span class="p">)</span>


<span class="c1"># Create approximator</span>
<span class="n">approximator</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">ContinuousApproximator</span><span class="p">(</span>
    <span class="n">inference_network</span><span class="o">=</span><span class="n">inference_network</span><span class="p">,</span>
    <span class="n">adapter</span><span class="o">=</span><span class="n">adapter</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">approximator</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

<span class="c1"># Train and compute the average of last 5 validation losses</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">approximator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">val_dataset</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 43ms/step - loss: 0.5660 - loss/inference_loss: 0.5660 - val_loss: 0.4609 - val_loss/inference_loss: 0.4609
Epoch 2/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.4378 - loss/inference_loss: 0.4378 - val_loss: 0.4148 - val_loss/inference_loss: 0.4148
Epoch 3/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.4134 - loss/inference_loss: 0.4134 - val_loss: 0.4250 - val_loss/inference_loss: 0.4250
Epoch 4/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.4145 - loss/inference_loss: 0.4145 - val_loss: 0.3148 - val_loss/inference_loss: 0.3148
Epoch 5/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.3950 - loss/inference_loss: 0.3950 - val_loss: 0.4395 - val_loss/inference_loss: 0.4395
Epoch 6/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3729 - loss/inference_loss: 0.3729 - val_loss: 0.3325 - val_loss/inference_loss: 0.3325
Epoch 7/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3508 - loss/inference_loss: 0.3508 - val_loss: 0.3795 - val_loss/inference_loss: 0.3795
Epoch 8/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3669 - loss/inference_loss: 0.3669 - val_loss: 0.3775 - val_loss/inference_loss: 0.3775
Epoch 9/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.3680 - loss/inference_loss: 0.3680 - val_loss: 0.2909 - val_loss/inference_loss: 0.2909
Epoch 10/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3446 - loss/inference_loss: 0.3446 - val_loss: 0.2990 - val_loss/inference_loss: 0.2990
Epoch 11/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3378 - loss/inference_loss: 0.3378 - val_loss: 0.2962 - val_loss/inference_loss: 0.2962
Epoch 12/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.3238 - loss/inference_loss: 0.3238 - val_loss: 0.3046 - val_loss/inference_loss: 0.3046
Epoch 13/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.3552 - loss/inference_loss: 0.3552 - val_loss: 0.3286 - val_loss/inference_loss: 0.3286
Epoch 14/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3375 - loss/inference_loss: 0.3375 - val_loss: 0.2796 - val_loss/inference_loss: 0.2796
Epoch 15/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3312 - loss/inference_loss: 0.3312 - val_loss: 0.2589 - val_loss/inference_loss: 0.2589
Epoch 16/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3253 - loss/inference_loss: 0.3253 - val_loss: 0.2748 - val_loss/inference_loss: 0.2748
Epoch 17/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.3164 - loss/inference_loss: 0.3164 - val_loss: 0.3016 - val_loss/inference_loss: 0.3016
Epoch 18/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.3031 - loss/inference_loss: 0.3031 - val_loss: 0.2771 - val_loss/inference_loss: 0.2771
Epoch 19/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3285 - loss/inference_loss: 0.3285 - val_loss: 0.2857 - val_loss/inference_loss: 0.2857
Epoch 20/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2987 - loss/inference_loss: 0.2987 - val_loss: 0.2930 - val_loss/inference_loss: 0.2930
Epoch 21/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3305 - loss/inference_loss: 0.3305 - val_loss: 0.3268 - val_loss/inference_loss: 0.3268
Epoch 22/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3166 - loss/inference_loss: 0.3166 - val_loss: 0.2777 - val_loss/inference_loss: 0.2777
Epoch 23/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3196 - loss/inference_loss: 0.3196 - val_loss: 0.2478 - val_loss/inference_loss: 0.2478
Epoch 24/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.3357 - loss/inference_loss: 0.3357 - val_loss: 0.2562 - val_loss/inference_loss: 0.2562
Epoch 25/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2970 - loss/inference_loss: 0.2970 - val_loss: 0.2990 - val_loss/inference_loss: 0.2990
Epoch 26/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 17ms/step - loss: 0.2938 - loss/inference_loss: 0.2938 - val_loss: 0.2803 - val_loss/inference_loss: 0.2803
Epoch 27/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3236 - loss/inference_loss: 0.3236 - val_loss: 0.2917 - val_loss/inference_loss: 0.2917
Epoch 28/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2862 - loss/inference_loss: 0.2862 - val_loss: 0.2312 - val_loss/inference_loss: 0.2312
Epoch 29/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2925 - loss/inference_loss: 0.2925 - val_loss: 0.2785 - val_loss/inference_loss: 0.2785
Epoch 30/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2981 - loss/inference_loss: 0.2981 - val_loss: 0.2893 - val_loss/inference_loss: 0.2893
Epoch 31/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3022 - loss/inference_loss: 0.3022 - val_loss: 0.2788 - val_loss/inference_loss: 0.2788
Epoch 32/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 18ms/step - loss: 0.2742 - loss/inference_loss: 0.2742 - val_loss: 0.3328 - val_loss/inference_loss: 0.3328
Epoch 33/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3231 - loss/inference_loss: 0.3231 - val_loss: 0.2749 - val_loss/inference_loss: 0.2749
Epoch 34/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2979 - loss/inference_loss: 0.2979 - val_loss: 0.2672 - val_loss/inference_loss: 0.2672
Epoch 35/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3028 - loss/inference_loss: 0.3028 - val_loss: 0.3041 - val_loss/inference_loss: 0.3041
Epoch 36/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2880 - loss/inference_loss: 0.2880 - val_loss: 0.3372 - val_loss/inference_loss: 0.3372
Epoch 37/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2748 - loss/inference_loss: 0.2748 - val_loss: 0.2557 - val_loss/inference_loss: 0.2557
Epoch 38/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2849 - loss/inference_loss: 0.2849 - val_loss: 0.2485 - val_loss/inference_loss: 0.2485
Epoch 39/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2967 - loss/inference_loss: 0.2967 - val_loss: 0.2582 - val_loss/inference_loss: 0.2582
Epoch 40/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2732 - loss/inference_loss: 0.2732 - val_loss: 0.3011 - val_loss/inference_loss: 0.3011
Epoch 41/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2957 - loss/inference_loss: 0.2957 - val_loss: 0.1968 - val_loss/inference_loss: 0.1968
Epoch 42/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2994 - loss/inference_loss: 0.2994 - val_loss: 0.2663 - val_loss/inference_loss: 0.2663
Epoch 43/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.3015 - loss/inference_loss: 0.3015 - val_loss: 0.2488 - val_loss/inference_loss: 0.2488
Epoch 44/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2802 - loss/inference_loss: 0.2802 - val_loss: 0.2848 - val_loss/inference_loss: 0.2848
Epoch 45/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2938 - loss/inference_loss: 0.2938 - val_loss: 0.3287 - val_loss/inference_loss: 0.3287
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 46/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2680 - loss/inference_loss: 0.2680 - val_loss: 0.2748 - val_loss/inference_loss: 0.2748
Epoch 47/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.3041 - loss/inference_loss: 0.3041 - val_loss: 0.2359 - val_loss/inference_loss: 0.2359
Epoch 48/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2683 - loss/inference_loss: 0.2683 - val_loss: 0.2485 - val_loss/inference_loss: 0.2485
Epoch 49/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2813 - loss/inference_loss: 0.2813 - val_loss: 0.2590 - val_loss/inference_loss: 0.2590
Epoch 50/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2713 - loss/inference_loss: 0.2713 - val_loss: 0.2769 - val_loss/inference_loss: 0.2769
Epoch 51/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2714 - loss/inference_loss: 0.2714 - val_loss: 0.3105 - val_loss/inference_loss: 0.3105
Epoch 52/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2778 - loss/inference_loss: 0.2778 - val_loss: 0.1946 - val_loss/inference_loss: 0.1946
Epoch 53/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2825 - loss/inference_loss: 0.2825 - val_loss: 0.2775 - val_loss/inference_loss: 0.2775
Epoch 54/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2959 - loss/inference_loss: 0.2959 - val_loss: 0.2072 - val_loss/inference_loss: 0.2072
Epoch 55/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2703 - loss/inference_loss: 0.2703 - val_loss: 0.2331 - val_loss/inference_loss: 0.2331
Epoch 56/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2811 - loss/inference_loss: 0.2811 - val_loss: 0.2426 - val_loss/inference_loss: 0.2426
Epoch 57/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2850 - loss/inference_loss: 0.2850 - val_loss: 0.2767 - val_loss/inference_loss: 0.2767
Epoch 58/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2686 - loss/inference_loss: 0.2686 - val_loss: 0.2659 - val_loss/inference_loss: 0.2659
Epoch 59/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2798 - loss/inference_loss: 0.2798 - val_loss: 0.2652 - val_loss/inference_loss: 0.2652
Epoch 60/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2527 - loss/inference_loss: 0.2527 - val_loss: 0.2040 - val_loss/inference_loss: 0.2040
Epoch 61/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2665 - loss/inference_loss: 0.2665 - val_loss: 0.2518 - val_loss/inference_loss: 0.2518
Epoch 62/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2621 - loss/inference_loss: 0.2621 - val_loss: 0.2517 - val_loss/inference_loss: 0.2517
Epoch 63/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2622 - loss/inference_loss: 0.2622 - val_loss: 0.2268 - val_loss/inference_loss: 0.2268
Epoch 64/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2560 - loss/inference_loss: 0.2560 - val_loss: 0.2020 - val_loss/inference_loss: 0.2020
Epoch 65/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2553 - loss/inference_loss: 0.2553 - val_loss: 0.2401 - val_loss/inference_loss: 0.2401
Epoch 66/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2837 - loss/inference_loss: 0.2837 - val_loss: 0.2716 - val_loss/inference_loss: 0.2716
Epoch 67/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2596 - loss/inference_loss: 0.2596 - val_loss: 0.2283 - val_loss/inference_loss: 0.2283
Epoch 68/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2382 - loss/inference_loss: 0.2382 - val_loss: 0.3468 - val_loss/inference_loss: 0.3468
Epoch 69/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2592 - loss/inference_loss: 0.2592 - val_loss: 0.2126 - val_loss/inference_loss: 0.2126
Epoch 70/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2690 - loss/inference_loss: 0.2690 - val_loss: 0.2943 - val_loss/inference_loss: 0.2943
Epoch 71/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2741 - loss/inference_loss: 0.2741 - val_loss: 0.2170 - val_loss/inference_loss: 0.2170
Epoch 72/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2611 - loss/inference_loss: 0.2611 - val_loss: 0.2701 - val_loss/inference_loss: 0.2701
Epoch 73/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2707 - loss/inference_loss: 0.2707 - val_loss: 0.2730 - val_loss/inference_loss: 0.2730
Epoch 74/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2498 - loss/inference_loss: 0.2498 - val_loss: 0.2310 - val_loss/inference_loss: 0.2310
Epoch 75/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2532 - loss/inference_loss: 0.2532 - val_loss: 0.2564 - val_loss/inference_loss: 0.2564
Epoch 76/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2514 - loss/inference_loss: 0.2514 - val_loss: 0.1609 - val_loss/inference_loss: 0.1609
Epoch 77/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 16ms/step - loss: 0.2477 - loss/inference_loss: 0.2477 - val_loss: 0.2392 - val_loss/inference_loss: 0.2392
Epoch 78/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2682 - loss/inference_loss: 0.2682 - val_loss: 0.1907 - val_loss/inference_loss: 0.1907
Epoch 79/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2652 - loss/inference_loss: 0.2652 - val_loss: 0.2167 - val_loss/inference_loss: 0.2167
Epoch 80/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2474 - loss/inference_loss: 0.2474 - val_loss: 0.2036 - val_loss/inference_loss: 0.2036
Epoch 81/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 16ms/step - loss: 0.2476 - loss/inference_loss: 0.2476 - val_loss: 0.1839 - val_loss/inference_loss: 0.1839
Epoch 82/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 18ms/step - loss: 0.2474 - loss/inference_loss: 0.2474 - val_loss: 0.1878 - val_loss/inference_loss: 0.1878
Epoch 83/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2663 - loss/inference_loss: 0.2663 - val_loss: 0.2071 - val_loss/inference_loss: 0.2071
Epoch 84/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2603 - loss/inference_loss: 0.2603 - val_loss: 0.2747 - val_loss/inference_loss: 0.2747
Epoch 85/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2554 - loss/inference_loss: 0.2554 - val_loss: 0.2746 - val_loss/inference_loss: 0.2746
Epoch 86/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2694 - loss/inference_loss: 0.2694 - val_loss: 0.1554 - val_loss/inference_loss: 0.1554
Epoch 87/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2586 - loss/inference_loss: 0.2586 - val_loss: 0.1826 - val_loss/inference_loss: 0.1826
Epoch 88/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 16ms/step - loss: 0.2539 - loss/inference_loss: 0.2539 - val_loss: 0.2710 - val_loss/inference_loss: 0.2710
Epoch 89/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2345 - loss/inference_loss: 0.2345 - val_loss: 0.1994 - val_loss/inference_loss: 0.1994
Epoch 90/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 18ms/step - loss: 0.2368 - loss/inference_loss: 0.2368 - val_loss: 0.2277 - val_loss/inference_loss: 0.2277
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 91/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2240 - loss/inference_loss: 0.2240 - val_loss: 0.2807 - val_loss/inference_loss: 0.2807
Epoch 92/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 19ms/step - loss: 0.2519 - loss/inference_loss: 0.2519 - val_loss: 0.1967 - val_loss/inference_loss: 0.1967
Epoch 93/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 18ms/step - loss: 0.2666 - loss/inference_loss: 0.2666 - val_loss: 0.2067 - val_loss/inference_loss: 0.2067
Epoch 94/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2526 - loss/inference_loss: 0.2526 - val_loss: 0.2070 - val_loss/inference_loss: 0.2070
Epoch 95/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2450 - loss/inference_loss: 0.2450 - val_loss: 0.2386 - val_loss/inference_loss: 0.2386
Epoch 96/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2619 - loss/inference_loss: 0.2619 - val_loss: 0.2506 - val_loss/inference_loss: 0.2506
Epoch 97/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 13ms/step - loss: 0.2672 - loss/inference_loss: 0.2672 - val_loss: 0.2199 - val_loss/inference_loss: 0.2199
Epoch 98/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2627 - loss/inference_loss: 0.2627 - val_loss: 0.2349 - val_loss/inference_loss: 0.2349
Epoch 99/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 15ms/step - loss: 0.2928 - loss/inference_loss: 0.2928 - val_loss: 0.2543 - val_loss/inference_loss: 0.2543
Epoch 100/100
<span class=" -Color -Color-Bold">8/8</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 14ms/step - loss: 0.2356 - loss/inference_loss: 0.2356 - val_loss: 0.2077 - val_loss/inference_loss: 0.2077
</pre></div>
</div>
</div>
</div>
<section id="quick-validation">
<h3>Quick Validation<a class="headerlink" href="#quick-validation" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the number of posterior draws you want to get</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">3000</span>

<span class="c1"># Obtain samples from amortized posterior</span>
<span class="n">conditions</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;observables&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)}</span>

<span class="c1"># Prepare figure</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Obtain samples</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">approximator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">conditions</span><span class="o">=</span><span class="n">conditions</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span>

<span class="c1"># Plot samples</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#7a1515&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s2">&quot;box&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_1$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_2$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">f</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/116ef3ca1bf658a01aee50ef3eebade095dc19c0f9319517e6d12d47be56255b.png" src="../../_images/116ef3ca1bf658a01aee50ef3eebade095dc19c0f9319517e6d12d47be56255b.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#TODO - Use a different objective</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulator-and-data">Simulator and Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-objective">Test Objective</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optuna-objective">Optuna Objective</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization">Optimization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-with-best-parameters">Training With Best Parameters</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-validation">Quick Validation</a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/bayesflow-org/bayesflow/edit/dev/docsrc/_examples/experimental/Hyperparameter_Optimization.ipynb">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2023-2025, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>