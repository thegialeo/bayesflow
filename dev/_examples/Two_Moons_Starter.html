
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2. Two Moons: Tackling Bimodal Posteriors &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=8fec244e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_examples/Two_Moons_Starter';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = '/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'dev';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="canonical" href="https://www.bayesflow.org/_examples/Two_Moons_Starter.html" />
    <link rel="icon" href="../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Posterior Estimation for SIR-like Models" href="SIR_Posterior_Estimation.html" />
    <link rel="prev" title="1. Amortized Posterior Estimation for Linear Regression" href="Linear_Regression_Starter.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/bayesflow_hor.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <img src="../_static/bayesflow_hor_dark.png" class="logo__image only-dark pst-js-only" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/bayesflow.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    About us
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Developer docs
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/bayesflow.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    About us
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Developer docs
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Linear_Regression_Starter.html">1. Amortized Posterior Estimation for Linear Regression</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2. Two Moons: Tackling Bimodal Posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="SIR_Posterior_Estimation.html">3. Posterior Estimation for SIR-like Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="Hyperparameter_Optimization.html">4. Hyperparameter Optimization Using Optuna</a></li>
<li class="toctree-l1"><a class="reference internal" href="Bayesian_Experimental_Design.html">5. Bayesian Experimental Design (BED) with BayesFlow and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="From_ABC_to_BayesFlow.html">6. From pyABC to BayesFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="One_Sample_TTest.html">7. Simple Model Comparison - One Sample T-Test</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../examples.html" class="nav-link">Examples</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis"><span class="section-number">2. </span>Two Moons: Tackling Bimodal Posteriors</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="two-moons-tackling-bimodal-posteriors">
<h1><span class="section-number">2. </span>Two Moons: Tackling Bimodal Posteriors<a class="headerlink" href="#two-moons-tackling-bimodal-posteriors" title="Link to this heading">#</a></h1>
<p><em>Authors: Lars Kühmichel, Marvin Schmitt, Valentin Pratz, Stefan T. Radev</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="c1"># For BayesFlow devs: this ensures that the latest dev version can be found</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;../&#39;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">bayesflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">bf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2025-02-11 16:22:30.912532: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-11 16:22:30.912881: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-02-11 16:22:30.914936: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-02-11 16:22:30.939014: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-11 16:22:31.425109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-02-11 16:22:31.935372: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-02-11 16:22:31.935638: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
</pre></div>
</div>
</div>
</div>
<section id="simulator">
<h2><span class="section-number">2.1. </span>Simulator<a class="anchor" id="simulator"></a><a class="headerlink" href="#simulator" title="Link to this heading">#</a></h2>
<p>This example will demonstrate amortized estimation of a somewhat strange Bayesian model, whose posterior evaluated at the origin <span class="math notranslate nohighlight">\(x = (0, 0)\)</span> of the “data” will resemble two crescent moons. The forward process is a noisy non-linear transformation on a 2D plane:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
x_1 &amp;= -|\theta_1 + \theta_2|/\sqrt{2} + r \cos(\alpha) + 0.25\\
x_2 &amp;= (-\theta_1 + \theta_2)/\sqrt{2} + r\sin{\alpha}
\end{align}
\end{split}\]</div>
<p>with <span class="math notranslate nohighlight">\(x = (x_1, x_2)\)</span> playing the role of “observables” (data to be learned from), <span class="math notranslate nohighlight">\(\alpha \sim \text{Uniform}(-\pi/2, \pi/2)\)</span>, and <span class="math notranslate nohighlight">\(r \sim \text{Normal}(0.1, 0.01)\)</span> being latent variables creating noise in the data, and <span class="math notranslate nohighlight">\(\theta = (\theta_1, \theta_2)\)</span> being the parameters that we will later seek to infer from new <span class="math notranslate nohighlight">\(x\)</span>. We set their priors to</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\theta_1, \theta_2 \sim \text{Uniform}(-1, 1).
\end{align}
\]</div>
<p>This model is typically used for benchmarking simulation-based inference (SBI) methods (see https://arxiv.org/pdf/2101.04653) and any method for amortized Bayesian inference should be capable of recovering the two moons posterior <em>without</em> using a gazillion of simulations. Note, that this is a considerably harder task than modeling the common unconditional two moons data set used often in the context of normalizing flows.</p>
<p>BayesFlow offers many ways to define your data generating process. Here, we use sequential functions to build a simulator object for online training. Within this composite simulator, each function has access to the outputs of the previous functions. This effectively allows you to define any generative graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">theta_prior</span><span class="p">():</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">forward_model</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">r</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.25</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">r</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p>Within the composite simulator, every simulator has access to the outputs of the previous simulators in the list. For example, the last simulator <code class="docutils literal notranslate"><span class="pre">forward_model</span></code> has access to the outputs of the three other simulators.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulator</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">make_simulator</span><span class="p">([</span><span class="n">theta_prior</span><span class="p">,</span> <span class="n">forward_model</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s generate some data to see what the simulator does:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate 3 random draws from the joint distribution p(r, alpha, theta, x)</span>
<span class="n">sample_data</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Type of sample_data:</span><span class="se">\n\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">sample_data</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Keys of sample_data:</span><span class="se">\n\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">sample_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Types of sample_data values:</span><span class="se">\n\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sample_data</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shapes of sample_data values:</span><span class="se">\n\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sample_data</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type of sample_data:
	 &lt;class &#39;dict&#39;&gt;
Keys of sample_data:
	 dict_keys([&#39;theta&#39;, &#39;x&#39;])
Types of sample_data values:
	 {&#39;theta&#39;: &lt;class &#39;numpy.ndarray&#39;&gt;, &#39;x&#39;: &lt;class &#39;numpy.ndarray&#39;&gt;}
Shapes of sample_data values:
	 {&#39;theta&#39;: (3, 2), &#39;x&#39;: (3, 2)}
</pre></div>
</div>
</div>
</div>
<p>BayesFlow also provides this simulator and a collection of others in the <code class="docutils literal notranslate"><span class="pre">bayesflow.benchmarks</span></code> module.</p>
</section>
<section id="adapter">
<h2><span class="section-number">2.2. </span>Adapter<a class="headerlink" href="#adapter" title="Link to this heading">#</a></h2>
<p>The next step is to tell BayesFlow how to deal with all the simulated variables. You may also think of this as informing BayesFlow about the data flow, i.e., which variables go into which network and what transformations needs to be performed prior to passing the simulator outputs into the networks. This is done via an adapter layer, which is implemented as a sequence of fixed, pseudo-invertible data transforms.</p>
<p>Below, we define the data adapter by specifying the input and output keys and the transformations to be applied. This allows us full control over the data flow.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adapter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">bf</span><span class="o">.</span><span class="n">adapters</span><span class="o">.</span><span class="n">Adapter</span><span class="p">()</span>
    
    <span class="c1"># convert any non-arrays to numpy arrays</span>
    <span class="o">.</span><span class="n">to_array</span><span class="p">()</span>
    
    <span class="c1"># convert from numpy&#39;s default float64 to deep learning friendly float32</span>
    <span class="o">.</span><span class="n">convert_dtype</span><span class="p">(</span><span class="s2">&quot;float64&quot;</span><span class="p">,</span> <span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    
    <span class="c1"># standardize target variables to zero mean and unit variance </span>
    <span class="o">.</span><span class="n">standardize</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="s2">&quot;theta&quot;</span><span class="p">)</span>
    
    <span class="c1"># rename the variables to match the required approximator inputs</span>
    <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;theta&quot;</span><span class="p">,</span> <span class="s2">&quot;inference_variables&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;inference_conditions&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">adapter</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Adapter([0: ToArray -&gt; 1: ConvertDType -&gt; 2: Standardize(exclude=[&#39;theta&#39;]) -&gt; 3: Rename(&#39;theta&#39; -&gt; &#39;inference_variables&#39;) -&gt; 4: Rename(&#39;x&#39; -&gt; &#39;inference_conditions&#39;)])
</pre></div>
</div>
</div>
</div>
</section>
<section id="dataset">
<h2><span class="section-number">2.3. </span>Dataset<a class="headerlink" href="#dataset" title="Link to this heading">#</a></h2>
<p>For this example, we will sample our training data ahead of time and use offline training with a very small number of epochs. In actual applications, you usually want to train much longer in order to max our performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_training_batches</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">num_validation_batches</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_data</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_training_batches</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,)</span>
<span class="n">validation_data</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_validation_batches</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-a-neural-network-to-approximate-all-posteriors">
<h2><span class="section-number">2.4. </span>Training a neural network to approximate all posteriors<a class="headerlink" href="#training-a-neural-network-to-approximate-all-posteriors" title="Link to this heading">#</a></h2>
<p>The next step is to set up the neural network that will approximate the posterior <span class="math notranslate nohighlight">\(p(\theta\,|\,x)\)</span>.</p>
<p>We choose <strong>Flow Matching</strong> [1, 2] as the backbone architecture for this example, as it can deal well with the multimodal nature of the posteriors that some observables imply.</p>
<ul class="simple">
<li><p>[1] Lipman, Y., Chen, R. T., Ben-Hamu, H., Nickel, M., &amp; Le, M. Flow Matching for Generative Modeling. In <em>The Eleventh International Conference on Learning Representations</em>.</p></li>
<li><p>[2] Wildberger, J. B., Dax, M., Buchholz, S., Green, S. R., Macke, J. H., &amp; Schölkopf, B. Flow Matching for Scalable Simulation-Based Inference. In <em>Thirty-seventh Conference on Neural Information Processing Systems</em>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">flow_matching</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">FlowMatching</span><span class="p">(</span>
    <span class="n">subnet</span><span class="o">=</span><span class="s2">&quot;mlp&quot;</span><span class="p">,</span> 
    <span class="n">subnet_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;widths&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">256</span><span class="p">,)</span><span class="o">*</span><span class="mi">6</span><span class="p">}</span> <span class="c1"># override default dropout = 0.05 and widths = (256,)*5</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This inference network is just a general Flow Matching backbone, not yet adapted to the specific inference task at hand (i.e., posterior appproximation). To achieve this adaptation, we combine the network with our data adapter, which together form an <code class="docutils literal notranslate"><span class="pre">approximator</span></code>. In this case, we need a <code class="docutils literal notranslate"><span class="pre">ContinuousApproximator</span></code> since the target we want to approximate is the posterior of the <em>continuous</em> parameter vector <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<section id="basic-workflow">
<h3><span class="section-number">2.4.1. </span>Basic Workflow<a class="headerlink" href="#basic-workflow" title="Link to this heading">#</a></h3>
<p>We can hide many of the traditional deep learning steps (e.g., specifying a learning rate and an optimizer) within a <code class="docutils literal notranslate"><span class="pre">Workflow</span></code> object. This object just wraps everything together and includes some nice utility functions for training and <em>in silico</em> validation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">flow_matching_workflow</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">BasicWorkflow</span><span class="p">(</span>
    <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
    <span class="n">adapter</span><span class="o">=</span><span class="n">adapter</span><span class="p">,</span>
    <span class="n">inference_network</span><span class="o">=</span><span class="n">flow_matching</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training">
<h3><span class="section-number">2.4.2. </span>Training<a class="headerlink" href="#training" title="Link to this heading">#</a></h3>
<p>We are ready to train our deep posterior approximator on the two moons example. We use the utility function <code class="docutils literal notranslate"><span class="pre">fit_offline</span></code>, which wraps the approximator’s super flexible <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">flow_matching_workflow</span><span class="o">.</span><span class="n">fit_offline</span><span class="p">(</span>
    <span class="n">training_data</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
    <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">3s</span> 3ms/step - loss: 1.5975 - loss/inference_loss: 1.5975 - val_loss: 0.3615 - val_loss/inference_loss: 0.3615
Epoch 2/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3963 - loss/inference_loss: 0.3963 - val_loss: 0.3259 - val_loss/inference_loss: 0.3259
Epoch 3/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3793 - loss/inference_loss: 0.3793 - val_loss: 0.3774 - val_loss/inference_loss: 0.3774
Epoch 4/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3734 - loss/inference_loss: 0.3734 - val_loss: 0.2816 - val_loss/inference_loss: 0.2816
Epoch 5/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3625 - loss/inference_loss: 0.3625 - val_loss: 0.2620 - val_loss/inference_loss: 0.2620
Epoch 6/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3600 - loss/inference_loss: 0.3600 - val_loss: 0.2465 - val_loss/inference_loss: 0.2465
Epoch 7/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3646 - loss/inference_loss: 0.3646 - val_loss: 0.3418 - val_loss/inference_loss: 0.3418
Epoch 8/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3593 - loss/inference_loss: 0.3593 - val_loss: 0.3830 - val_loss/inference_loss: 0.3830
Epoch 9/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3493 - loss/inference_loss: 0.3493 - val_loss: 0.4498 - val_loss/inference_loss: 0.4498
Epoch 10/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3492 - loss/inference_loss: 0.3492 - val_loss: 0.3947 - val_loss/inference_loss: 0.3947
Epoch 11/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3459 - loss/inference_loss: 0.3459 - val_loss: 0.2970 - val_loss/inference_loss: 0.2970
Epoch 12/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3457 - loss/inference_loss: 0.3457 - val_loss: 0.2243 - val_loss/inference_loss: 0.2243
Epoch 13/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3451 - loss/inference_loss: 0.3451 - val_loss: 0.4153 - val_loss/inference_loss: 0.4153
Epoch 14/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3433 - loss/inference_loss: 0.3433 - val_loss: 0.3919 - val_loss/inference_loss: 0.3919
Epoch 15/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3373 - loss/inference_loss: 0.3373 - val_loss: 0.3400 - val_loss/inference_loss: 0.3400
Epoch 16/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3440 - loss/inference_loss: 0.3440 - val_loss: 0.1885 - val_loss/inference_loss: 0.1885
Epoch 17/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3429 - loss/inference_loss: 0.3429 - val_loss: 0.3297 - val_loss/inference_loss: 0.3297
Epoch 18/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3389 - loss/inference_loss: 0.3389 - val_loss: 0.3932 - val_loss/inference_loss: 0.3932
Epoch 19/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3330 - loss/inference_loss: 0.3330 - val_loss: 0.2640 - val_loss/inference_loss: 0.2640
Epoch 20/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3272 - loss/inference_loss: 0.3272 - val_loss: 0.3262 - val_loss/inference_loss: 0.3262
Epoch 21/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3301 - loss/inference_loss: 0.3301 - val_loss: 0.4301 - val_loss/inference_loss: 0.4301
Epoch 22/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3329 - loss/inference_loss: 0.3329 - val_loss: 0.4407 - val_loss/inference_loss: 0.4407
Epoch 23/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3384 - loss/inference_loss: 0.3384 - val_loss: 0.2786 - val_loss/inference_loss: 0.2786
Epoch 24/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3283 - loss/inference_loss: 0.3283 - val_loss: 0.3840 - val_loss/inference_loss: 0.3840
Epoch 25/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3235 - loss/inference_loss: 0.3235 - val_loss: 0.3168 - val_loss/inference_loss: 0.3168
Epoch 26/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3227 - loss/inference_loss: 0.3227 - val_loss: 0.2289 - val_loss/inference_loss: 0.2289
Epoch 27/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3367 - loss/inference_loss: 0.3367 - val_loss: 0.2283 - val_loss/inference_loss: 0.2283
Epoch 28/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3331 - loss/inference_loss: 0.3331 - val_loss: 0.3331 - val_loss/inference_loss: 0.3331
Epoch 29/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3281 - loss/inference_loss: 0.3281 - val_loss: 0.1447 - val_loss/inference_loss: 0.1447
Epoch 30/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3228 - loss/inference_loss: 0.3228 - val_loss: 0.2868 - val_loss/inference_loss: 0.2868
Epoch 31/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3226 - loss/inference_loss: 0.3226 - val_loss: 0.2819 - val_loss/inference_loss: 0.2819
Epoch 32/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3167 - loss/inference_loss: 0.3167 - val_loss: 0.3676 - val_loss/inference_loss: 0.3676
Epoch 33/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3264 - loss/inference_loss: 0.3264 - val_loss: 0.2303 - val_loss/inference_loss: 0.2303
Epoch 34/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3141 - loss/inference_loss: 0.3141 - val_loss: 0.2125 - val_loss/inference_loss: 0.2125
Epoch 35/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3096 - loss/inference_loss: 0.3096 - val_loss: 0.2754 - val_loss/inference_loss: 0.2754
Epoch 36/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3187 - loss/inference_loss: 0.3187 - val_loss: 0.3006 - val_loss/inference_loss: 0.3006
Epoch 37/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3157 - loss/inference_loss: 0.3157 - val_loss: 0.3113 - val_loss/inference_loss: 0.3113
Epoch 38/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3212 - loss/inference_loss: 0.3212 - val_loss: 0.4190 - val_loss/inference_loss: 0.4190
Epoch 39/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3162 - loss/inference_loss: 0.3162 - val_loss: 0.3351 - val_loss/inference_loss: 0.3351
Epoch 40/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3159 - loss/inference_loss: 0.3159 - val_loss: 0.3813 - val_loss/inference_loss: 0.3813
Epoch 41/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3134 - loss/inference_loss: 0.3134 - val_loss: 0.4158 - val_loss/inference_loss: 0.4158
Epoch 42/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3142 - loss/inference_loss: 0.3142 - val_loss: 0.5772 - val_loss/inference_loss: 0.5772
Epoch 43/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3136 - loss/inference_loss: 0.3136 - val_loss: 0.3419 - val_loss/inference_loss: 0.3419
Epoch 44/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">1s</span> 3ms/step - loss: 0.3104 - loss/inference_loss: 0.3104 - val_loss: 0.5761 - val_loss/inference_loss: 0.5761
Epoch 45/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3166 - loss/inference_loss: 0.3166 - val_loss: 0.2678 - val_loss/inference_loss: 0.2678
Epoch 46/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3197 - loss/inference_loss: 0.3197 - val_loss: 0.3576 - val_loss/inference_loss: 0.3576
Epoch 47/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3165 - loss/inference_loss: 0.3165 - val_loss: 0.3637 - val_loss/inference_loss: 0.3637
Epoch 48/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3145 - loss/inference_loss: 0.3145 - val_loss: 0.3348 - val_loss/inference_loss: 0.3348
Epoch 49/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 4ms/step - loss: 0.3104 - loss/inference_loss: 0.3104 - val_loss: 0.3068 - val_loss/inference_loss: 0.3068
Epoch 50/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 4ms/step - loss: 0.3090 - loss/inference_loss: 0.3090 - val_loss: 0.4407 - val_loss/inference_loss: 0.4407
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="swapping-inference-networks">
<h2><span class="section-number">2.5. </span>Swapping Inference Networks <a class="anchor" id="swapping"></a><a class="headerlink" href="#swapping-inference-networks" title="Link to this heading">#</a></h2>
<p>Using BayesFlow, it is easy to switch to a different backbone architecture for the inference network. For instance, the code below demonstrates the use of a <strong>Consistency Model</strong>, which can allow for faster sampling during inference.</p>
<section id="consistency-models-background">
<h3><span class="section-number">2.5.1. </span>Consistency Models: Background<a class="headerlink" href="#consistency-models-background" title="Link to this heading">#</a></h3>
<p>Consistency Models (CM; [1]) leverage the nice properties of score-based diffusion to enable few-step sampling. Score-based diffusion initially relied on a stochastic differential equation (SDE) for sampling, but there is also a ordinary (non-stochastic) differential equation (ODE)that has the same <em>marginal</em> distribution at each time step <span class="math notranslate nohighlight">\(t\)</span> [2]. This means that even though SDE and ODE produce different paths from the noise distribution to the target distribution, the resulting distributions when looking at many paths at time <span class="math notranslate nohighlight">\(t\)</span> is the same. The ODE is also called Probability Flow ODE.</p>
<p>CMs leverage the fact that there is no randomness in the ODE formulation. That means, if you start at a certain point in the latent space, you will always take the same path and end up at the same point in the target <span class="math notranslate nohighlight">\(\theta\)</span>-space. The same is true for every point on the path: if you integrate to get to time <span class="math notranslate nohighlight">\(t=0\)</span>, you will end up at the same point as well. In short: for each path, there is exactly one corresponding point in latent space (at <span class="math notranslate nohighlight">\(t=T\)</span>) and one corresponding point in data space (at <span class="math notranslate nohighlight">\(t=0\)</span>).</p>
<p>The goal of CMs is the following: each point at a time point <span class="math notranslate nohighlight">\(t\)</span> belongs to exactly one path, and we want to predict where this path will end up at <span class="math notranslate nohighlight">\(t=0\)</span>. The function that does this is called the <em>consistency function</em> <span class="math notranslate nohighlight">\(f\)</span>. If we have the correct function for all <span class="math notranslate nohighlight">\(t\in(0,T]\)</span>, we can just sample from the latent distribution (<span class="math notranslate nohighlight">\(t=T\)</span>) and use <span class="math notranslate nohighlight">\(f\)</span> to directly map to the corresponding point at <span class="math notranslate nohighlight">\(t=0\)</span>, which is in the target distribution. So for sampling from the target distribution, we avoid any integration and only need one evaluation of the consistency function. In practice, the one-step sampling does not work very well. Instead, we leverage a multi-step sampling method where we call <span class="math notranslate nohighlight">\(f\)</span> multiple times. Please check out the [1] for more background on this sampling procedure.</p>
<p>When reading the above, you might wonder why we also learn the mapping to <span class="math notranslate nohighlight">\(t=0\)</span> of all intermediate time steps <span class="math notranslate nohighlight">\(t\in[0, T]\)</span>, and not only for <span class="math notranslate nohighlight">\(t=T\)</span>. The main answer is that for efficient training, we do not want to actually compute the two associated points explicitly. Doing so would require to do a precise integration at training time, which is often not feasible as it is too computationally costly. Learning all time steps opens up the possibility for a different training approach where we can avoid this. The details of this become a bit more complicated, and we advise you to take a look at [1] if you are interested in a more thorough and mathematical discussion. Below, we will give a rough description of the underlying concepts.</p>
<p><strong>Training</strong> First, we know that at <span class="math notranslate nohighlight">\(t=0\)</span>, it holds that <span class="math notranslate nohighlight">\(f(\theta,t=0)=\theta\)</span>, as <span class="math notranslate nohighlight">\(\theta\)</span> is part of the path that ends at <span class="math notranslate nohighlight">\(\theta\)</span>. This <em>boundary condition</em> serves as an “anchor” for our training, this is the information that the network knows at the start of the training procedure (we encode it with a time-dependent skip-connection, so the network is forced to be the identity function at <span class="math notranslate nohighlight">\(t=0\)</span>). For training, we now somehow have to propagate this information to the rest of the part. The basic idea for this is simple. We just take a point <span class="math notranslate nohighlight">\(\theta_1\)</span> closer to the data distribution (smaller time <span class="math notranslate nohighlight">\(t_1\)</span>) and integrate for a small time step <span class="math notranslate nohighlight">\(dt\)</span> to a point <span class="math notranslate nohighlight">\(\theta_2\)</span> on the same path that is closer to the latent distribution (larger time <span class="math notranslate nohighlight">\(t_2=t_1+dt\)</span>). As we know that for <span class="math notranslate nohighlight">\(t=0\)</span> our network provides the correct output for our path, we want to propagate the information from smaller times to larger times. Our training goal is to move the output of <span class="math notranslate nohighlight">\(f(\theta_2, t=t_2)\)</span> towards the output of <span class="math notranslate nohighlight">\(f(\theta_1, t=t_1)\)</span>. How to choose <span class="math notranslate nohighlight">\(\theta_1\)</span>, <span class="math notranslate nohighlight">\(t_1\)</span> and <span class="math notranslate nohighlight">\(dt\)</span> is an empirical question, see the [1] for some thoughts on what works well.</p>
<p><strong>Distilling inference</strong> In the case of <em>distillation</em>, we start with a trained score-based diffusion model. We can use it to integrate the Probability Flow ODE to get from <span class="math notranslate nohighlight">\(\theta_1\)</span> to <span class="math notranslate nohighlight">\(\theta_2\)</span>. If we do not have such a model, it seems as if we were stuck. We do not know which points lie on the same path, so we do not know which outputs to make similar. Fortunately, it turns out that there is an <em>unbiased approximator</em> that, if averaged over many samples (check out the paper for the exact description), will also give us the correct score. If we use this approximator instead of the score model, and use only a single Euler step to move along the path, we get an algorithm similar to the one described for distillation. It is called Consistency Training (CT) and allows us to train a consistency model using only <em>samples</em> from the data distribution. The algorithm for this was improved a lot in [3], and we have incorporated those improvements into our implementation.</p>
<p><strong>Improving consistency training</strong> We have made several approximations to get to a standalone <em>consistency training</em> algorithm. As a consequence, the introduced hyperparameters and their choice unfortunately becomes somewhat unintuitive. We have to rely on empirical observations and heuristics to see what works. This was done in [4], we encourage you to use the values provided there as starting points. If you happen to find hyperparameters that work significantly better, please let us know (e.g., by opening an issue or sending an email). This will help others to find the correct region in the hyperparameter space.</p>
<p>[1] Song, Y., Dhariwal, P., Chen, M., &amp; Sutskever, I. (2023). Consistency Models. <em>arXiv preprint</em>. <a class="reference external" href="https://doi.org/10.48550/arXiv.2303.01469">https://doi.org/10.48550/arXiv.2303.01469</a></p>
<p>[2] Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., &amp; Poole, B. (2021). Score-Based Generative Modeling through Stochastic Differential Equations. In <em>International Conference on Learning Representations</em>. <a class="reference external" href="https://openreview.net/forum?id=PxTIG12RRHS">https://openreview.net/forum?id=PxTIG12RRHS</a></p>
<p>[3] Song, Y., &amp; Dhariwal, P. (2023). Improved Techniques for Training Consistency Models. <em>arXiv preprint</em>. <a class="reference external" href="https://doi.org/10.48550/arXiv.2310.14189">https://doi.org/10.48550/arXiv.2310.14189</a></p>
<p>[4] Schmitt, M., Pratz, V., Köthe, U., Bürkner, P.-C., &amp; Radev, S. T. (2024). Consistency Models for Scalable and Fast Simulation-Based Inference. <em>arXiv preprint</em>. <a class="reference external" href="https://doi.org/10.48550/arXiv.2312.05440">https://doi.org/10.48550/arXiv.2312.05440</a></p>
</section>
<section id="consistency-models-specification">
<h3><span class="section-number">2.5.2. </span>Consistency Models: Specification<a class="headerlink" href="#consistency-models-specification" title="Link to this heading">#</a></h3>
<p>We can now go ahead and define our new inference network backbone. Apart from the usual parameters like learning rate and batch size, CMs come with a number of different hyperparameters. Unfortunately, they can heavily interact, so they can be hard to tune. The main hyperparameters are:</p>
<ul class="simple">
<li><p>Maximum time <code class="docutils literal notranslate"><span class="pre">max_time</span></code>: This also serves as the standard deviation of the latent distribution. You can experiment with this, values from 10-200 seem to work well. In any case, it should be larger than the standard deviation of the target distribution.</p></li>
<li><p>Minimum/maximum number of discretization steps during training <code class="docutils literal notranslate"><span class="pre">s0</span></code>/<code class="docutils literal notranslate"><span class="pre">s1</span></code>: The effect of those is hard to grasp. 10 works well for <code class="docutils literal notranslate"><span class="pre">s0</span></code>. Intuitively, increasing <code class="docutils literal notranslate"><span class="pre">s1</span></code> along with the number of epochs should lead to better result, but in practice we sometimes observe a breakdown for high values of <code class="docutils literal notranslate"><span class="pre">s1</span></code>. This seems to be problem-dependent, so just try it out.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sigma2</span></code> modifies the time-dependency of the skip connection. Its effect on the training is unclear, we recommend leaving it at 1.0 or setting it to the approximate variance of the target distribution.</p></li>
<li><p>Smallest time value <code class="docutils literal notranslate"><span class="pre">eps</span></code> (<span class="math notranslate nohighlight">\(t=\epsilon\)</span> is used instead of <span class="math notranslate nohighlight">\(t=0\)</span> for numerical reasons): No large effect in our experiments, as long as it is kept small enough. Probably not worth tuning.</p></li>
</ul>
<p>You may find that different hyperparameter values work better for your tasks.</p>
<p>A short note on dropout: in our experiments, dropout usually lead to worse performance, so generally we recommend setting the droput rate to <span class="math notranslate nohighlight">\(0.0\)</span>. Consistency training takes advantage of a noisy estimator of the score, so probably the training is already sufficiently noisy and extra dropout for regularization is not necessary.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the empirical variance of the draws from the prior θ ~ p(θ)</span>
<span class="n">consistency_model</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">ConsistencyModel</span><span class="p">(</span>
    <span class="n">subnet</span><span class="o">=</span><span class="s2">&quot;mlp&quot;</span><span class="p">,</span>
    <span class="n">subnet_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;widths&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">256</span><span class="p">,)</span><span class="o">*</span><span class="mi">6</span><span class="p">},</span>
    <span class="n">total_steps</span><span class="o">=</span><span class="n">num_training_batches</span><span class="o">*</span><span class="n">epochs</span><span class="p">,</span>
    <span class="n">max_time</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># this probably needs to be tuned for a novel application</span>
    <span class="n">sigma2</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># the data adapter standardizes our parameters, so set to 1.0</span>
<span class="p">)</span>

<span class="c1"># Workflow for consistency model</span>
<span class="n">consistency_model_workflow</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">BasicWorkflow</span><span class="p">(</span>
    <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
    <span class="n">adapter</span><span class="o">=</span><span class="n">adapter</span><span class="p">,</span>
    <span class="n">inference_network</span><span class="o">=</span><span class="n">consistency_model</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="consistency-training">
<h3><span class="section-number">2.5.3. </span>Consistency Training<a class="headerlink" href="#consistency-training" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">consistency_model_workflow</span><span class="o">.</span><span class="n">fit_offline</span><span class="p">(</span>
    <span class="n">training_data</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
    <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">3s</span> 4ms/step - loss: 0.3549 - loss/inference_loss: 0.3549 - val_loss: 0.2793 - val_loss/inference_loss: 0.2793
Epoch 2/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.3020 - loss/inference_loss: 0.3020 - val_loss: 0.3505 - val_loss/inference_loss: 0.3505
Epoch 3/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2831 - loss/inference_loss: 0.2831 - val_loss: 0.2429 - val_loss/inference_loss: 0.2429
Epoch 4/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2813 - loss/inference_loss: 0.2813 - val_loss: 0.3600 - val_loss/inference_loss: 0.3600
Epoch 5/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2732 - loss/inference_loss: 0.2732 - val_loss: 0.2537 - val_loss/inference_loss: 0.2537
Epoch 6/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2722 - loss/inference_loss: 0.2722 - val_loss: 0.2904 - val_loss/inference_loss: 0.2904
Epoch 7/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2618 - loss/inference_loss: 0.2618 - val_loss: 0.1984 - val_loss/inference_loss: 0.1984
Epoch 8/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2663 - loss/inference_loss: 0.2663 - val_loss: 0.1680 - val_loss/inference_loss: 0.1680
Epoch 9/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2599 - loss/inference_loss: 0.2599 - val_loss: 0.2595 - val_loss/inference_loss: 0.2595
Epoch 10/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2567 - loss/inference_loss: 0.2567 - val_loss: 0.2612 - val_loss/inference_loss: 0.2612
Epoch 11/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2530 - loss/inference_loss: 0.2530 - val_loss: 0.2694 - val_loss/inference_loss: 0.2694
Epoch 12/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2596 - loss/inference_loss: 0.2596 - val_loss: 0.3073 - val_loss/inference_loss: 0.3073
Epoch 13/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2566 - loss/inference_loss: 0.2566 - val_loss: 0.1798 - val_loss/inference_loss: 0.1798
Epoch 14/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2589 - loss/inference_loss: 0.2589 - val_loss: 0.2743 - val_loss/inference_loss: 0.2743
Epoch 15/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2493 - loss/inference_loss: 0.2493 - val_loss: 0.2189 - val_loss/inference_loss: 0.2189
Epoch 16/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2649 - loss/inference_loss: 0.2649 - val_loss: 0.2154 - val_loss/inference_loss: 0.2154
Epoch 17/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2609 - loss/inference_loss: 0.2609 - val_loss: 0.2758 - val_loss/inference_loss: 0.2758
Epoch 18/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2526 - loss/inference_loss: 0.2526 - val_loss: 0.1542 - val_loss/inference_loss: 0.1542
Epoch 19/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2510 - loss/inference_loss: 0.2510 - val_loss: 0.1860 - val_loss/inference_loss: 0.1860
Epoch 20/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2559 - loss/inference_loss: 0.2559 - val_loss: 0.2213 - val_loss/inference_loss: 0.2213
Epoch 21/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2524 - loss/inference_loss: 0.2524 - val_loss: 0.2497 - val_loss/inference_loss: 0.2497
Epoch 22/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2477 - loss/inference_loss: 0.2477 - val_loss: 0.2030 - val_loss/inference_loss: 0.2030
Epoch 23/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2447 - loss/inference_loss: 0.2447 - val_loss: 0.2862 - val_loss/inference_loss: 0.2862
Epoch 24/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2451 - loss/inference_loss: 0.2451 - val_loss: 0.3859 - val_loss/inference_loss: 0.3859
Epoch 25/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2429 - loss/inference_loss: 0.2429 - val_loss: 0.2310 - val_loss/inference_loss: 0.2310
Epoch 26/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2437 - loss/inference_loss: 0.2437 - val_loss: 0.2236 - val_loss/inference_loss: 0.2236
Epoch 27/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2432 - loss/inference_loss: 0.2432 - val_loss: 0.3466 - val_loss/inference_loss: 0.3466
Epoch 28/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2353 - loss/inference_loss: 0.2353 - val_loss: 0.2234 - val_loss/inference_loss: 0.2234
Epoch 29/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2351 - loss/inference_loss: 0.2351 - val_loss: 0.1637 - val_loss/inference_loss: 0.1637
Epoch 30/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2364 - loss/inference_loss: 0.2364 - val_loss: 0.2324 - val_loss/inference_loss: 0.2324
Epoch 31/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2310 - loss/inference_loss: 0.2310 - val_loss: 0.1853 - val_loss/inference_loss: 0.1853
Epoch 32/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2287 - loss/inference_loss: 0.2287 - val_loss: 0.1234 - val_loss/inference_loss: 0.1234
Epoch 33/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2159 - loss/inference_loss: 0.2159 - val_loss: 0.1985 - val_loss/inference_loss: 0.1985
Epoch 34/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2228 - loss/inference_loss: 0.2228 - val_loss: 0.4063 - val_loss/inference_loss: 0.4063
Epoch 35/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2155 - loss/inference_loss: 0.2155 - val_loss: 0.2233 - val_loss/inference_loss: 0.2233
Epoch 36/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2257 - loss/inference_loss: 0.2257 - val_loss: 0.1208 - val_loss/inference_loss: 0.1208
Epoch 37/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2231 - loss/inference_loss: 0.2231 - val_loss: 0.0776 - val_loss/inference_loss: 0.0776
Epoch 38/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2193 - loss/inference_loss: 0.2193 - val_loss: 0.2310 - val_loss/inference_loss: 0.2310
Epoch 39/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2204 - loss/inference_loss: 0.2204 - val_loss: 0.1733 - val_loss/inference_loss: 0.1733
Epoch 40/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2219 - loss/inference_loss: 0.2219 - val_loss: 0.1291 - val_loss/inference_loss: 0.1291
Epoch 41/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2127 - loss/inference_loss: 0.2127 - val_loss: 0.1073 - val_loss/inference_loss: 0.1073
Epoch 42/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2257 - loss/inference_loss: 0.2257 - val_loss: 0.2174 - val_loss/inference_loss: 0.2174
Epoch 43/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2178 - loss/inference_loss: 0.2178 - val_loss: 0.2001 - val_loss/inference_loss: 0.2001
Epoch 44/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2150 - loss/inference_loss: 0.2150 - val_loss: 0.2282 - val_loss/inference_loss: 0.2282
Epoch 45/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2130 - loss/inference_loss: 0.2130 - val_loss: 0.1956 - val_loss/inference_loss: 0.1956
Epoch 46/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2046 - loss/inference_loss: 0.2046 - val_loss: 0.1937 - val_loss/inference_loss: 0.1937
Epoch 47/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2082 - loss/inference_loss: 0.2082 - val_loss: 0.2303 - val_loss/inference_loss: 0.2303
Epoch 48/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2067 - loss/inference_loss: 0.2067 - val_loss: 0.1300 - val_loss/inference_loss: 0.1300
Epoch 49/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 4ms/step - loss: 0.2201 - loss/inference_loss: 0.2201 - val_loss: 0.1432 - val_loss/inference_loss: 0.1432
Epoch 50/50
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 3ms/step - loss: 0.2097 - loss/inference_loss: 0.2097 - val_loss: 0.1791 - val_loss/inference_loss: 0.1791
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="good-ol-coupling-flows">
<h2><span class="section-number">2.6. </span>Good ‘ol Coupling Flows<a class="headerlink" href="#good-ol-coupling-flows" title="Link to this heading">#</a></h2>
<p>Of course, BayesFlow also supports established coupling flow models with a variety of parameters, including the timeless <em>affine</em> and <em>spline</em> flows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">affine_flow</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">CouplingFlow</span><span class="p">(</span><span class="n">subnet</span><span class="o">=</span><span class="s2">&quot;mlp&quot;</span><span class="p">)</span>

<span class="n">spline_flow</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">CouplingFlow</span><span class="p">(</span><span class="n">subnet</span><span class="o">=</span><span class="s2">&quot;mlp&quot;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="s2">&quot;spline&quot;</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">30</span> <span class="c1"># coupling flows need less epochs than free-form methods</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">affine_flow_workflow</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">BasicWorkflow</span><span class="p">(</span>
    <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
    <span class="n">adapter</span><span class="o">=</span><span class="n">adapter</span><span class="p">,</span>
    <span class="n">inference_network</span><span class="o">=</span><span class="n">affine_flow</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">spline_flow_workflow</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">BasicWorkflow</span><span class="p">(</span>
    <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
    <span class="n">adapter</span><span class="o">=</span><span class="n">adapter</span><span class="p">,</span>
    <span class="n">inference_network</span><span class="o">=</span><span class="n">spline_flow</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="coupling-flow-training">
<h3><span class="section-number">2.6.1. </span>Coupling Flow Training<a class="headerlink" href="#coupling-flow-training" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">affine_flow_workflow</span><span class="o">.</span><span class="n">fit_offline</span><span class="p">(</span>
    <span class="n">training_data</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">11s</span> 6ms/step - loss: -1.2724 - loss/inference_loss: -1.2724 - val_loss: -2.2869 - val_loss/inference_loss: -2.2869
Epoch 2/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -2.4998 - loss/inference_loss: -2.4998 - val_loss: -2.1505 - val_loss/inference_loss: -2.1505
Epoch 3/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -2.6645 - loss/inference_loss: -2.6645 - val_loss: -2.6893 - val_loss/inference_loss: -2.6893
Epoch 4/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 4ms/step - loss: -2.7494 - loss/inference_loss: -2.7494 - val_loss: -2.4783 - val_loss/inference_loss: -2.4783
Epoch 5/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -2.7852 - loss/inference_loss: -2.7852 - val_loss: -2.7409 - val_loss/inference_loss: -2.7409
Epoch 6/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 4ms/step - loss: -2.8575 - loss/inference_loss: -2.8575 - val_loss: -2.6789 - val_loss/inference_loss: -2.6789
Epoch 7/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 4ms/step - loss: -2.9127 - loss/inference_loss: -2.9127 - val_loss: -3.0435 - val_loss/inference_loss: -3.0435
Epoch 8/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -2.9346 - loss/inference_loss: -2.9346 - val_loss: -2.9628 - val_loss/inference_loss: -2.9628
Epoch 9/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -2.9371 - loss/inference_loss: -2.9371 - val_loss: -2.3899 - val_loss/inference_loss: -2.3899
Epoch 10/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 4ms/step - loss: -2.9999 - loss/inference_loss: -2.9999 - val_loss: -2.9758 - val_loss/inference_loss: -2.9758
Epoch 11/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.0083 - loss/inference_loss: -3.0083 - val_loss: -2.5975 - val_loss/inference_loss: -2.5975
Epoch 12/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.0434 - loss/inference_loss: -3.0434 - val_loss: -3.0387 - val_loss/inference_loss: -3.0387
Epoch 13/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.0920 - loss/inference_loss: -3.0920 - val_loss: -2.3253 - val_loss/inference_loss: -2.3253
Epoch 14/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.1255 - loss/inference_loss: -3.1255 - val_loss: -3.1556 - val_loss/inference_loss: -3.1556
Epoch 15/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.1654 - loss/inference_loss: -3.1654 - val_loss: -2.8726 - val_loss/inference_loss: -2.8726
Epoch 16/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.1779 - loss/inference_loss: -3.1779 - val_loss: -3.1917 - val_loss/inference_loss: -3.1917
Epoch 17/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.2124 - loss/inference_loss: -3.2124 - val_loss: -2.1857 - val_loss/inference_loss: -2.1857
Epoch 18/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">3s</span> 5ms/step - loss: -3.2409 - loss/inference_loss: -3.2409 - val_loss: -2.9640 - val_loss/inference_loss: -2.9640
Epoch 19/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.2689 - loss/inference_loss: -3.2689 - val_loss: -2.7462 - val_loss/inference_loss: -2.7462
Epoch 20/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.2759 - loss/inference_loss: -3.2759 - val_loss: -2.9262 - val_loss/inference_loss: -2.9262
Epoch 21/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">3s</span> 5ms/step - loss: -3.3185 - loss/inference_loss: -3.3185 - val_loss: -2.1308 - val_loss/inference_loss: -2.1308
Epoch 22/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.3447 - loss/inference_loss: -3.3447 - val_loss: -2.6838 - val_loss/inference_loss: -2.6838
Epoch 23/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.3607 - loss/inference_loss: -3.3607 - val_loss: -3.4517 - val_loss/inference_loss: -3.4517
Epoch 24/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">3s</span> 5ms/step - loss: -3.3540 - loss/inference_loss: -3.3540 - val_loss: -3.0357 - val_loss/inference_loss: -3.0357
Epoch 25/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.3831 - loss/inference_loss: -3.3831 - val_loss: -3.3768 - val_loss/inference_loss: -3.3768
Epoch 26/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">3s</span> 5ms/step - loss: -3.4183 - loss/inference_loss: -3.4183 - val_loss: -3.1671 - val_loss/inference_loss: -3.1671
Epoch 27/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">3s</span> 5ms/step - loss: -3.4194 - loss/inference_loss: -3.4194 - val_loss: 9.2951 - val_loss/inference_loss: 9.2951
Epoch 28/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.3851 - loss/inference_loss: -3.3851 - val_loss: -2.9896 - val_loss/inference_loss: -2.9896
Epoch 29/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 5ms/step - loss: -3.4251 - loss/inference_loss: -3.4251 - val_loss: -3.3175 - val_loss/inference_loss: -3.3175
Epoch 30/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">3s</span> 5ms/step - loss: -3.4083 - loss/inference_loss: -3.4083 - val_loss: -3.2599 - val_loss/inference_loss: -3.2599
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">spline_flow_workflow</span><span class="o">.</span><span class="n">fit_offline</span><span class="p">(</span>
    <span class="n">training_data</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:bayesflow:Fitting on dataset instance of OfflineDataset.
INFO:bayesflow:Building on a test batch.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">21s</span> 11ms/step - loss: -1.0211 - loss/inference_loss: -1.0211 - val_loss: -1.5653 - val_loss/inference_loss: -1.5653
Epoch 2/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -2.2318 - loss/inference_loss: -2.2318 - val_loss: -2.4503 - val_loss/inference_loss: -2.4503
Epoch 3/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -2.5659 - loss/inference_loss: -2.5659 - val_loss: -2.6406 - val_loss/inference_loss: -2.6406
Epoch 4/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -2.7533 - loss/inference_loss: -2.7533 - val_loss: -2.6080 - val_loss/inference_loss: -2.6080
Epoch 5/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -2.8607 - loss/inference_loss: -2.8607 - val_loss: -2.8657 - val_loss/inference_loss: -2.8657
Epoch 6/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -2.9422 - loss/inference_loss: -2.9422 - val_loss: -2.3686 - val_loss/inference_loss: -2.3686
Epoch 7/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -2.9989 - loss/inference_loss: -2.9989 - val_loss: -2.9271 - val_loss/inference_loss: -2.9271
Epoch 8/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.0638 - loss/inference_loss: -3.0638 - val_loss: -3.0360 - val_loss/inference_loss: -3.0360
Epoch 9/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.0553 - loss/inference_loss: -3.0553 - val_loss: -3.2254 - val_loss/inference_loss: -3.2254
Epoch 10/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.1095 - loss/inference_loss: -3.1095 - val_loss: -3.0538 - val_loss/inference_loss: -3.0538
Epoch 11/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.2038 - loss/inference_loss: -3.2038 - val_loss: -3.1451 - val_loss/inference_loss: -3.1451
Epoch 12/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.2396 - loss/inference_loss: -3.2396 - val_loss: -3.2923 - val_loss/inference_loss: -3.2923
Epoch 13/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.2695 - loss/inference_loss: -3.2695 - val_loss: -2.7734 - val_loss/inference_loss: -2.7734
Epoch 14/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.2778 - loss/inference_loss: -3.2778 - val_loss: -3.3034 - val_loss/inference_loss: -3.3034
Epoch 15/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.3281 - loss/inference_loss: -3.3281 - val_loss: -2.5565 - val_loss/inference_loss: -2.5565
Epoch 16/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.3416 - loss/inference_loss: -3.3416 - val_loss: -3.1074 - val_loss/inference_loss: -3.1074
Epoch 17/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.3612 - loss/inference_loss: -3.3612 - val_loss: -3.4145 - val_loss/inference_loss: -3.4145
Epoch 18/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.3806 - loss/inference_loss: -3.3806 - val_loss: -3.3677 - val_loss/inference_loss: -3.3677
Epoch 19/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.4344 - loss/inference_loss: -3.4344 - val_loss: -2.7881 - val_loss/inference_loss: -2.7881
Epoch 20/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.4364 - loss/inference_loss: -3.4364 - val_loss: -3.2963 - val_loss/inference_loss: -3.2963
Epoch 21/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.4700 - loss/inference_loss: -3.4700 - val_loss: -2.8206 - val_loss/inference_loss: -2.8206
Epoch 22/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.4920 - loss/inference_loss: -3.4920 - val_loss: -3.0479 - val_loss/inference_loss: -3.0479
Epoch 23/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.5153 - loss/inference_loss: -3.5153 - val_loss: -3.0690 - val_loss/inference_loss: -3.0690
Epoch 24/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.5309 - loss/inference_loss: -3.5309 - val_loss: -2.9115 - val_loss/inference_loss: -2.9115
Epoch 25/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.5516 - loss/inference_loss: -3.5516 - val_loss: -3.0176 - val_loss/inference_loss: -3.0176
Epoch 26/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.5659 - loss/inference_loss: -3.5659 - val_loss: -3.0676 - val_loss/inference_loss: -3.0676
Epoch 27/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.5792 - loss/inference_loss: -3.5792 - val_loss: -3.3448 - val_loss/inference_loss: -3.3448
Epoch 28/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.5791 - loss/inference_loss: -3.5791 - val_loss: -3.1989 - val_loss/inference_loss: -3.1989
Epoch 29/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.5712 - loss/inference_loss: -3.5712 - val_loss: -3.0113 - val_loss/inference_loss: -3.0113
Epoch 30/30
<span class=" -Color -Color-Bold">512/512</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">4s</span> 8ms/step - loss: -3.4733 - loss/inference_loss: -3.4733 - val_loss: -3.4334 - val_loss/inference_loss: -3.4334
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="validation">
<h2><span class="section-number">2.7. </span>Validation<a class="headerlink" href="#validation" title="Link to this heading">#</a></h2>
<section id="two-moons-posterior">
<h3><span class="section-number">2.7.1. </span>Two Moons Posterior<a class="headerlink" href="#two-moons-posterior" title="Link to this heading">#</a></h3>
<p>The two moons posterior at point <span class="math notranslate nohighlight">\(x = (0, 0)\)</span> should resemble two crescent shapes. Below, we plot the corresponding posterior samples and posterior density.</p>
<p>These results suggest that these generative networks can approximate the true posterior well. You can achieve an even better fit if you use online training, more epochs, or better optimizer hyperparameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the number of posterior draws you want to get</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">3000</span>

<span class="c1"># Obtain samples from amortized posterior</span>
<span class="n">conditions</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)}</span>

<span class="c1"># Prepare figure</span>
<span class="n">f</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Obtain samples from the approximators (can also use the workflows&#39; methods)</span>
<span class="n">nets</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">flow_matching_workflow</span><span class="o">.</span><span class="n">approximator</span><span class="p">,</span> 
    <span class="n">consistency_model_workflow</span><span class="o">.</span><span class="n">approximator</span><span class="p">,</span>
    <span class="n">affine_flow_workflow</span><span class="o">.</span><span class="n">approximator</span><span class="p">,</span>
    <span class="n">spline_flow_workflow</span><span class="o">.</span><span class="n">approximator</span>
<span class="p">]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Flow Matching&quot;</span><span class="p">,</span> <span class="s2">&quot;Consistency Model&quot;</span><span class="p">,</span> <span class="s2">&quot;Affine Coupling Flow&quot;</span><span class="p">,</span> <span class="s2">&quot;Spline Coupling Flow&quot;</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;#153c7a&quot;</span><span class="p">,</span> <span class="s2">&quot;#7a1515&quot;</span><span class="p">,</span> <span class="s2">&quot;#157a2d&quot;</span><span class="p">,</span> <span class="s2">&quot;#7a6f15&quot;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">nets</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>

    <span class="c1"># Obtain samples</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">conditions</span><span class="o">=</span><span class="n">conditions</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)[</span><span class="s2">&quot;theta&quot;</span><span class="p">]</span>

    <span class="c1"># Plot samples</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s2">&quot;box&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_1$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_2$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">f</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/b2655f3e6364db7d606eacaa4dd45b75bbfb9a3f8420f93871b96a393b4b8f96.png" src="../_images/b2655f3e6364db7d606eacaa4dd45b75bbfb9a3f8420f93871b96a393b4b8f96.png" />
</div>
</div>
<p>The posterior looks as we have expected in this case. However, in general, we do not know how the posterior is supposed to look like for any specific dataset. As such, we need diagnostics that validate the correctness of the inferred posterior. One such diagnostic is simulation-based calibration(SBC), which we can apply for free due to amortization. For more details on SBC and diagnostic plots, see:</p>
<ol class="arabic simple">
<li><p>Talts, S., Betancourt, M., Simpson, D., Vehtari, A., &amp; Gelman, A. (2018). Validating Bayesian inference algorithms with simulation-based calibration. <em>arXiv preprint</em>.</p></li>
<li><p>Säilynoja, T., Bürkner, P. C., &amp; Vehtari, A. (2022). Graphical test for discrete uniformity and its applications in goodness-of-fit evaluation and multiple sample comparison. <em>Statistics and Computing</em>.</p></li>
<li><p>The practical SBC interpretation guide by Martin Modrák: https://hyunjimoon.github.io/SBC/articles/rank_visualizations.html</p></li>
</ol>
<p>Check out the next tutorial for a detailed walkthrough of the workflow’s functionality.</p>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Linear_Regression_Starter.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1. </span>Amortized Posterior Estimation for Linear Regression</p>
      </div>
    </a>
    <a class="right-next"
       href="SIR_Posterior_Estimation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Posterior Estimation for SIR-like Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulator">2.1. Simulator<a class="anchor" id="simulator"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adapter">2.2. Adapter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset">2.3. Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-neural-network-to-approximate-all-posteriors">2.4. Training a neural network to approximate all posteriors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-workflow">2.4.1. Basic Workflow</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training">2.4.2. Training</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swapping-inference-networks">2.5. Swapping Inference Networks <a class="anchor" id="swapping"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#consistency-models-background">2.5.1. Consistency Models: Background</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#consistency-models-specification">2.5.2. Consistency Models: Specification</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#consistency-training">2.5.3. Consistency Training</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#good-ol-coupling-flows">2.6. Good ‘ol Coupling Flows</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coupling-flow-training">2.6.1. Coupling Flow Training</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#validation">2.7. Validation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-moons-posterior">2.7.1. Two Moons Posterior</a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/bayesflow-org/bayesflow/edit/dev/docsrc/_examples/Two_Moons_Starter.ipynb">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2023-2025, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>