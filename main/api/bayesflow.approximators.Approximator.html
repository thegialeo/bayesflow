
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Approximator &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=8fec244e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api/bayesflow.approximators.Approximator';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = '/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="canonical" href="https://www.bayesflow.org/api/bayesflow.approximators.Approximator.html" />
    <link rel="icon" href="../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ContinuousApproximator" href="bayesflow.approximators.ContinuousApproximator.html" />
    <link rel="prev" title="approximators" href="bayesflow.approximators.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/bayesflow_hor.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <img src="../_static/bayesflow_hor_dark.png" class="logo__image only-dark pst-js-only" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../examples.html">
    Examples
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="bayesflow.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    About us
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Developer docs
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../examples.html">
    Examples
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="bayesflow.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    About us
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Developer docs
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.adapters.html">adapters</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="bayesflow.adapters.transforms.html">transforms</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.AsSet.html">AsSet</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.AsTimeSeries.html">AsTimeSeries</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Broadcast.html">Broadcast</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Concatenate.html">Concatenate</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Constrain.html">Constrain</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.ConvertDType.html">ConvertDType</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Drop.html">Drop</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.ElementwiseTransform.html">ElementwiseTransform</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.ExpandDims.html">ExpandDims</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.FilterTransform.html">FilterTransform</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Keep.html">Keep</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Log.html">Log</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.MapTransform.html">MapTransform</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.NumpyTransform.html">NumpyTransform</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.OneHot.html">OneHot</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Rename.html">Rename</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Scale.html">Scale</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.SerializableCustomTransform.html">SerializableCustomTransform</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Shift.html">Shift</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Sqrt.html">Sqrt</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Standardize.html">Standardize</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.ToArray.html">ToArray</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.adapters.transforms.Transform.html">Transform</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.adapters.Adapter.html">Adapter</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="bayesflow.approximators.html">approximators</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Approximator</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.approximators.ContinuousApproximator.html">ContinuousApproximator</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.approximators.ModelComparisonApproximator.html">ModelComparisonApproximator</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.approximators.PointApproximator.html">PointApproximator</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.datasets.html">datasets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.datasets.DiskDataset.html">DiskDataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.datasets.OfflineDataset.html">OfflineDataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.datasets.OnlineDataset.html">OnlineDataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.datasets.RoundsDataset.html">RoundsDataset</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.diagnostics.html">diagnostics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.calibration_ecdf.html">calibration_ecdf</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.calibration_ecdf_from_quantiles.html">calibration_ecdf_from_quantiles</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.calibration_error.html">calibration_error</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.calibration_histogram.html">calibration_histogram</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.loss.html">loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.mc_calibration.html">mc_calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.mc_confusion_matrix.html">mc_confusion_matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.mmd_hypothesis_test.html">mmd_hypothesis_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.pairs_posterior.html">pairs_posterior</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.pairs_samples.html">pairs_samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.posterior_contraction.html">posterior_contraction</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.recovery.html">recovery</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.recovery_from_estimates.html">recovery_from_estimates</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.root_mean_squared_error.html">root_mean_squared_error</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.diagnostics.z_score_contraction.html">z_score_contraction</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.distributions.html">distributions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.distributions.DiagonalNormal.html">DiagonalNormal</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.distributions.DiagonalStudentT.html">DiagonalStudentT</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.distributions.Distribution.html">Distribution</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.experimental.html">experimental</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.experimental.CIF.html">CIF</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.experimental.ContinuousTimeConsistencyModel.html">ContinuousTimeConsistencyModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.experimental.FreeFormFlow.html">FreeFormFlow</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.links.html">links</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.links.Ordered.html">Ordered</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.links.OrderedQuantiles.html">OrderedQuantiles</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.links.PositiveDefinite.html">PositiveDefinite</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.metrics.html">metrics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="bayesflow.metrics.functional.html">functional</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.metrics.functional.maximum_mean_discrepancy.html">maximum_mean_discrepancy</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.metrics.functional.root_mean_squared_error.html">root_mean_squared_error</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.metrics.MaximumMeanDiscrepancy.html">MaximumMeanDiscrepancy</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.metrics.RootMeanSquaredError.html">RootMeanSquaredError</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.networks.html">networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.ConsistencyModel.html">ConsistencyModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.CouplingFlow.html">CouplingFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.DeepSet.html">DeepSet</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.FlowMatching.html">FlowMatching</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.FusionTransformer.html">FusionTransformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.InferenceNetwork.html">InferenceNetwork</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.MLP.html">MLP</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.PointInferenceNetwork.html">PointInferenceNetwork</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.SetTransformer.html">SetTransformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.SummaryNetwork.html">SummaryNetwork</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.TimeSeriesNetwork.html">TimeSeriesNetwork</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.networks.TimeSeriesTransformer.html">TimeSeriesTransformer</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.scores.html">scores</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.scores.MeanScore.html">MeanScore</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.scores.MedianScore.html">MedianScore</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.scores.MultivariateNormalScore.html">MultivariateNormalScore</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.scores.NormedDifferenceScore.html">NormedDifferenceScore</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.scores.ParametricDistributionScore.html">ParametricDistributionScore</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.scores.QuantileScore.html">QuantileScore</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.scores.ScoringRule.html">ScoringRule</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.simulators.html">simulators</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.simulators.make_simulator.html">make_simulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.simulators.HierarchicalSimulator.html">HierarchicalSimulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.simulators.LambdaSimulator.html">LambdaSimulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.simulators.LotkaVolterra.html">LotkaVolterra</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.simulators.ModelComparisonSimulator.html">ModelComparisonSimulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.simulators.SIR.html">SIR</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.simulators.SequentialSimulator.html">SequentialSimulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.simulators.Simulator.html">Simulator</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.simulators.TwoMoons.html">TwoMoons</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="bayesflow.types.html">types</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.utils.html">utils</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="bayesflow.utils.keras_utils.html">keras_utils</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.keras_utils.inverse_shifted_softplus.html">inverse_shifted_softplus</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.keras_utils.inverse_softplus.html">inverse_softplus</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.keras_utils.shifted_softplus.html">shifted_softplus</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="bayesflow.utils.logging.html">logging</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.logging.critical.html">critical</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.logging.debug.html">debug</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.logging.error.html">error</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.logging.exception.html">exception</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.logging.info.html">info</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.logging.log.html">log</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.logging.warn_once.html">warn_once</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.logging.warning.html">warning</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="bayesflow.utils.numpy_utils.html">numpy_utils</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.numpy_utils.inverse_shifted_softplus.html">inverse_shifted_softplus</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.numpy_utils.inverse_sigmoid.html">inverse_sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.numpy_utils.inverse_softplus.html">inverse_softplus</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.numpy_utils.one_hot.html">one_hot</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.numpy_utils.shifted_softplus.html">shifted_softplus</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesflow.utils.numpy_utils.softplus.html">softplus</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.add_metric.html">add_metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.add_titles_and_labels.html">add_titles_and_labels</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.batched_call.html">batched_call</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.calibration_curve.html">calibration_curve</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.check_estimates_prior_shapes.html">check_estimates_prior_shapes</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.check_lengths_same.html">check_lengths_same</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.concatenate_valid.html">concatenate_valid</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.confusion_matrix.html">confusion_matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.convert_args.html">convert_args</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.convert_kwargs.html">convert_kwargs</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.deserialize_value_or_type.html">deserialize_value_or_type</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.detailed_loss_callback.html">detailed_loss_callback</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.devices.html">devices</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.expand.html">expand</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.expand_as.html">expand_as</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.expand_left.html">expand_left</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.expand_left_as.html">expand_left_as</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.expand_left_to.html">expand_left_to</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.expand_right.html">expand_right</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.expand_right_as.html">expand_right_as</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.expand_right_to.html">expand_right_to</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.expand_tile.html">expand_tile</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.expand_to.html">expand_to</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.fill_triangular_matrix.html">fill_triangular_matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.filter_kwargs.html">filter_kwargs</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.find_batch_size.html">find_batch_size</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.find_distribution.html">find_distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.find_inference_network.html">find_inference_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.find_memory_budget.html">find_memory_budget</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.find_network.html">find_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.find_permutation.html">find_permutation</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.find_pooling.html">find_pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.find_recurrent_net.html">find_recurrent_net</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.find_summary_network.html">find_summary_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.format_bytes.html">format_bytes</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.integrate.html">integrate</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.jacobian.html">jacobian</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.jacobian_trace.html">jacobian_trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.jvp.html">jvp</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.keras_kwargs.html">keras_kwargs</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.make_quadratic.html">make_quadratic</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.optimal_transport.html">optimal_transport</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.pad.html">pad</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.parse_bytes.html">parse_bytes</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.pickle_load.html">pickle_load</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.prepare_plot_data.html">prepare_plot_data</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.prettify_subplots.html">prettify_subplots</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.searchsorted.html">searchsorted</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.serialize_value_or_type.html">serialize_value_or_type</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.simultaneous_ecdf_bands.html">simultaneous_ecdf_bands</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.size_of.html">size_of</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.split_arrays.html">split_arrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.split_tensors.html">split_tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.squeeze_inner_estimates_dict.html">squeeze_inner_estimates_dict</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.stack_valid.html">stack_valid</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.tile_axis.html">tile_axis</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.tree_concatenate.html">tree_concatenate</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.tree_stack.html">tree_stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.vjp.html">vjp</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.utils.weighted_mean.html">weighted_mean</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.workflows.html">workflows</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bayesflow.workflows.BasicWorkflow.html">BasicWorkflow</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bayesflow.wrappers.html">wrappers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="bayesflow.wrappers.mamba.html">mamba</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="bayesflow.wrappers.mamba.mamba.html">mamba</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="bayesflow.wrappers.mamba.mamba.Mamba.html">Mamba</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="bayesflow.wrappers.mamba.mamba_block.html">mamba_block</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="bayesflow.wrappers.mamba.mamba_block.MambaBlock.html">MambaBlock</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="bayesflow.html" class="nav-link">API Reference</a></li>
    
    
    <li class="breadcrumb-item"><a href="bayesflow.approximators.html" class="nav-link">approximators</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Approximator</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="approximator">
<h1>Approximator<a class="headerlink" href="#approximator" title="Link to this heading">#</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bayesflow.approximators.</span></span><span class="sig-name descname"><span class="pre">Approximator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bayesflow/approximators/approximator.html#Approximator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayesflow.approximators.Approximator" title="Link to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BackendApproximator</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span></span><a class="reference internal" href="../_modules/bayesflow/approximators/approximator.html#Approximator.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayesflow.approximators.Approximator.build" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.build_adapter">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build_adapter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="bayesflow.adapters.Adapter.html#bayesflow.adapters.Adapter" title="bayesflow.adapters.adapter.Adapter"><span class="pre">Adapter</span></a></span></span><a class="reference internal" href="../_modules/bayesflow/approximators/approximator.html#Approximator.build_adapter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayesflow.approximators.Approximator.build_adapter" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.build_from_data">
<span class="sig-name descname"><span class="pre">build_from_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping" title="(in Python v3.13)"><span class="pre">Mapping</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span></span><a class="reference internal" href="../_modules/bayesflow/approximators/approximator.html#Approximator.build_from_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayesflow.approximators.Approximator.build_from_data" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.build_dataset">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_batches</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">adapter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="bayesflow.adapters.Adapter.html#bayesflow.adapters.Adapter" title="bayesflow.adapters.adapter.Adapter"><span class="pre">Adapter</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_budget</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">simulator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="bayesflow.simulators.Simulator.html#bayesflow.simulators.Simulator" title="bayesflow.simulators.simulator.Simulator"><span class="pre">Simulator</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">workers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_multiprocessing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_queue_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="bayesflow.datasets.OnlineDataset.html#bayesflow.datasets.OnlineDataset" title="bayesflow.datasets.online_dataset.OnlineDataset"><span class="pre">OnlineDataset</span></a></span></span><a class="reference internal" href="../_modules/bayesflow/approximators/approximator.html#Approximator.build_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayesflow.approximators.Approximator.build_dataset" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">PyDataset</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">simulator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="bayesflow.simulators.Simulator.html#bayesflow.simulators.Simulator" title="bayesflow.simulators.simulator.Simulator"><span class="pre">Simulator</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bayesflow/approximators/approximator.html#Approximator.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bayesflow.approximators.Approximator.fit" title="Link to this definition">#</a></dt>
<dd><p>Trains the approximator on the provided dataset or on-demand data generated from the given simulator.
If <cite>dataset</cite> is not provided, a dataset is built from the <cite>simulator</cite>.
If the model has not been built, it will be built using a batch from the dataset.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>dataset</strong><span class="classifier">keras.utils.PyDataset, optional</span></dt><dd><p>A dataset containing simulations for training. If provided, <cite>simulator</cite> must be None.</p>
</dd>
<dt><strong>simulator</strong><span class="classifier">Simulator, optional</span></dt><dd><p>A simulator used to generate a dataset. If provided, <cite>dataset</cite> must be None.</p>
</dd>
<dt><strong>**kwargs</strong></dt><dd><p>Additional keyword arguments passed to <cite>keras.Model.fit()</cite>, including (see also <cite>build_dataset</cite>):</p>
<dl class="simple">
<dt>batch_size<span class="classifier">int or None, default=’auto’</span></dt><dd><p>Number of samples per gradient update. Do not specify if <cite>dataset</cite> is provided as a
<cite>keras.utils.PyDataset</cite>, <cite>tf.data.Dataset</cite>, <cite>torch.utils.data.DataLoader</cite>, or a generator function.</p>
</dd>
<dt>epochs<span class="classifier">int, default=1</span></dt><dd><p>Number of epochs to train the model.</p>
</dd>
<dt>verbose<span class="classifier">{“auto”, 0, 1, 2}, default=”auto”</span></dt><dd><p>Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.</p>
</dd>
<dt>callbacks<span class="classifier">list of keras.callbacks.Callback, optional</span></dt><dd><p>List of callbacks to apply during training.</p>
</dd>
<dt>validation_split<span class="classifier">float, optional</span></dt><dd><p>Fraction of training data to use for validation (only supported if <cite>dataset</cite> consists of NumPy arrays
or tensors).</p>
</dd>
<dt>validation_data<span class="classifier">tuple or dataset, optional</span></dt><dd><p>Data for validation, overriding <cite>validation_split</cite>.</p>
</dd>
<dt>shuffle<span class="classifier">bool, default=True</span></dt><dd><p>Whether to shuffle the training data before each epoch (ignored for dataset generators).</p>
</dd>
<dt>initial_epoch<span class="classifier">int, default=0</span></dt><dd><p>Epoch at which to start training (useful for resuming training).</p>
</dd>
<dt>steps_per_epoch<span class="classifier">int or None, optional</span></dt><dd><p>Number of steps (batches) before declaring an epoch finished.</p>
</dd>
<dt>validation_steps<span class="classifier">int or None, optional</span></dt><dd><p>Number of validation steps per validation epoch.</p>
</dd>
<dt>validation_batch_size<span class="classifier">int or None, optional</span></dt><dd><p>Number of samples per validation batch (defaults to <cite>batch_size</cite>).</p>
</dd>
<dt>validation_freq<span class="classifier">int, default=1</span></dt><dd><p>Specifies how many training epochs to run before performing validation.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>keras.callbacks.History</dt><dd><p>A history object containing the training loss and metrics values.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>ValueError</dt><dd><p>If both <cite>dataset</cite> and <cite>simulator</cite> are provided or neither is provided.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.__call__" title="Link to this definition">#</a></dt>
<dd><p>Call self as a function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.add_loss">
<span class="sig-name descname"><span class="pre">add_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.add_loss" title="Link to this definition">#</a></dt>
<dd><p>Can be called inside of the <cite>call()</cite> method to add a scalar loss.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MyLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.add_metric">
<span class="sig-name descname"><span class="pre">add_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.add_metric" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.add_variable">
<span class="sig-name descname"><span class="pre">add_variable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">autocast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.add_variable" title="Link to this definition">#</a></dt>
<dd><p>Add a weight variable to the layer.</p>
<p>Alias of <cite>add_weight()</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.add_weight">
<span class="sig-name descname"><span class="pre">add_weight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">autocast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.add_weight" title="Link to this definition">#</a></dt>
<dd><p>Add a weight variable to the layer.</p>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>shape: Shape tuple for the variable. Must be fully-defined</dt><dd><p>(no <cite>None</cite> entries). Defaults to <cite>()</cite> (scalar) if unspecified.</p>
</dd>
<dt>initializer: Initializer object to use to populate the initial</dt><dd><p>variable value, or string name of a built-in initializer
(e.g. <cite>“random_normal”</cite>). If unspecified, defaults to
<cite>“glorot_uniform”</cite> for floating-point variables and to <cite>“zeros”</cite>
for all other types (e.g. int, bool).</p>
</dd>
<dt>dtype: Dtype of the variable to create, e.g. <cite>“float32”</cite>. If</dt><dd><p>unspecified, defaults to the layer’s variable dtype
(which itself defaults to <cite>“float32”</cite> if unspecified).</p>
</dd>
<dt>trainable: Boolean, whether the variable should be trainable via</dt><dd><p>backprop or whether its updates are managed manually. Defaults
to <cite>True</cite>.</p>
</dd>
<dt>autocast: Boolean, whether to autocast layers variables when</dt><dd><p>accessing them. Defaults to <cite>True</cite>.</p>
</dd>
<dt>regularizer: Regularizer object to call to apply penalty on the</dt><dd><p>weight. These penalties are summed into the loss function
during optimization. Defaults to <cite>None</cite>.</p>
</dd>
<dt>constraint: Contrainst object to call on the variable after any</dt><dd><p>optimizer update, or string name of a built-in constraint.
Defaults to <cite>None</cite>.</p>
</dd>
<dt>aggregation: Optional string, one of <cite>None</cite>, <cite>“none”</cite>, <cite>“mean”</cite>,</dt><dd><p><cite>“sum”</cite> or <cite>“only_first_replica”</cite>. Annotates the variable with
the type of multi-replica aggregation to be used for this
variable when writing custom data parallel training loops.
Defaults to <cite>“none”</cite>.</p>
</dd>
</dl>
<p>name: String name of the variable. Useful for debugging purposes.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.build_from_config">
<span class="sig-name descname"><span class="pre">build_from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.build_from_config" title="Link to this definition">#</a></dt>
<dd><p>Builds the layer’s states with the supplied config dict.</p>
<p>By default, this method calls the <cite>build(config[“input_shape”])</cite> method,
which creates weights based on the layer’s input shape in the supplied
config. If your config contains other information needed to load the
layer’s state, you should override this method.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>config: Dict containing the input shape associated with this layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.call" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rmsprop'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weighted_metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_eagerly</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">steps_per_execution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jit_compile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_scale_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.compile" title="Link to this definition">#</a></dt>
<dd><p>Configures the model for training.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">(),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">FalseNegatives</span><span class="p">(),</span>
    <span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>optimizer: String (name of optimizer) or optimizer instance. See</dt><dd><p><cite>keras.optimizers</cite>.</p>
</dd>
<dt>loss: Loss function. May be a string (name of loss function), or</dt><dd><p>a <cite>keras.losses.Loss</cite> instance. See <cite>keras.losses</cite>. A
loss function is any callable with the signature
<cite>loss = fn(y_true, y_pred)</cite>, where <cite>y_true</cite> are the ground truth
values, and <cite>y_pred</cite> are the model’s predictions.
<cite>y_true</cite> should have shape <cite>(batch_size, d0, .. dN)</cite>
(except in the case of sparse loss functions such as
sparse categorical crossentropy which expects integer arrays of
shape <cite>(batch_size, d0, .. dN-1)</cite>).
<cite>y_pred</cite> should have shape <cite>(batch_size, d0, .. dN)</cite>.
The loss function should return a float tensor.</p>
</dd>
<dt>loss_weights: Optional list or dictionary specifying scalar</dt><dd><p>coefficients (Python floats) to weight the loss contributions of
different model outputs. The loss value that will be minimized
by the model will then be the <em>weighted sum</em> of all individual
losses, weighted by the <cite>loss_weights</cite> coefficients.  If a list,
it is expected to have a 1:1 mapping to the model’s outputs. If
a dict, it is expected to map output names (strings) to scalar
coefficients.</p>
</dd>
<dt>metrics: List of metrics to be evaluated by the model during</dt><dd><p>training and testing. Each of this can be a string (name of a
built-in function), function or a <cite>keras.metrics.Metric</cite>
instance. See <cite>keras.metrics</cite>. Typically you will use
<cite>metrics=[‘accuracy’]</cite>. A function is any callable with the
signature <cite>result = fn(y_true, _pred)</cite>. To specify different
metrics for different outputs of a multi-output model, you could
also pass a dictionary, such as
<cite>metrics={‘a’:’accuracy’, ‘b’:[‘accuracy’, ‘mse’]}</cite>.
You can also pass a list to specify a metric or a list of
metrics for each output, such as
<cite>metrics=[[‘accuracy’], [‘accuracy’, ‘mse’]]</cite>
or <cite>metrics=[‘accuracy’, [‘accuracy’, ‘mse’]]</cite>. When you pass
the strings ‘accuracy’ or ‘acc’, we convert this to one of
<cite>keras.metrics.BinaryAccuracy</cite>,
<cite>keras.metrics.CategoricalAccuracy</cite>,
<cite>keras.metrics.SparseCategoricalAccuracy</cite> based on the
shapes of the targets and of the model output. A similar
conversion is done for the strings <cite>“crossentropy”</cite>
and <cite>“ce”</cite> as well.
The metrics passed here are evaluated without sample weighting;
if you would like sample weighting to apply, you can specify
your metrics via the <cite>weighted_metrics</cite> argument instead.</p>
</dd>
<dt>weighted_metrics: List of metrics to be evaluated and weighted by</dt><dd><p><cite>sample_weight</cite> or <cite>class_weight</cite> during training and testing.</p>
</dd>
<dt>run_eagerly: Bool. If <cite>True</cite>, this model’s forward pass</dt><dd><p>will never be compiled. It is recommended to leave this
as <cite>False</cite> when training (for best performance),
and to set it to <cite>True</cite> when debugging.</p>
</dd>
<dt>steps_per_execution: Int. The number of batches to run</dt><dd><p>during each a single compiled function call. Running multiple
batches inside a single compiled function call can
greatly improve performance on TPUs or small models with a large
Python overhead. At most, one full epoch will be run each
execution. If a number larger than the size of the epoch is
passed, the execution will be truncated to the size of the
epoch. Note that if <cite>steps_per_execution</cite> is set to <cite>N</cite>,
<cite>Callback.on_batch_begin</cite> and <cite>Callback.on_batch_end</cite> methods
will only be called every <cite>N</cite> batches (i.e. before/after
each compiled function execution).
Not supported with the PyTorch backend.</p>
</dd>
<dt>jit_compile: Bool or <cite>“auto”</cite>. Whether to use XLA compilation when</dt><dd><p>compiling a model. For <cite>jax</cite> and <cite>tensorflow</cite> backends,
<cite>jit_compile=”auto”</cite> enables XLA compilation if the model
supports it, and disabled otherwise.
For <cite>torch</cite> backend, <cite>“auto”</cite> will default to eager
execution and <cite>jit_compile=True</cite> will run with <cite>torch.compile</cite>
with the <cite>“inductor”</cite> backend.</p>
</dd>
<dt>auto_scale_loss: Bool. If <cite>True</cite> and the model dtype policy is</dt><dd><p><cite>“mixed_float16”</cite>, the passed optimizer will be automatically
wrapped in a <cite>LossScaleOptimizer</cite>, which will dynamically
scale the loss to prevent underflow.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.compile_from_config">
<span class="sig-name descname"><span class="pre">compile_from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.compile_from_config" title="Link to this definition">#</a></dt>
<dd><p>Compiles the model with the information given in config.</p>
<p>This method uses the information in the config (optimizer, loss,
metrics, etc.) to compile the model.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>config: Dict containing information for compiling the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.compute_dtype">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">compute_dtype</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.compute_dtype" title="Link to this definition">#</a></dt>
<dd><p>The dtype of the computations performed by the layer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.compute_loss">
<span class="sig-name descname"><span class="pre">compute_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.compute_loss" title="Link to this definition">#</a></dt>
<dd><p>Compute the total loss, validate it, and return it.</p>
<p>Subclasses can optionally override this method to provide custom loss
computation logic.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MyModel</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_tracker</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">ops</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_tracker</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reset_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_tracker</span><span class="o">.</span><span class="n">reset_state</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_tracker</span><span class="p">]</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_input&#39;</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">steps_per_execution</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Custom loss: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">loss_tracker</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="simple">
<dt>Args:</dt><dd><p>x: Input data.
y: Target data.
y_pred: Predictions returned by the model (output of <cite>model(x)</cite>)
sample_weight: Sample weights for weighting the loss function.
training: Whether we are training or evaluating the model.</p>
</dd>
<dt>Returns:</dt><dd><p>The total loss as a scalar tensor, or <cite>None</cite> if no loss results
(which is the case when called by <cite>Model.test_step</cite>).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.compute_loss_and_updates">
<span class="sig-name descname"><span class="pre">compute_loss_and_updates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainable_variables</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_trainable_variables</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_variables</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_variables</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.compute_loss_and_updates" title="Link to this definition">#</a></dt>
<dd><p>This method is stateless and is intended for use with jax.grad.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.compute_mask">
<span class="sig-name descname"><span class="pre">compute_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">previous_mask</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.compute_mask" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.compute_metrics">
<span class="sig-name descname"><span class="pre">compute_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><span class="pre">dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Array</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.compute_metrics" title="Link to this definition">#</a></dt>
<dd><p>Update metric states and collect all metrics to be returned.</p>
<p>Subclasses can optionally override this method to provide custom metric
updating and collection logic. Custom metrics are not passed in
<cite>compile()</cite>, they can be created in <cite>__init__</cite> or <cite>build</cite>. They are
automatically tracked and returned by <cite>self.metrics</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MyModel</span><span class="p">(</span><span class="n">Sequential</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_metric</span> <span class="o">=</span> <span class="n">MyMetric</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;custom_metric&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">):</span>
        <span class="c1"># This super call updates metrics from `compile` and returns</span>
        <span class="c1"># results for all metrics listed in `self.metrics`.</span>
        <span class="n">metric_results</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">compute_metrics</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

        <span class="c1"># `metric_results` contains the previous result for</span>
        <span class="c1"># `custom_metric`, this is where we update it.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
        <span class="n">metric_results</span><span class="p">[</span><span class="s1">&#39;custom_metric&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_metric</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">metric_results</span>
</pre></div>
</div>
<dl class="simple">
<dt>Args:</dt><dd><p>x: Input data.
y: Target data.
y_pred: Predictions returned by the model output of <cite>model.call(x)</cite>.
sample_weight: Sample weights for weighting the loss function.</p>
</dd>
<dt>Returns:</dt><dd><p>A <cite>dict</cite> containing values that will be passed to
<cite>keras.callbacks.CallbackList.on_train_batch_end()</cite>. Typically,
the values of the metrics listed in <cite>self.metrics</cite> are returned.
Example: <cite>{‘loss’: 0.2, ‘accuracy’: 0.7}</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.compute_output_shape">
<span class="sig-name descname"><span class="pre">compute_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.compute_output_shape" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.compute_output_spec">
<span class="sig-name descname"><span class="pre">compute_output_spec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.compute_output_spec" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.count_params">
<span class="sig-name descname"><span class="pre">count_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.count_params" title="Link to this definition">#</a></dt>
<dd><p>Count the total number of scalars composing the weights.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>An integer count.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.dtype">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.dtype" title="Link to this definition">#</a></dt>
<dd><p>Alias of <cite>layer.variable_dtype</cite>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.dtype_policy">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype_policy</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.dtype_policy" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.evaluate" title="Link to this definition">#</a></dt>
<dd><p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Computation is done in batches (see the <cite>batch_size</cite> arg.)</p>
<dl>
<dt>Args:</dt><dd><dl>
<dt>x: Input data. It can be:</dt><dd><ul class="simple">
<li><p>A NumPy array (or array-like), or a list of arrays</p></li>
</ul>
<p>(in case the model has multiple inputs).
- A backend-native tensor, or a list of tensors
(in case the model has multiple inputs).
- A dict mapping input names to the corresponding array/tensors,
if the model has named inputs.
- A <cite>keras.utils.PyDataset</cite> returning <cite>(inputs, targets)</cite> or
<cite>(inputs, targets, sample_weights)</cite>.
- A <cite>tf.data.Dataset</cite> yielding <cite>(inputs, targets)</cite> or
<cite>(inputs, targets, sample_weights)</cite>.
- A <cite>torch.utils.data.DataLoader</cite> yielding <cite>(inputs, targets)</cite>
or <cite>(inputs, targets, sample_weights)</cite>.
- A Python generator function yielding <cite>(inputs, targets)</cite> or
<cite>(inputs, targets, sample_weights)</cite>.</p>
</dd>
<dt>y: Target data. Like the input data <cite>x</cite>, it can be either NumPy</dt><dd><p>array(s) or backend-native tensor(s). If <cite>x</cite> is a
<cite>keras.utils.PyDataset</cite>, <cite>tf.data.Dataset</cite>,
<cite>torch.utils.data.DataLoader</cite> or a Python generator function,
<cite>y</cite> should not be specified since targets will be obtained from
<cite>x</cite>.</p>
</dd>
<dt>batch_size: Integer or <cite>None</cite>.</dt><dd><p>Number of samples per batch of computation.
If unspecified, <cite>batch_size</cite> will default to 32.
Do not specify the <cite>batch_size</cite> if your input data <cite>x</cite> is a
<cite>keras.utils.PyDataset</cite>, <cite>tf.data.Dataset</cite>,
<cite>torch.utils.data.DataLoader</cite> or Python generator function
since they generate batches.</p>
</dd>
<dt>verbose: <cite>“auto”</cite>, 0, 1, or 2. Verbosity mode.</dt><dd><p>0 = silent, 1 = progress bar, 2 = single line.
<cite>“auto”</cite> becomes 1 for most cases.
Note that the progress bar is not
particularly useful when logged to a file, so <cite>verbose=2</cite> is
recommended when not running interactively
(e.g. in a production environment). Defaults to <cite>“auto”</cite>.</p>
</dd>
<dt>sample_weight: Optional NumPy array or tensor of weights for</dt><dd><p>the training samples, used for weighting the loss function
(during training only). You can either pass a flat (1D)
NumPy array or tensor with the same length as the input samples
(1:1 mapping between weights and samples), or in the case of
temporal data, you can pass a 2D NumPy array or tensor with
shape <cite>(samples, sequence_length)</cite> to apply a different weight
to every timestep of every sample.
This argument is not supported when <cite>x</cite> is a
<cite>keras.utils.PyDataset</cite>, <cite>tf.data.Dataset</cite>,
<cite>torch.utils.data.DataLoader</cite> or Python generator function.
Instead, provide <cite>sample_weights</cite> as the third element of <cite>x</cite>.
Note that sample weighting does not apply to metrics specified
via the <cite>metrics</cite> argument in <cite>compile()</cite>. To apply sample
weighting to your metrics, you can specify them via the
<cite>weighted_metrics</cite> in <cite>compile()</cite> instead.</p>
</dd>
<dt>steps: Integer or <cite>None</cite>.</dt><dd><p>Total number of steps (batches of samples) to draw before
declaring the evaluation round finished. If <cite>steps</cite> is <cite>None</cite>,
it will run until <cite>x</cite> is exhausted. In the case of an infinitely
repeating dataset, it will run indefinitely.</p>
</dd>
<dt>callbacks: List of <cite>keras.callbacks.Callback</cite> instances.</dt><dd><p>List of callbacks to apply during evaluation.</p>
</dd>
<dt>return_dict: If <cite>True</cite>, loss and metric results are returned as a</dt><dd><p>dict, with each key being the name of the metric.
If <cite>False</cite>, they are returned as a list.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>Scalar test loss (if the model has a single output and no metrics)
or list of scalars (if the model has multiple outputs
and/or metrics). The attribute <cite>model.metrics_names</cite> will give you
the display labels for the scalar outputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.export">
<span class="sig-name descname"><span class="pre">export</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tf_saved_model'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_signature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.export" title="Link to this definition">#</a></dt>
<dd><p>Export the model as an artifact for inference.</p>
<dl>
<dt>Args:</dt><dd><dl>
<dt>filepath: <cite>str</cite> or <cite>pathlib.Path</cite> object. The path to save the</dt><dd><p>artifact.</p>
</dd>
<dt>format: <cite>str</cite>. The export format. Supported values:</dt><dd><p><cite>“tf_saved_model”</cite> and <cite>“onnx”</cite>.  Defaults to
<cite>“tf_saved_model”</cite>.</p>
</dd>
<dt>verbose: <cite>bool</cite>. Whether to print a message during export. Defaults</dt><dd><p>to <cite>None</cite>, which uses the default value set by different
backends and formats.</p>
</dd>
<dt>input_signature: Optional. Specifies the shape and dtype of the</dt><dd><p>model inputs. Can be a structure of <cite>keras.InputSpec</cite>,
<cite>tf.TensorSpec</cite>, <cite>backend.KerasTensor</cite>, or backend tensor. If
not provided, it will be automatically computed. Defaults to
<cite>None</cite>.</p>
</dd>
<dt><a href="#id1"><span class="problematic" id="id2">**</span></a>kwargs: Additional keyword arguments:</dt><dd><ul>
<li><dl>
<dt>Specific to the JAX backend and <cite>format=”tf_saved_model”</cite>:</dt><dd><ul>
<li><dl class="simple">
<dt><cite>is_static</cite>: Optional <cite>bool</cite>. Indicates whether <cite>fn</cite> is</dt><dd><p>static. Set to <cite>False</cite> if <cite>fn</cite> involves state updates
(e.g., RNG seeds and counters).</p>
</dd>
</dl>
</li>
<li><dl>
<dt><cite>jax2tf_kwargs</cite>: Optional <cite>dict</cite>. Arguments for</dt><dd><p><cite>jax2tf.convert</cite>. See the documentation for
[<cite>jax2tf.convert</cite>](</p>
<blockquote>
<div><p><a class="github reference external" href="https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md">google/jax</a>).</p>
</div></blockquote>
<p>If <cite>native_serialization</cite> and <cite>polymorphic_shapes</cite> are
not provided, they will be automatically computed.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p><strong>Note:</strong> This feature is currently supported only with TensorFlow, JAX
and Torch backends.</p>
<p><strong>Note:</strong> Be aware that the exported artifact may contain information
from the local file system when using <cite>format=”onnx”</cite>, <cite>verbose=True</cite>
and Torch backend.</p>
<p>Examples:</p>
<p>Here’s how to export a TensorFlow SavedModel for inference.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Export the model as a TensorFlow SavedModel artifact</span>
<span class="n">model</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s2">&quot;path/to/location&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;tf_saved_model&quot;</span><span class="p">)</span>

<span class="c1"># Load the artifact in a different process/environment</span>
<span class="n">reloaded_artifact</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;path/to/location&quot;</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">reloaded_artifact</span><span class="o">.</span><span class="n">serve</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</pre></div>
</div>
<p>Here’s how to export an ONNX for inference.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Export the model as a ONNX artifact</span>
<span class="n">model</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s2">&quot;path/to/location&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;onnx&quot;</span><span class="p">)</span>

<span class="c1"># Load the artifact in a different process/environment</span>
<span class="n">ort_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="s2">&quot;path/to/location&quot;</span><span class="p">)</span>
<span class="n">ort_inputs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">k</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ort_session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">(),</span> <span class="n">input_data</span><span class="p">)</span>
<span class="p">}</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">ort_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">ort_inputs</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.from_config">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.from_config" title="Link to this definition">#</a></dt>
<dd><p>Creates an operation from its config.</p>
<p>This method is the reverse of <cite>get_config</cite>, capable of instantiating the
same operation from the config dictionary.</p>
<p>Note: If you override this method, you might receive a serialized dtype
config, which is a <cite>dict</cite>. You can deserialize it as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s2">&quot;dtype&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;dtype&quot;</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="n">policy</span> <span class="o">=</span> <span class="n">dtype_policies</span><span class="o">.</span><span class="n">deserialize</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;dtype&quot;</span><span class="p">])</span>
</pre></div>
</div>
<dl class="simple">
<dt>Args:</dt><dd><p>config: A Python dictionary, typically the output of <cite>get_config</cite>.</p>
</dd>
<dt>Returns:</dt><dd><p>An operation instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.get_build_config">
<span class="sig-name descname"><span class="pre">get_build_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.get_build_config" title="Link to this definition">#</a></dt>
<dd><p>Returns a dictionary with the layer’s input shape.</p>
<p>This method returns a config dict that can be used by
<cite>build_from_config(config)</cite> to create all states (e.g. Variables and
Lookup tables) needed by the layer.</p>
<p>By default, the config only contains the input shape that the layer
was built with. If you’re writing a custom layer that creates state in
an unusual way, you should override this method to make sure this state
is already created when Keras attempts to load its value upon model
loading.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>A dict containing the input shape associated with the layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.get_compile_config">
<span class="sig-name descname"><span class="pre">get_compile_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.get_compile_config" title="Link to this definition">#</a></dt>
<dd><p>Returns a serialized config with information for compiling the model.</p>
<p>This method returns a config dictionary containing all the information
(optimizer, loss, metrics, etc.) with which the model was compiled.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>A dict containing information for compiling the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.get_config" title="Link to this definition">#</a></dt>
<dd><p>Returns the config of the object.</p>
<p>An object config is a Python dictionary (serializable)
containing the information needed to re-instantiate it.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.get_layer">
<span class="sig-name descname"><span class="pre">get_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.get_layer" title="Link to this definition">#</a></dt>
<dd><p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <cite>name</cite> and <cite>index</cite> are both provided, <cite>index</cite> will take precedence.
Indices are based on order of horizontal graph traversal (bottom-up).</p>
<dl class="simple">
<dt>Args:</dt><dd><p>name: String, name of layer.
index: Integer, index of layer.</p>
</dd>
<dt>Returns:</dt><dd><p>A layer instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.get_metrics_result">
<span class="sig-name descname"><span class="pre">get_metrics_result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.get_metrics_result" title="Link to this definition">#</a></dt>
<dd><p>Returns the model’s metrics values as a dict.</p>
<p>If any of the metric result is a dict (containing multiple metrics),
each of them gets added to the top level returned dict of this method.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>A <cite>dict</cite> containing values of the metrics listed in <cite>self.metrics</cite>.
Example: <cite>{‘loss’: 0.2, ‘accuracy’: 0.7}</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.get_state_tree">
<span class="sig-name descname"><span class="pre">get_state_tree</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'backend_tensor'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.get_state_tree" title="Link to this definition">#</a></dt>
<dd><p>Retrieves tree-like structure of model variables.</p>
<p>This method allows retrieval of different model variables (trainable,
non-trainable, optimizer, and metrics). The variables are returned in a
nested dictionary format, where the keys correspond to the variable
names and the values are the nested representations of the variables.</p>
<dl class="simple">
<dt>Returns:</dt><dd><dl class="simple">
<dt>dict: A dictionary containing the nested representations of the</dt><dd><p>requested variables. The keys are the variable names, and the
values are the corresponding nested dictionaries.</p>
</dd>
<dt>value_format: One of <cite>“backend_tensor”</cite>, <cite>“numpy_array”</cite>.</dt><dd><dl class="simple">
<dt>The kind of array to return as the leaves of the nested</dt><dd><p>state tree.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;my_input&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;my_dense&quot;</span><span class="p">),</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;my_sequential&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mae&quot;</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">]]))</span>
<span class="n">state_tree</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_state_tree</span><span class="p">()</span>
</pre></div>
</div>
<p>The <cite>state_tree</cite> dictionary returned looks like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">&#39;metrics_variables&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;count&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
            <span class="s1">&#39;total&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s1">&#39;mean_absolute_error&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;count&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
            <span class="s1">&#39;total&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="s1">&#39;trainable_variables&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;my_sequential&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;my_dense&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;bias&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
                <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="s1">&#39;non_trainable_variables&#39;</span><span class="p">:</span> <span class="p">{},</span>
    <span class="s1">&#39;optimizer_variables&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;adam&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;iteration&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
                <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
                <span class="s1">&#39;my_sequential_my_dense_bias_momentum&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
                <span class="s1">&#39;my_sequential_my_dense_bias_velocity&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
                <span class="s1">&#39;my_sequential_my_dense_kernel_momentum&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
                <span class="s1">&#39;my_sequential_my_dense_kernel_velocity&#39;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.get_weights">
<span class="sig-name descname"><span class="pre">get_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.get_weights" title="Link to this definition">#</a></dt>
<dd><p>Return the values of <cite>layer.weights</cite> as a list of NumPy arrays.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.input">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.input" title="Link to this definition">#</a></dt>
<dd><p>Retrieves the input tensor(s) of a symbolic operation.</p>
<p>Only returns the tensor(s) corresponding to the <em>first time</em>
the operation was called.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>Input tensor or list of input tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.input_dtype">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_dtype</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.input_dtype" title="Link to this definition">#</a></dt>
<dd><p>The dtype layer inputs should be converted to.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.input_spec">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">input_spec</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.input_spec" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.jax_state_sync">
<span class="sig-name descname"><span class="pre">jax_state_sync</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.jax_state_sync" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.jit_compile">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">jit_compile</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.jit_compile" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.layers">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">layers</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.layers" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.load_own_variables">
<span class="sig-name descname"><span class="pre">load_own_variables</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">store</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.load_own_variables" title="Link to this definition">#</a></dt>
<dd><p>Loads the state of the layer.</p>
<p>You can override this method to take full control of how the state of
the layer is loaded upon calling <cite>keras.models.load_model()</cite>.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>store: Dict from which the state of the model will be loaded.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.load_weights">
<span class="sig-name descname"><span class="pre">load_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_mismatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.load_weights" title="Link to this definition">#</a></dt>
<dd><p>Load weights from a file saved via <cite>save_weights()</cite>.</p>
<p>Weights are loaded based on the network’s
topology. This means the architecture should be the same as when the
weights were saved. Note that layers that don’t have weights are not
taken into account in the topological ordering, so adding or removing
layers is fine as long as they don’t have weights.</p>
<p><strong>Partial weight loading</strong></p>
<p>If you have modified your model, for instance by adding a new layer
(with weights) or by changing the shape of the weights of a layer,
you can choose to ignore errors and continue loading
by setting <cite>skip_mismatch=True</cite>. In this case any layer with
mismatching weights will be skipped. A warning will be displayed
for each skipped layer.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>filepath: String, path to the weights file to load.</dt><dd><p>It can either be a <cite>.weights.h5</cite> file
or a legacy <cite>.h5</cite> weights file.</p>
</dd>
<dt>skip_mismatch: Boolean, whether to skip loading of layers where</dt><dd><p>there is a mismatch in the number of weights, or a mismatch in
the shape of the weights.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.losses">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">losses</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.losses" title="Link to this definition">#</a></dt>
<dd><p>List of scalar losses from <cite>add_loss</cite>, regularizers and sublayers.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.make_predict_function">
<span class="sig-name descname"><span class="pre">make_predict_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">force</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.make_predict_function" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.make_test_function">
<span class="sig-name descname"><span class="pre">make_test_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">force</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.make_test_function" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.make_train_function">
<span class="sig-name descname"><span class="pre">make_train_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">force</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.make_train_function" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.metrics">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metrics</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.metrics" title="Link to this definition">#</a></dt>
<dd><p>List of all metrics.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.metrics_names">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metrics_names</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.metrics_names" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.metrics_variables">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metrics_variables</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.metrics_variables" title="Link to this definition">#</a></dt>
<dd><p>List of all metric variables.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.non_trainable_variables">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">non_trainable_variables</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.non_trainable_variables" title="Link to this definition">#</a></dt>
<dd><p>List of all non-trainable layer state.</p>
<p>This extends <cite>layer.non_trainable_weights</cite> to include all state used by
the layer including state for metrics and <a href="#id3"><span class="problematic" id="id4">`</span></a>SeedGenerator`s.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.non_trainable_weights">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">non_trainable_weights</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.non_trainable_weights" title="Link to this definition">#</a></dt>
<dd><p>List of all non-trainable weight variables of the layer.</p>
<p>These are the weights that should not be updated by the optimizer during
training. Unlike, <cite>layer.non_trainable_variables</cite> this excludes metric
state and random seeds.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.output">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.output" title="Link to this definition">#</a></dt>
<dd><p>Retrieves the output tensor(s) of a layer.</p>
<p>Only returns the tensor(s) corresponding to the <em>first time</em>
the operation was called.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>Output tensor or list of output tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.path">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">path</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.path" title="Link to this definition">#</a></dt>
<dd><p>The path of the layer.</p>
<p>If the layer has not been built yet, it will be <cite>None</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.predict" title="Link to this definition">#</a></dt>
<dd><p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches. This method is designed for batch
processing of large numbers of inputs. It is not intended for use inside
of loops that iterate over your data and process small numbers of inputs
at a time.</p>
<p>For small numbers of inputs that fit in one batch,
directly use <cite>__call__()</cite> for faster execution, e.g.,
<cite>model(x)</cite>, or <cite>model(x, training=False)</cite> if you have layers such as
<cite>BatchNormalization</cite> that behave differently during
inference.</p>
<p>Note: See [this FAQ entry](
<a class="reference external" href="https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call">https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call</a>)
for more details about the difference between <cite>Model</cite> methods
<cite>predict()</cite> and <cite>__call__()</cite>.</p>
<dl>
<dt>Args:</dt><dd><dl>
<dt>x: Input data. It can be:</dt><dd><ul class="simple">
<li><p>A NumPy array (or array-like), or a list of arrays</p></li>
</ul>
<p>(in case the model has multiple inputs).
- A backend-native tensor, or a list of tensors
(in case the model has multiple inputs).
- A dict mapping input names to the corresponding array/tensors,
if the model has named inputs.
- A <cite>keras.utils.PyDataset</cite>.
- A <cite>tf.data.Dataset</cite>.
- A <cite>torch.utils.data.DataLoader</cite>.
- A Python generator function.</p>
</dd>
<dt>batch_size: Integer or <cite>None</cite>.</dt><dd><p>Number of samples per batch of computation.
If unspecified, <cite>batch_size</cite> will default to 32.
Do not specify the <cite>batch_size</cite> if your input data <cite>x</cite> is a
<cite>keras.utils.PyDataset</cite>, <cite>tf.data.Dataset</cite>,
<cite>torch.utils.data.DataLoader</cite> or Python generator function
since they generate batches.</p>
</dd>
<dt>verbose: <cite>“auto”</cite>, 0, 1, or 2. Verbosity mode.</dt><dd><p>0 = silent, 1 = progress bar, 2 = single line.
<cite>“auto”</cite> becomes 1 for most cases. Note that the progress bar
is not particularly useful when logged to a file,
so <cite>verbose=2</cite> is recommended when not running interactively
(e.g. in a production environment). Defaults to <cite>“auto”</cite>.</p>
</dd>
<dt>steps: Total number of steps (batches of samples) to draw before</dt><dd><p>declaring the prediction round finished. If <cite>steps</cite> is <cite>None</cite>,
it will run until <cite>x</cite> is exhausted. In the case of an infinitely
repeating dataset, it will run indefinitely.</p>
</dd>
<dt>callbacks: List of <cite>keras.callbacks.Callback</cite> instances.</dt><dd><p>List of callbacks to apply during prediction.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>NumPy array(s) of predictions.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.predict_on_batch">
<span class="sig-name descname"><span class="pre">predict_on_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.predict_on_batch" title="Link to this definition">#</a></dt>
<dd><p>Returns predictions for a single batch of samples.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>x: Input data. It must be array-like.</p>
</dd>
<dt>Returns:</dt><dd><p>NumPy array(s) of predictions.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.predict_step">
<span class="sig-name descname"><span class="pre">predict_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.predict_step" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.quantization_mode">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">quantization_mode</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.quantization_mode" title="Link to this definition">#</a></dt>
<dd><p>The quantization mode of this layer, <cite>None</cite> if not quantized.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.quantize">
<span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.quantize" title="Link to this definition">#</a></dt>
<dd><p>Quantize the weights of the model.</p>
<p>Note that the model must be built first before calling this method.
<cite>quantize</cite> will recursively call <cite>quantize(mode)</cite> in all layers and
will be skipped if the layer doesn’t implement the function.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>mode: The mode of the quantization. Only ‘int8’ is supported at this</dt><dd><p>time.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.quantized_build">
<span class="sig-name descname"><span class="pre">quantized_build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.quantized_build" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.quantized_call">
<span class="sig-name descname"><span class="pre">quantized_call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.quantized_call" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.rematerialized_call">
<span class="sig-name descname"><span class="pre">rematerialized_call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_call</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.rematerialized_call" title="Link to this definition">#</a></dt>
<dd><p>Enable rematerialization dynamically for layer’s call method.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>layer_call: The original <cite>call</cite> method of a layer.</p>
</dd>
<dt>Returns:</dt><dd><p>Rematerialized layer’s <cite>call</cite> method.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.reset_metrics">
<span class="sig-name descname"><span class="pre">reset_metrics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.reset_metrics" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.run_eagerly">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">run_eagerly</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.run_eagerly" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zipped</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.save" title="Link to this definition">#</a></dt>
<dd><p>Saves a model as a <cite>.keras</cite> file.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>filepath: <cite>str</cite> or <cite>pathlib.Path</cite> object.</dt><dd><p>The path where to save the model. Must end in <cite>.keras</cite>
(unless saving the model as an unzipped directory
via <cite>zipped=False</cite>).</p>
</dd>
<dt>overwrite: Whether we should overwrite any existing model at</dt><dd><p>the target location, or instead ask the user via
an interactive prompt.</p>
</dd>
<dt>zipped: Whether to save the model as a zipped <cite>.keras</cite></dt><dd><p>archive (default when saving locally), or as an
unzipped directory (default when saving on the
Hugging Face Hub).</p>
</dd>
</dl>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(),</span>
    <span class="p">],</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;model.keras&quot;</span><span class="p">)</span>
<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">saving</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;model.keras&quot;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>Note that <cite>model.save()</cite> is an alias for <cite>keras.saving.save_model()</cite>.</p>
<p>The saved <cite>.keras</cite> file contains:</p>
<ul class="simple">
<li><p>The model’s configuration (architecture)</p></li>
<li><p>The model’s weights</p></li>
<li><p>The model’s optimizer’s state (if any)</p></li>
</ul>
<p>Thus models can be reinstantiated in the exact same state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.save_own_variables">
<span class="sig-name descname"><span class="pre">save_own_variables</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">store</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.save_own_variables" title="Link to this definition">#</a></dt>
<dd><p>Saves the state of the layer.</p>
<p>You can override this method to take full control of how the state of
the layer is saved upon calling <cite>model.save()</cite>.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>store: Dict where the state of the model will be saved.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.save_weights">
<span class="sig-name descname"><span class="pre">save_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.save_weights" title="Link to this definition">#</a></dt>
<dd><p>Saves all layer weights to a <cite>.weights.h5</cite> file.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>filepath: <cite>str</cite> or <cite>pathlib.Path</cite> object.</dt><dd><p>Path where to save the model. Must end in <cite>.weights.h5</cite>.</p>
</dd>
<dt>overwrite: Whether we should overwrite any existing model</dt><dd><p>at the target location, or instead ask the user
via an interactive prompt.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.set_state_tree">
<span class="sig-name descname"><span class="pre">set_state_tree</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_tree</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.set_state_tree" title="Link to this definition">#</a></dt>
<dd><p>Assigns values to variables of the model.</p>
<p>This method takes a dictionary of nested variable values, which
represents the state tree of the model, and assigns them to the
corresponding variables of the model. The dictionary keys represent the
variable names (e.g., <cite>‘trainable_variables’</cite>, <cite>‘optimizer_variables’</cite>),
and the values are nested dictionaries containing the variable
paths and their corresponding values.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>state_tree: A dictionary representing the state tree of the model.</dt><dd><p>The keys are the variable names, and the values are nested
dictionaries representing the variable paths and their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.set_weights">
<span class="sig-name descname"><span class="pre">set_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.set_weights" title="Link to this definition">#</a></dt>
<dd><p>Sets the values of <cite>layer.weights</cite> from a list of NumPy arrays.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.stateless_call">
<span class="sig-name descname"><span class="pre">stateless_call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainable_variables</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_trainable_variables</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_losses</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.stateless_call" title="Link to this definition">#</a></dt>
<dd><p>Call the layer without any side effects.</p>
<dl>
<dt>Args:</dt><dd><p>trainable_variables: List of trainable variables of the model.
non_trainable_variables: List of non-trainable variables of the</p>
<blockquote>
<div><p>model.</p>
</div></blockquote>
<p><a href="#id5"><span class="problematic" id="id6">*</span></a>args: Positional arguments to be passed to <cite>call()</cite>.
return_losses: If <cite>True</cite>, <cite>stateless_call()</cite> will return the list of</p>
<blockquote>
<div><p>losses created during <cite>call()</cite> as part of its return values.</p>
</div></blockquote>
<p><a href="#id7"><span class="problematic" id="id8">**</span></a>kwargs: Keyword arguments to be passed to <cite>call()</cite>.</p>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>A tuple. By default, returns <cite>(outputs, non_trainable_variables)</cite>.</dt><dd><p>If <cite>return_losses = True</cite>, then returns
<cite>(outputs, non_trainable_variables, losses)</cite>.</p>
</dd>
</dl>
</dd>
</dl>
<p>Note: <cite>non_trainable_variables</cite> include not only non-trainable weights
such as <cite>BatchNormalization</cite> statistics, but also RNG seed state
(if there are any random operations part of the layer, such as dropout),
and <cite>Metric</cite> state (if there are any metrics attached to the layer).
These are all elements of state of the layer.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">data</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">trainable_variables</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span>
<span class="n">non_trainable_variables</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">non_trainable_variables</span>
<span class="c1"># Call the model with zero side effects</span>
<span class="n">outputs</span><span class="p">,</span> <span class="n">non_trainable_variables</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">stateless_call</span><span class="p">(</span>
    <span class="n">trainable_variables</span><span class="p">,</span>
    <span class="n">non_trainable_variables</span><span class="p">,</span>
    <span class="n">data</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># Attach the updated state to the model</span>
<span class="c1"># (until you do this, the model is still in its pre-call state).</span>
<span class="k">for</span> <span class="n">ref_var</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">non_trainable_variables</span><span class="p">,</span> <span class="n">non_trainable_variables</span>
<span class="p">):</span>
    <span class="n">ref_var</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.stateless_compute_loss">
<span class="sig-name descname"><span class="pre">stateless_compute_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainable_variables</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_trainable_variables</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_variables</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.stateless_compute_loss" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.stateless_compute_metrics">
<span class="sig-name descname"><span class="pre">stateless_compute_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">trainable_variables:</span> <span class="pre">any,</span> <span class="pre">non_trainable_variables:</span> <span class="pre">any,</span> <span class="pre">metrics_variables:</span> <span class="pre">any,</span> <span class="pre">data:</span> <span class="pre">dict[str,</span> <span class="pre">any],</span> <span class="pre">stage:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'training')</span> <span class="pre">-&gt;</span> <span class="pre">(&lt;class</span> <span class="pre">'jax.Array'&gt;,</span> <span class="pre">&lt;class</span> <span class="pre">'tuple'&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.stateless_compute_metrics" title="Link to this definition">#</a></dt>
<dd><p>Things we do for jax:
1. Accept trainable variables as the first argument</p>
<blockquote>
<div><dl class="simple">
<dt>(can be at any position as indicated by the argnum parameter</dt><dd><p>in autograd, but needs to be an explicit arg)</p>
</dd>
</dl>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p>Accept, potentially modify, and return other state variables</p></li>
<li><p>Return just the loss tensor as the first value</p></li>
<li><p>Return all other values in a tuple as the second value</p></li>
</ol>
<p>This ensures:
1. The function is stateless
2. The function can be differentiated with jax autograd</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.stateless_test_step">
<span class="sig-name descname"><span class="pre">stateless_test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">state:</span> <span class="pre">tuple,</span> <span class="pre">data:</span> <span class="pre">dict[str,</span> <span class="pre">any])</span> <span class="pre">-&gt;</span> <span class="pre">(dict[str,</span> <span class="pre">jax.Array],</span> <span class="pre">&lt;class</span> <span class="pre">'tuple'&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.stateless_test_step" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.stateless_train_step">
<span class="sig-name descname"><span class="pre">stateless_train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">state:</span> <span class="pre">tuple,</span> <span class="pre">data:</span> <span class="pre">dict[str,</span> <span class="pre">any])</span> <span class="pre">-&gt;</span> <span class="pre">(dict[str,</span> <span class="pre">jax.Array],</span> <span class="pre">&lt;class</span> <span class="pre">'tuple'&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.stateless_train_step" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.summary">
<span class="sig-name descname"><span class="pre">summary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">line_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">positions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expand_nested</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_trainable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.summary" title="Link to this definition">#</a></dt>
<dd><p>Prints a string summary of the network.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>line_length: Total length of printed lines</dt><dd><p>(e.g. set this to adapt the display to different
terminal window sizes).</p>
</dd>
<dt>positions: Relative or absolute positions of log elements</dt><dd><p>in each line. If not provided, becomes
<cite>[0.3, 0.6, 0.70, 1.]</cite>. Defaults to <cite>None</cite>.</p>
</dd>
<dt>print_fn: Print function to use. By default, prints to <cite>stdout</cite>.</dt><dd><p>If <cite>stdout</cite> doesn’t work in your environment, change to <cite>print</cite>.
It will be called on each line of the summary.
You can set it to a custom function
in order to capture the string summary.</p>
</dd>
<dt>expand_nested: Whether to expand the nested models.</dt><dd><p>Defaults to <cite>False</cite>.</p>
</dd>
<dt>show_trainable: Whether to show if a layer is trainable.</dt><dd><p>Defaults to <cite>False</cite>.</p>
</dd>
<dt>layer_range: a list or tuple of 2 strings,</dt><dd><p>which is the starting layer name and ending layer name
(both inclusive) indicating the range of layers to be printed
in summary. It also accepts regex patterns instead of exact
names. In this case, the start predicate will be
the first element that matches <cite>layer_range[0]</cite>
and the end predicate will be the last element
that matches <cite>layer_range[1]</cite>.
By default <cite>None</cite> considers all layers of the model.</p>
</dd>
</dl>
</dd>
<dt>Raises:</dt><dd><p>ValueError: if <cite>summary()</cite> is called before the model is built.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.supports_masking">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_masking</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.supports_masking" title="Link to this definition">#</a></dt>
<dd><p>Whether this layer supports computing a mask using <cite>compute_mask</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.symbolic_call">
<span class="sig-name descname"><span class="pre">symbolic_call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.symbolic_call" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.test_on_batch">
<span class="sig-name descname"><span class="pre">test_on_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.test_on_batch" title="Link to this definition">#</a></dt>
<dd><p>Test the model on a single batch of samples.</p>
<dl>
<dt>Args:</dt><dd><p>x: Input data. Must be array-like.
y: Target data. Must be array-like.
sample_weight: Optional array of the same length as x, containing</p>
<blockquote>
<div><p>weights to apply to the model’s loss for each sample.
In the case of temporal data, you can pass a 2D array
with shape <cite>(samples, sequence_length)</cite>, to apply a different
weight to every timestep of every sample.</p>
</div></blockquote>
<dl class="simple">
<dt>return_dict: If <cite>True</cite>, loss and metric results are returned as a</dt><dd><p>dict, with each key being the name of the metric. If <cite>False</cite>,
they are returned as a list.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>A scalar loss value (when no metrics and <cite>return_dict=False</cite>),
a list of loss and metric values
(if there are metrics and <cite>return_dict=False</cite>), or a dict of
metric and loss values (if <cite>return_dict=True</cite>).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.test_step" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.to_json">
<span class="sig-name descname"><span class="pre">to_json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.to_json" title="Link to this definition">#</a></dt>
<dd><p>Returns a JSON string containing the network configuration.</p>
<p>To load a network from a JSON save file, use
<cite>keras.models.model_from_json(json_string, custom_objects={…})</cite>.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt><a href="#id9"><span class="problematic" id="id10">**</span></a>kwargs: Additional keyword arguments to be passed to</dt><dd><p><cite>json.dumps()</cite>.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>A JSON string.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.train_on_batch">
<span class="sig-name descname"><span class="pre">train_on_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.train_on_batch" title="Link to this definition">#</a></dt>
<dd><p>Runs a single gradient update on a single batch of data.</p>
<dl>
<dt>Args:</dt><dd><p>x: Input data. Must be array-like.
y: Target data. Must be array-like.
sample_weight: Optional array of the same length as x, containing</p>
<blockquote>
<div><p>weights to apply to the model’s loss for each sample.
In the case of temporal data, you can pass a 2D array
with shape <cite>(samples, sequence_length)</cite>, to apply a different
weight to every timestep of every sample.</p>
</div></blockquote>
<dl class="simple">
<dt>class_weight: Optional dictionary mapping class indices (integers)</dt><dd><p>to a weight (float) to apply to the model’s loss for the samples
from this class during training. This can be useful to tell the
model to “pay more attention” to samples from an
under-represented class. When <cite>class_weight</cite> is specified
and targets have a rank of 2 or greater, either <cite>y</cite> must
be one-hot encoded, or an explicit final dimension of 1
must be included for sparse class labels.</p>
</dd>
<dt>return_dict: If <cite>True</cite>, loss and metric results are returned as a</dt><dd><p>dict, with each key being the name of the metric. If <cite>False</cite>,
they are returned as a list.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>A scalar loss value (when no metrics and <cite>return_dict=False</cite>),
a list of loss and metric values
(if there are metrics and <cite>return_dict=False</cite>), or a dict of
metric and loss values (if <cite>return_dict=True</cite>).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.train_step">
<span class="sig-name descname"><span class="pre">train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesflow.approximators.Approximator.train_step" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.trainable">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">trainable</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.trainable" title="Link to this definition">#</a></dt>
<dd><p>Settable boolean, whether this layer should be trainable or not.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.trainable_variables">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">trainable_variables</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.trainable_variables" title="Link to this definition">#</a></dt>
<dd><p>List of all trainable layer state.</p>
<p>This is equivalent to <cite>layer.trainable_weights</cite>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.trainable_weights">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">trainable_weights</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.trainable_weights" title="Link to this definition">#</a></dt>
<dd><p>List of all trainable weight variables of the layer.</p>
<p>These are the weights that get updated by the optimizer during training.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.variable_dtype">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">variable_dtype</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.variable_dtype" title="Link to this definition">#</a></dt>
<dd><p>The dtype of the state (weights) of the layer.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.variables">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">variables</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.variables" title="Link to this definition">#</a></dt>
<dd><p>List of all layer state, including random seeds.</p>
<p>This extends <cite>layer.weights</cite> to include all state used by the layer
including <a href="#id11"><span class="problematic" id="id12">`</span></a>SeedGenerator`s.</p>
<p>Note that metrics variables are not included here, use
<cite>metrics_variables</cite> to visit all the metric variables.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="bayesflow.approximators.Approximator.weights">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">weights</span></span><a class="headerlink" href="#bayesflow.approximators.Approximator.weights" title="Link to this definition">#</a></dt>
<dd><p>List of all weight variables of the layer.</p>
<p>Unlike, <cite>layer.variables</cite> this excludes metric state and random seeds.</p>
</dd></dl>

</dd></dl>

</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="bayesflow.approximators.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">approximators</p>
      </div>
    </a>
    <a class="right-next"
       href="bayesflow.approximators.ContinuousApproximator.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">ContinuousApproximator</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator"><code class="docutils literal notranslate"><span class="pre">Approximator</span></code></a><ul class="nav section-nav flex-column visible">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.build"><code class="docutils literal notranslate"><span class="pre">build()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.build_adapter"><code class="docutils literal notranslate"><span class="pre">build_adapter()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.build_from_data"><code class="docutils literal notranslate"><span class="pre">build_from_data()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.build_dataset"><code class="docutils literal notranslate"><span class="pre">build_dataset()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.fit"><code class="docutils literal notranslate"><span class="pre">fit()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.__call__"><code class="docutils literal notranslate"><span class="pre">__call__()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.add_loss"><code class="docutils literal notranslate"><span class="pre">add_loss()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.add_metric"><code class="docutils literal notranslate"><span class="pre">add_metric()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.add_variable"><code class="docutils literal notranslate"><span class="pre">add_variable()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.add_weight"><code class="docutils literal notranslate"><span class="pre">add_weight()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.build_from_config"><code class="docutils literal notranslate"><span class="pre">build_from_config()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.call"><code class="docutils literal notranslate"><span class="pre">call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.compile"><code class="docutils literal notranslate"><span class="pre">compile()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.compile_from_config"><code class="docutils literal notranslate"><span class="pre">compile_from_config()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.compute_dtype"><code class="docutils literal notranslate"><span class="pre">compute_dtype</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.compute_loss"><code class="docutils literal notranslate"><span class="pre">compute_loss()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.compute_loss_and_updates"><code class="docutils literal notranslate"><span class="pre">compute_loss_and_updates()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.compute_mask"><code class="docutils literal notranslate"><span class="pre">compute_mask()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.compute_metrics"><code class="docutils literal notranslate"><span class="pre">compute_metrics()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.compute_output_shape"><code class="docutils literal notranslate"><span class="pre">compute_output_shape()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.compute_output_spec"><code class="docutils literal notranslate"><span class="pre">compute_output_spec()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.count_params"><code class="docutils literal notranslate"><span class="pre">count_params()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.dtype"><code class="docutils literal notranslate"><span class="pre">dtype</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.dtype_policy"><code class="docutils literal notranslate"><span class="pre">dtype_policy</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.evaluate"><code class="docutils literal notranslate"><span class="pre">evaluate()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.export"><code class="docutils literal notranslate"><span class="pre">export()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.from_config"><code class="docutils literal notranslate"><span class="pre">from_config()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.get_build_config"><code class="docutils literal notranslate"><span class="pre">get_build_config()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.get_compile_config"><code class="docutils literal notranslate"><span class="pre">get_compile_config()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.get_config"><code class="docutils literal notranslate"><span class="pre">get_config()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.get_layer"><code class="docutils literal notranslate"><span class="pre">get_layer()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.get_metrics_result"><code class="docutils literal notranslate"><span class="pre">get_metrics_result()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.get_state_tree"><code class="docutils literal notranslate"><span class="pre">get_state_tree()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.get_weights"><code class="docutils literal notranslate"><span class="pre">get_weights()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.input"><code class="docutils literal notranslate"><span class="pre">input</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.input_dtype"><code class="docutils literal notranslate"><span class="pre">input_dtype</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.input_spec"><code class="docutils literal notranslate"><span class="pre">input_spec</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.jax_state_sync"><code class="docutils literal notranslate"><span class="pre">jax_state_sync()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.jit_compile"><code class="docutils literal notranslate"><span class="pre">jit_compile</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.layers"><code class="docutils literal notranslate"><span class="pre">layers</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.load_own_variables"><code class="docutils literal notranslate"><span class="pre">load_own_variables()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.load_weights"><code class="docutils literal notranslate"><span class="pre">load_weights()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.losses"><code class="docutils literal notranslate"><span class="pre">losses</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.make_predict_function"><code class="docutils literal notranslate"><span class="pre">make_predict_function()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.make_test_function"><code class="docutils literal notranslate"><span class="pre">make_test_function()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.make_train_function"><code class="docutils literal notranslate"><span class="pre">make_train_function()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.metrics"><code class="docutils literal notranslate"><span class="pre">metrics</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.metrics_names"><code class="docutils literal notranslate"><span class="pre">metrics_names</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.metrics_variables"><code class="docutils literal notranslate"><span class="pre">metrics_variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.non_trainable_variables"><code class="docutils literal notranslate"><span class="pre">non_trainable_variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.non_trainable_weights"><code class="docutils literal notranslate"><span class="pre">non_trainable_weights</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.output"><code class="docutils literal notranslate"><span class="pre">output</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.path"><code class="docutils literal notranslate"><span class="pre">path</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.predict"><code class="docutils literal notranslate"><span class="pre">predict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.predict_on_batch"><code class="docutils literal notranslate"><span class="pre">predict_on_batch()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.predict_step"><code class="docutils literal notranslate"><span class="pre">predict_step()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.quantization_mode"><code class="docutils literal notranslate"><span class="pre">quantization_mode</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.quantize"><code class="docutils literal notranslate"><span class="pre">quantize()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.quantized_build"><code class="docutils literal notranslate"><span class="pre">quantized_build()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.quantized_call"><code class="docutils literal notranslate"><span class="pre">quantized_call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.rematerialized_call"><code class="docutils literal notranslate"><span class="pre">rematerialized_call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.reset_metrics"><code class="docutils literal notranslate"><span class="pre">reset_metrics()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.run_eagerly"><code class="docutils literal notranslate"><span class="pre">run_eagerly</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.save"><code class="docutils literal notranslate"><span class="pre">save()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.save_own_variables"><code class="docutils literal notranslate"><span class="pre">save_own_variables()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.save_weights"><code class="docutils literal notranslate"><span class="pre">save_weights()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.set_state_tree"><code class="docutils literal notranslate"><span class="pre">set_state_tree()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.set_weights"><code class="docutils literal notranslate"><span class="pre">set_weights()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.stateless_call"><code class="docutils literal notranslate"><span class="pre">stateless_call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.stateless_compute_loss"><code class="docutils literal notranslate"><span class="pre">stateless_compute_loss()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.stateless_compute_metrics"><code class="docutils literal notranslate"><span class="pre">stateless_compute_metrics()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.stateless_test_step"><code class="docutils literal notranslate"><span class="pre">stateless_test_step()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.stateless_train_step"><code class="docutils literal notranslate"><span class="pre">stateless_train_step()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.summary"><code class="docutils literal notranslate"><span class="pre">summary()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.supports_masking"><code class="docutils literal notranslate"><span class="pre">supports_masking</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.symbolic_call"><code class="docutils literal notranslate"><span class="pre">symbolic_call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.test_on_batch"><code class="docutils literal notranslate"><span class="pre">test_on_batch()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.test_step"><code class="docutils literal notranslate"><span class="pre">test_step()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.to_json"><code class="docutils literal notranslate"><span class="pre">to_json()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.train_on_batch"><code class="docutils literal notranslate"><span class="pre">train_on_batch()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.train_step"><code class="docutils literal notranslate"><span class="pre">train_step()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.trainable"><code class="docutils literal notranslate"><span class="pre">trainable</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.trainable_variables"><code class="docutils literal notranslate"><span class="pre">trainable_variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.trainable_weights"><code class="docutils literal notranslate"><span class="pre">trainable_weights</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.variable_dtype"><code class="docutils literal notranslate"><span class="pre">variable_dtype</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.variables"><code class="docutils literal notranslate"><span class="pre">variables</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesflow.approximators.Approximator.weights"><code class="docutils literal notranslate"><span class="pre">weights</span></code></a></li>
</ul>
</li>
</ul>



  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/bayesflow-org/bayesflow/edit/main/docsrc/source/api/bayesflow.approximators.Approximator.rst">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2023-2025, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>