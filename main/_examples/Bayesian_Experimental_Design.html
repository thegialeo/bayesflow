
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5. Bayesian Experimental Design (BED) with BayesFlow and PyTorch &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=8fec244e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_examples/Bayesian_Experimental_Design';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = '/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="canonical" href="https://www.bayesflow.org/_examples/Bayesian_Experimental_Design.html" />
    <link rel="icon" href="../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6. From ABC to BayesFlow" href="From_ABC_to_BayesFlow.html" />
    <link rel="prev" title="4. Posterior Estimation for SIR-like Models" href="SIR_Posterior_Estimation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/bayesflow_hor.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <img src="../_static/bayesflow_hor_dark.png" class="logo__image only-dark pst-js-only" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/bayesflow.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    About us
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Developer docs
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/bayesflow.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    About us
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Developer docs
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Linear_Regression_Starter.html">1. Bayesian Linear Regression Starter</a></li>
<li class="toctree-l1"><a class="reference internal" href="From_BayesFlow_1.1_to_2.0.html">2. Moving from BayesFlow v1.1 to v2.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="Two_Moons_Starter.html">3. Two Moons: Tackling Bimodal Posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="SIR_Posterior_Estimation.html">4. Posterior Estimation for SIR-like Models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5. Bayesian Experimental Design (BED) with BayesFlow and PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="From_ABC_to_BayesFlow.html">6. From ABC to BayesFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="One_Sample_TTest.html">7. Simple Model Comparison - One Sample T-Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lotka_Volterra_Point_Estimation_and_Expert_Stats.html">8. Rapid Iteration with Point Estimation - Lotka-Volterra Dynamics</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../examples.html" class="nav-link">Examples</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis"><span class="section-number">5. </span>Bayesian Experimental Design (BED) with BayesFlow and PyTorch</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="bayesian-experimental-design-bed-with-bayesflow-and-pytorch">
<h1><span class="section-number">5. </span>Bayesian Experimental Design (BED) with BayesFlow and PyTorch<a class="headerlink" href="#bayesian-experimental-design-bed-with-bayesflow-and-pytorch" title="Link to this heading">#</a></h1>
<p><em>Author: Desi R. Ivanova</em></p>
<p>How can we ensure that the data we collect will give us the most information about the system we are studying? This is where Bayesian experimental design (BED) comes into play.</p>
<p>BED is a principled framework that combines ideas from information theory and Bayesian modelling to systematically plan experiments that maximise information gain.
As with any Bayesian approach, BED allows us to explicitly incorporate prior knowledge and uncertainty into the process.
In this tutorial, we will:</p>
<ul class="simple">
<li><p>Introduce the core concepts in static (i.e. non-adaptive) BED</p></li>
<li><p>Show how to use low-level BayesFlow features to learn the optimal designs for a simple chemical reaction system</p></li>
<li><p>Demonstrate the multi-backend capabilities of BayesFlow</p></li>
<li><p>Use PyTorch components (model, optimisers, etc.) via Keras3 through BayesFlow</p></li>
<li><p>Use a normalizing flow from BayesFlow with a custom loss function that’s written in pure PyTorch</p></li>
</ul>
<p>This tutorial is aimed at intermediate / advanced users who want to create custom training loops and capitalize on the stable generative network implementations.</p>
<section id="short-intro-to-bed">
<h2><span class="section-number">5.1. </span>Short intro to BED<a class="headerlink" href="#short-intro-to-bed" title="Link to this heading">#</a></h2>
<p>(<em>For a longer, more comprehensive overview, please see [1] or [2], or <a class="reference external" href="https://desirivanova.com/post/boed-intro/">this blogpost</a> for a slightly longer introduction.</em>)</p>
<p>BED is a model-based approach to designing optimal experiments.
We start with a Bayesian model (or simulator) <span class="math notranslate nohighlight">\(p(\theta)\,p(y \mid \xi, \theta)\)</span> of the underlying process we’re interested in.
The model has parameters <span class="math notranslate nohighlight">\(\theta\)</span> with prior <span class="math notranslate nohighlight">\(p(\theta)\)</span>: these are the quantities we’d like to learn or infer.
The data model <span class="math notranslate nohighlight">\(p(y \mid \xi, \theta)\)</span> describes (or simulates) how the data <span class="math notranslate nohighlight">\(y\)</span> are generated given the parameters <span class="math notranslate nohighlight">\(\theta\)</span> and the design variables <span class="math notranslate nohighlight">\(\xi\)</span>.</p>
<p>The optimal design <span class="math notranslate nohighlight">\(\xi^*\)</span> is the one that maximises the expected information gain (EIG) about the parameters <span class="math notranslate nohighlight">\(\theta\)</span>.
The EIG is the expected reduction in Shannon entropy from the prior <span class="math notranslate nohighlight">\(p(\theta)\)</span> to the posterior <span class="math notranslate nohighlight">\(p(\theta \mid y, \xi)\)</span> that results from the experiment with design <span class="math notranslate nohighlight">\(\xi\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\text{EIG}_\theta(\xi) = H[p(\theta)] - \mathbb{E}_{p(y \mid \xi)} \big[ H[p(\theta \mid y, \xi)] \big] = I(\theta; y \mid \xi).
\]</div>
<p>The EIG is equivalent to the mutual information (MI) between the parameters and the outcomes for a given design.
With some Bayes rule gymnastics, we can write the EIG in the following equivalent forms:</p>
<div class="math notranslate nohighlight">
\[
\text{EIG}(\xi) = \mathbb{E}_{p(\theta, y \mid \xi)} \left[ \log \frac{p(\theta, y \mid \xi)}{p(\theta)p(y \mid \xi)} \right] =  \mathbb{E}_{p(\theta, y \mid \xi)} \left[ \log \frac{p(y \mid  \theta, \xi)}{p(y \mid \xi)} \right] = \mathbb{E}_{p(\theta, y \mid \xi)} \left[ \log \frac{p(\theta \mid y, \xi)}{p(\theta)} \right].
\]</div>
<p>In general, the EIG is difficult to estimate and optimise regardless of which form we pick: we either have to deal with an expectation of a non-linear function (<span class="math notranslate nohighlight">\(\log\)</span>) of the intractable marginal <span class="math notranslate nohighlight">\(p(y \mid \xi)\)</span>, or alternatively with an intractable posterior <span class="math notranslate nohighlight">\(p(\theta \mid y, \xi)\)</span>.</p>
<p>In this tutorial we are going to use the Barber-Agakov estimator [3, 4]—a popular variational lower bound on the mutual information:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\xi, q) :=  \mathbb{E}_{p(\theta, y \mid \xi)} \left[ \log \frac{q(\theta \mid y, \xi)}{p(\theta)} \right] \leq I(\theta; y \mid \xi),
\]</div>
<p>where <span class="math notranslate nohighlight">\(q(\cdot)\)</span> is any distribution over the parameters <span class="math notranslate nohighlight">\(\theta\)</span>. The optimal <span class="math notranslate nohighlight">\(q(\cdot)\)</span>, which makes the bound tight, is the true posterior <span class="math notranslate nohighlight">\(p(\theta \mid y, \xi)\)</span>.</p>
<p>Notice that the prior <span class="math notranslate nohighlight">\(p(\theta)\)</span> is independent of the designs <span class="math notranslate nohighlight">\(\xi\)</span> and the variational distribution <span class="math notranslate nohighlight">\(q(\theta \mid y, \xi)\)</span>, so maximising the objective <span class="math notranslate nohighlight">\(\mathcal{L}(\xi, q)\)</span> is equivalent to minimising:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\xi, q) := -\mathbb{E}_{p(\theta, y \mid \xi)} \big[ \log q(\theta \mid y, \xi)\big],
\]</div>
<p>which is very similar to the standard cross-entropy objective we use to train our neural posterior estimators (NPEs)! The <strong>key difference</strong> is that we are now also optimising over the designs <span class="math notranslate nohighlight">\(\xi\)</span>, which also appear in the expectation. The cool thing is that we can use the <a class="reference external" href="https://en.wikipedia.org/wiki/Reparameterization_trick">reparameterisation trick</a> to optimise <span class="math notranslate nohighlight">\(\xi\)</span> jointly with the parameters of our neural posterior estimator <span class="math notranslate nohighlight">\(q(\cdot)\)</span>.</p>
<p>Let’s see how this works in practice!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">trange</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.lines</span><span class="w"> </span><span class="kn">import</span> <span class="n">Line2D</span>

<span class="c1"># ensure the backend is set</span>
<span class="k">if</span> <span class="s2">&quot;KERAS_BACKEND&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;KERAS_BACKEND&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;torch&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Size</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># for BayesFlow devs: this ensures that the latest dev version can be found</span>
<span class="c1"># this is not required if you have BayesFlow installed (e.g., via pip)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;../&quot;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">bayesflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">bf</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">cmdstanpy</span><span class="w"> </span><span class="kn">import</span> <span class="n">CmdStanModel</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>

<span class="c1"># disable the long printouts from stan.</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;cmdstanpy&quot;</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">NullHandler</span><span class="p">())</span>
<span class="n">logger</span><span class="o">.</span><span class="n">propagate</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">CRITICAL</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="michaelis-menten-kinetics">
<h2><span class="section-number">5.2. </span>Michaelis-Menten Kinetics<a class="headerlink" href="#michaelis-menten-kinetics" title="Link to this heading">#</a></h2>
<p>As an example, we are going to use the <a class="reference external" href="https://en.wikipedia.org/wiki/Michaelis%E2%80%93Menten_kinetics">Michaelis-Menten kinetics</a>, which is a model that describes the rate of enzyme-catalyzed reactions. The model has the following form:
$<span class="math notranslate nohighlight">\( f(\xi, \theta) = \frac{(L\xi)^s \theta_1}{(L\xi)^s + \theta_2^s} \)</span>$</p>
<p>We observe a noise-corrupted reaction rate <span class="math notranslate nohighlight">\(y\)</span>, where <span class="math notranslate nohighlight">\(p(y \mid \xi, \theta) = \mathcal{N}(y; f(\xi, \theta), \sigma_\epsilon)\)</span> and:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\xi\)</span> is the substrate concentration, this will be our design variable</p></li>
<li><p><span class="math notranslate nohighlight">\(\theta = (\theta_1, \theta_2)\)</span> are the model parameters, which we wish to infer from data. We assume a prior <span class="math notranslate nohighlight">\(p(\theta) = \mathcal{N}(\theta; [0.5, 0.5], \text{diag}(0.1^2))\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span> is a scaling factor for the substrate concentration (fixed to 400)</p></li>
<li><p><span class="math notranslate nohighlight">\(s\)</span> is a shape parameter (fixed to 4).</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_\epsilon\)</span> is the scale of the observation noise (fixed to 5).</p></li>
</ul>
<p>The code below implements the Michaelis-Menten kinetics model as a PyTorch module, along with some helper functions for plotting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MichaelisMenten</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">designs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">learn_designs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">s</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
        <span class="n">obs_noise</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MichaelisMenten</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;theta_mean&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;theta_covmat&quot;</span><span class="p">,</span> <span class="mf">0.1</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;obs_noise&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">obs_noise</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">s</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_theta_upper</span> <span class="o">=</span> <span class="mf">200.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_theta_lower</span> <span class="o">=</span> <span class="mf">20.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="mf">400.0</span>

        <span class="c1"># for the purpose of scaling y to be close to 0, as that will make learning the posterior networks easier</span>
        <span class="n">max_design</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="o">**</span><span class="n">s</span>
        <span class="n">min_design</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_mean_y</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">max_design</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_theta_upper</span> <span class="o">/</span> <span class="p">(</span><span class="n">max_design</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_theta_lower</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">min_design</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_theta_lower</span> <span class="o">/</span> <span class="p">(</span><span class="n">min_design</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_theta_upper</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learn_design</span> <span class="o">=</span> <span class="n">learn_designs</span>
        <span class="k">if</span> <span class="n">learn_designs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;designs&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">designs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;designs&quot;</span><span class="p">,</span> <span class="n">designs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">prior</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">dist</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span>
            <span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">theta_mean</span><span class="p">,</span> <span class="n">covariance_matrix</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">theta_covmat</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_design</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">designs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">designs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">designs</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">*</span> <span class="n">designs</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">outcome_likelihood</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">designs</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">dist</span><span class="o">.</span><span class="n">Distribution</span><span class="p">:</span>
        <span class="n">designs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">designs</span> <span class="k">if</span> <span class="n">designs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">designs</span>
        <span class="n">batch_dims</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># batch dims is [B] = B or (N, B)</span>
        <span class="c1"># scale the designs</span>
        <span class="n">designs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_design</span><span class="p">(</span><span class="n">designs</span><span class="p">)</span>  <span class="c1"># [D]</span>
        <span class="n">designs</span> <span class="o">=</span> <span class="n">designs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_dims</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [[B], D]</span>
        <span class="c1"># scale the param to ~[20, 200]</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">theta</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale_theta_upper</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_theta_lower</span><span class="p">)</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_theta_lower</span>
        <span class="p">)</span>
        <span class="c1"># theta is [[B], 2], x is [[B], D]</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">theta</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="n">designs</span> <span class="o">/</span> <span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">+</span> <span class="n">designs</span><span class="p">)</span>
        <span class="p">)</span>  <span class="c1"># [B, D]</span>
        <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span>
            <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">covariance_matrix</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">loc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">scale_y</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_mean_y</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">unscale_y</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_mean_y</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_mean_y</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_shape</span><span class="p">:</span> <span class="n">Size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="p">()</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">)</span>  <span class="c1"># [[B], 2]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outcome_likelihood</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">rsample</span><span class="p">()</span>  <span class="c1"># [[B], D]</span>
        <span class="c1"># passing scaled y to the posterior nets makes it easier to train</span>
        <span class="k">return</span> <span class="n">theta</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_y</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_shape</span><span class="p">:</span> <span class="n">Size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scaled_y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">scaled_y</span><span class="o">=</span><span class="n">scaled_y</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">run_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outcome_likelihood</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># [[B], D]</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_y</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">plot_realisations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">num_realisations</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_realisations</span><span class="p">))</span>

        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
        <span class="n">_xx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
        <span class="n">_xx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">_xx</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">_xx</span><span class="p">))</span>  <span class="c1"># inverse sigmoid</span>
        <span class="n">_mean_outcome</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outcome_likelihood</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span> <span class="n">designs</span><span class="o">=</span><span class="n">_xx</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">loc</span>

        <span class="c1"># line plot of mean_outcome vs _xx</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_realisations</span><span class="p">):</span>
            <span class="n">color</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">_xx</span><span class="p">),</span>
                <span class="n">_mean_outcome</span><span class="p">[</span><span class="n">b</span><span class="p">],</span>
                <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Realisation </span><span class="si">{</span><span class="n">b</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_policy</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">b</span><span class="p">])</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">designs</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Substrate concentration (design)&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Reaction rate (outcome)&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run_hmc_posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">num_chains</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">stan_model</span> <span class="o">=</span> <span class="n">CmdStanModel</span><span class="p">(</span><span class="n">stan_file</span><span class="o">=</span><span class="s2">&quot;misc/mm_gsn.stan&quot;</span><span class="p">)</span>
        <span class="n">hmc_posterior_samples</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">y_sample</span> <span class="ow">in</span> <span class="n">y</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;D&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">designs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y_sample</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
                <span class="s2">&quot;s&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">,</span>
                <span class="s2">&quot;designs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">designs</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
                <span class="s2">&quot;obs_noise&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs_noise</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="p">}</span>
            <span class="n">fit</span> <span class="o">=</span> <span class="n">stan_model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                <span class="n">inits</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="c1"># initialise at 0</span>
                <span class="n">chains</span><span class="o">=</span><span class="n">num_chains</span><span class="p">,</span>
                <span class="n">iter_sampling</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
                <span class="n">iter_warmup</span><span class="o">=</span><span class="n">num_samples</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span>
                <span class="n">show_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">max_treedepth</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                <span class="n">adapt_delta</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">hmc_thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span><span class="n">fit</span><span class="o">.</span><span class="n">stan_variable</span><span class="p">(</span><span class="s2">&quot;theta1&quot;</span><span class="p">),</span> <span class="n">fit</span><span class="o">.</span><span class="n">stan_variable</span><span class="p">(</span><span class="s2">&quot;theta2&quot;</span><span class="p">)],</span>
                <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">hmc_posterior_samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">hmc_thetas</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">hmc_posterior_samples</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># [num_samples, 2]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot_posterior_comparison</span><span class="p">(</span>
    <span class="n">amortised_posterior_samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">hmc_posterior_samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">true_theta</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">prior_samples</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="n">true_theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">if</span> <span class="n">bs</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="p">[</span><span class="n">axs</span><span class="p">]</span>

    <span class="c1"># Define plot settings</span>
    <span class="n">plot_settings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;prior&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Prior&quot;</span><span class="p">,</span> <span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="s2">&quot;zorder&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
        <span class="s2">&quot;amortised&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Amortised Posterior&quot;</span><span class="p">,</span>
            <span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span>
            <span class="s2">&quot;zorder&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;hmc&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;HMC Posterior&quot;</span><span class="p">,</span> <span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="s2">&quot;zorder&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
        <span class="s2">&quot;true&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;True parameter&quot;</span><span class="p">,</span> <span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;zorder&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">},</span>
    <span class="p">}</span>

    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;CouplingFlow NPE vs HMC&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">prior_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">prior_samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                <span class="n">prior_samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                <span class="n">c</span><span class="o">=</span><span class="n">plot_settings</span><span class="p">[</span><span class="s2">&quot;prior&quot;</span><span class="p">][</span><span class="s2">&quot;color&quot;</span><span class="p">],</span>
                <span class="n">label</span><span class="o">=</span><span class="n">plot_settings</span><span class="p">[</span><span class="s2">&quot;prior&quot;</span><span class="p">][</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">amortised_posterior_samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">amortised_posterior_samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="n">plot_settings</span><span class="p">[</span><span class="s2">&quot;amortised&quot;</span><span class="p">][</span><span class="s2">&quot;color&quot;</span><span class="p">],</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="n">plot_settings</span><span class="p">[</span><span class="s2">&quot;amortised&quot;</span><span class="p">][</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">hmc_posterior_samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">hmc_posterior_samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="n">plot_settings</span><span class="p">[</span><span class="s2">&quot;hmc&quot;</span><span class="p">][</span><span class="s2">&quot;color&quot;</span><span class="p">],</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="n">plot_settings</span><span class="p">[</span><span class="s2">&quot;hmc&quot;</span><span class="p">][</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">true_theta</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">true_theta</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">plot_settings</span><span class="p">[</span><span class="s2">&quot;true&quot;</span><span class="p">][</span><span class="s2">&quot;color&quot;</span><span class="p">],</span>
            <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="n">plot_settings</span><span class="p">[</span><span class="s2">&quot;true&quot;</span><span class="p">][</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_1$&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\theta_2$&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>  <span class="c1"># room for the legend</span>
    <span class="n">legend_elements</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">Line2D</span><span class="p">(</span>
            <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">color</span><span class="o">=</span><span class="n">settings</span><span class="p">[</span><span class="s2">&quot;color&quot;</span><span class="p">],</span>
            <span class="n">marker</span><span class="o">=</span><span class="n">settings</span><span class="p">[</span><span class="s2">&quot;marker&quot;</span><span class="p">],</span>
            <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;None&quot;</span><span class="p">,</span>
            <span class="n">markersize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="n">settings</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">settings</span> <span class="ow">in</span> <span class="n">plot_settings</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
    <span class="p">]</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="n">handles</span><span class="o">=</span><span class="n">legend_elements</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower center&quot;</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The reparameterisation trick can be handled automatically by PyTorch using the <code class="docutils literal notranslate"><span class="pre">rsample</span></code> method when sampling random variables affected by the parameters we are optimising over (in this case, the outcome <code class="docutils literal notranslate"><span class="pre">y</span></code>).</p>
<p>We will initialise <code class="docutils literal notranslate"><span class="pre">num_designs</span> <span class="pre">=</span> <span class="pre">7</span></code> designs randomly and plot the results of <code class="docutils literal notranslate"><span class="pre">num_test_sims</span> <span class="pre">=</span> <span class="pre">3</span></code> test simulations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">20240929</span><span class="p">)</span>
<span class="n">num_parameters</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># \theta = \theta_1, \theta_2 as described above</span>
<span class="n">num_designs</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">num_test_sims</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">train_batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">num_grad_steps</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">xi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_designs</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>

<span class="n">simulator</span> <span class="o">=</span> <span class="n">MichaelisMenten</span><span class="p">(</span><span class="n">designs</span><span class="o">=</span><span class="n">xi</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="n">learn_designs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">test_sims</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">batch_shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_test_sims</span><span class="p">,))</span>  <span class="c1"># type: ignore</span>
<span class="n">simulator</span><span class="o">.</span><span class="n">plot_realisations</span><span class="p">(</span><span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;theta&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f1c504cc6948a1c86f6937ae2c4b2adbb62d2dc60d8e640aa58c5e9dd61485fc.png" src="../_images/f1c504cc6948a1c86f6937ae2c4b2adbb62d2dc60d8e640aa58c5e9dd61485fc.png" />
</div>
</div>
<p>Let’s now set up and learn the NPE <span class="math notranslate nohighlight">\(q(\theta \mid y, \xi)\)</span>, keeping the designs fixed. We’ll use a normalising flow to model this posterior distribution. For an extended tutorial on NPE, checkout <a class="reference external" href="https://github.com/stefanradev93/BayesFlow/blob/dev/examples/TwoMoons_FlowMatching.ipynb">this notebook</a>.</p>
<p>Setting up and training amortised posteriors in BayesFlow is straightforward:</p>
<ol class="arabic simple">
<li><p>We’ll create a <code class="docutils literal notranslate"><span class="pre">CouplingFlow</span></code> network to parameterise our posterior.</p></li>
<li><p>We’ll <code class="docutils literal notranslate"><span class="pre">build</span></code> the network by specifying input shapes.</p></li>
<li><p>We’ll train the network using simulated data from our <code class="docutils literal notranslate"><span class="pre">MichaelisMenten</span></code> model defined above.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;***** Designs before training *****</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">simulator</span><span class="o">.</span><span class="n">designs</span><span class="p">),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
    <span class="n">posterior_net</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">CouplingFlow</span><span class="p">()</span>
    <span class="c1"># compile/build the torch model posterior_net</span>
    <span class="n">posterior_net</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
        <span class="n">xz_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_parameters</span><span class="p">),</span> <span class="n">conditions_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_designs</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># train the designs:</span>
    <span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">posterior_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">num_grad_steps</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training: loss =&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scaled_y</span> <span class="o">=</span> <span class="n">simulator</span><span class="p">(</span><span class="n">batch_shape</span><span class="o">=</span><span class="p">(</span><span class="n">train_batch_size</span><span class="p">,))</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="o">-</span><span class="n">posterior_net</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span>
            <span class="n">theta</span><span class="p">,</span>
            <span class="n">conditions</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">scaled_y</span><span class="p">,</span> <span class="n">simulator</span><span class="o">.</span><span class="n">designs</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">scaled_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">log_prob</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training: loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">***** Designs after training (unchanged) *****</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">simulator</span><span class="o">.</span><span class="n">designs</span><span class="p">))</span> <span class="c1"># unchanged</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Designs before training *****
 tensor([[0.4745, 0.4456, 0.5147, 0.5618, 0.4844, 0.4880, 0.5162]]) 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training: loss = -3.9650492668151855: 100%|██████████| 5000/5000 [02:41&lt;00:00, 30.92it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Designs after training (unchanged) *****
 tensor([[0.4745, 0.4456, 0.5147, 0.5618, 0.4844, 0.4880, 0.5162]])
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s evaluate how well our approximate posterior matches the ground truth. We’ll do this by:</p>
<ol class="arabic simple">
<li><p>Running Hamiltonian Monte Carlo (HMC) to obtain a high-quality posterior estimate.</p></li>
<li><p>Visually comparing our approximate posterior to the HMC results for our test simulations.</p></li>
</ol>
<p>This comparison will give us a quick, qualitative assessment of our learnt posterior.</p>
<p><strong>Note:</strong> While this visual inspection is useful, more rigorous and quantitative evaluation methods exist. We’ll explore these advanced techniques in a future blog post.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># sample from the amortised posterior</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">amortised_posterior_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">posterior_net</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">conditions</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">yy</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">simulator</span><span class="o">.</span><span class="n">designs</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">yy</span> <span class="ow">in</span> <span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;scaled_y&quot;</span><span class="p">]</span>
    <span class="p">],</span>
    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># sample from the hmc posterior: we pass the actual (unscaled) y</span>
<span class="n">hmc_posterior_samples</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">run_hmc_posterior</span><span class="p">(</span><span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">])</span>

<span class="n">plot_posterior_comparison</span><span class="p">(</span>
    <span class="n">amortised_posterior_samples</span><span class="p">,</span>
    <span class="n">hmc_posterior_samples</span><span class="p">,</span>
    <span class="n">true_theta</span><span class="o">=</span><span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;theta&quot;</span><span class="p">],</span>
    <span class="n">prior_samples</span><span class="o">=</span><span class="n">simulator</span><span class="o">.</span><span class="n">prior</span><span class="p">()</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">10000</span><span class="p">,)),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c3b8e8983eede893374c00c0e5824473ef4996fb9f0c832283d322d548b24b8f.png" src="../_images/c3b8e8983eede893374c00c0e5824473ef4996fb9f0c832283d322d548b24b8f.png" />
</div>
</div>
<p>The samples from our learnt posterior show excellent agreement with the ground truth.
However, these posteriors exhibit considerable uncertainty (wide distributions).</p>
<p>Can we reduce this uncertainty (i.e., decrease the entropy) in our parameter estimates by optimising our choice of experimental designs?</p>
<section id="learning-the-designs-along-with-the-normalising-flow-posterior">
<h3><span class="section-number">5.2.1. </span>Learning the designs along with the normalising flow posterior<a class="headerlink" href="#learning-the-designs-along-with-the-normalising-flow-posterior" title="Link to this heading">#</a></h3>
<p>We will use the same initial designs and the same architecture (<code class="docutils literal notranslate"><span class="pre">CouplingFlow</span></code>) for the NPE as before. The two changes we are making are:</p>
<ol class="arabic simple">
<li><p>Setting <code class="docutils literal notranslate"><span class="pre">learn_designs=True</span></code> when instantiating the <code class="docutils literal notranslate"><span class="pre">simulator</span></code>.</p></li>
<li><p>Passing the design parameters (<code class="docutils literal notranslate"><span class="pre">simulator.parameters()</span></code>) to the AdamW optimiser (<code class="docutils literal notranslate"><span class="pre">optim</span></code>).</p></li>
</ol>
<p>This approach allows us to simultaneously maximise the EIG (by optimising the experimental designs) and tighten the BA bound (by improving the approximate posterior).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">simulator</span> <span class="o">=</span> <span class="n">MichaelisMenten</span><span class="p">(</span><span class="n">designs</span><span class="o">=</span><span class="n">xi</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="n">learn_designs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;***** Designs before training *****</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">simulator</span><span class="o">.</span><span class="n">designs</span><span class="p">),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
    <span class="n">posterior_net_designs</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">CouplingFlow</span><span class="p">()</span>

    <span class="c1"># could try to attach the x-s too. so secnd would be (32, 7*2)</span>
    <span class="n">posterior_net_designs</span><span class="o">.</span><span class="n">build</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_parameters</span><span class="p">),</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_designs</span><span class="o">*</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1"># train the designs:</span>
    <span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
        <span class="nb">list</span><span class="p">(</span><span class="n">simulator</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">posterior_net_designs</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
        <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">num_grad_steps</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training: loss =&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scaled_y</span> <span class="o">=</span> <span class="n">simulator</span><span class="p">(</span><span class="n">batch_shape</span><span class="o">=</span><span class="p">(</span><span class="n">train_batch_size</span><span class="p">,))</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="o">-</span><span class="n">posterior_net_designs</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span>
            <span class="n">theta</span><span class="p">,</span> 
            <span class="n">conditions</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">scaled_y</span><span class="p">,</span> <span class="n">simulator</span><span class="o">.</span><span class="n">designs</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">scaled_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">log_prob</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training: loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">***** Designs after training *****</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">simulator</span><span class="o">.</span><span class="n">designs</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Designs before training *****
 tensor([[0.4745, 0.4456, 0.5147, 0.5618, 0.4844, 0.4880, 0.5162]]) 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training: loss = -5.109278678894043: 100%|██████████| 5000/5000 [02:42&lt;00:00, 30.70it/s] 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Designs after training *****
 tensor([[0.2885, 0.2667, 0.7111, 0.7969, 0.3647, 0.6234, 0.7139]])
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the final designs</span>
<span class="n">simulator</span><span class="o">.</span><span class="n">plot_realisations</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;theta&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c5f18c7ae84033188c67ad51b1e9b66d9562656d55b0d006150d574cc3603422.png" src="../_images/c5f18c7ae84033188c67ad51b1e9b66d9562656d55b0d006150d574cc3603422.png" />
</div>
</div>
<p>Let’s look at the resulting posteriors for the same set of test parameters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Obtain the outcomes under the learnt design</span>
<span class="n">designed_y</span><span class="p">,</span> <span class="n">designed_scaled_y</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">run_policy</span><span class="p">(</span><span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;theta&quot;</span><span class="p">])</span>

<span class="n">designed_amortised_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">posterior_net_designs</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="n">batch_shape</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> 
            <span class="n">conditions</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">yy</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">simulator</span><span class="o">.</span><span class="n">designs</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">yy</span> <span class="ow">in</span> <span class="n">designed_scaled_y</span>
    <span class="p">],</span>
    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">designed_hmc_samples</span> <span class="o">=</span> <span class="n">simulator</span><span class="o">.</span><span class="n">run_hmc_posterior</span><span class="p">(</span><span class="n">designed_y</span><span class="p">)</span>

<span class="n">plot_posterior_comparison</span><span class="p">(</span>
    <span class="n">amortised_posterior_samples</span><span class="o">=</span><span class="n">designed_amortised_samples</span><span class="p">,</span>
    <span class="n">hmc_posterior_samples</span><span class="o">=</span><span class="n">designed_hmc_samples</span><span class="p">,</span>
    <span class="n">true_theta</span><span class="o">=</span><span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;theta&quot;</span><span class="p">],</span>
    <span class="n">prior_samples</span><span class="o">=</span><span class="n">simulator</span><span class="o">.</span><span class="n">prior</span><span class="p">()</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">10000</span><span class="p">,)),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f2bf04f6bc34bd3f24934779e20d98496e7d259722c4545e91375d1db730f38c.png" src="../_images/f2bf04f6bc34bd3f24934779e20d98496e7d259722c4545e91375d1db730f38c.png" />
</div>
</div>
<p>As before, the amortised posteriors closely align with the ground truth.
The key improvement is that by learning optimal designs, we’ve achieved significantly more concentrated posteriors using the same amount of data! #gains 🚀 🎉</p>
<section id="references">
<h4><span class="section-number">5.2.1.1. </span>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h4>
<p>[1] Rainforth, T., Foster, A., Ivanova, D. R., &amp; Bickford Smith, F. (2024). Modern Bayesian experimental design. Statistical Science, 39(1), 100-114.</p>
<p>[2] Huan, X., Jagalur, J., &amp; Marzouk, Y. (2024). Optimal experimental design: Formulations and computations. Acta Numerica, 33, 715-840.</p>
<p>[3] Barber, D., &amp; Agakov, F. (2004). The im algorithm: a variational approach to information maximization. Advances in neural information processing systems, 16(320), 201.</p>
<p>[4] Foster, A., Jankowiak, M., O’Meara, M., Teh, Y. W., &amp; Rainforth, T. (2020, June). A unified stochastic gradient approach to designing bayesian-optimal experiments. In International Conference on Artificial Intelligence and Statistics (pp. 2959-2969). PMLR.</p>
</section>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="SIR_Posterior_Estimation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Posterior Estimation for SIR-like Models</p>
      </div>
    </a>
    <a class="right-next"
       href="From_ABC_to_BayesFlow.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6. </span>From ABC to BayesFlow</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#short-intro-to-bed">5.1. Short intro to BED</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#michaelis-menten-kinetics">5.2. Michaelis-Menten Kinetics</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-the-designs-along-with-the-normalising-flow-posterior">5.2.1. Learning the designs along with the normalising flow posterior</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#references">5.2.1.1. References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/bayesflow-org/bayesflow/edit/main/docsrc/source/_examples/Bayesian_Experimental_Design.ipynb">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2023-2025, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>